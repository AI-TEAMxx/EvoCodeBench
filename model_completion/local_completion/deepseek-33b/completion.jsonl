{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Running command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    import subprocess\n\n    print(f\"Executing command: {cmd}\")\n    process = subprocess.Popen(cmd, shell=True)\n    process.wait()\n    return process.returncode"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(\"Running command: {}\".format(cmd))\n    return os.system(cmd)"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    return os.system(cmd)\n\n"}
{"namespace": "chat.utils.run_cmd", "completion": "    print(f\"Executing command: {cmd}\")\n    exit_status = os.system(cmd)\n    return exit_status\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "skfolio.utils.stats.is_cholesky_dec", "completion": "    try:\n        np.linalg.cholesky(x)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 / (4 * jnp.sqrt(z_mag_sq) + 2 * jnp.sqrt(2 * z_mag_sq - 1) - 1))\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - 2 / jnp.sqrt(1 + 2 * z_mag_sq)) / z_mag_sq\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 / (2 * jnp.sqrt(z_mag_sq) - 1)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 / (2 * jnp.sqrt(z_mag_sq))) * (z_mag_sq - 1) / z_mag_sq\n  x = scale * z\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - jnp.sqrt(z_mag_sq)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Compute the magnitude of the input vector\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n\n  # Compute the scale factor using the inverse of the contract function\n  scale = (1 - jnp.sqrt(1 - z_mag_sq / 4)) / z_mag_sq\n\n  # Scale the input vector\n  x = scale * z\n\n  return x"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 / (2 * jnp.sqrt(z_mag_sq) - 1)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 / (2 * jnp.sqrt(z_mag_sq) - 1)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |z| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 / (2 * jnp.sqrt(z_mag_sq) - 1)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - jnp.sqrt(1 - 2 * z_mag_sq)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Compute the magnitude of the input vector\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n\n  # Compute the scaling factor\n  scale = (1 / (4 * jnp.sqrt(z_mag_sq))) * (3 * jnp.sqrt(z_mag_sq) + 1)\n\n  # Scale the input vector\n  x = scale * z\n\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 / (4 * jnp.sqrt(z_mag_sq) + 1) + 1) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Compute the magnitude of the input vector\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n\n  # Compute the scaling factor\n  scale = (1 - 0.5 * z_mag_sq) / z_mag_sq\n\n  # Scale the input vector\n  x = scale * z\n\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 / (2 * jnp.sqrt(z_mag_sq) - 1)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Clamping to 1 produces correct scale inside |x| < 1\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 / (2 * jnp.sqrt(z_mag_sq)))\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 / (2 * jnp.sqrt(x_mag_sq) - 1)) / x_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - jnp.sqrt(1 - z_mag_sq / 4)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 - jnp.sqrt(1 - z_mag_sq)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n  scale = (1 / (2 * jnp.sqrt(z_mag_sq) - 1)) / z_mag_sq\n  x = scale * z\n  return x\n\n"}
{"namespace": "coord.inv_contract", "completion": "  # Compute the magnitude of the input vector\n  z_mag_sq = jnp.maximum(1, jnp.sum(z**2, axis=-1, keepdims=True))\n\n  # Compute the scaling factor based on the magnitude of the input vector\n  scale = (1 - jnp.sqrt(1 - 0.5 * z_mag_sq)) / z_mag_sq\n\n  # Scale the input vector to obtain the output vector\n  x = scale * z\n\n  return x\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the table if it doesn't exist\n            c.execute(\n                \"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, kwargs TEXT, result TEXT)\"\n            )\n\n            # Check if the result is already in the database\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\",\n                (func_name, str(args), str(kwargs)),\n            )\n            result = c.fetchone()\n\n            if result is not None:\n                # If the result is in the database, return it\n                return json.loads(result[0])\n            else:\n                # If the result is not in the database, compute it and store it\n                result = func(*args, **kwargs)\n                c.execute(\n                    \"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\",\n                    (func_name, str(args), str(kwargs), json.dumps(result)),\n                )\n                conn.commit()\n                conn.close()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the cache table if it doesn't exist\n            c.execute(\n                \"\"\"CREATE TABLE IF NOT EXISTS cache (\n                    func_name TEXT,\n                    args TEXT,\n                    kwargs TEXT,\n                    result TEXT,\n                    PRIMARY KEY (func_name, args, kwargs)\n                )\"\"\"\n            )\n\n            # Serialize the arguments and keyword arguments\n            args_serialized = json.dumps(args)\n            kwargs_serialized = json.dumps(kwargs)\n\n            # Compute the hash of the arguments and keyword arguments\n            args_hash = hashlib.sha256(args_serialized.encode()).hexdigest()\n            kwargs_hash = hashlib.sha256(kwargs_serialized.encode()).hexdigest()\n\n            # Check if the result is already cached in the database\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\",\n                (func_name, args_hash, kwargs_hash),\n            )\n            result = c.fetchone()\n\n            if result:\n                # If the result is cached, retrieve it from the database\n                result = json.loads(result[0])\n            else:\n                # If the result is not cached, compute it and store it in the database\n                result = func(*args, **kwargs)\n                result_serialized = json.dumps(result)\n                c.execute(\n                    \"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\",\n                    (func_name, args_hash, kwargs_hash, result_serialized),\n                )\n                conn.commit()\n\n            # Close the database connection\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the cache table if it doesn't exist\n            c.execute(\n                \"\"\"CREATE TABLE IF NOT EXISTS cache (\n                    func_name TEXT,\n                    args TEXT,\n                    kwargs TEXT,\n                    result TEXT\n                )\"\"\"\n            )\n\n            # Check if the result is already cached\n            args_str = json.dumps(args)\n            kwargs_str = json.dumps(kwargs)\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name=? AND args=? AND kwargs=?\",\n                (func_name, args_str, kwargs_str),\n            )\n            result = c.fetchone()\n\n            if result is not None:\n                # Return the cached result\n                return json.loads(result[0])\n\n            # Compute the result\n            result = func(*args, **kwargs)\n\n            # Store the result in the cache\n            result_str = json.dumps(result)\n            c.execute(\n                \"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\",\n                (func_name, args_str, kwargs_str, result_str),\n            )\n            conn.commit()\n\n            # Close the database connection\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the table if it doesn't exist\n            c.execute(\n                \"\"\"CREATE TABLE IF NOT EXISTS cache\n                   (func_name TEXT, args TEXT, kwargs TEXT, result TEXT)\"\"\"\n            )\n\n            # Check if the result is already in the database\n            args_str = json.dumps(args)\n            kwargs_str = json.dumps(kwargs)\n            hash_input = f\"{func_name}{args_str}{kwargs_str}\".encode(\"utf-8\")\n            hash_output = hashlib.sha256(hash_input).hexdigest()\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name=? AND args=? AND kwargs=?\",\n                (func_name, args_str, kwargs_str),\n            )\n            result = c.fetchone()\n\n            if result is not None:\n                # Return the cached result\n                return json.loads(result[0])\n            else:\n                # Compute the result and store it in the database\n                result = func(*args, **kwargs)\n                result_str = json.dumps(result)\n                c.execute(\n                    \"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\",\n                    (func_name, args_str, kwargs_str, result_str),\n                )\n                conn.commit()\n                conn.close()\n                return result"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the cache table if it doesn't exist\n            c.execute(\"\"\"CREATE TABLE IF NOT EXISTS cache (\n                        func_name TEXT,\n                        args TEXT,\n                        kwargs TEXT,\n                        result TEXT\n                    )\"\"\")\n\n            # Generate a unique key for the function call\n            key = (func_name, json.dumps(args), json.dumps(kwargs))\n            key_hash = hashlib.sha256(str(key).encode('utf-8')).hexdigest()\n\n            # Check if the result is already cached in the database\n            c.execute(\"SELECT result FROM cache WHERE func_name=? AND args=? AND kwargs=?\", (func_name, json.dumps(args), json.dumps(kwargs)))\n            result = c.fetchone()\n\n            if result:\n                # If the result is already cached, return it\n                return json.loads(result[0])\n            else:\n                # If the result is not cached, compute it and store it in the database\n                result = func(*args, **kwargs)\n                c.execute(\"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\", (func_name, json.dumps(args), json.dumps(kwargs), json.dumps(result)))\n                conn.commit()\n                conn.close()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the cache table if it doesn't exist\n            c.execute('''CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, kwargs TEXT, result TEXT)''')\n\n            # Create a unique key for the function call\n            key = (func_name, str(args), str(kwargs))\n            key_hash = hashlib.sha256(str(key).encode()).hexdigest()\n\n            # Check if the result is already in the cache\n            c.execute('''SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?''', (func_name, str(args), str(kwargs)))\n            result = c.fetchone()\n\n            if result is not None:\n                # If the result is in the cache, return it\n                result = json.loads(result[0])\n            else:\n                # If the result is not in the cache, compute it and store it\n                result = func(*args, **kwargs)\n                c.execute('''INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)''', (func_name, str(args), str(kwargs), json.dumps(result)))\n                conn.commit()\n\n            # Close the database connection\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the cache table if it doesn't exist\n            c.execute('''CREATE TABLE IF NOT EXISTS cache\n                         (func_name text, args text, kwargs text, result text)''')\n\n            # Generate a unique key for the function call\n            key = (func_name, json.dumps(args), json.dumps(kwargs))\n            key_hash = hashlib.sha256(str(key).encode('utf-8')).hexdigest()\n\n            # Check if the result is already in the cache\n            c.execute(\"SELECT result FROM cache WHERE func_name=? AND args=? AND kwargs=?\", (func_name, json.dumps(args), json.dumps(kwargs)))\n            result = c.fetchone()\n\n            if result is not None:\n                # Return the cached result\n                return json.loads(result[0])\n            else:\n                # Compute the result\n                result = func(*args, **kwargs)\n\n                # Store the result in the cache\n                c.execute(\"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\", (func_name, json.dumps(args), json.dumps(kwargs), json.dumps(result)))\n                conn.commit()\n\n                # Return the result\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the cache table if it doesn't exist\n            c.execute(\n                \"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, kwargs TEXT, result BLOB)\"\n            )\n\n            # Hash the function arguments to use as a cache key\n            arg_hash = hashlib.sha256(\n                json.dumps((args, kwargs)).encode(\"utf-8\")\n            ).hexdigest()\n\n            # Check if the result is already in the cache\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\",\n                (func_name, arg_hash, json.dumps(kwargs)),\n            )\n            result = c.fetchone()\n\n            if result is not None:\n                # If the result is in the cache, return it\n                return pickle.loads(result[0])\n\n            # If the result is not in the cache, compute it and store it\n            result = func(*args, **kwargs)\n            c.execute(\n                \"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\",\n                (func_name, arg_hash, json.dumps(kwargs), pickle.dumps(result)),\n            )\n            conn.commit()\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the cache table if it doesn't exist\n            c.execute('''CREATE TABLE IF NOT EXISTS cache (func_name text, args text, kwargs text, result text)''')\n\n            # Hash the input arguments to create a unique key for the function call\n            key = hashlib.sha256()\n            key.update(func_name.encode('utf-8'))\n            key.update(json.dumps(args).encode('utf-8'))\n            key.update(json.dumps(kwargs).encode('utf-8'))\n            key = key.hexdigest()\n\n            # Check if the result is already in the cache\n            c.execute('''SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?''', (func_name, json.dumps(args), json.dumps(kwargs)))\n            result = c.fetchone()\n\n            if result is not None:\n                # If the result is in the cache, return it\n                return json.loads(result[0])\n            else:\n                # If the result is not in the cache, compute it and store it\n                result = func(*args, **kwargs)\n                c.execute('''INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)''', (func_name, json.dumps(args), json.dumps(kwargs), json.dumps(result)))\n                conn.commit()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create a table to store the function outputs if it doesn't exist\n            c.execute(\n                \"\"\"\n                CREATE TABLE IF NOT EXISTS cache (\n                    func_name TEXT,\n                    args TEXT,\n                    kwargs TEXT,\n                    result TEXT,\n                    PRIMARY KEY (func_name, args, kwargs)\n                )\n            \"\"\"\n            )\n\n            # Hash the function arguments to use as a cache key\n            args_hash = hashlib.sha256(\n                json.dumps(args, sort_keys=True).encode(\"utf-8\")\n            ).hexdigest()\n            kwargs_hash = hashlib.sha256(\n                json.dumps(kwargs, sort_keys=True).encode(\"utf-8\")\n            ).hexdigest()\n\n            # Check if the result is already in the cache\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\",\n                (func_name, args_hash, kwargs_hash),\n            )\n            result = c.fetchone()\n\n            if result is not None:\n                # If the result is in the cache, return it\n                return json.loads(result[0])\n\n            # If the result is not in the cache, compute it and store it in the cache\n            result = func(*args, **kwargs)\n            c.execute(\n                \"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\",\n                (func_name, args_hash, kwargs_hash, json.dumps(result)),\n            )\n            conn.commit()\n\n            # Close the database connection\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the table if it doesn't exist\n            c.execute(\n                \"\"\"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, kwargs TEXT, result TEXT)\"\"\"\n            )\n\n            # Convert the arguments and keyword arguments to a string representation\n            args_str = json.dumps(args)\n            kwargs_str = json.dumps(kwargs)\n\n            # Compute the hash of the arguments and keyword arguments\n            args_hash = hashlib.sha256(args_str.encode()).hexdigest()\n            kwargs_hash = hashlib.sha256(kwargs_str.encode()).hexdigest()\n\n            # Check if the result is already in the database\n            c.execute(\n                \"\"\"SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\"\"\",\n                (func_name, args_hash, kwargs_hash),\n            )\n            result = c.fetchone()\n\n            if result:\n                # If the result is in the database, retrieve it\n                result = json.loads(result[0])\n            else:\n                # If the result is not in the database, compute it and store it\n                result = func(*args, **kwargs)\n                c.execute(\n                    \"\"\"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\"\"\",\n                    (func_name, args_hash, kwargs_hash, json.dumps(result)),\n                )\n                conn.commit()\n\n            # Close the connection to the database\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create a table to store the function outputs if it doesn't exist\n            c.execute(\n                \"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, kwargs TEXT, result TEXT)\"\n            )\n\n            # Generate a unique key for the function call\n            key = hashlib.sha256(\n                (func_name + str(args) + str(kwargs)).encode(\"utf-8\")\n            ).hexdigest()\n\n            # Check if the result is already in the cache\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name=? AND args=? AND kwargs=?\",\n                (func_name, str(args), str(kwargs)),\n            )\n            result = c.fetchone()\n\n            if result:\n                # If the result is in the cache, retrieve it\n                result = json.loads(result[0])\n            else:\n                # If the result is not in the cache, compute it and store it\n                result = func(*args, **kwargs)\n                c.execute(\n                    \"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\",\n                    (func_name, str(args), str(kwargs), json.dumps(result)),\n                )\n                conn.commit()\n\n            # Close the database connection\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create a table to store the function outputs if it doesn't exist\n            c.execute(\n                \"\"\"CREATE TABLE IF NOT EXISTS cache (\n                    func_name TEXT,\n                    args TEXT,\n                    kwargs TEXT,\n                    result TEXT,\n                    UNIQUE(func_name, args, kwargs)\n                )\"\"\"\n            )\n\n            # Hash the function arguments to use as a key in the database\n            args_str = json.dumps(args)\n            kwargs_str = json.dumps(kwargs)\n            key = hashlib.sha256(\n                (func_name + args_str + kwargs_str).encode(\"utf-8\")\n            ).hexdigest()\n\n            # Check if the result is already in the database\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\",\n                (func_name, args_str, kwargs_str),\n            )\n            result = c.fetchone()\n\n            if result is None:\n                # Compute the result and store it in the database\n                result = func(*args, **kwargs)\n                result_str = json.dumps(result)\n                c.execute(\n                    \"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\",\n                    (func_name, args_str, kwargs_str, result_str),\n                )\n                conn.commit()\n            else:\n                # Retrieve the result from the database\n                result = json.loads(result[0])\n\n            # Close the database connection\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n            c.execute(\n                \"\"\"CREATE TABLE IF NOT EXISTS cache\n                            (func_name TEXT, args TEXT, kwargs TEXT, result TEXT)\"\"\"\n            )\n\n            # Check if the result is already in the cache\n            key = (func_name, str(args), str(kwargs))\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name=? AND args=? AND kwargs=?\", key\n            )\n            result = c.fetchone()\n\n            if result is not None:\n                # Return the cached result\n                return json.loads(result[0])\n\n            # Compute the result\n            result = func(*args, **kwargs)\n\n            # Store the result in the cache\n            c.execute(\n                \"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\",\n                (func_name, str(args), str(kwargs), json.dumps(result)),\n            )\n            conn.commit()\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create a table to store the function outputs if it doesn't exist\n            c.execute('''CREATE TABLE IF NOT EXISTS cache\n                         (func_name text, args text, kwargs text, result text)''')\n\n            # Check if the result is already in the cache\n            args_str = json.dumps(args)\n            kwargs_str = json.dumps(kwargs)\n            hash_str = hashlib.sha256((args_str + kwargs_str).encode('utf-8')).hexdigest()\n            c.execute('SELECT result FROM cache WHERE func_name=? AND args=? AND kwargs=?',\n                      (func_name, args_str, kwargs_str))\n            result = c.fetchone()\n\n            if result is not None:\n                # The result is already in the cache, return it\n                return json.loads(result[0])\n            else:\n                # The result is not in the cache, compute it and store it\n                result = func(*args, **kwargs)\n                result_str = json.dumps(result)\n                c.execute('INSERT INTO cache VALUES (?, ?, ?, ?)',\n                          (func_name, args_str, kwargs_str, result_str))\n                conn.commit()\n                conn.close()\n                return result\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the cache table if it doesn't exist\n            c.execute(\n                \"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, kwargs TEXT, result TEXT)\"\n            )\n\n            # Serialize the function arguments\n            args_str = json.dumps(args)\n            kwargs_str = json.dumps(kwargs)\n\n            # Generate a unique key for the function call\n            key = f\"{func_name}_{hashlib.sha256(args_str.encode() + kwargs_str.encode()).hexdigest()}\"\n\n            # Check if the result is already in the cache\n            c.execute(\"SELECT result FROM cache WHERE func_name=? AND args=? AND kwargs=?\", (func_name, args_str, kwargs_str))\n            result = c.fetchone()\n\n            if result:\n                # If the result is in the cache, return it\n                return json.loads(result[0])\n            else:\n                # If the result is not in the cache, compute it and store it in the cache\n                result = func(*args, **kwargs)\n                c.execute(\"INSERT INTO cache VALUES (?, ?, ?, ?)\", (func_name, args_str, kwargs_str, json.dumps(result)))\n                conn.commit()\n                conn.close()\n                return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            cursor = conn.cursor()\n\n            # Create a table to store the function outputs, if it doesn't exist\n            cursor.execute(\"CREATE TABLE IF NOT EXISTS cache (func_name TEXT, args TEXT, kwargs TEXT, result TEXT)\")\n\n            # Generate a unique key for the current function call\n            key = (func_name, str(args), str(kwargs))\n            key_hash = hashlib.sha256(str(key).encode()).hexdigest()\n\n            # Check if the result is already in the database\n            cursor.execute(\"SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\", (func_name, str(args), str(kwargs)))\n            result = cursor.fetchone()\n\n            if result is not None:\n                # If the result is in the database, retrieve it\n                result = json.loads(result[0])\n            else:\n                # If the result is not in the database, compute it and store it\n                result = func(*args, **kwargs)\n                cursor.execute(\"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\", (func_name, str(args), str(kwargs), json.dumps(result)))\n                conn.commit()\n\n            # Close the database connection\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Generate a unique key for the function call\n            key = f\"{func_name}-{hashlib.sha256(json.dumps((args, kwargs)).encode()).hexdigest()}\"\n\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create a table to store the function outputs if it doesn't exist\n            c.execute(\n                \"\"\"\n                CREATE TABLE IF NOT EXISTS cache (\n                    key TEXT PRIMARY KEY,\n                    value TEXT\n                )\n            \"\"\"\n            )\n\n            # Check if the result is already in the database\n            c.execute(\"SELECT value FROM cache WHERE key = ?\", (key,))\n            result = c.fetchone()\n\n            if result is not None:\n                # If the result is in the database, retrieve it\n                result = json.loads(result[0])\n            else:\n                # If the result is not in the database, compute it and store it\n                result = func(*args, **kwargs)\n                c.execute(\"INSERT INTO cache (key, value) VALUES (?, ?)\", (key, json.dumps(result)))\n                conn.commit()\n\n            # Close the database connection\n            conn.close()\n\n            # Return the result\n            return result\n\n        return wrapper\n\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the cache table if it doesn't exist\n            c.execute('''CREATE TABLE IF NOT EXISTS cache (func_name text, args text, kwargs text, result text)''')\n\n            # Serialize the arguments and keyword arguments to JSON strings\n            args_json = json.dumps(args)\n            kwargs_json = json.dumps(kwargs)\n\n            # Compute a hash of the function name, arguments, and keyword arguments\n            hash_input = f\"{func_name}{args_json}{kwargs_json}\".encode()\n            hash_output = hashlib.sha256(hash_input).hexdigest()\n\n            # Check if the result is already in the cache\n            c.execute(\"SELECT result FROM cache WHERE func_name=? AND args=? AND kwargs=?\", (func_name, args_json, kwargs_json))\n            result = c.fetchone()\n\n            if result is not None:\n                # If the result is in the cache, return it\n                return json.loads(result[0])\n            else:\n                # If the result is not in the cache, compute it and store it in the cache\n                result = func(*args, **kwargs)\n                result_json = json.dumps(result)\n                c.execute(\"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\", (func_name, args_json, kwargs_json, result_json))\n                conn.commit()\n                return result\n\n        return wrapper\n    return decorator"}
{"namespace": "memoize.memoize_to_sqlite", "completion": "    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Connect to the SQLite database\n            conn = sqlite3.connect(filename)\n            c = conn.cursor()\n\n            # Create the table if it doesn't exist\n            c.execute(\n                \"\"\"\n                CREATE TABLE IF NOT EXISTS cache (\n                    func_name TEXT,\n                    args TEXT,\n                    kwargs TEXT,\n                    result BLOB\n                )\n            \"\"\"\n            )\n\n            # Check if the result is already cached\n            c.execute(\n                \"SELECT result FROM cache WHERE func_name = ? AND args = ? AND kwargs = ?\",\n                (func_name, json.dumps(args), json.dumps(kwargs)),\n            )\n            result = c.fetchone()\n\n            if result:\n                # The result is already cached, return it\n                return json.loads(result[0])\n\n            # The result is not cached, compute it and cache it\n            result = func(*args, **kwargs)\n            c.execute(\n                \"INSERT INTO cache (func_name, args, kwargs, result) VALUES (?, ?, ?, ?)\",\n                (func_name, json.dumps(args), json.dumps(kwargs), json.dumps(result)),\n            )\n            conn.commit()\n\n            # Close the database connection\n            conn.close()\n\n            return result\n\n        return wrapper\n\n    return decorator\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received {values}\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received {values}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received {values}\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received {values}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received {values}\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received {values}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received {values}\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received {values}\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] > values[\"x_max\"] or values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: invalid bounding box. Got {values}\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Received {values}\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Received {values}\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max. Got x_min={values['x_min']} and x_max={values['x_max']}.\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max. Got y_min={values['y_min']} and y_max={values['y_max']}.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] > values[\"x_max\"] or values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: bounding box is invalid.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be smaller than x_max. Got x_min={values['x_min']} and x_max={values['x_max']}.\")\n\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be smaller than y_max. Got y_min={values['y_min']} and y_max={values['y_max']}.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: x_min must be less than x_max. Got x_min={values['x_min']}, x_max={values['x_max']}\"\n        )\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: y_min must be less than y_max. Got y_min={values['y_min']}, y_max={values['y_max']}\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    x_min, y_min, x_max, y_max = (\n        values[\"x_min\"],\n        values[\"y_min\"],\n        values[\"x_max\"],\n        values[\"y_max\"],\n    )\n\n    if x_min >= x_max:\n        raise ValueError(\n            f\"{cls.__name__}: x_min must be less than x_max. Received {x_min} and {x_max}.\"\n        )\n\n    if y_min >= y_max:\n        raise ValueError(\n            f\"{cls.__name__}: y_min must be less than y_max. Received {y_min} and {y_max}.\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"] or values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(\n            f\"{cls.__name__}: bounding box values must be in the form (x_min, x_max, y_min, y_max). Received {values}.\"\n        )\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] > values[\"x_max\"] or values[\"y_min\"] > values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: Invalid bounding box values. Min values cannot be greater than max values.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if values[\"x_min\"] >= values[\"x_max\"]:\n        raise ValueError(f\"{cls.__name__}: x_min must be less than x_max.\")\n    if values[\"y_min\"] >= values[\"y_max\"]:\n        raise ValueError(f\"{cls.__name__}: y_min must be less than y_max.\")\n\n    return values\n\n"}
{"namespace": "iris.io.validators.is_valid_bbox", "completion": "    if (values[\"x_min\"] > values[\"x_max\"]) or (values[\"y_min\"] > values[\"y_max\"]):\n        raise ValueError(\n            f\"{cls.__name__}: x_min, y_min must be smaller than x_max, y_max. Received {values}\"\n        )\n\n    return values\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the dot product between all pairs of columns in the matrices\n  dot_prod = np.dot(mat0.T, mat1)\n\n  # Compute the squared norm of each column in the matrices\n  sq_norm0 = np.sum(mat0 ** 2, axis=0)\n  sq_norm1 = np.sum(mat1 ** 2, axis=0)\n\n  # Compute the squared Euclidean distance between all pairs of columns\n  sq_dist = sq_norm0[:, np.newaxis] + sq_norm1[np.newaxis, :] - 2 * dot_prod\n\n  # Set negative distances to zero\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  mat0_norm = np.sum(mat0 ** 2, axis=0)\n  mat1_norm = np.sum(mat1 ** 2, axis=0)\n  dist = mat0_norm[:, None] + mat1_norm[None, :] - 2 * np.dot(mat0.T, mat1)\n  dist[dist < 0] = 0\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  return np.maximum(\n      np.sum(np.square(mat0), axis=0)[:, np.newaxis] +\n      np.sum(np.square(mat1), axis=0)[np.newaxis, :] - 2 * mat0.T @ mat1, 0)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  mat0_norm = np.sum(mat0 ** 2, axis=0)\n  mat1_norm = np.sum(mat1 ** 2, axis=0)\n  mat_dot = np.dot(mat0.T, mat1)\n  sq_dist = np.abs(mat0_norm[:, None] + mat1_norm[None, :] - 2 * mat_dot)\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the dot product of each column in `mat0` with each column in `mat1`.\n  dot_prod = mat0.T @ mat1\n\n  # Compute the squared norm of each column in `mat0` and `mat1`.\n  sq_norm0 = np.sum(mat0 ** 2, axis=0)\n  sq_norm1 = np.sum(mat1 ** 2, axis=0)\n\n  # Compute the squared Euclidean distance between each pair of columns in `mat0` and `mat1`.\n  sq_dist = sq_norm0[:, np.newaxis] + sq_norm1[np.newaxis, :] - 2 * dot_prod\n\n  # Set negative distances to zero.\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  return np.maximum(0,\n                    np.sum(mat0 ** 2, axis=0)[:, np.newaxis] +\n                    np.sum(mat1 ** 2, axis=0) - 2 * mat0.T @ mat1)\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  dist_mat = np.sum(mat0**2, axis=0)[:, np.newaxis] + np.sum(\n      mat1**2, axis=0)[np.newaxis, :] - 2 * mat0.T @ mat1\n  dist_mat[dist_mat < 0] = 0\n  return dist_mat\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norm0 = np.sum(mat0 ** 2, axis=0)\n  norm1 = np.sum(mat1 ** 2, axis=0)\n  dot = mat0.T.dot(mat1)\n  dist = np.abs(norm0[:, np.newaxis] + norm1[np.newaxis, :] - 2 * dot)\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  return np.maximum(\n      np.sum(mat0**2, axis=0) + np.sum(mat1**2, axis=0) - 2 * np.dot(mat0.T, mat1), 0\n  )\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  sq_norm0 = np.sum(mat0**2, axis=0)\n  sq_norm1 = np.sum(mat1**2, axis=0)\n  dot_prod = mat0.T.dot(mat1)\n  sq_dist = sq_norm0[:, None] - 2 * dot_prod + sq_norm1[None, :]\n  sq_dist[sq_dist < 0] = 0\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each column in both matrices\n  norms0 = np.sum(mat0 ** 2, axis=0)\n  norms1 = np.sum(mat1 ** 2, axis=0)\n\n  # Compute the dot products between all pairs of columns\n  dot_prods = mat0.T.dot(mat1)\n\n  # Compute the squared distances using the mathematical property\n  sq_dists = norms0[:, None] + norms1[None, :] - 2 * dot_prods\n\n  # Set negative distances to zero for numerical stability\n  sq_dists[sq_dists < 0] = 0\n\n  return sq_dists\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  dists = np.sum(mat0 ** 2, axis=0).reshape(1, -1) + np.sum(mat1 ** 2, axis=0) - 2 * mat0.T.dot(mat1)\n  dists[dists < 0] = 0\n  return dists\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  norm0 = np.sum(mat0**2, axis=0)\n  norm1 = np.sum(mat1**2, axis=0)\n  dot = np.dot(mat0.T, mat1)\n  dist = norm0[:, None] + norm1[None, :] - 2 * dot\n  dist[dist < 0] = 0\n  return dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  # Compute the squared norm of each column in mat0\n  sq_norm0 = np.sum(mat0 * mat0, axis=0)\n\n  # If mat1 is not provided, compute distances within mat0\n  if mat1 is None:\n    # Compute the squared norm of each column in mat0\n    sq_norm1 = sq_norm0\n\n    # Compute the dot product between all pairs of columns in mat0\n    dot_prod = mat0.T @ mat0\n\n  # If mat1 is provided, compute distances between mat0 and mat1\n  else:\n    # Compute the squared norm of each column in mat1\n    sq_norm1 = np.sum(mat1 * mat1, axis=0)\n\n    # Compute the dot product between all pairs of columns between mat0 and mat1\n    dot_prod = mat0.T @ mat1\n\n  # Compute the squared Euclidean distance using the mathematical property\n  sq_dist = sq_norm0[:, np.newaxis] + sq_norm1[np.newaxis, :] - 2 * dot_prod\n\n  # Set negative distances to zero\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  dist_mat = np.sum(np.square(mat0), axis=0, keepdims=True) + np.sum(\n      np.square(mat1), axis=0, keepdims=True).T - 2 * mat0.T @ mat1\n  dist_mat[dist_mat < 0] = 0\n  return dist_mat\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  sq_norm0 = np.sum(mat0**2, axis=0)\n  sq_norm1 = np.sum(mat1**2, axis=0)\n  inner_product = mat0.T @ mat1\n\n  sq_dist = sq_norm0[:, np.newaxis] + sq_norm1[np.newaxis, :] - 2 * inner_product\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n\n  # Compute the norms of each column in `mat0` and `mat1`\n  norm0 = np.sum(mat0 ** 2, axis=0)\n  norm1 = np.sum(mat1 ** 2, axis=0)\n\n  # Compute the dot product between all pairs of columns in `mat0` and `mat1`\n  dot = mat0.T @ mat1\n\n  # Compute the squared Euclidean distance matrix\n  sq_dist = norm0[:, None] + norm1[None, :] - 2 * dot\n\n  # Set negative distances to zero\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  dist_mat = np.sum(np.square(mat0), axis=0)[:, np.newaxis] + np.sum(\n      np.square(mat1), axis=0)[np.newaxis, :] - 2 * mat0.T.dot(mat1)\n  dist_mat[dist_mat < 0] = 0.0\n  return dist_mat\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  if mat1 is None:\n    mat1 = mat0\n  return np.maximum(0,\n                    np.sum(mat0 ** 2, axis=0)[:, None] + np.sum(mat1 ** 2, axis=0) -\n                    2 * mat0.T.dot(mat1))\n\n"}
{"namespace": "geopoly.compute_sq_dist", "completion": "  # Compute the dot product of all pairs of columns between the two matrices\n  dot_product = np.dot(mat0.T, mat1)\n\n  # Compute the squared norms of each column in the two matrices\n  norm_mat0 = np.sum(mat0 ** 2, axis=0)\n  norm_mat1 = np.sum(mat1 ** 2, axis=0)\n\n  # Compute the squared Euclidean distance matrix\n  sq_dist = norm_mat0[:, np.newaxis] - 2 * dot_product + norm_mat1[np.newaxis, :]\n\n  # Set negative distances to zero to handle numerical errors\n  sq_dist[sq_dist < 0] = 0\n\n  return sq_dist\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return False\n    if path.startswith(\"s3://\") or path.startswith(\"gs://\"):\n        return True\n    return False"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    if path == \"\":\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    if path.startswith(\"hdfs://\"):\n        return True\n    if path.startswith(\"http://\"):\n        return True\n    if path.startswith(\"https://\"):\n        return True\n    if path.startswith(\"azure://\"):\n        return True\n    if path.startswith(\"s3a://\"):\n        return True\n    if path.startswith(\"s3n://\"):\n        return True\n    if path.startswith(\"s3p://\"):\n        return True\n    if path.startswith(\"s3k://\"):\n        return True\n    if path.startswith(\"s3g://\"):\n        return True\n    if path.startswith(\"s3s://\"):\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"s3p://\"):\n        return True\n    if path.startswith(\"s3k://\"):\n        return True\n    if path.startswith(\"s3g://\"):\n        return True\n    if path.startswith(\"s3s://\"):\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"s3p://\"):\n        return True\n    if path.startswith(\"s3k://\"):\n        return True\n    if path.startswith(\"s3g://\"):\n        return True\n    if path.startswith(\"s3s://\"):\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"s3p://\"):\n        return True\n    if path.startswith(\"s3k://\"):\n        return True\n    if path.startswith(\"s3g://\""}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n\n    if path == \"\":\n        return True\n\n    if path.startswith(\"s3://\"):\n        return True\n\n    if path.startswith(\"gs://\"):\n        return True\n\n    if path.startswith(\"https://\"):\n        return True\n\n    if path.startswith(\"http://\"):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return False\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    if path.startswith(\"hdfs://\"):\n        return True\n    if path.startswith(\"http://\"):\n        return True\n    if path.startswith(\"https://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return False\n    if path.startswith(\"s3://\") or path.startswith(\"gs://\") or path.startswith(\"hdfs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return False\n    return path.startswith(\"s3://\") or path.startswith(\"gs://\") or path.startswith(\"https://\") or path.startswith(\"http://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    if path == \"\":\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return False\n    if path.startswith(\"s3://\") or path.startswith(\"gs://\") or path.startswith(\"hdfs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return False\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    if path.startswith(\"hdfs://\"):\n        return True\n    if path.startswith(\"http://\"):\n        return True\n    if path.startswith(\"https://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return False\n    if path.startswith(\"s3://\") or path.startswith(\"gs://\") or path.startswith(\"hdfs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    if path == \"\":\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    if path.startswith(\"hdfs://\"):\n        return True\n    if path.startswith(\"http://\"):\n        return True\n    if path.startswith(\"https://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return False\n\n    prefixes = [\n        \"s3://\",\n        \"gs://\",\n        \"wasbs://\",\n        \"azure://\",\n        \"hdfs://\",\n        \"http://\",\n        \"https://\",\n        \"ftp://\",\n        \"sftp://\",\n        \"ssh://\",\n        \"file://\",\n    ]\n\n    for prefix in prefixes:\n        if path.startswith(prefix):\n            return False\n\n    return True\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return False\n    if path.startswith(\"s3://\") or path.startswith(\"gs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    return path is None or path == \"\" or path.startswith(\"s3://\") or path.startswith(\"gs://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    if path == \"\":\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"hdfs://\"):\n        return True\n    if path.startswith(\"azure://\"):\n        return True\n    if path.startswith(\"abfs://\"):\n        return True\n    if path.startswith(\"adl://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return False\n    return (\n        path.startswith(\"s3://\")\n        or path.startswith(\"gs://\")\n        or path.startswith(\"hdfs://\")\n        or path.startswith(\"http://\")\n        or path.startswith(\"https://\")\n    )\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    if path == \"\":\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    if path.startswith(\"hdfs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None or path == \"\":\n        return False\n    return path.startswith(\"s3://\") or path.startswith(\"gs://\") or path.startswith(\"wasbs://\")\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n    if path == \"\":\n        return True\n    if path.startswith(\"s3://\"):\n        return True\n    if path.startswith(\"gs://\"):\n        return True\n    if path.startswith(\"hdfs://\"):\n        return True\n    return False\n\n"}
{"namespace": "litdata.streaming.dataset._should_replace_path", "completion": "    if path is None:\n        return True\n\n    if path == \"\":\n        return True\n\n    if path.startswith(\"s3://\"):\n        return True\n\n    if path.startswith(\"gs://\"):\n        return True\n\n    if path.startswith(\"http://\"):\n        return True\n\n    if path.startswith(\"https://\"):\n        return True\n\n    return False\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        items = np.array([items.get(name, fill_value) for name in assets_names])\n    elif isinstance(items, npt.ArrayLike):\n        items = np.array(items)\n    else:\n        raise TypeError(\n            f\"Expected type dict or array-like, got {type(items)} for {name}.\"\n        )\n\n    if dim == 1:\n        if items.shape != (n_assets,):\n            raise ValueError(\n                f\"Expected shape (n_assets,), got {items.shape} for {name}.\"\n            )\n    elif dim == 2:\n        if items.shape != (n_assets, n_assets):\n            raise ValueError(\n                f\"Expected shape (n_assets, n_assets), got {items.shape} for {name}.\"\n            )\n    else:\n        raise ValueError(f\"Expected dim 1 or 2, got {dim} for {name}.\")\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        else:\n            assets_names = np.array(assets_names)\n        if dim == 1:\n            items = np.array([items.get(name, fill_value) for name in assets_names])\n        else:\n            items = np.array(\n                [\n                    [items.get(name, fill_value) for name in assets_names]\n                    for _ in range(dim)\n                ]\n            )\n    if isinstance(items, npt.ArrayLike):\n        items = np.array(items)\n    if dim == 1:\n        if items.ndim != 1:\n            raise ValueError(f\"{name} must be a 1D array\")\n        if items.shape[0] != n_assets:\n            raise ValueError(f\"{name} must have {n_assets} elements\")\n    else:\n        if items.ndim != 2:\n            raise ValueError(f\"{name} must be a 2D array\")\n        if items.shape[0] != n_assets or items.shape[1] != n_assets:\n            raise ValueError(f\"{name} must have shape ({n_assets}, {n_assets})\")\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if dim not in [1, 2]:\n        raise ValueError(\"dim must be either 1 or 2.\")\n\n    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"assets_names must be provided when items is a dictionary.\"\n            )\n        items = np.array(\n            [items.get(asset, fill_value) for asset in assets_names], dtype=float\n        )\n    elif not isinstance(items, np.ndarray):\n        items = np.array(items, dtype=float)\n\n    if dim == 1:\n        if items.ndim != 1:\n            raise ValueError(\n                f\"{name} must be a 1D array-like or dictionary with {n_assets} elements.\"\n            )\n        elif len(items) != n_assets:\n            raise ValueError(\n                f\"{name} must have {n_assets} elements, got {len(items)}.\"\n            )\n    elif dim == 2:\n        if items.ndim != 2:\n            raise ValueError(\n                f\"{name} must be a 2D array-like or dictionary with {n_assets} elements.\"\n            )\n        elif items.shape[1] != n_assets:\n            raise ValueError(\n                f\"{name} must have {n_assets} columns, got {items.shape[1]}.\"\n            )\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        else:\n            assets_names = np.array(assets_names)\n        items = np.array(list(items.values()))\n    elif isinstance(items, np.ndarray):\n        pass\n    elif isinstance(items, pd.Series):\n        items = items.values\n    else:\n        items = np.array(items)\n\n    if items.ndim == 1:\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"{name} must have shape (n_assets,) or (n_groups, n_assets), \"\n                f\"got {items.shape}\"\n            )\n        if assets_names is not None:\n            items = items[assets_names]\n        if dim == 2:\n            items = items.reshape(1, -1)\n    elif items.ndim == 2:\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"{name} must have shape (n_assets,) or (n_groups, n_assets), \"\n                f\"got {items.shape}\"\n            )\n        if assets_names is not None:\n            items = items[:, assets_names]\n    else:\n        raise ValueError(\n            f\"{name} must have shape (n_assets,) or (n_groups, n_assets), \"\n            f\"got {items.shape}\"\n        )\n\n    if assets_names is not None:\n        if items.shape[0] != assets_names.shape[0]:\n            raise ValueError(\n                f\"{name} must have shape (n_assets,) or (n_groups, n_assets), \"\n                f\"got {items.shape}\"\n            )\n\n    if assets_names is not None:\n        missing_assets = np.setdiff1d(assets_names, np.array(items.columns))\n        if missing_assets.size > 0:\n            items = items.reindex"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(f\"{name} must be a dictionary with assets names\")\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"{name} must have {n_assets} assets, got {len(assets_names)}\"\n            )\n        items = np.array(\n            [items.get(name, fill_value) for name in assets_names], dtype=float\n        )\n    elif isinstance(items, npt.ArrayLike):\n        items = np.array(items, dtype=float)\n    else:\n        raise TypeError(f\"{name} must be a dictionary or array-like\")\n\n    if dim == 1:\n        if items.ndim != 1:\n            raise ValueError(f\"{name} must be a 1-D array\")\n        if items.shape[0] != n_assets:\n            raise ValueError(f\"{name} must have {n_assets} assets\")\n    elif dim == 2:\n        if items.ndim != 2:\n            raise ValueError(f\"{name} must be a 2-D array\")\n        if items.shape[1] != n_assets:\n            raise ValueError(f\"{name} must have {n_assets} assets\")\n    else:\n        raise ValueError(f\"dim must be 1 or 2, got {dim}\")\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        items = np.array(list(items.values()))\n    if isinstance(items, np.ndarray):\n        if dim == 1:\n            if items.ndim == 2:\n                items = items.squeeze()\n            elif items.ndim != 1:\n                raise ValueError(\n                    f\"The {name} must be a 1D array or a dictionary, got {items.ndim}D array.\"\n                )\n        elif dim == 2:\n            if items.ndim != 2:\n                raise ValueError(\n                    f\"The {name} must be a 2D array, got {items.ndim}D array.\"\n                )\n    else:\n        items = np.array(items)\n    if dim == 1:\n        if items.ndim != 1:\n            raise ValueError(\n                f\"The {name} must be a 1D array or a dictionary, got {items.ndim}D array.\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"The {name} must have {n_assets} elements, got {items.shape[0]}.\"\n            )\n        if assets_names is not None:\n            if assets_names.shape[0] != n_assets:\n                raise ValueError(\n                    f\"The {name} must have {n_assets} elements, got {assets_names.shape[0]}.\"\n                )\n            items = pd.Series(items, index=assets_names).reindex(assets_names).values\n    elif dim == 2:\n        if items.ndim != 2:\n            raise ValueError(f\"The {name} must be a 2D array, got {items.ndim}D array.\")\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"The {name} must have {n_assets} elements, got {items.shape[1]}.\"\n            )"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        else:\n            assets_names = np.array(assets_names)\n        if dim == 1:\n            items_array = np.array([items.get(name, fill_value) for name in assets_names])\n        else:\n            items_array = np.array(\n                [items.get(name, fill_value) for name in assets_names]\n            ).T\n    else:\n        items_array = np.array(items)\n\n    if dim == 2:\n        if items_array.ndim != 2:\n            raise ValueError(\n                f\"{name} must be a 2D array with shape (n_groups, n_assets) or a dictionary with keys as assets names.\"\n            )\n        if items_array.shape[1] != n_assets:\n            raise ValueError(\n                f\"{name} must have {n_assets} columns when it is a 2D array.\"\n            )\n    else:\n        if items_array.ndim != 1:\n            raise ValueError(\n                f\"{name} must be a 1D array with shape (n_assets,) or a dictionary with keys as assets names.\"\n            )\n        if items_array.shape[0] != n_assets:\n            raise ValueError(\n                f\"{name} must have {n_assets} elements when it is a 1D array.\"\n            )\n\n    return items_array\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"Assets names must be provided when {name} is a dictionary\"\n            )\n        items = np.array([items.get(name, fill_value) for name in assets_names])\n    if dim == 1:\n        items = np.atleast_1d(items)\n    elif dim == 2:\n        items = np.atleast_2d(items)\n    else:\n        raise ValueError(f\"Dimension {dim} is not supported\")\n    if items.shape[0] != n_assets:\n        raise ValueError(\n            f\"{name} must have shape ({n_assets},) or (n_groups, {n_assets})\"\n        )\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        else:\n            assets_names = np.array(assets_names)\n        if assets_names.shape[0] != n_assets:\n            raise ValueError(\n                f\"Expected {n_assets} assets, got {assets_names.shape[0]}\"\n            )\n        items = np.array([items.get(k, fill_value) for k in assets_names])\n    elif isinstance(items, np.ndarray):\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"Expected {n_assets} assets, got {items.shape[0]}\"\n            )\n    elif isinstance(items, pd.DataFrame):\n        items = items.to_numpy()\n    else:\n        items = np.array(items)\n\n    if items.shape[0] != n_assets:\n        raise ValueError(f\"Expected {n_assets} assets, got {items.shape[0]}\")\n\n    if dim == 1:\n        if items.ndim != 1:\n            raise ValueError(f\"Expected 1-dimensional array, got {items.ndim}\")\n    elif dim == 2:\n        if items.ndim == 1:\n            items = np.expand_dims(items, axis=0)\n        elif items.ndim != 2:\n            raise ValueError(f\"Expected 2-dimensional array, got {items.ndim}\")\n    else:\n        raise ValueError(f\"Expected dim=1 or dim=2, got {dim}\")\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"{name} is a dictionary and assets_names must be provided\"\n            )\n        items = np.array(\n            [\n                items.get(asset, fill_value)\n                for asset in assets_names\n            ]\n        )\n    if isinstance(items, npt.ArrayLike):\n        items = np.array(items)\n    if not isinstance(items, np.ndarray):\n        raise TypeError(\n            f\"{name} must be a dictionary, array-like or a numpy array, got {type(items)}\"\n        )\n    if dim == 1:\n        if items.ndim != 1:\n            raise ValueError(\n                f\"{name} must be a 1-dimensionnal array, got {items.ndim}\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"{name} must have {n_assets} elements, got {items.shape[0]}\"\n            )\n    elif dim == 2:\n        if items.ndim != 2:\n            raise ValueError(\n                f\"{name} must be a 2-dimensionnal array, got {items.ndim}\"\n            )\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"{name} must have {n_assets} columns, got {items.shape[1]}\"\n            )\n    else:\n        raise ValueError(f\"dim must be 1 or 2, got {dim}\")\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"Assets names are required when the input is a dictionary.\"\n            )\n        items = np.array([items.get(asset, fill_value) for asset in assets_names])\n    if isinstance(items, np.ndarray):\n        if dim == 1:\n            if items.ndim != 1:\n                raise ValueError(\n                    f\"Expected 1-dimensional array for {name}, got {items.ndim}\"\n                )\n            if items.shape[0] != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} assets for {name}, got {items.shape[0]}\"\n                )\n        elif dim == 2:\n            if items.ndim != 2:\n                raise ValueError(\n                    f\"Expected 2-dimensional array for {name}, got {items.ndim}\"\n                )\n            if items.shape[1] != n_assets:\n                raise ValueError(\n                    f\"Expected {n_assets} assets for {name}, got {items.shape[1]}\"\n                )\n        else:\n            raise ValueError(\n                f\"Expected dimension 1 or 2 for {name}, got {dim}\"\n            )\n        return items\n    if isinstance(items, Iterator):\n        items = np.array(list(items))\n    if isinstance(items, pd.Series):\n        items = items.values\n    if isinstance(items, list):\n        items = np.array(items)\n    if isinstance(items, (int, float)):\n        items = np.array([items] * n_assets)\n    if items.ndim == 0:\n        items = np.array([items] * n_assets)\n    if items.ndim == 1:\n        if dim == 2:\n            items = np.repeat(items[:, np.newaxis], n_assets, axis=1)\n        if dim == 1:\n            if items.shape[0] != n_assets:\n                raise ValueError(\n                    f"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        items = np.array([items.get(k, fill_value) for k in assets_names])\n    elif isinstance(items, (list, tuple)):\n        items = np.array(items)\n    elif isinstance(items, (int, float)):\n        items = np.full(n_assets, items)\n    else:\n        raise TypeError(f\"{name} must be a dictionary, list, tuple or a scalar\")\n\n    if dim == 1:\n        if items.shape != (n_assets,):\n            raise ValueError(f\"{name} must have shape (n_assets,)\")\n    elif dim == 2:\n        if items.shape != (n_assets, n_assets):\n            raise ValueError(f\"{name} must have shape (n_assets, n_assets)\")\n    else:\n        raise ValueError(\"dim must be 1 or 2\")\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    # Check that the input items is not empty\n    if not items:\n        raise ValueError(f\"{name} cannot be empty\")\n\n    # If the input is a dictionary, convert it to a numpy array\n    if isinstance(items, dict):\n\n        # If assets_names is provided, check that all keys in the dictionary are present in assets_names\n        if assets_names is not None:\n            missing = set(assets_names) - set(items.keys())\n            if missing:\n                raise ValueError(f\"Missing {name}: {missing}\")\n\n        # If assets_names is not provided, create a list of keys from the dictionary\n        else:\n            assets_names = list(items.keys())\n\n        # Create a numpy array from the dictionary values, filling in missing values with fill_value\n        items = np.array([items.get(name, fill_value) for name in assets_names])\n\n    # If the input is not a dictionary, convert it to a numpy array\n    else:\n        items = np.array(items)\n\n    # Check that the input array has the correct number of dimensions\n    if items.ndim != dim:\n        raise ValueError(f\"{name} must have {dim} dimensions\")\n\n    # If the input array has only one dimension, check that it has the correct shape\n    if dim == 1:\n        if items.shape[0] != n_assets:\n            raise ValueError(f\"{name} must have shape (n_assets,)\")\n\n    # If the input array has two dimensions, check that it has the correct shape\n    else:\n        if items.shape[1] != n_assets:\n            raise ValueError(f\"{name} must have shape (n_groups, n_assets)\")\n\n    # Return the converted array\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        else:\n            assets_names = np.array(assets_names)\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"The number of assets ({len(assets_names)}) in {name} does not match the number of assets ({n_assets})\"\n            )\n        items = np.array([items.get(asset, fill_value) for asset in assets_names])\n\n    if isinstance(items, np.ndarray):\n        if dim == 1:\n            if items.shape != (n_assets,):\n                raise ValueError(\n                    f\"The shape of {name} ({items.shape}) does not match the expected shape ({n_assets},)\"\n                )\n        elif dim == 2:\n            if items.shape != (n_assets, n_assets):\n                raise ValueError(\n                    f\"The shape of {name} ({items.shape}) does not match the expected shape ({n_assets}, {n_assets})\"\n                )\n        else:\n            raise ValueError(\n                f\"The dimension of {name} ({dim}) is not supported. It must be either 1 or 2.\"\n            )\n    else:\n        raise TypeError(f\"{name} must be a dictionary or numpy array\")\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"{name} is a dictionary but no asset names were provided.\"\n            )\n        if dim == 2:\n            raise ValueError(\n                f\"{name} is a dictionary but dim=2 was provided. Use a numpy array instead.\"\n            )\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"{name} is a dictionary but the number of assets does not match.\"\n            )\n        items = np.array([items.get(a, fill_value) for a in assets_names])\n    elif not isinstance(items, np.ndarray):\n        items = np.array(items)\n    if items.ndim == 0:\n        items = np.array([items])\n    if items.ndim != dim:\n        raise ValueError(\n            f\"{name} must be a {dim}D array. Got a {items.ndim}D array instead.\"\n        )\n    if dim == 2:\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"{name} must have {n_assets} columns. Got {items.shape[1]} instead.\"\n            )\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    # Check if the items are a dictionary\n    if isinstance(items, dict):\n        # If assets_names is provided, check that all keys in items are present in assets_names\n        if assets_names is not None:\n            missing_assets = set(assets_names) - set(items.keys())\n            if missing_assets:\n                raise ValueError(\n                    f\"{name} missing assets: {missing_assets}. \"\n                    f\"Available assets: {list(items.keys())}\"\n                )\n        # If dim is 1, convert the dictionary to a 1D numpy array\n        if dim == 1:\n            array = np.array([items.get(asset, fill_value) for asset in assets_names])\n        # If dim is 2, convert the dictionary to a 2D numpy array\n        elif dim == 2:\n            array = np.array(\n                [\n                    [items.get(asset, fill_value) for asset in assets_names]\n                    for _ in range(n_assets)\n                ]\n            )\n        # Raise an error if dim is not 1 or 2\n        else:\n            raise ValueError(f\"{name} dim must be 1 or 2, got {dim}\")\n    # If items is an array-like object, convert it to a numpy array\n    elif isinstance(items, npt.ArrayLike):\n        array = np.array(items)\n    # If items is neither a dictionary nor an array-like object, raise an error\n    else:\n        raise TypeError(\n            f\"{name} must be a dictionary or an array-like object, got {type(items)}\"\n        )\n\n    # Verify the shape of the converted array\n    if dim == 1:\n        if array.shape != (n_assets,):\n            raise ValueError(\n                f\"{name} shape must be (n_assets,), got {array.shape} for n_assets={n_assets}\"\n            )\n    elif dim == 2:\n        if array.shape != (n_assets, n_assets):\n            raise ValueError("}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                \"assets_names must be provided when items is a dictionary\"\n            )\n        items = np.array([items.get(asset, fill_value) for asset in assets_names])\n    elif not isinstance(items, np.ndarray):\n        items = np.array(items)\n    if items.ndim == 0:\n        items = np.array([items] * n_assets)\n    if items.ndim != dim:\n        raise ValueError(\n            f\"{name} must be a {dim}-dimensional array, got {items.ndim}-dimensional array\"\n        )\n    if items.shape[-1] != n_assets:\n        raise ValueError(\n            f\"{name} must have shape (n_assets,), got shape {items.shape}\"\n        )\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            raise ValueError(\n                f\"{name} is a dictionary, so you need to provide the assets names\"\n            )\n        if len(items) != n_assets:\n            raise ValueError(\n                f\"{name} dictionary must have {n_assets} elements, \"\n                f\"got {len(items)}\"\n            )\n        items = np.array([items[asset] for asset in assets_names])\n    if dim == 1:\n        items = np.array(items)\n        if items.ndim != 1:\n            raise ValueError(\n                f\"{name} must be a 1D array-like, got {items.ndim}D array\"\n            )\n    else:\n        items = np.array(items)\n        if items.ndim == 1:\n            items = items.reshape(-1, 1)\n        if items.ndim != 2:\n            raise ValueError(\n                f\"{name} must be a 2D array-like, got {items.ndim}D array\"\n            )\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"{name} must have {n_assets} columns, got {items.shape[1]}\"\n            )\n    if np.isnan(items).any():\n        items = np.nan_to_num(items, nan=fill_value)\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        items = np.array([items.get(k, fill_value) for k in assets_names])\n    elif not isinstance(items, np.ndarray):\n        items = np.array(items)\n\n    if dim == 1:\n        if items.ndim > 1:\n            raise ValueError(\n                f\"{name} must be a 1-dimensional array or dictionary, \"\n                f\"got {items.ndim} dimensions\"\n            )\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"{name} must have shape (n_assets,)={n_assets}, \"\n                f\"got {items.shape}\"\n            )\n    elif dim == 2:\n        if items.ndim != 2:\n            raise ValueError(\n                f\"{name} must be a 2-dimensional array, \" f\"got {items.ndim} dimensions\"\n            )\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"{name} must have shape (n_groups, n_assets)=({items.shape[0]}, {n_assets}), \"\n                f\"got {items.shape}\"\n            )\n    else:\n        raise ValueError(f\"dim must be either 1 or 2, got {dim}\")\n\n    return items\n\n"}
{"namespace": "skfolio.utils.tools.input_to_array", "completion": "    if isinstance(items, dict):\n        if assets_names is None:\n            assets_names = np.array(list(items.keys()))\n        else:\n            assets_names = np.array(assets_names)\n        if len(assets_names) != n_assets:\n            raise ValueError(\n                f\"The number of assets ({n_assets}) does not match the number of items in '{name}' ({len(assets_names)}).\"\n            )\n        items = np.array([items.get(asset, fill_value) for asset in assets_names])\n    elif isinstance(items, npt.ArrayLike):\n        items = np.array(items)\n    else:\n        raise TypeError(\n            f\"'{name}' must be a dictionary or an array-like structure, not {type(items)}\"\n        )\n    if items.ndim == 0:\n        items = np.array([items])\n    if dim == 2:\n        if items.ndim != 2:\n            raise ValueError(f\"'{name}' must be a 2-dimensional array.\")\n        if items.shape[1] != n_assets:\n            raise ValueError(\n                f\"The number of assets ({n_assets}) does not match the number of items in '{name}' ({items.shape[1]}).\"\n            )\n    elif dim == 1:\n        if items.ndim != 1:\n            raise ValueError(f\"'{name}' must be a 1-dimensional array.\")\n        if items.shape[0] != n_assets:\n            raise ValueError(\n                f\"The number of assets ({n_assets}) does not match the number of items in '{name}' ({items.shape[0]}).\"\n            )\n    return items\n\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\")\n        agent.purpose = data.get(\"purpose\")\n        agent.purpose_embedding = data.get(\"purpose_embedding\")\n        agent.depth = data.get(\"depth\")\n        agent.max_depth = data.get(\"max_depth\")\n        agent.usage_count = data.get(\"usage_count\")\n        agent.id = data.get(\"id\")\n        agent.parent_id = data.get(\"parent_id\")\n        agent.working_agent = data.get(\"working_agent\")\n        agent.is_prime = data.get(\"is_prime\")\n        agent.evolve_count = data.get(\"evolve_count\")\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\")\n        agent.last_input = data.get(\"last_input\")\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", \"\")\n        agent.purpose = data.get(\"purpose\", \"\")\n        agent.purpose_embedding = data.get(\"purpose_embedding\", None)\n        agent.depth = data.get(\"depth\", 0)\n        agent.max_depth = data.get(\"max_depth\", 0)\n        agent.usage_count = data.get(\"usage_count\", 0)\n        agent.id = data.get(\"id\", None)\n        agent.parent_id = data.get(\"parent_id\", None)\n        agent.working_agent = data.get(\"working_agent\", False)\n        agent.is_prime = data.get(\"is_prime\", False)\n        agent.evolve_count = data.get(\"evolve_count\", 0)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        agent.last_input = data.get(\"last_input\", None)\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", \"\")\n        agent.purpose = data.get(\"purpose\", \"\")\n        agent.purpose_embedding = data.get(\"purpose_embedding\", [])\n        agent.depth = data.get(\"depth\", 0)\n        agent.max_depth = data.get(\"max_depth\", 0)\n        agent.usage_count = data.get(\"usage_count\", 0)\n        agent.id = data.get(\"id\", \"\")\n        agent.parent_id = data.get(\"parent_id\", \"\")\n        agent.working_agent = data.get(\"working_agent\", False)\n        agent.is_prime = data.get(\"is_prime\", False)\n        agent.evolve_count = data.get(\"evolve_count\", 0)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        agent.last_input = data.get(\"last_input\", \"\")\n\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", None)\n        agent.purpose = data.get(\"purpose\", None)\n        agent.purpose_embedding = data.get(\"purpose_embedding\", None)\n        agent.depth = data.get(\"depth\", 0)\n        agent.max_depth = data.get(\"max_depth\", 0)\n        agent.usage_count = data.get(\"usage_count\", 0)\n        agent.id = data.get(\"id\", None)\n        agent.parent_id = data.get(\"parent_id\", None)\n        agent.working_agent = data.get(\"working_agent\", False)\n        agent.is_prime = data.get(\"is_prime\", False)\n        agent.evolve_count = data.get(\"evolve_count\", 0)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        agent.last_input = data.get(\"last_input\", None)\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", \"\")\n        agent.purpose = data.get(\"purpose\", \"\")\n        agent.purpose_embedding = data.get(\"purpose_embedding\", None)\n        agent.depth = data.get(\"depth\", 0)\n        agent.max_depth = data.get(\"max_depth\", 0)\n        agent.usage_count = data.get(\"usage_count\", 0)\n        agent.id = data.get(\"id\", None)\n        agent.parent_id = data.get(\"parent_id\", None)\n        agent.working_agent = data.get(\"working_agent\", False)\n        agent.is_prime = data.get(\"is_prime\", False)\n        agent.evolve_count = data.get(\"evolve_count\", 0)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        agent.last_input = data.get(\"last_input\", \"\")\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", \"\")\n        agent.purpose = data.get(\"purpose\", \"\")\n        agent.purpose_embedding = np.array(data.get(\"purpose_embedding\", []))\n        agent.depth = data.get(\"depth\", 0)\n        agent.max_depth = data.get(\"max_depth\", 0)\n        agent.usage_count = data.get(\"usage_count\", 0)\n        agent.id = data.get(\"id\", \"\")\n        agent.parent_id = data.get(\"parent_id\", \"\")\n        agent.working_agent = data.get(\"working_agent\", False)\n        agent.is_prime = data.get(\"is_prime\", False)\n        agent.evolve_count = data.get(\"evolve_count\", 0)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        agent.last_input = data.get(\"last_input\", \"\")\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\")\n        agent.purpose = data.get(\"purpose\")\n        agent.purpose_embedding = np.array(data.get(\"purpose_embedding\"))  # Convert list to ndarray\n        agent.depth = data.get(\"depth\")\n        agent.max_depth = data.get(\"max_depth\")\n        agent.usage_count = data.get(\"usage_count\")\n        agent.id = data.get(\"id\")\n        agent.parent_id = data.get(\"parent_id\")\n        agent.working_agent = data.get(\"working_agent\", False)\n        agent.is_prime = data.get(\"is_prime\", False)\n        agent.evolve_count = data.get(\"evolve_count\", 0)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        agent.last_input = data.get(\"last_input\", \"\")\n        return agent"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", \"\")\n        agent.purpose = data.get(\"purpose\", \"\")\n        agent.purpose_embedding = data.get(\"purpose_embedding\", None)\n        agent.depth = data.get(\"depth\", 0)\n        agent.max_depth = data.get(\"max_depth\", 0)\n        agent.usage_count = data.get(\"usage_count\", 0)\n        agent.id = data.get(\"id\", None)\n        agent.parent_id = data.get(\"parent_id\", None)\n        agent.working_agent = data.get(\"working_agent\", False)\n        agent.is_prime = data.get(\"is_prime\", False)\n        agent.evolve_count = data.get(\"evolve_count\", 0)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        agent.last_input = data.get(\"last_input\", None)\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", \"\")\n        agent.purpose = data.get(\"purpose\", \"\")\n        agent.purpose_embedding = data.get(\"purpose_embedding\", None)\n        agent.depth = data.get(\"depth\", 0)\n        agent.max_depth = data.get(\"max_depth\", 0)\n        agent.usage_count = data.get(\"usage_count\", 0)\n        agent.id = data.get(\"id\", None)\n        agent.parent_id = data.get(\"parent_id\", None)\n        agent.working_agent = data.get(\"working_agent\", False)\n        agent.is_prime = data.get(\"is_prime\", False)\n        agent.evolve_count = data.get(\"evolve_count\", 0)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        agent.last_input = data.get(\"last_input\", None)\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\", None)\n        if isinstance(purpose_embedding, list):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        agent = MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\", \"\"),\n            purpose=data.get(\"purpose\", \"\"),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\", 0),\n            max_depth=data.get(\"max_depth\", 0),\n            usage_count=data.get(\"usage_count\", 0),\n            id=data.get(\"id\", None),\n            parent_id=data.get(\"parent_id\", None),\n            working_agent=data.get(\"working_agent\", False),\n            is_prime=data.get(\"is_prime\", False),\n            evolve_count=data.get(\"evolve_count\", 0),\n            number_of_code_executions=data.get(\"number_of_code_executions\", 0),\n            last_input=data.get(\"last_input\", None),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        # Initialize the MicroAgent with the required arguments\n        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n\n        # Set the MicroAgent's attributes based on the input dictionary\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", \"\")\n        agent.purpose = data.get(\"purpose\", \"\")\n        agent.purpose_embedding = np.array(data.get(\"purpose_embedding\", []))  # Convert list to ndarray\n        agent.depth = data.get(\"depth\", 0)\n        agent.max_depth = data.get(\"max_depth\", 0)\n        agent.usage_count = data.get(\"usage_count\", 0)\n        agent.id = data.get(\"id\", \"\")\n        agent.parent_id = data.get(\"parent_id\", \"\")\n        agent.working_agent = data.get(\"working_agent\", False)\n        agent.is_prime = data.get(\"is_prime\", False)\n        agent.evolve_count = data.get(\"evolve_count\", 0)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        agent.last_input = data.get(\"last_input\", \"\")\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\")\n        agent.purpose = data.get(\"purpose\")\n        agent.purpose_embedding = np.array(data.get(\"purpose_embedding\", []))  # Convert list to ndarray\n        agent.depth = data.get(\"depth\", 0)\n        agent.max_depth = data.get(\"max_depth\", 0)\n        agent.usage_count = data.get(\"usage_count\", 0)\n        agent.id = data.get(\"id\")\n        agent.parent_id = data.get(\"parent_id\")\n        agent.working_agent = data.get(\"working_agent\", False)\n        agent.is_prime = data.get(\"is_prime\", False)\n        agent.evolve_count = data.get(\"evolve_count\", 0)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        agent.last_input = data.get(\"last_input\")\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", \"\")\n        agent.purpose = data.get(\"purpose\", \"\")\n        agent.purpose_embedding = data.get(\"purpose_embedding\", \"\")\n        agent.depth = data.get(\"depth\", 0)\n        agent.max_depth = data.get(\"max_depth\", 0)\n        agent.usage_count = data.get(\"usage_count\", 0)\n        agent.id = data.get(\"id\", None)\n        agent.parent_id = data.get(\"parent_id\", None)\n        agent.working_agent = data.get(\"working_agent\", False)\n        agent.is_prime = data.get(\"is_prime\", False)\n        agent.evolve_count = data.get(\"evolve_count\", 0)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        agent.last_input = data.get(\"last_input\", \"\")\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        # Extract values from the dictionary and handle optional keys gracefully\n        dynamic_prompt = data.get(\"dynamic_prompt\", \"\")\n        purpose = data.get(\"purpose\", \"\")\n        purpose_embedding = data.get(\"purpose_embedding\", [])\n        depth = data.get(\"depth\", 0)\n        max_depth = data.get(\"max_depth\", 0)\n        usage_count = data.get(\"usage_count\", 0)\n        id = data.get(\"id\", None)\n        parent_id = data.get(\"parent_id\", None)\n        working_agent = data.get(\"working_agent\", None)\n        is_prime = data.get(\"is_prime\", False)\n        evolve_count = data.get(\"evolve_count\", 0)\n        number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        last_input = data.get(\"last_input\", \"\")\n\n        # Create a new MicroAgent instance with the extracted values\n        agent = MicroAgent(\n            dynamic_prompt=dynamic_prompt,\n            purpose=purpose,\n            purpose_embedding=purpose_embedding,\n            depth=depth,\n            max_depth=max_depth,\n            usage_count=usage_count,\n            id=id,\n            parent_id=parent_id,\n            working_agent=working_agent,\n            is_prime=is_prime,\n            evolve_count=evolve_count,\n            number_of_code_executions=number_of_code_executions,\n            last_input=last_input,\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\", None)\n        if purpose_embedding is not None and not isinstance(purpose_embedding, np.ndarray):\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        return MicroAgent(\n            dynamic_prompt=data.get(\"dynamic_prompt\", None),\n            purpose=data.get(\"purpose\", None),\n            purpose_embedding=purpose_embedding,\n            depth=data.get(\"depth\", 0),\n            max_depth=data.get(\"max_depth\", 0),\n            usage_count=data.get(\"usage_count\", 0),\n            id=data.get(\"id\", None),\n            parent_id=data.get(\"parent_id\", None),\n            working_agent=data.get(\"working_agent\", False),\n            is_prime=data.get(\"is_prime\", False),\n            evolve_count=data.get(\"evolve_count\", 0),\n            number_of_code_executions=data.get(\"number_of_code_executions\", 0),\n            last_input=data.get(\"last_input\", None),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper\n        )\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            agent_lifecycle,\n            openai_wrapper,\n            purpose=data.get(\"purpose\", \"\"),\n            purpose_embedding=data.get(\"purpose_embedding\", []),\n            depth=data.get(\"depth\", 0),\n            max_depth=data.get(\"max_depth\", 0),\n            usage_count=data.get(\"usage_count\", 0),\n            id=data.get(\"id\", None),\n            parent_id=data.get(\"parent_id\", None),\n            working_agent=data.get(\"working_agent\", False),\n            is_prime=data.get(\"is_prime\", False),\n            evolve_count=data.get(\"evolve_count\", 0),\n            number_of_code_executions=data.get(\"number_of_code_executions\", 0),\n            last_input=data.get(\"last_input\", \"\"),\n        )\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", \"\")\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(\n            purpose=data.get(\"purpose\", \"\"),\n            dynamic_prompt=data.get(\"dynamic_prompt\", \"\"),\n            purpose_embedding=data.get(\"purpose_embedding\", None),\n            depth=data.get(\"depth\", 0),\n            max_depth=data.get(\"max_depth\", 0),\n            usage_count=data.get(\"usage_count\", 0),\n            id=data.get(\"id\", None),\n            parent_id=data.get(\"parent_id\", None),\n            working_agent=data.get(\"working_agent\", False),\n            is_prime=data.get(\"is_prime\", False),\n            evolve_count=data.get(\"evolve_count\", 0),\n            number_of_code_executions=data.get(\"number_of_code_executions\", 0),\n            last_input=data.get(\"last_input\", None),\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n        )\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        agent = MicroAgent(agent_lifecycle=agent_lifecycle, openai_wrapper=openai_wrapper)\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", \"\")\n        agent.purpose = data.get(\"purpose\", \"\")\n        agent.purpose_embedding = data.get(\"purpose_embedding\", [])\n        agent.depth = data.get(\"depth\", 0)\n        agent.max_depth = data.get(\"max_depth\", 0)\n        agent.usage_count = data.get(\"usage_count\", 0)\n        agent.id = data.get(\"id\", None)\n        agent.parent_id = data.get(\"parent_id\", None)\n        agent.working_agent = data.get(\"working_agent\", None)\n        agent.is_prime = data.get(\"is_prime\", False)\n        agent.evolve_count = data.get(\"evolve_count\", 0)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        agent.last_input = data.get(\"last_input\", \"\")\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        purpose_embedding = data.get(\"purpose_embedding\", None)\n        if purpose_embedding is not None:\n            purpose_embedding = np.array(purpose_embedding)  # Convert list to ndarray\n\n        agent = MicroAgent(\n            agent_lifecycle=agent_lifecycle,\n            openai_wrapper=openai_wrapper,\n            purpose=data.get(\"purpose\", None),\n            purpose_embedding=purpose_embedding,\n            dynamic_prompt=data.get(\"dynamic_prompt\", None),\n            depth=data.get(\"depth\", 0),\n            max_depth=data.get(\"max_depth\", 0),\n            usage_count=data.get(\"usage_count\", 0),\n            id=data.get(\"id\", None),\n            parent_id=data.get(\"parent_id\", None),\n            working_agent=data.get(\"working_agent\", False),\n            is_prime=data.get(\"is_prime\", False),\n            evolve_count=data.get(\"evolve_count\", 0),\n            number_of_code_executions=data.get(\"number_of_code_executions\", 0),\n            last_input=data.get(\"last_input\", None),\n        )\n\n        return agent\n"}
{"namespace": "agent_serializer.AgentSerializer.from_dict", "completion": "        # Create a new MicroAgent object\n        agent = MicroAgent(agent_lifecycle, openai_wrapper)\n\n        # Set the attributes of the MicroAgent object based on the dictionary's key-value pairs\n        agent.dynamic_prompt = data.get(\"dynamic_prompt\", None)\n        agent.purpose = data.get(\"purpose\", None)\n        agent.purpose_embedding = np.array(data.get(\"purpose_embedding\", None))\n        agent.depth = data.get(\"depth\", 0)\n        agent.max_depth = data.get(\"max_depth\", 0)\n        agent.usage_count = data.get(\"usage_count\", 0)\n        agent.id = data.get(\"id\", None)\n        agent.parent_id = data.get(\"parent_id\", None)\n        agent.working_agent = data.get(\"working_agent\", None)\n        agent.is_prime = data.get(\"is_prime\", False)\n        agent.evolve_count = data.get(\"evolve_count\", 0)\n        agent.number_of_code_executions = data.get(\"number_of_code_executions\", 0)\n        agent.last_input = data.get(\"last_input\", None)\n\n        return agent\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb_linear0 = srgb / 12.92\n  srgb_linear1 = ((srgb + 0.055) / 1.055) ** 2.4\n  return xnp.where(srgb <= 0.04045, srgb_linear0, srgb_linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb_linear0 = srgb / 12.92\n  srgb_linear1 = ((srgb + 0.055) / 1.055) ** 2.4\n  return xnp.where(srgb <= 0.04045, srgb_linear0, srgb_linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb_linear0 = srgb / 12.92\n  srgb_linear1 = ((srgb + 0.055) / 1.055) ** 2.4\n  return xnp.where(srgb <= 0.04045, srgb_linear0, srgb_linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb_linear0 = srgb / 12.92\n  srgb_linear1 = ((srgb + 0.055) / 1.055) ** 2.4\n  return xnp.where(srgb <= 0.04045, srgb_linear0, srgb_linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = ((srgb + 0.055) / 1.055) ** 2.4\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb_linear0 = srgb / 12.92\n  srgb_linear1 = ((srgb + 0.055) / 1.055) ** 2.4\n  return xnp.where(srgb <= 0.04045, srgb_linear0, srgb_linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 25 / 323 * srgb\n  linear1 = xnp.where(srgb <= 0.04045, srgb / 12.92, ((srgb + 0.055) / 1.055) ** 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb = xnp.clip(srgb, 0, 1)\n  srgb_linear0 = 1 / 12.92 * srgb\n  srgb_linear1 = ((srgb + 0.055) / 1.055) ** 2.4\n  return xnp.where(srgb <= 0.04045, srgb_linear0, srgb_linear1)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = srgb / 12.92\n  linear1 = (((srgb + 0.055) / 1.055) ** 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 25 / 323 * srgb\n  linear1 = (200 * srgb + 11) / 211\n  return xnp.where(srgb <= 0.04045, linear0, linear1 ** 3)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  linear0 = 25 / 323 * srgb\n  linear1 = xnp.where(srgb <= 0.04045, srgb / 12.92,\n                      ((srgb + 0.055) / 1.055) ** 2.4)\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb = xnp.clip(srgb, 0, 1)\n  linear0 = 25 / 323 * srgb\n  linear1 = (200 * srgb + 11) / 211\n  linear1 = xnp.where(srgb <= 0.04045, linear0, linear1)\n  return xnp.where(srgb <= 0.0031308, srgb * 12.92, linear1 ** 3)"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb = xnp.clip(srgb, 0, 1)\n  srgb_linear0 = 25 / 323 * srgb\n  srgb_linear1 = xnp.where(\n      srgb <= 0.04045, srgb / 12.92, xnp.power((srgb + 0.055) / 1.055, 2.4)\n  )\n  return xnp.where(srgb <= 0.04045, srgb_linear0, srgb_linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb_linear0 = 25 / 323 * srgb\n  srgb_linear1 = (200 * srgb + 11) / 211\n  srgb_linear2 = xnp.where(srgb <= 0.04045, srgb_linear0, srgb_linear1)\n  return xnp.where(srgb <= eps, 0.0, srgb_linear2)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb_linear0 = 1 / 25 * srgb\n  srgb_linear1 = ((srgb + 0.055) / 1.055) ** 2.4\n  return xnp.where(srgb <= 0.04045, srgb_linear0, srgb_linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb = xnp.clip(srgb, 0, 1)\n  linear0 = srgb / 12.92\n  linear1 = ((srgb + 0.055) / 1.055) ** 2.4\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb = xnp.clip(srgb, 0, 1)\n  a = 0.055\n  linear0 = srgb / 12.92\n  linear1 = ((srgb + a) / (1 + a)) ** 2.4\n  return xnp.where(srgb <= 0.04045, linear0, linear1)\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb = xnp.where(srgb <= 0.0404482362771082, srgb / 12.92,\n                   xnp.power((srgb + 0.055) / 1.055, 2.4))\n  return srgb\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb = xnp.where(srgb <= 0.0404482362771082, srgb / 12.92,\n                   ((srgb + 0.055) / 1.055) ** 2.4)\n  return srgb\n\n"}
{"namespace": "image_utils.srgb_to_linear", "completion": "  if eps is None:\n    eps = xnp.finfo(xnp.float32).eps\n  srgb = xnp.array(srgb)\n  return xnp.where(\n      srgb <= 0.0404482362771082, srgb / 12.92,\n      ((srgb + 0.055) / 1.055) ** 2.4\n  )\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Compute the spline coefficients\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  return x_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Compute the spline coefficients\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  return x_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Compute the spline coefficients using the input signal and times\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  return x_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Fit the spline to the input signal x\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times t_output\n  x_interp = scipy.interpolate.splev(t_output, tck)\n\n  return x_interp\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Create a spline object using the input signal and times\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  # Return the interpolated values\n  return x_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Ensure spline_degree is at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Interpolate the signal using spline interpolation\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  # Return the interpolated values\n  return x_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Check if the input arrays are valid\n  if len(x) != len(t_input):\n    raise ValueError(\"The length of x and t_input must be the same.\")\n\n  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Fit the spline\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  return x_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Compute the knot sequence for the B-spline\n  knots = np.linspace(t_input[0], t_input[-1], len(x) + spline_degree - 1)\n\n  # Compute the spline coefficients\n  coeffs = scipy.interpolate.splrep(t_input, x, k=spline_degree, t=knots, s=smoothness)\n\n  # Evaluate the spline at the output times\n  x_output = scipy.interpolate.splev(t_output, coeffs)\n\n  return x_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  if len(x) <= 1:\n    return x\n\n  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Fit the spline to the input signal\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  return x_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Convert input data to numpy arrays\n  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n\n  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Fit a spline to the input data\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  return x_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Compute the knot locations for the spline\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times\n  y_output = scipy.interpolate.splev(t_output, tck)\n\n  return y_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Compute the spline coefficients using the input signal x and input times t_input\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times t_output to obtain the interpolated values\n  return scipy.interpolate.splev(t_output, tck)\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust spline degree to be at most one less than the number of points in x.\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Fit the spline to the input signal.\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times.\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  # Return the interpolated values.\n  return x_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Convert input arrays to numpy arrays\n  x = np.array(x)\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n\n  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Calculate the spline coefficients using the specified degree and smoothness\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the specified output times\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  return x_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Check if t_input is sorted\n  if not np.all(np.diff(t_input) >= 0):\n    raise ValueError(\"t_input must be sorted in ascending order\")\n\n  # Check if t_output is sorted\n  if not np.all(np.diff(t_output) >= 0):\n    raise ValueError(\"t_output must be sorted in ascending order\")\n\n  # Check if t_input and t_output have the same start and end times\n  if t_input[0] != t_output[0] or t_input[-1] != t_output[-1]:\n    raise ValueError(\"t_input and t_output must have the same start and end times\")\n\n  # Check if t_input and t_output have the same length\n  if len(t_input) != len(x):\n    raise ValueError(\"t_input and x must have the same length\")\n\n  # Adjust spline_degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Fit a spline to the input signal\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  return x_output"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  if len(x) < 2:\n    raise ValueError('x must have at least two elements')\n  if len(t_input) != len(x):\n    raise ValueError('t_input and x must have the same length')\n  if len(t_output) == 0:\n    raise ValueError('t_output must have at least one element')\n\n  # Adjust spline_degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Compute the spline coefficients using scipy.interpolate.splrep\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times using scipy.interpolate.splev\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  return x_output"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Check if t_input and t_output are increasing\n  if not np.all(np.diff(t_input) > 0):\n    raise ValueError(\"t_input must be strictly increasing.\")\n  if not np.all(np.diff(t_output) > 0):\n    raise ValueError(\"t_output must be strictly increasing.\")\n\n  # Adjust spline_degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Calculate the spline coefficients using scipy's splrep function\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times using scipy's splev function\n  y_output = scipy.interpolate.splev(t_output, tck)\n\n  return y_output\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Check if the input signal is empty\n  if len(x) == 0:\n    raise ValueError(\"Input signal is empty.\")\n\n  # Check if the input and output times are empty\n  if len(t_input) == 0 or len(t_output) == 0:\n    raise ValueError(\"Input or output times are empty.\")\n\n  # Check if the input and output times are increasing\n  if not np.all(np.diff(t_input) > 0) or not np.all(np.diff(t_output) > 0):\n    raise ValueError(\"Input or output times are not increasing.\")\n\n  # Check if the input and output times are within the bounds of the input signal\n  if t_input[0] < t_input[-1] and (t_input[0] > t_input[-1] or t_input[-1] < t_input[0]):\n    raise ValueError(\"Input times are not within the bounds of the input signal.\")\n\n  # Check if the input and output times are within the bounds of the output signal\n  if t_output[0] < t_output[-1] and (t_output[0] > t_output[-1] or t_output[-1] < t_output[0]):\n    raise ValueError(\"Output times are not within the bounds of the output signal.\")\n\n  # Check if the input and output times have the same length\n  if len(t_input) != len(x):\n    raise ValueError(\"Input times and signal have different lengths.\")\n\n  # Check if the input and output times are the same\n  if np.array_equal(t_input, t_output):\n    return x\n\n  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Fit a spline to the input signal\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Evaluate the spline at the output times\n  y = scipy."}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Calculate the knot points for the spline\n  knots = np.linspace(0, 1, spline_degree + 2)\n\n  # Calculate the spline coefficients using the input signal and knots\n  spline_coeffs = np.zeros((len(x), spline_degree + 1))\n  for i in range(len(x)):\n    spline_coeffs[i] = scipy.interpolate.splrep(t_input, x[i], k=spline_degree, s=smoothness, t=knots[1:-1])[0]\n\n  # Calculate the interpolated values of the signal at the output times using the spline coefficients\n  y = np.zeros((len(t_output), len(x)))\n  for i in range(len(t_output)):\n    y[i] = np.array([scipy.interpolate.splev(t_output[i], spline_coeffs[j], der=0) for j in range(len(x))])\n\n  return y\n\n"}
{"namespace": "camera_utils.safe_interpolate_1d", "completion": "  # Convert input and output times to numpy arrays\n  t_input = np.array(t_input)\n  t_output = np.array(t_output)\n\n  # Check if the input and output times have the same shape\n  assert t_input.shape == t_output.shape\n\n  # Adjust the spline degree to be at most one less than the number of points in x\n  spline_degree = min(spline_degree, len(x) - 1)\n\n  # Use the scipy.interpolate.splrep function to fit a spline to the input signal x\n  # The spline is fit using the input times t_input and the degree of the spline specified by spline_degree\n  # The smoothness parameter is used to control the smoothness of the fit\n  tck = scipy.interpolate.splrep(t_input, x, k=spline_degree, s=smoothness)\n\n  # Use the scipy.interpolate.splev function to evaluate the spline at the output times t_output\n  # The spline is evaluated using the spline representation tck and the output times t_output\n  # The splev function returns an array of interpolated values\n  x_output = scipy.interpolate.splev(t_output, tck)\n\n  # Return the interpolated values\n  return x_output\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    return word"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    return word"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    return word"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    return word"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    return word"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    return word"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n\n    return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.islower():\n        return word\n    elif word.isupper():\n        return word\n    else:\n        if word[0].isupper() and word[1].isupper():\n            return word.upper()\n        elif word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper():\n        if word[1].isupper():\n            return word.capitalize()\n        return word.upper()\n    if word[0].islower():\n        if word[1].islower():\n            return word.capitalize()\n        return word.lower()\n    return word"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word.istitle():\n        return word\n    if word.isspace():\n        return word\n    if word.isnumeric():\n        return word\n    if word.isalpha():\n        return word\n    if word.isalnum():\n        return word\n    if word.isascii():\n        return word\n    if word.isdecimal():\n        return word\n    if word.isdigit():\n        return word\n    if word.isidentifier():\n        return word\n    if word.isprintable():\n        return word\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word.isspace():\n        return word\n    if word.isnumeric():\n        return word\n    if word.isalpha():\n        return word\n    if word.isalnum():\n        return word\n    if word.isascii():\n        return word\n    if word.isdecimal():\n        return word\n    if word.isdigit():\n        return word\n    if word.isidentifier():\n        return word\n    if word.isprintable():\n        return word\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word.isspace():\n        return word\n    if word.isnumeric():\n        return word\n    if word.isalpha():\n        return word\n    if word.isalnum():\n        return word\n    if word.isascii():\n        return word\n    if word.isdecimal():\n        return word\n    if word.isdigit():\n        return word\n    if word.isidentifier():\n        return word\n    if word.isprintable():\n        return word\n    if word.islower():\n        return word\n    if word.isupper():\n        return word\n    if word.istitle():\n        return word\n    if word.isspace():\n        return"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word.lower()\n    if word.islower():\n        return word.upper()\n    if len(word) == 1:\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    return word.lower()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.capitalize()\n    if word[0].isupper() and word[1].islower():\n        return word.upper()\n    if word[0].islower() and word[1].isupper():\n        return word.capitalize()\n    return word.lower()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n\n    # if first letter is upper\n    if word[0].isupper():\n        # if second letter is also upper\n        if word[1].isupper():\n            # if rest of the word is upper\n            if word[2:].isupper():\n                return word\n            # if rest of the word is lower\n            else:\n                return word.capitalize()\n        # if second letter is lower\n        else:\n            # if rest of the word is upper\n            if word[2:].isupper():\n                return word.upper()\n            # if rest of the word is lower\n            else:\n                return word.capitalize()\n    # if first letter is lower\n    else:\n        # if second letter is upper\n        if word[1].isupper():\n            # if rest of the word is upper\n            if word[2:].isupper():\n                return word.lower()\n            # if rest of the word is lower\n            else:\n                return word\n        # if second letter is lower\n        else:\n            # if rest of the word is upper\n            if word[2:].isupper():\n                return word.lower()\n            # if rest of the word is lower\n            else:\n                return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    elif word.islower():\n        return word\n    else:\n        if word[0].isupper() and word[1].isupper():\n            return word.upper()\n        elif word[0].isupper() and word[1].islower():\n            return word.capitalize()\n        else:\n            return word.lower()\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n    if word[0].isupper() and word[1].islower():\n        return word.capitalize()\n    if word[0].islower() and word[1].isupper():\n        return word.lower()\n    return word\n\n"}
{"namespace": "nlm_ingestor.ingestor.formatter.fix_mixedcase_words", "completion": "    if word.isupper():\n        return word\n    if word.islower():\n        return word\n\n    if word[0].isupper() and word[1].islower():\n        return word.lower()\n\n    if word[0].isupper() and word[1].isupper():\n        return word.upper()\n\n    return word.capitalize()\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values. Found {v.dtype}.\"\n        )\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values. Found {v.dtype}.\"\n        )\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.array_equal(v, v.astype(bool)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values. Found {v.dtype}.\"\n        )\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values, not {v.dtype}.\"\n        )\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.array_equal(v, v.astype(bool)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array. Found {v.dtype}.\"\n        )\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != np.bool_:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be an array of booleans, not {v.dtype}.\"\n        )\n\n    return v"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.array_equal(v, v.astype(bool)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.array_equal(v, v.astype(bool)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values, found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values. Found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.array_equal(v, v.astype(bool)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be binary. Found {v.dtype} instead.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values. Found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array. Found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.array_equal(v, v.astype(bool)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values. Found: {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.array_equal(v, v.astype(bool)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only binary values. Found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values. Got {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values. Found: {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != np.bool_:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be binary, but it contains {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.array_equal(v, v.astype(bool)):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values. Got {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if not np.issubdtype(v.dtype, np.bool_):\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a binary array. Found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "iris.io.validators.is_binary", "completion": "    if v.dtype != bool:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only boolean values. Found {v.dtype}.\"\n        )\n\n    return v\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag) - 1) / x_mag\n  z = scale * x\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Calculate the norm of the input array\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  # Calculate the scaling factor based on the norm\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  # Apply the scaling factor to the input array\n  z = scale * x\n  # Return the scaled version of the input array\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Calculate the norm of the input array\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n\n  # Calculate the scaling factor based on the norm\n  scale = (2 * jnp.sqrt(x_norm) - 1) / x_norm\n\n  # Apply the scaling operation to the input array\n  z = scale * x\n\n  return z"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n\n  # Calculate the scaling factor using the norm\n  scale = 2 * jnp.sqrt(x_norm) - x_norm\n\n  # Apply the scaling factor to the input array\n  scaled_x = scale * x\n\n  # Return the scaled array\n  return scaled_x"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Calculate the norm of the input array.\n  x_norm = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n\n  # Calculate the scaling factor based on the norm.\n  scale_factor = (2 * jnp.sqrt(x_norm) - 1) / x_norm\n\n  # Apply the scaling factor to the input array.\n  scaled_x = scale_factor * x\n\n  # Return the scaled version of the input array.\n  return scaled_x"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Calculate the norm of the input array.\n  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  # Calculate the scaling factor based on the norm.\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  # Apply the scaling factor to the input array.\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array.\n  x_norm = jnp.linalg.norm(x, axis=-1)\n\n  # Compute the scaling factor based on the norm.\n  scale_factor = 1.0 - 1.0 / (1.0 + x_norm ** 2)\n\n  # Apply the scaling factor to the input array.\n  return scale_factor * x"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Calculate the norm of the input array\n  x_mag = jnp.sqrt(jnp.sum(x**2, axis=-1, keepdims=True))\n\n  # Apply the isotropic scaling operation based on the norm\n  scale = (2 * jnp.sqrt(x_mag) - 1) / x_mag\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  x_mag_sq = jnp.maximum(1, jnp.sum(x**2, axis=-1, keepdims=True))\n  scale = (2 * jnp.sqrt(x_mag_sq) - 1) / x_mag_sq\n  z = scale * x\n  return z\n\n"}
{"namespace": "coord.contract3_isoscale", "completion": "  # Compute the norm of the input array\n  x_norm = jnp.linalg.norm(x, axis=-1)\n  # Apply the isotropic scaling operation\n  return (2 * jnp.sqrt(x_norm) - 1) / x_norm * x\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(ast.literal_eval)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(lambda x: ast.literal_eval(x))\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    summary_df = pd.read_csv(summary_path)\n    if dict_columns is None:\n        dict_columns = ['module_params']\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(lambda x: ast.literal_eval(x))\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for dict_column in dict_columns:\n        summary_df[dict_column] = summary_df[dict_column].apply(lambda x: ast.literal_eval(x))\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path, sep='\\t')\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column_name in dict_columns:\n        summary_df[column_name] = summary_df[column_name].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    if not os.path.exists(summary_path):\n        raise FileNotFoundError(f\"Summary file not found at {summary_path}\")\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path, sep='\\t')\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x) if x != '{}' else {})\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    if not os.path.isfile(summary_path):\n        raise FileNotFoundError(f\"The summary file '{summary_path}' does not exist.\")\n\n    summary_df = pd.read_csv(summary_path)\n\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    def convert_dict_string_to_dict(dict_string: str) -> Dict[str, Any]:\n        \"\"\"\n        Converts a dictionary-like string into an actual dictionary object.\n\n        :param dict_string: str, The dictionary-like string to be converted.\n        :return: Dict[str, Any], The converted dictionary object.\n        \"\"\"\n        try:\n            return ast.literal_eval(dict_string)\n        except (ValueError, SyntaxError):\n            return {}\n\n    summary_df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(convert_dict_string_to_dict)\n\n    return summary_df"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if not dict_columns:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path, sep='\\t')\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n\n    for col in dict_columns:\n        if col in summary_df.columns:\n            summary_df[col] = summary_df[col].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for col in dict_columns:\n        summary_df[col] = summary_df[col].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n    summary_df = pd.read_csv(summary_path)\n    for column in dict_columns:\n        summary_df[column] = summary_df[column].apply(lambda x: ast.literal_eval(x))\n    return summary_df\n\n"}
{"namespace": "autorag.utils.util.load_summary_file", "completion": "    if dict_columns is None:\n        dict_columns = ['module_params']\n\n    summary_df = pd.read_csv(summary_path)\n    for dict_column in dict_columns:\n        summary_df[dict_column] = summary_df[dict_column].apply(lambda x: ast.literal_eval(x))\n\n    return summary_df\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n  elif mode == 'accurate':\n    det = jnp.exp(jnp.linalg.slogdet(cov)[1])\n  else:\n    raise ValueError(f'Unknown mode {mode}')\n  eps = jnp.finfo(jnp.float32).tiny\n  det = jnp.maximum(eps, det)\n  d = cov.shape[-1]\n  # Equivalent to cbrt((2 * sqrt(det) - 1) ** 2) / det:\n  scale = jnp.exp(2 / d * jnp.log(2 * jnp.sqrt(det) - 1) - jnp.log(det))\n  return cov * scale[Ellipsis, None, None]"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Fast mode: use the determinant directly.\n    det = jnp.linalg.det(cov)\n  elif mode == 'accurate':\n    # Accurate mode: use the logarithm of the determinant for stability.\n    det = jnp.exp(jnp.linalg.slogdet(cov)[1])\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n\n  # Check if the determinant is valid.\n  if jnp.any(jnp.isnan(det)) or jnp.any(det == 0):\n    raise ValueError('Invalid determinant')\n\n  # Compute the isotropic covariance matrices.\n  d = cov.shape[-1]\n  eye = jnp.eye(d)\n  cov_iso = det ** (1 / d) * eye\n\n  return cov_iso"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n  elif mode == 'accurate':\n    det = jnp.exp(jnp.linalg.slogdet(cov)[1])\n  else:\n    raise ValueError(f'Unrecognized mode {mode}.')\n  if jnp.isclose(det, 0):\n    raise ValueError('Cannot isotropize a covariance matrix with zero determinant.')\n  return det ** (1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])"}
{"namespace": "coord.isotropize", "completion": "  # Compute the determinant of the input covariance matrices.\n  det = jnp.linalg.det(cov)\n\n  # Check for invalid determinants.\n  if jnp.any(det <= 0):\n    raise ValueError('Invalid determinant encountered.')\n\n  # Compute the logarithm of the determinant for stability.\n  log_det = jnp.log(det)\n\n  # Check for invalid logarithms of determinants.\n  if jnp.any(jnp.isinf(log_det)):\n    raise ValueError('Invalid logarithm of determinant encountered.')\n\n  # Compute the isotropic covariance matrices.\n  if mode == 'fast':\n    # Compute the isotropic covariance matrices using the determinant directly.\n    iso_cov = cov / jnp.sqrt(det[Ellipsis, None, None])\n  elif mode == 'accurate':\n    # Compute the isotropic covariance matrices using the logarithm of the determinant.\n    iso_cov = cov / jnp.exp(log_det[Ellipsis, None, None] / cov.shape[-1])\n  else:\n    # Raise an error for an invalid mode.\n    raise ValueError(f'Invalid mode: {mode}')\n\n  # Return the isotropic covariance matrices.\n  return iso_cov"}
{"namespace": "coord.isotropize", "completion": "  eps = jnp.finfo(jnp.float32).tiny  # Guard against an inf gradient at 0.\n  if mode == 'fast':\n    cov_diag = jnp.diagonal(cov, axis1=-2, axis2=-1)\n    cov_diag_mean = jnp.mean(cov_diag, axis=-1, keepdims=True)\n    cov_diag_mean = jnp.broadcast_to(cov_diag_mean, cov_diag.shape)\n    cov_diag_mean = jnp.clip(cov_diag_mean, eps)\n    cov_diag_mean = jnp.broadcast_to(cov_diag_mean, cov.shape)\n    cov = cov_diag_mean\n  elif mode == 'accurate':\n    cov_diag = jnp.diagonal(cov, axis1=-2, axis2=-1)\n    cov_diag_mean = jnp.mean(cov_diag, axis=-1, keepdims=True)\n    cov_diag_mean = jnp.broadcast_to(cov_diag_mean, cov_diag.shape)\n    cov_diag_mean = jnp.clip(cov_diag_mean, eps)\n    cov_diag_mean = jnp.broadcast_to(cov_diag_mean, cov.shape)\n    cov_diag_mean = jnp.sqrt(cov_diag_mean)\n    cov = cov / cov_diag_mean / jnp.sqrt(cov_diag_mean)\n  else:\n    raise ValueError(f'Unknown mode {mode}.')\n  return cov"}
{"namespace": "coord.isotropize", "completion": "  # Compute the determinant of the covariance matrix.\n  det = jnp.linalg.det(cov)\n\n  # Check if the determinant is invalid (i.e., zero or negative).\n  if mode == 'fast':\n    # If the determinant is invalid, return the input covariance matrix.\n    if det <= 0:\n      return cov\n    # Otherwise, compute the square root of the determinant.\n    det_sqrt = jnp.sqrt(det)\n  else:\n    # If the determinant is invalid, return the input covariance matrix.\n    if det <= 0:\n      return cov\n    # Otherwise, compute the logarithm of the determinant.\n    det_sqrt = jnp.exp(0.5 * jnp.log(det))\n\n  # Compute the inverse of the covariance matrix.\n  inv_cov = jnp.linalg.inv(cov)\n\n  # Compute the trace of the inverse covariance matrix.\n  trace_inv_cov = jnp.trace(inv_cov, axis1=-2, axis2=-1)\n\n  # Compute the inverse of the trace of the inverse covariance matrix.\n  inv_trace_inv_cov = 1.0 / trace_inv_cov\n\n  # Compute the isotropic covariance matrix.\n  iso_cov = inv_cov * inv_trace_inv_cov * det_sqrt\n\n  # Return the isotropic covariance matrix.\n  return iso_cov"}
{"namespace": "coord.isotropize", "completion": "  # Compute the determinant of the input covariance matrix or matrices.\n  det = jnp.linalg.det(cov)\n\n  # Check if the determinant is negative or zero.\n  if jnp.any(det <= 0):\n    # If the determinant is negative or zero, raise a ValueError.\n    raise ValueError('Invalid determinant.')\n\n  # Compute the logarithm of the determinant.\n  log_det = jnp.log(det)\n\n  # Check if the logarithm of the determinant is infinite.\n  if jnp.any(jnp.isinf(log_det)):\n    # If the logarithm of the determinant is infinite, raise a ValueError.\n    raise ValueError('Invalid log determinant.')\n\n  # Compute the inverse of the input covariance matrix or matrices.\n  inv_cov = jnp.linalg.inv(cov)\n\n  # Compute the eigenvalues and eigenvectors of the inverse covariance matrix or matrices.\n  eigval, eigvec = jnp.linalg.eigh(inv_cov)\n\n  # Compute the logarithm of the eigenvalues.\n  log_eigval = jnp.log(eigval)\n\n  # Check if any of the eigenvalues are infinite.\n  if jnp.any(jnp.isinf(eigval)):\n    # If any of the eigenvalues are infinite, raise a ValueError.\n    raise ValueError('Invalid eigenvalues.')\n\n  # Compute the mean of the logarithm of the eigenvalues.\n  mean_log_eigval = jnp.mean(log_eigval, axis=-1, keepdims=True)\n\n  # Compute the isotropic covariance matrix or matrices using the mean of the logarithm of the eigenvalues.\n  if mode == 'fast':\n    # If the mode is 'fast', compute the isotropic covariance matrix or matrices using the determinant directly.\n    iso_cov = jnp.exp(mean_log_eigval) * inv_cov\n  elif mode == 'accurate':\n    # If the mode is 'accurate', compute the isotropic covariance matrix or matrices using"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    d = jnp.linalg.det(cov) ** (1 / cov.shape[-1])\n  elif mode == 'accurate':\n    d = jnp.exp(jnp.log(jnp.linalg.det(cov)) / cov.shape[-1])\n  else:\n    raise ValueError(f'Invalid mode {mode}')\n\n  # Check for invalid determinants\n  if jnp.any(jnp.isnan(d)) or jnp.any(jnp.isinf(d)):\n    raise ValueError('Invalid determinant')\n\n  # Compute the isotropic covariance matrices\n  return d * jnp.eye(cov.shape[-1])\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Check if the input is a single covariance matrix or a batch of covariance matrices\n  if cov.ndim == 2:\n    cov_shape = cov.shape\n  elif cov.ndim == 3:\n    cov_shape = cov.shape[:-2]\n  else:\n    raise ValueError(\n        f'Input covariance matrix or matrices must have either 2 or 3 dimensions, '\n        f'but got {cov.ndim} dimensions.'\n    )\n\n  # Compute the determinant of the input covariance matrix or matrices\n  det = jnp.linalg.det(cov)\n\n  # Check if the determinant is positive\n  if jnp.any(det <= 0):\n    raise ValueError(\n        f'Input covariance matrix or matrices must have positive determinant, '\n        f'but got determinant {det}.'\n    )\n\n  # Compute the logarithm of the determinant for numerical stability\n  log_det = jnp.log(det)\n\n  # Compute the isotropic covariance matrix or matrices with the same determinant as the input covariance matrix or matrices\n  if mode == 'fast':\n    # Compute the isotropic covariance matrix or matrices with the same determinant as the input covariance matrix or matrices using the determinant directly\n    cov_diag = jnp.diagonal(cov, axis1=-2, axis2=-1)\n    cov_diag_mean = jnp.mean(cov_diag, axis=-1, keepdims=True)\n    cov_diag_mean_tile = jnp.tile(cov_diag_mean, (1, cov.shape[-1]))\n    cov_diag_mean_tile = jnp.reshape(\n        cov_diag_mean_tile, cov_shape + (cov.shape[-1],)\n    )\n    cov_diag_mean_tile = jnp.broadcast_to(\n        cov_diag_mean_tile, cov.shape[:-2] + (cov.shape[-1], cov.shape[-1])\n    )\n    cov_diag_mean_tile = jnp.tile("}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n  elif mode == 'accurate':\n    det = jnp.exp(jnp.linalg.slogdet(cov)[1])\n  else:\n    raise ValueError(f'Unknown mode: {mode}')\n  if jnp.any(det <= 0):\n    raise ValueError(f'Invalid determinant: {det}')\n  if mode == 'fast':\n    return jnp.eye(cov.shape[-1]) * det\n  elif mode == 'accurate':\n    return jnp.eye(cov.shape[-1]) * jnp.sqrt(det)\n\n"}
{"namespace": "coord.isotropize", "completion": "  # Compute the determinant of the input covariance matrices.\n  det = jnp.linalg.det(cov)\n\n  # Check if the determinant is valid. If not, return the input covariance matrices.\n  if jnp.any(jnp.isnan(det)) or jnp.any(jnp.isinf(det)) or jnp.any(det <= 0):\n    return cov\n\n  # Compute the logarithm of the determinant.\n  log_det = jnp.log(det)\n\n  # Check if the logarithm of the determinant is valid. If not, return the input covariance matrices.\n  if jnp.any(jnp.isnan(log_det)) or jnp.any(jnp.isinf(log_det)):\n    return cov\n\n  # Compute the isotropic covariance matrices using the specified mode.\n  if mode == 'fast':\n    return det ** (-1 / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  elif mode == 'accurate':\n    return jnp.exp(log_det / cov.shape[-1]) * jnp.eye(cov.shape[-1])\n  else:\n    raise ValueError(f'Invalid mode: {mode}')\n\n"}
{"namespace": "coord.isotropize", "completion": "  eps = jnp.finfo(jnp.float32).tiny  # Guard against an inf gradient at 0.\n  d = cov.shape[-1]\n  if mode == 'fast':\n    # Fast mode, but not accurate for small determinants.\n    det = jnp.maximum(eps, jnp.linalg.det(cov))\n    isotropic_cov = det ** (1 / d) * jnp.eye(d)\n  elif mode == 'accurate':\n    # Accurate mode, but not as fast as the fast mode.\n    # Compute the logarithm of the determinant of cov, but guard against\n    # taking the logarithm of a number too close to zero.\n    log_det = jnp.maximum(\n        jnp.log(eps), jnp.log(jnp.maximum(eps, jnp.linalg.det(cov)))\n    )\n    isotropic_cov = jnp.exp(log_det / d) * jnp.eye(d)\n  else:\n    raise ValueError(f'Mode {mode} not recognized.')\n  return isotropic_cov"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    return cov / jnp.sqrt(jnp.linalg.det(cov))[Ellipsis, None, None]\n  elif mode == 'accurate':\n    log_det = jnp.linalg.slogdet(cov)[1]\n    if jnp.any(jnp.isnan(log_det)):\n      raise ValueError('log_det is nan')\n    if jnp.any(log_det == 0):\n      raise ValueError('log_det is zero')\n    return cov / jnp.sqrt(jnp.exp(log_det))[Ellipsis, None, None]\n  else:\n    raise ValueError(f'Unknown mode {mode}')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    return cov / jnp.sqrt(jnp.linalg.det(cov))\n  elif mode == 'accurate':\n    # Compute the logarithm of the determinant of the covariance matrix.\n    logdet = jnp.linalg.slogdet(cov)[1]\n    # Compute the logarithm of the determinant of the identity matrix.\n    logdet_I = jnp.log(jnp.linalg.det(jnp.eye(cov.shape[-1])))\n    # Compute the logarithm of the determinant of the isotropic covariance matrix.\n    logdet_isotropic = logdet - logdet_I\n    # Compute the isotropic covariance matrix.\n    return cov / jnp.exp(0.5 * logdet_isotropic)\n  else:\n    raise ValueError(f\"Invalid mode: {mode}\")\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Fast mode: use the determinant directly.\n    det = jnp.linalg.det(cov)\n  elif mode == 'accurate':\n    # Accurate mode: use the logarithm of the determinant for stability.\n    det = jnp.exp(jnp.linalg.slogdet(cov)[1])\n  else:\n    raise ValueError(f'Invalid mode {mode}.')\n\n  # Check for invalid determinants.\n  if jnp.any(jnp.isnan(det)):\n    raise ValueError('NaN detected in determinant.')\n  if jnp.any(det <= 0):\n    raise ValueError('Non-positive determinant.')\n\n  # Compute the isotropic covariance matrix.\n  d = cov.shape[-1]\n  eye = jnp.eye(d)\n  return det ** (1 / d) * eye\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # Fast mode: use the determinant directly.\n    d = jnp.linalg.det(cov)\n    d = jnp.maximum(d, jnp.finfo(jnp.float32).tiny)\n    return cov * jnp.eye(cov.shape[-1]) * jnp.sqrt(1 / d)\n  elif mode == 'accurate':\n    # Accurate mode: use the logarithm of the determinant.\n    # This is more stable, but more expensive.\n    d = jnp.linalg.slogdet(cov)[1]\n    d = jnp.maximum(d, jnp.finfo(jnp.float32).tiny)\n    return cov * jnp.eye(cov.shape[-1]) * jnp.exp(-0.5 * jnp.log(d))\n  else:\n    raise ValueError(f\"Invalid mode: {mode}\")\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n  elif mode == 'accurate':\n    det = jnp.exp(jnp.linalg.slogdet(cov)[1])\n  else:\n    raise ValueError(f'Invalid mode: {mode}.')\n  if det <= 0:\n    raise ValueError('Invalid determinant.')\n  dim = cov.shape[-1]\n  # Compute the isotropic covariance matrices.\n  isotropic_cov = jnp.eye(dim) * (det ** (1 / dim))\n  return isotropic_cov\n\n"}
{"namespace": "coord.isotropize", "completion": "  eps = jnp.finfo(jnp.float32).tiny  # Guard against an inf gradient at 0.\n  if mode == 'accurate':\n    # Compute the log determinant of the covariance matrix.\n    log_det = jnp.linalg.slogdet(cov)[1]\n    log_det = jnp.clip(log_det, a_min=jnp.log(eps))\n    # Compute the isotropic covariance matrix.\n    cov_iso = jnp.eye(cov.shape[-1]) * jnp.exp(log_det / cov.shape[-1])\n  elif mode == 'fast':\n    # Compute the determinant of the covariance matrix.\n    det = jnp.linalg.det(cov)\n    det = jnp.clip(det, a_min=eps)\n    # Compute the isotropic covariance matrix.\n    cov_iso = jnp.eye(cov.shape[-1]) * jnp.sqrt(det)\n  else:\n    raise ValueError(f'Unknown mode: {mode}')\n  return cov_iso\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    det = jnp.linalg.det(cov)\n    eps = jnp.finfo(jnp.float32).eps\n    if jnp.any(det < eps):\n      raise ValueError(\n          'Covariance matrix determinants are too small to compute isotropic '\n          'covariances. This is likely due to a precision loss. Please use '\n          '`mode=\"accurate\"` if you want to compute isotropic covariances.'\n      )\n    d = jnp.sqrt(det)\n    return jnp.broadcast_to(jnp.eye(cov.shape[-1]) * d, cov.shape)\n\n  elif mode == 'accurate':\n    log_det = jnp.linalg.slogdet(cov)[1]\n    if jnp.any(jnp.isinf(log_det)):\n      raise ValueError(\n          'Covariance matrix determinants are too small to compute isotropic '\n          'covariances. This is likely due to a precision loss. Please use '\n          '`mode=\"fast\"` if you want to compute isotropic covariances.'\n      )\n    d = jnp.exp(log_det / cov.shape[-1])\n    return jnp.broadcast_to(jnp.eye(cov.shape[-1]) * d, cov.shape)\n\n  else:\n    raise ValueError(f'Invalid mode: {mode}.')\n\n"}
{"namespace": "coord.isotropize", "completion": "  if mode == 'fast':\n    # This is a fast mode that uses the determinant directly.\n    det = jnp.linalg.det(cov)\n    if jnp.isnan(det):\n      raise ValueError('Invalid determinant in isotropize.')\n    return jnp.eye(cov.shape[-1]) * det ** (1 / cov.shape[-1])\n  elif mode == 'accurate':\n    # This is a more accurate mode that uses the logarithm of the determinant.\n    log_det = jnp.linalg.slogdet(cov)[1]\n    if jnp.isnan(log_det):\n      raise ValueError('Invalid log determinant in isotropize.')\n    return jnp.eye(cov.shape[-1]) * jnp.exp(log_det / cov.shape[-1])\n  else:\n    raise ValueError('Invalid mode in isotropize.')\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent Command Line Interface\")\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"The task description, specifying what task should be performed.\",\n    )\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        nargs=\"+\",\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n    )\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\",\n    )\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n    )\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n    )\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n    )\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n    )\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        help=\"Flag to enable asking for human assistance during task execution.\",\n    )\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\",\n    )\n    parser.add_argument(\n        \"--max-plan-tree-depth\",\n        type=int,\n        help=\"Maximum depth of"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent Command Line Interface\")\n\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"The task description, specifying what task should be performed.\",\n    )\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        nargs=\"+\",\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n    )\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\",\n    )\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n    )\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n    )\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n    )\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n    )\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        help=\"Flag to enable asking for human assistance during task execution.\",\n    )\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\",\n    )\n    parser.add_argument(\n        \"--max-plan-tree-depth\",\n        type=int,\n        help=\"Maximum depth"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent Command Line Interface\")\n\n    parser.add_argument(\n        \"--task\",\n        type=str,\n        required=True,\n        help=\"Task description, specifying what task should be performed.\",\n    )\n\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        nargs=\"+\",\n        help=\"List of files to upload, allowing multiple files to be specified.\",\n    )\n\n    parser.add_argument(\n        \"--model\",\n        type=str,\n        help=\"Model identifier for the task, specifying which model to use.\",\n    )\n\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        help=\"Directory to record task execution logs, specifying where to save the logs.\",\n    )\n\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        choices=[\"auto\", \"manual\"],\n        default=\"auto\",\n        help=\"Operational mode, which can be 'auto' or 'manual', specifying how the task should be executed.\",\n    )\n\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        default=False,\n        help=\"If set, the program runs in quiet mode with minimal output.\",\n    )\n\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be.\",\n    )\n\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        help=\"Flag to enable asking for human assistance during task execution.\",\n    )\n\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans.\",\n    )\n\n    parser.add_argument("}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent command line interface\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"Task description\")\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        nargs=\"+\",\n        help=\"List of files to upload, allowing multiple files to be specified\",\n    )\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task\")\n    parser.add_argument(\n        \"--record-dir\", type=str, help=\"Directory to record task execution logs\"\n    )\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        default=\"auto\",\n        choices=[\"auto\", \"manual\"],\n        help=\"Operational mode, which can be 'auto' or 'manual'\",\n    )\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        default=False,\n        help=\"If set, the program runs in quiet mode with minimal output\",\n    )\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain, specifying how long a subtask chain can be\",\n    )\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        help=\"Flag to enable asking for human assistance during task execution\",\n    )\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain, specifying the limit for refining plans\",\n    )\n    parser.add_argument(\n        \"--max-plan-tree-depth\",\n        type=int,\n        help=\"Maximum depth of the plan tree, specifying how deep the plan tree can be\",\n    )\n    parser.add_argument(\n        \"--max-plan-tree-width\",\n        type="}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent Command Line Interface\")\n\n    parser.add_argument(\"--task\", type=str, required=True, help=\"Task description\")\n    parser.add_argument(\n        \"--upload-files\", nargs=\"+\", type=str, help=\"List of files to upload\"\n    )\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier for the task\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs\")\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        choices=[\"auto\", \"manual\"],\n        default=\"auto\",\n        help=\"Operational mode\",\n    )\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"Run in quiet mode with minimal output\",\n    )\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        help=\"Maximum length of subtask chain\",\n    )\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        help=\"Enable asking for human assistance during task execution\",\n    )\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        help=\"Maximum length of plan refinement chain\",\n    )\n    parser.add_argument(\n        \"--max-plan-tree-depth\",\n        type=int,\n        help=\"Maximum depth of the plan tree\",\n    )\n    parser.add_argument(\n        \"--max-plan-tree-width\",\n        type=int,\n        help=\"Maximum width of the plan tree\",\n    )\n    parser.add_argument(\n        \"--max-retry-times\",\n        type=int,\n        help=\"Maximum number of retry attempts\",\n    )\n    parser.add_argument(\n        \"--config-"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent command line interface')\n\n    # Define the command line arguments\n    parser.add_argument('--task', type=str, required=True, help='Task description')\n    parser.add_argument('--upload-files', type=str, nargs='*', help='Files to upload')\n    parser.add_argument('--model', type=str, help='Model identifier')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode')\n    parser.add_argument('--quiet', action='store_true', help='Run in quiet mode')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Enable asking for human assistance')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file')\n\n    # Parse the command line arguments\n    args = parser.parse_args()\n\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent Command Line Interface\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"Task description\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"*\", help=\"Files to upload\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"Run in quiet mode\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Enable asking for human assistance\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts\")\n    parser.add_argument(\"--config-file\", type=str, default=os.environ.get(\"CONFIG_FILE\", \"assets/config.yml\"), help=\"Path to the configuration file\")\n    args = parser.parse_args()\n\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent command line interface')\n    parser.add_argument('--task', type=str, required=True, help='Task description')\n    parser.add_argument('--upload-files', type=str, nargs='*', help='List of files to upload')\n    parser.add_argument('--model', type=str, help='Model identifier')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode')\n    parser.add_argument('--quiet', action='store_true', help='Run in quiet mode')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file')\n\n    args = parser.parse_args()\n\n    # Update the global configuration with the command line arguments\n    CONFIG.update(vars(args))\n\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent command line interface')\n    parser.add_argument('--task', type=str, required=True, help='Task description')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='Files to upload')\n    parser.add_argument('--model', type=str, help='Model identifier')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs')\n    parser.add_argument('--mode', type=str, choices=['auto', 'manual'], default='auto', help='Operational mode')\n    parser.add_argument('--quiet', action='store_true', help='Run in quiet mode')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Enable asking for human assistance')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file')\n    args = parser.parse_args()\n\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='Task description')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload')\n    parser.add_argument('--model', type=str, help='Model identifier for the task')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode')\n    parser.add_argument('--quiet', action='store_true', help='Run in quiet mode')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file')\n    args = parser.parse_args()\n\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent command line interface')\n\n    parser.add_argument('--task', type=str, required=True, help='Task description')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='Files to upload')\n    parser.add_argument('--model', type=str, help='Model identifier')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode')\n    parser.add_argument('--quiet', action='store_true', help='Run in quiet mode')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file')\n\n    args = parser.parse_args()\n\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent command line arguments.\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"Task description.\")\n    parser.add_argument(\"--upload-files\", type=str, nargs=\"+\", help=\"Files to upload.\")\n    parser.add_argument(\"--model\", type=str, help=\"Model identifier.\")\n    parser.add_argument(\"--record-dir\", type=str, help=\"Directory to record task execution logs.\")\n    parser.add_argument(\"--mode\", type=str, default=\"auto\", help=\"Operational mode.\")\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"Run in quiet mode.\")\n    parser.add_argument(\"--max-subtask-chain-length\", type=int, help=\"Maximum length of subtask chain.\")\n    parser.add_argument(\"--enable-ask-human-for-help\", action=\"store_true\", help=\"Enable asking for human assistance.\")\n    parser.add_argument(\"--max-plan-refine-chain-length\", type=int, help=\"Maximum length of plan refinement chain.\")\n    parser.add_argument(\"--max-plan-tree-depth\", type=int, help=\"Maximum depth of the plan tree.\")\n    parser.add_argument(\"--max-plan-tree-width\", type=int, help=\"Maximum width of the plan tree.\")\n    parser.add_argument(\"--max-retry-times\", type=int, help=\"Maximum number of retry attempts.\")\n    parser.add_argument(\"--config-file\", type=str, default=os.environ.get(\"CONFIG_FILE\", \"assets/config.yml\"), help=\"Path to the configuration file.\")\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='Task description')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='Files to upload')\n    parser.add_argument('--model', type=str, help='Model identifier')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode (auto or manual)')\n    parser.add_argument('--quiet', action='store_true', help='Run in quiet mode')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file')\n\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent Command Line Interface')\n    parser.add_argument('--task', type=str, required=True, help='Task description')\n    parser.add_argument('--upload-files', nargs='+', type=str, help='List of files to upload')\n    parser.add_argument('--model', type=str, help='Model identifier')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode')\n    parser.add_argument('--quiet', action='store_true', help='Run in quiet mode')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file')\n    args = parser.parse_args()\n\n    # Update ARGS with the parsed arguments\n    ARGS.update(vars(args))\n\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"Command-line interface for XAgent.\")\n    parser.add_argument(\"--task\", type=str, required=True, help=\"Task description.\")\n    parser.add_argument(\n        \"--upload-files\",\n        type=str,\n        nargs=\"*\",\n        default=[],\n        help=\"List of files to upload.\",\n    )\n    parser.add_argument(\n        \"--model\", type=str, default=\"gpt-3.5-turbo\", help=\"Model identifier for the task.\"\n    )\n    parser.add_argument(\n        \"--record-dir\",\n        type=str,\n        default=\"assets/records\",\n        help=\"Directory to record task execution logs.\",\n    )\n    parser.add_argument(\n        \"--mode\",\n        type=str,\n        choices=[\"auto\", \"manual\"],\n        default=\"auto\",\n        help=\"Operational mode.\",\n    )\n    parser.add_argument(\n        \"--quiet\", action=\"store_true\", default=False, help=\"Run in quiet mode.\"\n    )\n    parser.add_argument(\n        \"--max-subtask-chain-length\",\n        type=int,\n        default=5,\n        help=\"Maximum length of subtask chain.\",\n    )\n    parser.add_argument(\n        \"--enable-ask-human-for-help\",\n        action=\"store_true\",\n        default=False,\n        help=\"Enable asking for human assistance.\",\n    )\n    parser.add_argument(\n        \"--max-plan-refine-chain-length\",\n        type=int,\n        default=5,\n        help=\"Maximum length of plan refinement chain.\",\n    )\n    parser.add_argument(\n        \"--max-plan-tree-depth\", type=int, default=5, help=\"Maximum depth of the plan tree.\"\n    )\n    parser.add_argument(\n        \"--max-plan-tree-width\",\n        type=int,\n        default=5,"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent: An Agent with the ability to execute tasks.')\n    parser.add_argument('--task', type=str, required=True, help='Task description.')\n    parser.add_argument('--upload-files', nargs='+', type=str, default=[], help='List of files to upload.')\n    parser.add_argument('--model', type=str, default='gpt-3.5-turbo', help='Model identifier for the task.')\n    parser.add_argument('--record-dir', type=str, default='assets/records', help='Directory to record task execution logs.')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode.')\n    parser.add_argument('--quiet', action='store_true', default=False, help='Run in quiet mode with minimal output.')\n    parser.add_argument('--max-subtask-chain-length', type=int, default=3, help='Maximum length of subtask chain.')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', default=False, help='Enable asking for human assistance during task execution.')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, default=3, help='Maximum length of plan refinement chain.')\n    parser.add_argument('--max-plan-tree-depth', type=int, default=3, help='Maximum depth of the plan tree.')\n    parser.add_argument('--max-plan-tree-width', type=int, default=3, help='Maximum width of the plan tree.')\n    parser.add_argument('--max-retry-times', type=int, default=3, help='Maximum number of retry attempts.')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent: A General Agent for Anything')\n    parser.add_argument('--task', type=str, required=True, help='Task description')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='Files to upload')\n    parser.add_argument('--model', type=str, help='Model identifier')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', help='Operational mode')\n    parser.add_argument('--quiet', action='store_true', help='Run in quiet mode')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file')\n\n    args = parser.parse_args()\n\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description='XAgent')\n    parser.add_argument('--task', type=str, required=True, help='Task description')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='Files to upload')\n    parser.add_argument('--model', type=str, help='Model identifier')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode')\n    parser.add_argument('--quiet', action='store_true', help='Quiet mode')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Enable asking for human assistance')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file')\n    args = parser.parse_args()\n\n    # Set the global ARGS variable to the parsed arguments\n    global ARGS\n    ARGS = args\n\n    # Return the parsed arguments\n    return args\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser()\n    parser.add_argument('--task', type=str, required=True, help='Task description')\n    parser.add_argument('--upload-files', type=str, nargs='+', help='List of files to upload')\n    parser.add_argument('--model', type=str, help='Model identifier for the task')\n    parser.add_argument('--record-dir', type=str, help='Directory to record task execution logs')\n    parser.add_argument('--mode', type=str, default='auto', choices=['auto', 'manual'], help='Operational mode')\n    parser.add_argument('--quiet', action='store_true', help='Run in quiet mode with minimal output')\n    parser.add_argument('--max-subtask-chain-length', type=int, help='Maximum length of subtask chain')\n    parser.add_argument('--enable-ask-human-for-help', action='store_true', help='Enable asking for human assistance during task execution')\n    parser.add_argument('--max-plan-refine-chain-length', type=int, help='Maximum length of plan refinement chain')\n    parser.add_argument('--max-plan-tree-depth', type=int, help='Maximum depth of the plan tree')\n    parser.add_argument('--max-plan-tree-width', type=int, help='Maximum width of the plan tree')\n    parser.add_argument('--max-retry-times', type=int, help='Maximum number of retry attempts')\n    parser.add_argument('--config-file', type=str, default=os.environ.get('CONFIG_FILE', 'assets/config.yml'), help='Path to the configuration file')\n    return parser.parse_args()\n\n"}
{"namespace": "run.parse_args", "completion": "    parser = argparse.ArgumentParser(description=\"XAgent: An AI-Powered Task Executor\")\n\n    # Add arguments for each command line parameter\n    for param in CommandLineParam:\n        parser.add_argument(\n            f\"--{param.name.replace('_', '-')}\",\n            type=param.type,\n            default=param.default,\n            help=param.help,\n            required=param.required,\n            nargs=param.nargs,\n            choices=param.choices,\n        )\n\n    # Parse command line arguments\n    args = parser.parse_args()\n\n    # Set configuration file path\n    args.config_file = os.environ.get(\"CONFIG_FILE\", \"assets/config.yml\")\n\n    return args\n\n"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\"\n        )\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\"\n        )\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\"\n        )\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\"\n        )\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of points. got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of points. got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of points. got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of points.\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[-1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points. got shape {v.shape}\"\n        )\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be a list of points. got shape {v.shape}\")\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of points. got shape {v.shape}\"\n        )\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points, i.e. (_, 2). got shape {v.shape}\"\n        )\n\n    return v"}
{"namespace": "iris.io.validators.is_list_of_points", "completion": "    if v.shape[1] != 2:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must be a list of 2D points, i.e. (_, 2). got {v.shape}\"\n        )\n\n    return v"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    # Check if the input is a valid integer\n    if not isinstance(n, int):\n        raise TypeError(\"Input must be an integer.\")\n\n    # Check if the input is within the valid range\n    if n < 0 or n >= len(character_set):\n        raise ValueError(\"Input must be within the valid range.\")\n\n    # Return the encoded character\n    return character_set[n]"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n    return character_set[n]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n    return character_set[n]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n    return character_set[n]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n\n    # Encode the integer into a single character\n    encoded_char = character_set[n]\n\n    return encoded_char\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    char_set = string.ascii_lowercase + string.digits + '_'\n    # Encode the integer into a single character\n    return char_set[n]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n    return character_set[n]\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n    # Encode the integer into a single character using the character set\n    encoded_char = character_set[n]\n    return encoded_char\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n\n    # Check if the input is within the range of the character set\n    if n < 0 or n >= len(character_set):\n        raise ValueError(\"Input out of range\")\n\n    # Return the encoded character\n    return character_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n\n    # Encode the integer using the character set\n    encoded_char = character_set[n]\n\n    return encoded_char\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n\n    # Check if n is within the range of the character set\n    if n < 0 or n >= len(character_set):\n        raise ValueError(\"Input integer out of range for encoding.\")\n\n    # Return the character at the specified index\n    return character_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n\n    # Check if the input integer is within the range of the character set\n    if n < 0 or n >= len(character_set):\n        raise ValueError(\"Input integer out of range\")\n\n    # Select the character from the character set based on the input integer\n    encoded_char = character_set[n]\n\n    return encoded_char\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n    # Encode the integer into a single character\n    encoded_char = character_set[n]\n    return encoded_char\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n    # Check if the input is within the range of the character set\n    if n < 0 or n >= len(character_set):\n        raise ValueError(\"Input integer out of range\")\n    # Return the character at the specified index\n    return character_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n    # Calculate the number of characters in the character set\n    base = len(character_set)\n    # If the input integer is less than the base, return the corresponding character from the character set\n    if n < base:\n        return character_set[n]\n    # Otherwise, recursively encode the integer by dividing it by the base and appending the encoded character\n    else:\n        return encode_int(n // base) + character_set[n % base]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set\n    charset = string.ascii_lowercase + string.digits + '_'\n\n    # Check if n is within the range of the character set\n    if n < 0 or n >= len(charset):\n        raise ValueError(\"Input integer out of range\")\n\n    # Return the corresponding character from the character set\n    return charset[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    # Define the character set for encoding\n    character_set = string.ascii_lowercase + string.digits + '_'\n\n    # Calculate the number of characters needed to represent the input integer\n    num_chars = len(character_set)\n\n    # Initialize an empty string to store the encoded characters\n    encoded_chars = ''\n\n    # Encode the integer by repeatedly dividing it by the number of characters and appending the corresponding character to the encoded string\n    while n > 0:\n        n, remainder = divmod(n, num_chars)\n        encoded_chars += character_set[remainder]\n\n    # Reverse the encoded string to get the correct order of characters\n    encoded_chars = encoded_chars[::-1]\n\n    # Return the encoded string\n    return encoded_chars\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n    if n < 0:\n        raise ValueError(\"Input must be a non-negative integer\")\n    if n >= len(character_set):\n        raise ValueError(\"Input is too large to encode\")\n    return character_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + \"_\"\n    # Check if the input is within the range of the character set\n    if n < 0 or n >= len(character_set):\n        raise ValueError(\"Input out of range for encoding\")\n    # Return the character at the specified index in the character set\n    return character_set[n]\n\n"}
{"namespace": "tanuki.utils.encode_int", "completion": "    character_set = string.ascii_lowercase + string.digits + '_'\n\n    # Calculate the length of the character set\n    base = len(character_set)\n\n    # Initialize an empty string to store the encoded character\n    encoded_char = ''\n\n    # Encode the integer by repeatedly dividing it by the base and selecting the corresponding character from the character set\n    while n > 0:\n        n, remainder = divmod(n, base)\n        encoded_char = character_set[remainder] + encoded_char\n\n    # Return the encoded character\n    return encoded_char\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(jnp.abs(x) > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "spin_math.safe_log", "completion": "  safe_x = jnp.where(x > eps, x, jnp.full_like(x, value_at_zero))\n  return jnp.log(safe_x)\n\n"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        chunks_index[worker_idx] = 0\n        for interval in intervals:\n            if indexes[worker_idx] >= interval[1] - interval[0]:\n                indexes[worker_idx] -= interval[1] - interval[0]\n                chunks_index[worker_idx] += 1\n            else:\n                break\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        chunks_index[worker_idx] = 0\n        for interval in intervals:\n            if indexes[worker_idx] >= interval[1] - interval[0]:\n                indexes[worker_idx] -= interval[1] - interval[0]\n                chunks_index[worker_idx] += 1\n            else:\n                break\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        chunks_index[worker_idx] = 0\n        for interval in intervals:\n            interval_size = interval[1] - interval[0]\n            if indexes[worker_idx] >= interval_size:\n                indexes[worker_idx] -= interval_size\n                chunks_index[worker_idx] += 1\n            else:\n                break\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_indexes[worker_idx] = 0\n        for interval in intervals:\n            if indexes[worker_idx] >= interval[1] - interval[0]:\n                indexes[worker_idx] -= interval[1] - interval[0]\n                chunk_indexes[worker_idx] += 1\n            else:\n                break\n\n    return chunk_indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        for interval in intervals:\n            if indexes[worker_idx] >= interval[1] - interval[0]:\n                indexes[worker_idx] -= interval[1] - interval[0]\n                chunk_index += 1\n            else:\n                break\n        chunks_index[worker_idx] = chunk_index\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        chunks_index[worker_idx] = 0\n        for interval in intervals:\n            if indexes[worker_idx] >= interval[1] - interval[0]:\n                indexes[worker_idx] -= interval[1] - interval[0]\n                chunks_index[worker_idx] += 1\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        chunk_index = 0\n        current_index = indexes[worker_idx]\n        for interval in intervals:\n            size = interval[1] - interval[0]\n            if current_index >= size:\n                current_index -= size\n                chunk_index += 1\n            else:\n                break\n        chunks_index[worker_idx] = chunk_index\n        indexes[worker_idx] = current_index\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        chunks_index[worker_idx] = 0\n\n    for worker_idx, intervals in workers_intervals.items():\n        for interval in intervals:\n            size = interval[1] - interval[0]\n            if size <= indexes[worker_idx]:\n                indexes[worker_idx] -= size\n                chunks_index[worker_idx] += 1\n            else:\n                break\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n        for interval in intervals:\n            chunk_size = interval[1] - interval[0]\n            if current_index >= chunk_size:\n                current_index -= chunk_size\n                chunk_index += 1\n            else:\n                break\n\n        chunks_index[worker_idx] = chunk_index\n        indexes[worker_idx] = current_index\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n        for interval in intervals:\n            size = interval[1] - interval[0]\n            if current_index < size:\n                chunks_index[worker_idx] = chunk_index\n                indexes[worker_idx] = current_index\n                break\n            current_index -= size\n            chunk_index += 1\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n        for interval in intervals:\n            size = interval[1] - interval[0]\n            if current_index < size:\n                break\n            current_index -= size\n            chunk_index += 1\n        chunk_indexes[worker_idx] = chunk_index\n        indexes[worker_idx] = current_index\n\n    return chunk_indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        chunks_index[worker_idx] = 0\n\n    for worker_idx in range(len(workers_intervals)):\n        intervals = workers_intervals[worker_idx]\n        for interval in intervals:\n            size = interval[1] - interval[0]\n            if indexes[worker_idx] >= size:\n                indexes[worker_idx] -= size\n                chunks_index[worker_idx] += 1\n            else:\n                break\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx in range(len(workers_intervals)):\n        chunks_index[worker_idx] = 0\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        for interval in intervals:\n            if current_index >= interval[1] - interval[0]:\n                current_index -= interval[1] - interval[0]\n                chunks_index[worker_idx] += 1\n            else:\n                indexes[worker_idx] = current_index\n                break\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        chunk_index = 0\n        for i, interval in enumerate(intervals):\n            interval_size = interval[1] - interval[0]\n            if current_index >= interval_size:\n                current_index -= interval_size\n                chunk_index += 1\n            else:\n                break\n        chunks_index[worker_idx] = chunk_index\n        indexes[worker_idx] = current_index\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        chunks_index[worker_idx] = 0\n\n        while True:\n            if indexes[worker_idx] >= intervals[chunks_index[worker_idx]][1] - intervals[chunks_index[worker_idx]][0]:\n                indexes[worker_idx] -= intervals[chunks_index[worker_idx]][1] - intervals[chunks_index[worker_idx]][0]\n                chunks_index[worker_idx] += 1\n            else:\n                break\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunks_index = {}\n    for worker_idx, intervals in workers_intervals.items():\n        chunks_index[worker_idx] = 0\n\n    for worker_idx, intervals in workers_intervals.items():\n        for i, interval in enumerate(intervals):\n            if indexes[worker_idx] >= interval[1] - interval[0]:\n                indexes[worker_idx] -= interval[1] - interval[0]\n                chunks_index[worker_idx] += 1\n            else:\n                break\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # Initialize the chunk index for each worker\n    chunks_index = {worker_idx: 0 for worker_idx in workers_intervals.keys()}\n\n    # Iterate through each worker's intervals\n    for worker_idx, intervals in workers_intervals.items():\n        # Iterate through each interval\n        for interval in intervals:\n            # Calculate the size of the interval\n            interval_size = interval[1] - interval[0]\n\n            # Check if the current index is within the current interval\n            if indexes[worker_idx] < interval_size:\n                # Update the current index within the current interval\n                indexes[worker_idx] -= interval_size\n                # Update the chunk index for the current worker\n                chunks_index[worker_idx] += 1\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    chunk_indexes = {}\n\n    for worker_idx, intervals in workers_intervals.items():\n        current_index = indexes[worker_idx]\n        for interval_idx, interval in enumerate(intervals):\n            if current_index < interval[1] - interval[0]:\n                chunk_indexes[worker_idx] = interval_idx\n                break\n            else:\n                current_index -= interval[1] - interval[0]\n        else:\n            chunk_indexes[worker_idx] = len(intervals) - 1\n\n    return chunk_indexes, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # Initialize variables\n    chunks_index = {}\n    for worker_idx in workers_intervals.keys():\n        chunks_index[worker_idx] = 0\n\n    # Iterate through each worker's intervals\n    for worker_idx, intervals in workers_intervals.items():\n        # Iterate through each interval\n        for interval in intervals:\n            # Calculate the size of the interval\n            interval_size = interval[1] - interval[0]\n\n            # If the current index is less than the size of the interval, update it\n            if indexes[worker_idx] < interval_size:\n                indexes[worker_idx] += interval_size\n                break\n\n            # If the current index is greater than or equal to the size of the interval, update the chunk index and reset the current index\n            else:\n                chunks_index[worker_idx] += 1\n                indexes[worker_idx] = indexes[worker_idx] - interval_size\n\n    return chunks_index, indexes"}
{"namespace": "litdata.streaming.dataset._replay_chunks_sampling", "completion": "    # calculate the chunk sizes for each worker\n    chunk_sizes = {worker_idx: len(intervals) for worker_idx, intervals in workers_intervals.items()}\n\n    # initialize the chunk index for each worker\n    chunks_index = {worker_idx: 0 for worker_idx in workers_intervals.keys()}\n\n    # iterate through each worker's intervals\n    for worker_idx, intervals in workers_intervals.items():\n        # get the current index for this worker\n        current_index = indexes[worker_idx]\n\n        # iterate through each interval for this worker\n        for interval_idx, interval in enumerate(intervals):\n            # get the size of this interval\n            interval_size = interval[1] - interval[0]\n\n            # if the current index is within this interval\n            if current_index < interval_size:\n                # update the chunk index for this worker\n                chunks_index[worker_idx] = interval_idx\n\n                # update the current index for this worker\n                indexes[worker_idx] = current_index\n\n                # break out of the loop since we've found the interval\n                break\n\n            # otherwise, subtract the size of this interval from the current index\n            else:\n                current_index -= interval_size\n\n    return chunks_index, indexes"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.grid_trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.hash_trilerp(values, coordinates)\n  else:\n    raise ValueError(f\"Unknown datastructure: {datastructure}\")\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilerp_3d(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilerp_3d(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.grid_trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.hash_trilerp(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure: {datastructure}')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = jnp.clip(coordinates, 0.0, values.shape[0] - 1.0)\n    return resample.trilerp_3d(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(f'Datastructure {datastructure} not supported.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  # Check if the datastructure is valid\n  if datastructure not in ['grid', 'hash']:\n    raise ValueError(f\"Invalid datastructure: {datastructure}\")\n\n  # If the datastructure is a grid, perform trilinear interpolation\n  if datastructure == 'grid':\n    return resample.trilerp(values, coordinates)\n\n  # If the datastructure is a hash, perform hash sampling\n  if datastructure == 'hash':\n    return hash_resample.hash_sample(values, coordinates)\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == \"grid\":\n    return resample.trilerp_grid(values, coordinates)\n  elif datastructure == \"hash\":\n    return resample.trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(\n        f\"Datastructure {datastructure} not supported. Choose 'grid' or 'hash'.\"\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilerp_3d(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilerp_2d(values, coordinates)\n  else:\n    raise ValueError(\n        f'Invalid datastructure: {datastructure}. Only \"grid\" and \"hash\" are supported.'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = jnp.clip(coordinates, 0, values.shape[0] - 1)\n    return resample.trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Invalid datastructure')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilerp_3d(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilerp_3d(values, coordinates)\n  else:\n    raise ValueError(f'Datastructure {datastructure} not implemented.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    # Adjust coordinates to match the voxel grid.\n    coordinates = coordinates - 0.5\n    # Sample from the voxel grid.\n    return resample.trilerp_grid(values, coordinates)\n  elif datastructure == 'hash':\n    # Adjust coordinates to match the hash data structure.\n    coordinates = coordinates - 0.5\n    # Sample from the hash data structure.\n    return hash_resample.trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(\n        f'Invalid datastructure {datastructure}. Must be \"grid\" or \"hash\".'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = coordinates[..., [2, 1, 0]]\n    return resample.trilerp_3d(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilerp_hash(values, coordinates, datastructure)\n  else:\n    raise ValueError(\n        f'Datastructure {datastructure} not known. Must be grid or hash.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = jnp.clip(coordinates, 0, values.shape[0] - 1)\n    return resample.resample_3d_grid(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.resample_hash_grid(values, coordinates)\n  else:\n    raise ValueError(\n        f'Invalid datastructure: {datastructure}. '\n        f'Only \"grid\" and \"hash\" are supported.'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.trilerp_3d(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.trilerp_3d(values, coordinates)\n  else:\n    raise ValueError(\n        f'Datastructure {datastructure} not implemented for trilerp.'\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = coordinates[..., [2, 1, 0]]\n    return jax.scipy.ndimage.map_coordinates(\n        values, coordinates, order=1, mode='nearest'\n    )\n  elif datastructure == 'hash':\n    return hash_resample.trilerp_hash(values, coordinates)\n  else:\n    raise ValueError('Unknown datastructure.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = jnp.clip(coordinates, 0, values.shape[0] - 1)\n    return resample.grid_trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.hash_trilerp(values, coordinates)\n  else:\n    raise ValueError('Unknown data structure: {}'.format(datastructure))\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    coordinates = jnp.clip(\n        coordinates, jnp.array([0.0, 0.0, 0.0]),\n        jnp.array([values.shape[0] - 1.0, values.shape[1] - 1.0,\n                   values.shape[2] - 1.0]))\n    return resample.resample_3d_grid(\n        values, coordinates, resample.ResampleMethod.LINEAR)\n  elif datastructure == 'hash':\n    return hash_resample.resample_hash_grid(\n        values, coordinates, resample.ResampleMethod.LINEAR)\n  else:\n    raise ValueError('Datastructure must be grid or hash.')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == 'grid':\n    return resample.grid_trilerp(values, coordinates)\n  elif datastructure == 'hash':\n    return hash_resample.hash_trilerp(values, coordinates)\n  else:\n    raise ValueError(f'Invalid datastructure: {datastructure}')\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == \"grid\":\n    return resample.trilerp_grid(values, coordinates)\n  elif datastructure == \"hash\":\n    return hash_resample.trilerp_hash(values, coordinates)\n  else:\n    raise ValueError(\n        f\"Unknown datastructure {datastructure}.\"\n        \"Can only be 'grid' or 'hash'.\"\n    )\n\n"}
{"namespace": "grid_utils.trilerp", "completion": "  if datastructure == \"grid\":\n    return resample.grid_trilerp(values, coordinates)\n  elif datastructure == \"hash\":\n    return hash_resample.hash_trilerp(values, coordinates)\n  else:\n    raise ValueError(f\"Invalid datastructure: {datastructure}\")\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate integer weights for each vertex of the triangle\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Filter out weights that do not sum to v\n  weights = weights[np.sum(weights, axis=1) == v]\n\n  # Normalize the weights to get barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of integers that sum to v\n  combinations = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Filter out combinations that don't sum to v\n  valid_combinations = combinations[np.sum(combinations, axis=1) == v]\n\n  # Compute the barycentric coordinates for each valid combination\n  barycentric_coords = valid_combinations / v\n\n  # Normalize the barycentric coordinates to sum to 1\n  barycentric_coords = barycentric_coords / np.sum(barycentric_coords, axis=1)[:, np.newaxis]\n\n  return barycentric_coords"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Check if the input is valid\n  if v < 1:\n    raise ValueError(\"The tessellation factor must be greater than or equal to 1.\")\n\n  # Generate the integer weights for each vertex of the triangle\n  weights = np.array([[i, j] for i in range(v + 1) for j in range(v + 1 - i)])\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of integers that sum to v\n  combinations = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Filter out combinations that don't sum to v\n  combinations = combinations[np.sum(combinations, axis=1) == v]\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = combinations / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate integer weights for each vertex of the triangle\n  weights = np.array(list(itertools.product(range(v+1), repeat=3)))\n  weights = weights[np.sum(weights, axis=1) <= v]\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the integer weights for each vertex of the triangle.\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n\n  # Return the barycentric weights.\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all integer weights for the vertices of the triangle\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Filter out weights that do not sum to v\n  weights = weights[np.sum(weights, axis=1) == v]\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError('Tesselation factor must be >= 1.')\n\n  # Generate integer weights for each vertex of the triangle.\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n  weights = weights[weights.sum(axis=1) <= 1]\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the integer weights for each vertex of the triangle.\n  weights = np.array([[i, j, v - i - j]\n                      for i in range(v + 1)\n                      for j in range(v - i + 1)])\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError('Tesselation factor must be >= 1.')\n\n  # Generate all possible combinations of integers that sum to v.\n  # These combinations represent the integer weights for each vertex of the triangle.\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Normalize the weights so that they sum to 1.\n  # These weights are used to interpolate values across the triangle.\n  weights = weights / v\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  if v < 1:\n    raise ValueError('Tessellation factor must be >= 1.')\n  # Generate all integer weights for the triangle.\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n  # Remove weights that are not in the triangle.\n  weights = weights[weights.sum(axis=1) <= 1]\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate integer weights for each vertex of the triangle.\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Filter out weights that do not sum up to v.\n  weights = weights[np.sum(weights, axis=1) == v]\n\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Initialize an empty list to store the barycentric weights\n  weights = []\n\n  # Iterate over all possible combinations of weights for the vertices of the triangle\n  for i in range(v+1):\n    for j in range(v+1-i):\n      # Calculate the weight for the third vertex\n      k = v - i - j\n      # Append the weights to the list\n      weights.append([i, j, k])\n\n  # Convert the list of weights to a numpy array\n  weights = np.array(weights)\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  # Return the barycentric weights\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate integer weights for each vertex of the triangle.\n  weights = np.array(\n      list(itertools.product(range(v + 1), range(v + 1), range(v + 1))))\n  # Normalize the weights to get the barycentric coordinates.\n  weights = weights / v\n  # Remove weights that do not sum to 1.\n  weights = weights[np.sum(weights, axis=1) == 1]\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate the vertices of the triangle\n  vertices = np.array([[0, 0], [1, 0], [0, 1]])\n\n  # Compute the barycentric weights for each vertex\n  weights = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n\n  # Compute the barycentric weights for each point in the tessellated triangle\n  for i in range(1, v):\n    new_weights = np.zeros((3 * i, 3))\n    for j in range(i):\n      new_weights[3 * j, :] = (j + 1) / (i + 1) * weights[j, :] + (i - j) / (i + 1) * weights[j + 1, :]\n      new_weights[3 * j + 1, :] = (j + 1) / (i + 1) * weights[j, :] + (i - j) / (i + 1) * weights[j + 1, :]\n      new_weights[3 * j + 2, :] = weights[j + 1, :]\n    weights = new_weights\n\n  # Normalize the barycentric weights\n  weights /= np.sum(weights, axis=1, keepdims=True)\n\n  return weights"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Compute the barycentric weights for tessellating the vertices of a triangle by a given factor.\n  # This involves generating integer weights for each vertex of the triangle and then normalizing these weights to get the barycentric coordinates.\n  # Input-Output Arguments\n  # v: Int, the tessellation factor, which determines how finely the triangle is subdivided. It must be greater than or equal to 1.\n  # Returns\n  # weights: Numpy array, the barycentric weights for each point in the tessellated triangle. These weights are used to interpolate values across the triangle.\n\n  # Check that the tessellation factor is valid\n  assert v >= 1\n\n  # Initialize the weights array with the first vertex of the triangle\n  weights = np.array([1, 0, 0])\n\n  # Iterate over the remaining vertices of the triangle\n  for i in range(1, v + 1):\n    # Compute the weights for the current vertex\n    weights = np.vstack((weights, np.array([0, i, 0])))\n    weights = np.vstack((weights, np.array([0, 0, i])))\n\n    # Compute the weights for the remaining vertices\n    for j in range(1, i):\n      weights = np.vstack((weights, np.array([j, i - j, 0])))\n      weights = np.vstack((weights, np.array([0, i - j, j])))\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / v\n\n  # Return the weights\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate all possible combinations of weights that sum to v\n  weights = np.array(list(itertools.product(range(v + 1), repeat=3)))\n\n  # Filter out combinations that don't sum to v\n  weights = weights[np.sum(weights, axis=1) == v]\n\n  # Normalize the weights to get barycentric coordinates\n  weights = weights / v\n\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Generate integer weights for each vertex of the triangle\n  weights = np.array(\n      list(itertools.product(range(v + 1), repeat=3)), dtype=np.float64)\n  # Normalize the weights to get the barycentric coordinates\n  weights /= v\n  # Compute the squared Euclidean distance between all pairs of columns\n  sq_dist = compute_sq_dist(weights)\n  # Set the diagonal entries of the distance matrix to a large value to ensure that the minimum distance is not 0\n  np.fill_diagonal(sq_dist, 1e10)\n  # Find the minimum distance between each pair of vertices\n  min_dist = np.min(sq_dist, axis=0)\n  # Normalize the weights by the minimum distance\n  weights /= min_dist\n  # Return the normalized weights\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  # Initialize the weights array with the first vertex of the triangle\n  weights = np.array([1, 0, 0])\n\n  # Loop through the tessellation factor and generate weights for each level\n  for i in range(v):\n    # Initialize an empty array to hold the new weights\n    new_weights = []\n\n    # Loop through the existing weights and generate new weights for each vertex\n    for j in range(len(weights)):\n      # If the current weight is zero, skip to the next vertex\n      if weights[j] == 0:\n        continue\n\n      # Calculate the new weights for the current vertex and add them to the array\n      new_weights.extend([weights[j] / 2, 0, weights[j] / 2])\n\n    # Set the weights array to the new weights array\n    weights = np.array(new_weights)\n\n  # Normalize the weights to get the barycentric coordinates\n  weights = weights / np.sum(weights)\n\n  # Return the barycentric coordinates\n  return weights\n\n"}
{"namespace": "geopoly.compute_tesselation_weights", "completion": "  assert v >= 1\n  if v == 1:\n    return np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n  else:\n    # Initialize the weights matrix with the vertices of the triangle\n    weights = np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n\n    # Generate integer weights for each vertex of the triangle\n    for i in range(1, v):\n      for j in range(i + 1):\n        weights = np.concatenate((weights, np.array([[i - j, j, i]])))\n\n    # Normalize the weights to get the barycentric coordinates\n    weights = weights / v\n\n    return weights\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid\n  check_zero_endpoints(v)\n\n  # Interpolate the spline at the query points\n  vq = math.interp(tq, t, v)\n\n  # Set the extrapolated values to 0\n  vq = jnp.where(tq < t[0], 0, vq)\n  vq = jnp.where(tq > t[-1], 0, vq)\n\n  return vq"}
{"namespace": "linspline.query", "completion": "  # Ensure the spline is valid\n  check_zero_endpoints(v)\n\n  # Interpolate the spline at the query points\n  vq = math.interpolate(tq, t, v)\n\n  # Set values outside the original range to 0\n  vq = jnp.where((tq < t[0]) | (tq > t[-1]), 0, vq)\n\n  return vq\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid.\n  check_zero_endpoints(v)\n\n  # Interpolate the spline at the query points.\n  vq = math.interp(tq, t, v)\n\n  # Set values outside the original range to 0.\n  vq = jnp.where((tq < t[0]) | (tq > t[-1]), 0, vq)\n\n  return vq\n\n"}
{"namespace": "linspline.query", "completion": "  # Check the validity of the spline\n  check_zero_endpoints(v)\n\n  # Interpolate the values at the query points\n  vq = math.interp(tq, t, v)\n\n  # Set extrapolated values to 0\n  vq = jnp.where((tq < t[0]) | (tq > t[-1]), 0, vq)\n\n  return vq\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid.\n  check_zero_endpoints(v)\n\n  # Interpolate the spline at the query points.\n  vq = math.interp(tq, t, v)\n\n  # Set any values outside the original range to 0.\n  vq = jnp.where((tq < t[0]) | (tq > t[-1]), 0., vq)\n\n  return vq\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid\n  check_zero_endpoints(v)\n\n  # Interpolate the values at the query points\n  vq = math.interp(tq, t, v)\n\n  # Set the extrapolated values to 0\n  vq = jnp.where((tq < t[0]) | (tq > t[-1]), 0, vq)\n\n  return vq\n\n"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  tq = jnp.asarray(tq)\n  tq = jnp.clip(tq, t[0], t[-1])\n  tq = tq[..., None]\n  t = t[None, :]\n  v = v[None, :]\n  return jnp.where(\n      jnp.logical_and(tq >= t[..., :-1], tq < t[..., 1:]),\n      jnp.divide(\n          jnp.multiply(tq - t[..., :-1], v[..., 1:]) -\n          jnp.multiply(tq - t[..., 1:], v[..., :-1]), t[..., 1:] - t[..., :-1]),\n      jnp.where(tq == t[..., -1], v[..., -1], 0.0))\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid\n  check_zero_endpoints(v)\n\n  # Query the spline\n  y = jnp.interp(tq, t, v, left=0.0, right=0.0)\n\n  return y\n\n"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  t = jnp.asarray(t, dtype=tq.dtype)\n  v = jnp.asarray(v, dtype=tq.dtype)\n  tq = jnp.asarray(tq, dtype=tq.dtype)\n  vq = math.interpolate(tq, t, v)\n  vq = jnp.where(tq < t[0], 0., vq)\n  vq = jnp.where(tq > t[-1], 0., vq)\n  return vq\n\n"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  tq = jnp.asarray(tq)\n  # Check that the knots are sorted.\n  checkify.check(jnp.all(t[Ellipsis, 1:] > t[Ellipsis, :-1]), 'Spline knots must be sorted.')\n  # Check that the knots are not too close together.\n  checkify.check(jnp.all(t[Ellipsis, 1:] > t[Ellipsis, :-1] + 1e-6), 'Spline knots must be at least 1e-6 apart.')\n  # Check that the knots are not too far apart.\n  checkify.check(jnp.all(t[Ellipsis, 1:] < t[Ellipsis, -1] - 1e-6), 'Spline knots must be at most 1e-6 from the end.')\n  # Check that the knots are not too far apart.\n  checkify.check(jnp.all(t[Ellipsis, 1:] < t[Ellipsis, -1] - 1e-6), 'Spline knots must be at most 1e-6 from the end.')\n  # Check that the knots are not too far apart.\n  checkify.check(jnp.all(t[Ellipsis, 1:] < t[Ellipsis, -1] - 1e-6), 'Spline knots must be at most 1e-6 from the end.')\n  # Check that the knots are not too far apart.\n  checkify.check(jnp.all(t[Ellipsis, 1:] < t[Ellipsis, -1] - 1e-6), 'Spline knots must be at most 1e-6 from the end.')\n  # Check that the knots are not too far apart.\n  checkify.check(jnp.all("}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid.\n  check_zero_endpoints(v)\n\n  # Ensure that the spline is defined on the interval [0, 1].\n  t = jnp.clip(t, 0, 1)\n  v = jnp.clip(v, 0, 1)\n\n  # Ensure that the query points are within the interval [0, 1].\n  tq = jnp.clip(tq, 0, 1)\n\n  # Compute the indices of the knots that bracket each query point.\n  indices = jnp.searchsorted(t, tq)\n\n  # Compute the interpolation weights for each query point.\n  weights = (tq - t[indices - 1]) / (t[indices] - t[indices - 1])\n\n  # Compute the interpolated values for each query point.\n  vq = v[indices - 1] + weights * (v[indices] - v[indices - 1])\n\n  # Set the extrapolated values to 0.\n  vq = jnp.where((tq < t[0]) | (tq > t[-1]), 0, vq)\n\n  return vq"}
{"namespace": "linspline.query", "completion": "  # Ensure the spline is valid.\n  check_zero_endpoints(v)\n\n  # Ensure the query points are in the correct range.\n  tq = jnp.clip(tq, t[0], t[-1])\n\n  # Find the indices of the time points that bracket each query point.\n  indices = jnp.searchsorted(t, tq) - 1\n\n  # Compute the interpolation weights for each query point.\n  weights = (tq - t[indices]) / (t[indices + 1] - t[indices])\n\n  # Interpolate the values at each query point.\n  vq = jnp.where(\n      (indices >= 0) & (indices < len(t) - 1),\n      (1 - weights) * v[..., indices] + weights * v[..., indices + 1],\n      0.0)\n\n  return vq\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid\n  check_zero_endpoints(v)\n\n  # Find the indices of the knots that bracket each query point\n  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  indices = jnp.searchsorted(t, tq)\n\n  # Ensure the query points are within the valid range of the spline\n  indices = jnp.clip(indices, 1, len(t) - 1)\n\n  # Calculate the interpolation weights for each query point\n  t_prev = t[indices - 1]\n  t_next = t[indices]\n  w = (tq - t_prev) / (t_next - t_prev)\n\n  # Interpolate the values at the query points\n  v_prev = v[indices - 1]\n  v_next = v[indices]\n  vq = (1 - w) * v_prev + w * v_next\n\n  return vq\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(\n      jnp.all(jnp.diff(t) > 0),\n      'Spline knots must be in ascending order.',\n  )\n  check_zero_endpoints(v)\n\n  # Extrapolate to 0 outside the original range.\n  tq = jnp.clip(tq, t[0], t[-1])\n\n  # Find the index of the knot below each query point.\n  i = jnp.searchsorted(t, tq, side='right') - 1\n\n  # Compute the interpolation weights.\n  w = (tq - t[i]) / (t[i + 1] - t[i])\n\n  # Compute the interpolated values.\n  return (1 - w) * v[i] + w * v[i + 1]"}
{"namespace": "linspline.query", "completion": "  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n\n  # Check that the spline is valid\n  check_zero_endpoints(v)\n  checkify.check(jnp.all(t[1:] > t[:-1]), 'Spline time points must be sorted.')\n\n  # Find the indices of the knots to the left and right of each query point\n  tq_indices = jnp.searchsorted(t, tq)\n  tq_indices = jnp.clip(tq_indices, 0, len(t) - 1)\n\n  # Compute the interpolation weights\n  t_left = t[tq_indices]\n  t_right = t[jnp.clip(tq_indices + 1, 0, len(t) - 1)]\n  w_left = (t_right - tq) / (t_right - t_left)\n  w_right = 1 - w_left\n\n  # Compute the interpolated values\n  v_left = v[tq_indices]\n  v_right = v[jnp.clip(tq_indices + 1, 0, len(t) - 1)]\n  vq = w_left * v_left + w_right * v_right\n\n  return vq\n\n"}
{"namespace": "linspline.query", "completion": "  # Check that the spline is valid.\n  check_zero_endpoints(v)\n\n  # Check that the spline is monotonically increasing.\n  checkify.check(jnp.all(jnp.diff(t) > 0), 'Spline time points must be monotonically increasing.')\n\n  # Check that the spline is valid.\n  checkify.check(jnp.all(jnp.diff(v) >= 0), 'Spline values must be monotonically increasing.')\n\n  # Interpolate the spline at the query points.\n  y = jnp.interp(tq, t, v, left=0, right=0)\n\n  return y\n\n"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  tq = jnp.asarray(tq)\n  checkify.check(t.ndim == v.ndim == tq.ndim + 1, 't, v, and tq must have matching shapes.')\n  checkify.check(t.shape[:-1] == v.shape[:-1], 't and v must have matching batch shapes.')\n  checkify.check(t.shape[-1] == v.shape[-1] + 1, 't and v must have matching knot shapes.')\n  checkify.check(t.shape[-1] >= 2, 't must have at least 2 knots.')\n  checkify.check(tq.shape[-1] >= 1, 'tq must have at least 1 query point.')\n  checkify.check(tq.dtype == t.dtype == v.dtype, 't, v, and tq must have matching dtypes.')\n  tq = jnp.expand_dims(tq, axis=-1)\n  t = jnp.expand_dims(t, axis=0)\n  v = jnp.expand_dims(v, axis=0)\n  tq = jnp.broadcast_to(tq, tq.shape[:-1] + t.shape[-1])\n  t = jnp.broadcast_to(t, tq.shape[:-1] + t.shape[-1])\n  v = jnp.broadcast_to(v, tq.shape[:-1] + v.shape[-1])\n  tq = jnp.clip(tq, t[..., 0], t[..., -1])\n  idx = jnp.searchsorted(t, tq, side='left')\n  idx = jnp.clip(idx, 1, t.shape[-1] - 1)\n  tl = t[..., idx - 1]\n  tr = t[..., idx]\n  v"}
{"namespace": "linspline.query", "completion": "  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n  checkify.check(tq.ndim == 1, 'tq must be 1D.')\n  checkify.check(t.ndim == 1, 't must be 1D.')\n  checkify.check(v.ndim == 1, 'v must be 1D.')\n  checkify.check(t.shape[0] == v.shape[0], 't and v must have the same length.')\n  check_zero_endpoints(v)\n  # Ensure that t is sorted.\n  t = jnp.sort(t)\n  # Ensure that tq is sorted.\n  tq = jnp.sort(tq)\n  # Ensure that tq is within the range of t.\n  tq = jnp.where(tq < t[0], t[0], tq)\n  tq = jnp.where(tq > t[-1], t[-1], tq)\n  # Ensure that tq is increasing.\n  tq = jnp.maximum.accumulate(tq)\n  # Find the index of the last time point in t that is less than or equal to each query point in tq.\n  idx = jnp.searchsorted(t, tq, side='right') - 1\n  # Compute the interpolation weights for each query point.\n  w = (tq - t[idx]) / (t[idx + 1] - t[idx])\n  # Compute the interpolated values for each query point.\n  vq = (1 - w) * v[idx] + w * v[idx + 1]\n  return vq\n\n"}
{"namespace": "linspline.query", "completion": "  check_zero_endpoints(v)\n\n  # Add a small epsilon to the query points to avoid issues with numerical precision.\n  tq = tq + jnp.finfo(tq.dtype).eps\n\n  # Ensure 'tq' is a 1D array.\n  tq = jnp.atleast_1d(tq)\n\n  # Find the indices of the time points that are less than the query points.\n  i = jnp.searchsorted(t, tq)\n\n  # Ensure 'i' is within the valid range of indices for 't'.\n  i = jnp.clip(i, 0, len(t) - 1)\n\n  # Compute the fractional distance between the query points and the time points.\n  frac = (tq - t[i]) / (t[i + 1] - t[i])\n\n  # Compute the interpolated values using linear interpolation.\n  yq = (1 - frac) * v[i] + frac * v[i + 1]\n\n  # Set the extrapolated values to 0.\n  yq = jnp.where((tq < t[0]) | (tq > t[-1]), 0, yq)\n\n  return yq\n\n"}
{"namespace": "linspline.query", "completion": "  checkify.check(t.shape == v.shape, 't and v must have the same shape.')\n  checkify.check(t.ndim == 2, 't must be a 2D array.')\n  checkify.check(t.shape[0] > 1, 't must have at least two time points.')\n  checkify.check(t.shape[1] > 1, 't must have at least two time points.')\n  checkify.check(t.shape == (t.shape[0], t.shape[1]),\n                 't must have the same number of time points in each row.')\n  checkify.check(jnp.all(jnp.diff(t, axis=-1) > 0),\n                 't must be sorted in increasing order.')\n  check_zero_endpoints(v)\n\n  tq = jnp.asarray(tq)\n  t = jnp.asarray(t)\n  v = jnp.asarray(v)\n\n  tq = jnp.broadcast_to(tq, tq.shape + (1,))\n  t = jnp.broadcast_to(t, t.shape + (1,))\n  v = jnp.broadcast_to(v, v.shape + (1,))\n\n  tq = jnp.reshape(tq, (-1,))\n  t = jnp.reshape(t, (-1,))\n  v = jnp.reshape(v, (-1,))\n\n  tq_indices = jnp.searchsorted(t, tq, side='right') - 1\n  tq_indices = jnp.clip(tq_indices, 0, t.size - 2)\n\n  t_low = t[tq_indices]\n  t_high = t[tq_indices + 1]\n  v_low = v[tq_indices]\n  v_high = v[tq_indices + 1]\n\n  alpha = (tq - t_low) / (t_high - t_"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(x <= 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(x <= 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: all values in {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: all values in {field.name} must be positive.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(x <= 0 for x in v):\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must contain only positive values.\"\n            )\n    else:\n        if v <= 0:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must contain only positive values.\"\n            )\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(x <= 0 for x in v):\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must contain only positive values.\"\n            )\n    else:\n        if v <= 0:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must contain only positive values.\"\n            )\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if any(val <= 0 for val in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    elif v <= 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    elif v <= 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(f\"{cls.__name__}: All values in {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: All values in {field.name} must be positive.\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for i, item in enumerate(v):\n            if item <= 0:\n                raise ValueError(\n                    f\"{cls.__name__}: {field.name} must be positive. got {item} at index {i}\"\n                )\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive. got {v}\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for i, val in enumerate(v):\n            if val <= 0:\n                raise ValueError(\n                    f\"{cls.__name__}: {field.name} must be positive. got value {val} at index {i}\"\n                )\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive. got value {v}\")\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for val in v:\n            if val <= 0:\n                raise ValueError(\n                    f\"{cls.__name__}: {field.name} must contain only positive values.\"\n                )\n    elif v <= 0:\n        raise ValueError(\n            f\"{cls.__name__}: {field.name} must contain only positive values.\"\n        )\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    elif v <= 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for i, item in enumerate(v):\n            if item <= 0:\n                raise ValueError(\n                    f\"{cls.__name__}: All values in {field.name} must be positive. \"\n                    f\"{field.name}[{i}] is not positive.\"\n                )\n    else:\n        if v <= 0:\n            raise ValueError(\n                f\"{cls.__name__}: All values in {field.name} must be positive. \"\n                f\"{field.name} is not positive.\"\n            )\n\n    return v"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        for item in v:\n            if item <= 0:\n                raise ValueError(f\"{cls.__name__}: {field.name} must be positive. got {item}\")\n    elif v <= 0:\n        raise ValueError(f\"{cls.__name__}: {field.name} must be positive. got {v}\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: All values in {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: All values in {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n    else:\n        if v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be positive.\")\n\n    return v\n\n"}
{"namespace": "iris.io.validators.are_all_positive", "completion": "    if isinstance(v, Iterable):\n        if not all(isinstance(x, (int, float)) and x > 0 for x in v):\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n    else:\n        if not isinstance(v, (int, float)) or v <= 0:\n            raise ValueError(f\"{cls.__name__}: {field.name} must contain only positive values.\")\n\n    return v\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  \"\"\"\n  Converts a set of rays from world space to normalized device coordinates (NDC) using a perspective projection model. This is useful for rendering or processing 3D scenes in a standardized coordinate system.\n\n  Input-Output Arguments\n  :param origins: ndarray(float32), The origins of the rays in world space, used to determine their starting points in NDC.\n  :param directions: ndarray(float32), The directions of the rays in world space, used to calculate their orientation in NDC.\n  :param pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera, used for the perspective projection calculation.\n  :param near: float, The distance to the near plane along the negative z-axis, used to define the depth range of the projection.\n  :param xnp: module, Either numpy or jax.numpy, specifies the numerical library to use for calculations.\n  :return: Tuple of ndarray(float32), The origins and directions of the rays in normalized device coordinates.\n\n  This function performs a perspective projection of rays defined in world space into a normalized device coordinate system, assuming an identity extrinsic matrix (camera pose) and intrinsic parameters defined by the pixtocam matrix. The function adjusts ray origins to the near plane and calculates the corresponding directions in NDC, facilitating the rendering or analysis of 3D scenes from a standardized viewpoint.\n  \"\"\"\n\n  \"\"\"\n  Converts a set of rays from world space to normalized device coordinates (NDC) using a perspective projection model. This is useful for rendering or processing 3D scenes in a standardized coordinate system.\n\n  Input-Output Arguments\n  :param origins: ndarray(float32), The origins of the rays in world space, used to determine their starting points in NDC.\n  :param directions: ndarray(float32), The directions of the rays in world space, used to calculate their orientation in NDC.\n  :param pixtocam: ndarray(float32), The inverse intrinsic matrix of the camera, used for the perspective projection calculation.\n  :param near: float, The distance to the near plane"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Adjust ray origins to the near plane.\n  origins = origins / directions[..., 2:3] * near\n  # Calculate the directions in NDC.\n  directions = xnp.matmul(origins[..., None, :], pixtocam)[..., :2]\n  # Normalize the directions.\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Adjust ray origins to the near plane.\n  t = -(near + origins[..., 2]) / directions[..., 2]\n  origins = origins + t[..., None] * directions\n\n  # Convert origins to NDC.\n  origins = xnp.dot(origins, pixtocam.T)\n  origins = origins[..., :2] / origins[..., 2:]\n\n  # Convert directions to NDC.\n  directions = xnp.dot(directions, pixtocam.T)\n  directions = directions[..., :2] / directions[..., 2:]\n\n  # Normalize directions.\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Shape as input (..., 3).\n  # pyformat: disable\n  \"\"\"\n  # origins:    (..., 3)\n  # directions: (..., 3)\n  # pixtocam:   (3,  3)\n  # returns:    (..., 3), (..., 3)\n  \"\"\"\n  # pyformat: enable\n  origins_ndc, directions_ndc = jaxcam.convert_to_ndc(origins, directions, pixtocam, near, xnp)\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  if pixtocam.shape[-2:] == (3, 3):\n    pixtocam = pixtocam @ xnp.array(\n        [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, near], [0, 0, 0, 1]]\n    )\n    pixtocam = pixtocam[..., :3, :]\n  near = xnp.array(near, dtype=xnp.float32)\n  origins = xnp.array(origins, dtype=xnp.float32)\n  directions = xnp.array(directions, dtype=xnp.float32)\n  # Shift ray origins to near plane\n  t = -(near + origins[..., 2]) / directions[..., 2]\n  origins = origins + t[..., None] * directions\n  # Projection\n  origins = origins @ pixtocam.T\n  directions = directions @ pixtocam.T\n  origins = origins[..., :2] / origins[..., 2:]\n  directions = directions[..., :2] / directions[..., 2:]\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.array(origins)\n  directions = xnp.array(directions)\n  pixtocam = xnp.array(pixtocam)\n\n  # Move the origins to the near plane.\n  origins = origins / (near / directions[..., -1])\n\n  # Compute the directions in NDC.\n  directions = xnp.einsum(\"ij,bj->bi\", pixtocam, directions)\n  directions = directions / (xnp.linalg.norm(directions, axis=-1, keepdims=True) + 1e-10)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.array(origins, dtype=xnp.float32)\n  directions = xnp.array(directions, dtype=xnp.float32)\n  pixtocam = xnp.array(pixtocam, dtype=xnp.float32)\n\n  origins = origins / origins[..., -1:]\n  origins = xnp.concatenate(\n      [origins, xnp.ones_like(origins[..., :1])], axis=-1\n  )\n  origins = xnp.dot(origins, pixtocam.T)\n  origins = origins[..., :2] / origins[..., 2:]\n  origins = origins - xnp.array(\n      [pixtocam[0, 2], pixtocam[1, 2]], dtype=xnp.float32\n  )\n  origins = origins / xnp.array(\n      [pixtocam[0, 0], pixtocam[1, 1]], dtype=xnp.float32\n  )\n  origins = near * origins / origins[..., -1:]\n  origins = xnp.concatenate(\n      [origins, xnp.ones_like(origins[..., :1])], axis=-1\n  )\n\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  directions = xnp.dot(directions, pixtocam.T[:3, :3].T)\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  directions = directions / directions[..., -1:]\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins_ndc = origins / origins[..., -1:]\n  origins_ndc = xnp.concatenate(\n      [origins_ndc[..., :2], xnp.ones_like(origins_ndc[..., :1])], axis=-1\n  )\n  origins_ndc = xnp.dot(origins_ndc, pixtocam.T)\n  origins_ndc[..., 0] = origins_ndc[..., 0] / origins_ndc[..., 2]\n  origins_ndc[..., 1] = origins_ndc[..., 1] / origins_ndc[..., 2]\n  origins_ndc = origins_ndc[..., :2]\n  directions_ndc = directions / directions[..., -1:]\n  directions_ndc = xnp.concatenate(\n      [directions_ndc[..., :2], xnp.ones_like(directions_ndc[..., :1])], axis=-1\n  )\n  directions_ndc = xnp.dot(directions_ndc, pixtocam.T)\n  directions_ndc[..., 0] = directions_ndc[..., 0] / directions_ndc[..., 2]\n  directions_ndc[..., 1] = directions_ndc[..., 1] / directions_ndc[..., 2]\n  directions_ndc = directions_ndc[..., :2]\n  directions_ndc = directions_ndc / xnp.linalg.norm(\n      directions_ndc, axis=-1, keepdims=True\n  )\n  near = xnp.ones_like(origins[..., :1]) * near\n  origins_ndc = origins_ndc / near\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Adjust ray origins to the near plane.\n  origins = origins / directions[..., None, :] * near\n\n  # Convert origins to homogeneous coordinates.\n  origins = xnp.concatenate(\n      [origins, xnp.ones_like(origins[..., :1])], axis=-1\n  )\n\n  # Convert directions to homogeneous coordinates.\n  directions = xnp.concatenate(\n      [directions, xnp.zeros_like(directions[..., :1])], axis=-1\n  )\n\n  # Apply perspective projection.\n  origins = origins @ pixtocam.T\n  directions = directions @ pixtocam.T\n\n  # Convert origins back to Cartesian coordinates.\n  origins = origins[..., :3] / origins[..., 3:]\n\n  # Convert directions back to Cartesian coordinates.\n  directions = directions[..., :3]\n\n  # Normalize directions.\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  batch_shape = origins.shape[:-1]\n  origins = origins.reshape(-1, 3)\n  directions = directions.reshape(-1, 3)\n  pixtocam = pixtocam.reshape(-1, 3, 3)\n  near = xnp.broadcast_to(near, directions.shape[:-1])\n\n  # Convert to homogeneous coordinates\n  origins_hom = xnp.concatenate(\n      [origins, xnp.ones_like(origins[..., :1])], axis=-1)\n  directions_hom = xnp.concatenate(\n      [directions, xnp.zeros_like(directions[..., :1])], axis=-1)\n\n  # Transform to camera space\n  origins_cam = xnp.einsum(\"bij,bj->bi\", pixtocam, origins_hom)\n  directions_cam = xnp.einsum(\"bij,bj->bi\", pixtocam, directions_hom)\n\n  # Project onto the near plane\n  origins_near = origins_cam * (near / origins_cam[..., -1:])\n\n  # Convert to NDC\n  origins_ndc = origins_near / origins_near[..., -1:]\n  directions_ndc = directions_cam / directions_cam[..., -1:]\n\n  # Reshape to original batch shape\n  origins_ndc = origins_ndc.reshape(batch_shape + (3,))\n  directions_ndc = directions_ndc.reshape(batch_shape + (3,))\n\n  return origins_ndc, directions_ndc\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  if pixtocam.shape[-2:] == (3, 3):\n    pixtocam = pixtocam @ xnp.diag(xnp.array([1.0, 1.0, 1.0, 1.0],\n                                              dtype=pixtocam.dtype))\n  if pixtocam.shape[-2:] == (3, 4):\n    pixtocam = pixtocam @ xnp.diag(xnp.array([1.0, 1.0, 1.0, 0.0],\n                                              dtype=pixtocam.dtype))\n  origins = origins + directions * near\n  origins = origins[..., None, :]\n  directions = directions[..., None, :]\n  origins_px = xnp.squeeze(origins @ pixtocam[:, :3, :3].T +\n                          pixtocam[:, :3, 3:4],\n                          axis=-2)\n  origins_px = origins_px / origins_px[..., -1:]\n  directions_px = xnp.squeeze(directions @ pixtocam[:, :3, :3].T, axis=-2)\n  directions_px = directions_px / xnp.linalg.norm(directions_px, axis=-1,\n                                                  keepdims=True)\n  return origins_px[..., :-1], directions_px\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  batch_shape = origins.shape[:-1]\n  origins = origins.reshape(-1, 3)\n  directions = directions.reshape(-1, 3)\n  pixtocam = pixtocam.reshape(-1, 3, 3)\n  near = xnp.array(near, dtype=xnp.float32)\n\n  origins = xnp.concatenate(\n      [origins, xnp.ones_like(origins[Ellipsis, :1])], axis=-1)\n  origins = xnp.linalg.solve(pixtocam, origins[Ellipsis, None])[Ellipsis, 0]\n  origins = near * origins / origins[Ellipsis, -1:]\n\n  directions = xnp.concatenate(\n      [directions, xnp.zeros_like(directions[Ellipsis, :1])], axis=-1)\n  directions = xnp.linalg.solve(pixtocam, directions[Ellipsis, None])[Ellipsis, 0]\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  origins = origins.reshape(*batch_shape, 3)\n  directions = directions.reshape(*batch_shape, 3)\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  origins = xnp.array(origins)\n  directions = xnp.array(directions)\n  pixtocam = xnp.array(pixtocam)\n\n  near = xnp.array(near)\n\n  # Shift ray origins to near plane.\n  t = -(near + origins[..., 2]) / directions[..., 2]\n  origins = origins + t[..., None] * directions\n\n  # Projection\n  o = xnp.ones_like(origins[..., :1])\n  d = xnp.ones_like(directions[..., :1])\n  origins = xnp.concatenate([origins, o], -1)\n  directions = xnp.concatenate([directions, d], -1)\n  origins = origins @ pixtocam.T\n  directions = directions @ pixtocam.T\n  origins = origins[..., :2] / origins[..., 2:]\n  directions = directions[..., :2]\n\n  # Ray origins are now in [-1, 1]. Fix the rays that are behind the camera.\n  mask = xnp.sum(directions**2, -1) > 0\n  if xnp.any(~mask):\n    logging.warning(\n        \"Rays behind camera detected. Clamping ray directions to near plane.\"\n    )\n    directions = directions / xnp.linalg.norm(\n        directions, axis=-1, keepdims=True\n    )\n    origins[~mask] = -directions[~mask] * near\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Adjust ray origins to the near plane.\n  t = -(near + origins[..., 2]) / directions[..., 2]\n  origins = origins + t[..., None] * directions\n\n  # Project points to NDC.\n  origins = xnp.einsum(\"...ij,...j->...i\", origins, pixtocam)\n  directions = xnp.einsum(\"...ij,...j->...i\", directions, pixtocam)\n  t = (near / origins[..., 2])\n  origins = origins * t[..., None]\n  directions = directions * t[..., None]\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  if pixtocam.shape[-2:] == (3, 3):\n    pixtocam = pixtocam @ xnp.diag([1, 1, 1, 1])\n    pixtocam = pixtocam[..., :3, :]\n  if pixtocam.shape[-2:] == (3, 4):\n    pixtocam = pixtocam[..., :3, :]\n  if pixtocam.shape[-2:] != (4, 4):\n    raise ValueError(\n        f'pixtocam.shape[-2:]={pixtocam.shape[-2:]} is not (4, 4) or (3, 3) or (3, 4)'\n    )\n  if origins.shape[-1] != 3:\n    raise ValueError(f'origins.shape[-1]={origins.shape[-1]} is not 3')\n  if directions.shape[-1] != 3:\n    raise ValueError(f'directions.shape[-1]={directions.shape[-1]} is not 3')\n  if pixtocam.shape[:-2] != origins.shape[:-1]:\n    raise ValueError(\n        f'pixtocam.shape[:-2]={pixtocam.shape[:-2]} and origins.shape[:-1]={origins.shape[:-1]} are not compatible'\n    )\n  if pixtocam.shape[:-2] != directions.shape[:-1]:\n    raise ValueError(\n        f'pixtocam.shape[:-2]={pixtocam.shape[:-2]} and directions.shape[:-1]={directions.shape[:-1]} are not compatible'\n    )\n  if xnp != np and xnp != jnp:\n    raise ValueError(f'xnp={xnp} is not np and jnp')\n\n  # Shape as xnp.ndarray: [..., 3].\n  origins_near = origins / origins[..."}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Shape as input (..., 3).\n  batching_prefix = origins.shape[:-1]\n  origins = origins.reshape((-1, 3))\n  directions = directions.reshape((-1, 3))\n\n  # Bring point to near plane.\n  origins = origins / jnp.maximum(near, directions[..., 2:3])\n\n  # Change coordinate system from camera to NDC.\n  mat = xnp.array([\n      [pixtocam[0, 0], pixtocam[1, 0], pixtocam[2, 0]],\n      [pixtocam[0, 1], pixtocam[1, 1], pixtocam[2, 1]],\n      [pixtocam[0, 2], pixtocam[1, 2], pixtocam[2, 2]],\n  ], dtype=xnp.float32)\n  origins = xnp.dot(origins, mat.T)\n  directions = xnp.dot(directions, mat.T)\n\n  near_origins = jnp.concatenate([origins, xnp.ones_like(origins[Ellipsis, :1])], axis=-1)\n  near_directions = directions\n  origins = origins.reshape(batching_prefix + (3,))\n  directions = directions.reshape(batching_prefix + (3,))\n  near_origins = near_origins.reshape(batching_prefix + (4,))\n  near_directions = near_directions.reshape(batching_prefix + (3,))\n  return origins, directions, near_origins, near_directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Adjust the ray origins to the near plane.\n  origins = origins / directions[..., None, :] * near\n\n  # Calculate the ray directions in NDC.\n  directions = directions[..., None, :] * pixtocam[:3, :3]\n  directions = directions / (xnp.linalg.norm(directions, axis=-1, keepdims=True) + 1e-9)\n\n  # Return the origins and directions in NDC.\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Adjust ray origins to the near plane.\n  origins = origins / directions[..., -1:] * near\n\n  # Compute the ray directions in NDC.\n  directions = xnp.matmul(directions, pixtocam[:3, :3].T)\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Shape assertions.\n  chex.assert_equal_shape([\n      origins,\n      directions,\n      pixtocam,\n  ])\n\n  # Adjust ray origins to the near plane.\n  origins = origins / directions[..., 2:3] * near\n\n  # Compute the ray directions in NDC.\n  directions = xnp.einsum(\"...ij,...j->...i\", pixtocam, directions)\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  return origins, directions\n\n"}
{"namespace": "camera_utils.convert_to_ndc", "completion": "  # Compute the origins of the rays on the near plane.\n  origins = xnp.concatenate([origins, xnp.ones_like(origins[..., :1])], axis=-1)\n  origins = origins @ pixtocam.T\n  origins = origins[..., :3] / origins[..., 3:]\n  origins = near / origins[..., -1:] * origins\n\n  # Compute the directions of the rays in NDC.\n  directions = xnp.concatenate([directions, xnp.zeros_like(directions[..., :1])],\n                               axis=-1)\n  directions = directions @ pixtocam.T\n  directions = directions[..., :3]\n  directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  return origins, directions\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1 - 1e-6"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1 - 1e-6"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1.0 - 1e-6"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.isclose(jnp.dot(dir1, dir2), 1.0, atol=1e-6)"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) >= 1.0 - 1e-6"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) >= 1 - 1e-6"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Check if the dot product is close enough to 1 or -1 to consider the lines parallel\n  return jnp.isclose(jnp.abs(dot_product), 1.0, atol=1e-6)"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Set a small epsilon value for numerical precision\n  epsilon = 1e-6\n\n  # Check if the dot product is close to 1 or -1, within the epsilon range\n  return jnp.isclose(jnp.abs(dot_product), 1, atol=epsilon)"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  # Compute the dot product of the normalized direction vectors.\n  dot_product = jnp.dot(dir1, dir2)\n  # Compare the dot product with a small epsilon to account for numerical precision issues.\n  return jnp.abs(dot_product - 1.0) < 1e-6"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors.\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Define a small epsilon value to account for numerical precision.\n  epsilon = 1e-6\n\n  # Check if the dot product is close to 1 or -1, within the epsilon range.\n  return jnp.abs(jnp.abs(dot_product) - 1) < epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors.\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors.\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Check if the dot product is close to 1 (within a small epsilon) or -1 (within a small epsilon).\n  # If it is, the lines are parallel.\n  return jnp.isclose(jnp.abs(dot_product), 1.0, atol=1e-5)"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Define a small epsilon value\n  epsilon = 1e-6\n\n  # Check if the dot product is close to 1 (or -1) within the epsilon range\n  return jnp.abs(dot_product - 1) < epsilon or jnp.abs(dot_product + 1) < epsilon"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1.0 - 1e-6\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Check if the absolute value of the dot product is close to 1, within a small epsilon\n  epsilon = 1e-6\n  return jnp.abs(dot_product - 1) < epsilon\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Check if the absolute value of the dot product is close to 1, within a small epsilon\n  epsilon = 1e-6\n  return jnp.abs(dot_product - 1.0) < epsilon\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  epsilon = 1e-6\n  return jnp.abs(jnp.dot(dir1, dir2)) > 1 - epsilon\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Define a small epsilon value to account for numerical precision issues\n  epsilon = 1e-6\n\n  # Check if the absolute value of the dot product is close to 1, within the epsilon range\n  return jnp.abs(dot_product - 1) < epsilon\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors\n  dot_product = jnp.dot(dir1, dir2)\n\n  # Set a small epsilon value for numerical precision\n  epsilon = 1e-6\n\n  # Check if the absolute value of the dot product is close to 1, within the epsilon range\n  return jnp.abs(dot_product) > (1 - epsilon)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n  return jnp.allclose(jnp.dot(dir1, dir2), 1.0)\n\n"}
{"namespace": "geometry.are_lines_parallel", "completion": "  # Normalize the direction vectors\n  dir1 = spin_math.normalize(dir1)\n  dir2 = spin_math.normalize(dir2)\n\n  # Compute the dot product of the normalized direction vectors\n  dot_product = jnp.sum(dir1 * dir2, axis=-1)\n\n  # Set the tolerance level for numerical precision\n  epsilon = 1e-6\n\n  # Check if the absolute value of the dot product is greater than 1 - epsilon\n  return jnp.abs(dot_product) > 1 - epsilon\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    bleu = evaluate.load(\"bleu\")\n    results = bleu.compute(predictions=[tokenizer(continuation)], references=[tokenizer(reference)])\n    if with_penalty:\n        return results[\"bleu\"]\n    else:\n        return results[\"bleu\"] * 100\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    metric = evaluate.load('bleu')\n    score = metric.compute(\n        predictions=[tokenizer(continuation)],\n        references=[tokenizer(reference)],\n        max_order=4,\n        smooth=True\n    )\n    if with_penalty:\n        return score['bleu']\n    else:\n        return score['bleu'] * 100\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    bleu = evaluate.load(\"bleu\")\n    bleu_score = bleu.compute(\n        predictions=[tokenizer(continuation)],\n        references=[tokenizer(reference)],\n        max_order=4,\n        smooth=True\n    )\n    if with_penalty:\n        return bleu_score[\"bleu\"]\n    else:\n        return bleu_score[\"bleu\"] * 100\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts using a custom tokenizer function\n    tokenizer = lambda x: list(jieba.cut(x))\n    continuation_tokens = tokenizer(continuation)\n    reference_tokens = tokenizer(reference)\n\n    # Compute the BLEU-4 score\n    bleu_metric = evaluate.load(\"bleu\")\n    bleu_score = bleu_metric.compute(\n        predictions=[continuation_tokens],\n        references=[reference_tokens],\n        max_order=4,\n        smooth=True\n    )[\"bleu\"]\n\n    # Optionally adjust the score for brevity penalty\n    if with_penalty:\n        if len(continuation_tokens) < len(reference_tokens):\n            ratio = len(continuation_tokens) / len(reference_tokens)\n            bleu_score = bleu_score * (1 - ratio) + ratio\n\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    metric = evaluate.load(\"bleu\")\n    score = metric.compute(predictions=[continuation], references=[[reference]], tokenizer=tokenizer)\n    if with_penalty:\n        return score[\"bleu\"]\n    else:\n        return score[\"bleu\"] * 100\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    bleu = evaluate.load(\"bleu\")\n    result = bleu.compute(\n        predictions=[continuation],\n        references=[[reference]],\n        tokenize=tokenizer,\n        max_order=4,\n        smooth=False\n    )\n    if with_penalty:\n        return result[\"bleu\"]\n    else:\n        return result[\"bleu\"] * 100\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    bleu = evaluate.load(\"bleu\")\n    bleu_score = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=tokenizer)['bleu']\n    if with_penalty:\n        return bleu_score\n    else:\n        return bleu_score['precisions'][0]\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    bleu = evaluate.load(\"bleu\")\n    bleu_score = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=tokenizer)[\"bleu\"]\n    if with_penalty:\n        reference_length = len(tokenizer(reference))\n        continuation_length = len(tokenizer(continuation))\n        if continuation_length < reference_length:\n            penalty = 1\n        else:\n            penalty = min(1, reference_length / continuation_length)\n        bleu_score = bleu_score * penalty\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    bleu = evaluate.load(\"bleu\")\n    results = bleu.compute(\n        predictions=[tokenizer(continuation)],\n        references=[tokenizer(reference)],\n        max_order=4,\n        smooth=True\n    )\n    if with_penalty:\n        return results[\"bleu\"]\n    else:\n        return results[\"bleu\"] * 100\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    bleu = evaluate.load(\"bleu\")\n    results = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=tokenizer)\n    if with_penalty:\n        return results[\"bleu\"]\n    else:\n        return results[\"bleu\"] * 100\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = custom_tokenizer(continuation)\n    reference_tokens = custom_tokenizer(reference)\n\n    # Compute the BLEU-4 score using the evaluate library's BLEU metric\n    bleu_metric = evaluate.load(\"bleu\")\n    bleu_score = bleu_metric.compute(predictions=[continuation_tokens], references=[reference_tokens])\n\n    # Optionally adjust the BLEU score for brevity penalty\n    if with_penalty:\n        bleu_score = bleu_score[\"bleu\"]\n    else:\n        bleu_score = bleu_score[\"bleu\"] * 100\n\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    bleu = evaluate.load(\"bleu\")\n    references = [tokenizer(reference)]\n    candidates = tokenizer(continuation)\n    results = bleu.compute(predictions=[candidates], references=references)\n    bleu_score = results[\"bleu\"]\n    if with_penalty:\n        return bleu_score\n    else:\n        return bleu_score * 100\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Define the tokenizer function\n    def tokenize_func(text):\n        return list(jieba.cut(text))\n\n    # Create a BLEU evaluator with 4-grams\n    evaluator = evaluate.load(\"bleu\", max_order=4)\n\n    # Tokenize the input texts\n    continuation_tokens = tokenize_func(continuation)\n    reference_tokens = tokenize_func(reference)\n\n    # Calculate the BLEU score\n    score = evaluator.compute(predictions=[continuation_tokens], references=[reference_tokens])\n\n    # Adjust the score for brevity penalty if required\n    if with_penalty:\n        reference_length = len(reference_tokens)\n        continuation_length = len(continuation_tokens)\n        if reference_length < continuation_length:\n            ratio = continuation_length / reference_length\n            score[\"bleu\"] = score[\"bleu\"] * (1 - 1 / ratio)\n\n    return score[\"bleu\"]\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    bleu = evaluate.load(\"bleu\")\n    bleu_score = bleu.compute(\n        predictions=[continuation],\n        references=[[reference]],\n        tokenizer=tokenizer,\n        max_order=4,\n        smooth=True\n    )\n    if with_penalty:\n        return bleu_score[\"bleu\"]\n    else:\n        return bleu_score[\"bleu\"] * 100\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    bleu = evaluate.load(\"bleu\")\n    bleu_score = bleu.compute(\n        predictions=[continuation],\n        references=[[reference]],\n        tokenizer=tokenizer,\n        max_order=4,\n        smooth=True\n    )[\"bleu\"]\n    if with_penalty:\n        reference_length = len(tokenizer(reference))\n        continuation_length = len(tokenizer(continuation))\n        if continuation_length < reference_length:\n            ratio = continuation_length / reference_length\n        else:\n            ratio = 1\n        bleu_score = bleu_score * ratio\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Tokenize the input texts using a custom tokenizer function\n    continuation_tokens = tokenizer(continuation)\n    reference_tokens = tokenizer(reference)\n\n    # Compute the BLEU-4 score\n    bleu = evaluate.load(\"bleu\")\n    results = bleu.compute(predictions=[continuation_tokens], references=[[reference_tokens]])\n    bleu_score = results[\"bleu\"]\n\n    # If the brevity penalty is included, adjust the score accordingly\n    if with_penalty:\n        # Calculate the length of the reference text\n        reference_length = len(reference_tokens)\n        # Calculate the length of the generated text\n        continuation_length = len(continuation_tokens)\n        # Calculate the brevity penalty\n        if continuation_length < reference_length:\n            penalty = 1\n        else:\n            penalty = math.exp(1 - reference_length / continuation_length)\n        # Adjust the BLEU-4 score with the brevity penalty\n        bleu_score = bleu_score * penalty\n\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    bleu = evaluate.load('bleu')\n    bleu_score = bleu.compute(\n        predictions=[continuation],\n        references=[[reference]],\n        tokenizer=tokenizer\n    )\n    if with_penalty:\n        return bleu_score['bleu']\n    else:\n        return bleu_score['bleu'] * 100\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    bleu = evaluate.load(\"bleu\")\n    bleu_score = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=tokenizer)['bleu']\n    if with_penalty:\n        # calculate the brevity penalty\n        reference_length = len(reference.split())\n        continuation_length = len(continuation.split())\n        if reference_length < continuation_length:\n            ratio = continuation_length / reference_length\n        else:\n            ratio = 1\n        # calculate the final BLEU score with the brevity penalty\n        bleu_score = bleu_score * (1 - 1 / ratio ** 4) ** 4\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    tokenizer = lambda x: list(jieba.cut(x))\n    bleu = evaluate.load('bleu')\n    bleu_score = bleu.compute(predictions=[continuation], references=[[reference]], tokenizer=tokenizer)['bleu']\n    if with_penalty:\n        reference_length = len(tokenizer(reference))\n        continuation_length = len(tokenizer(continuation))\n        if continuation_length < reference_length:\n            penalty = 1\n        else:\n            penalty = (1 - reference_length / continuation_length)\n        bleu_score = bleu_score * penalty\n    return bleu_score\n\n"}
{"namespace": "common.bleu4_score", "completion": "    # Define the tokenizer function\n    def tokenizer(text: str) -> list:\n        return list(jieba.cut(text))\n\n    # Create an instance of the BLEU evaluator\n    bleu_evaluator = evaluate.load(\"bleu\")\n\n    # Compute the BLEU score\n    bleu_score = bleu_evaluator.compute(\n        predictions=[continuation],\n        references=[reference],\n        tokenizer=tokenizer,\n        max_order=4,\n        smooth=True,\n        use_bp=with_penalty\n    )[\"bleu\"]\n\n    return bleu_score\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, value_at_zero, x)\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, value_at_zero, x)\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, value_at_zero + eps, x)\n  return jnp.sqrt(safe_x)"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, value_at_zero, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, value_at_zero, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, value_at_zero, jnp.sqrt(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, eps, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.maximum(x, eps)\n  return jnp.sqrt(safe_x) + value_at_zero\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, value_at_zero, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, value_at_zero, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, eps, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, value_at_zero + eps, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.maximum(x, eps)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, value_at_zero, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, eps, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, value_at_zero, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  return jnp.where(x < eps, value_at_zero, jnp.sqrt(x))\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, value_at_zero, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, value_at_zero + eps, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "spin_math.safe_sqrt", "completion": "  safe_x = jnp.where(x < eps, value_at_zero + eps, x)\n  return jnp.sqrt(safe_x)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / (t[..., 1:] - t[..., :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t, axis=-1, append=t[Ellipsis, -1:] - t[Ellipsis, -2:-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF by dividing the weights by the difference between consecutive elements.\n  pdf = w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n  return pdf\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.diff(t, axis=-1, append=1)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Calculate the differences between consecutive elements in the input vector t.\n  t_diff = t[..., 1:] - t[..., :-1]\n\n  # Divide the weights by the differences between consecutive elements in t to obtain the PDF.\n  pdf = w[..., :-1] / t_diff\n\n  # Append a zero to the end of the PDF to ensure that the PDF integrates to 1.\n  pdf = jnp.concatenate([pdf, jnp.zeros_like(pdf[..., :1])], axis=-1)\n\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF.\n  pdf = w / jnp.diff(t, axis=-1, append=1.)\n  return pdf\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Compute the difference between consecutive elements in the input vector t\n  t = jnp.diff(t, axis=-1)\n\n  # Divide the weights by the difference between consecutive elements in the input vector t\n  # to obtain the PDF\n  pdf = w / t\n\n  # Return the resulting PDF\n  return pdf"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  return w / jnp.concatenate([t[Ellipsis, :1], t[Ellipsis, 1:] - t[Ellipsis, :-1]], -1)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF.\n  pdf = w / jnp.diff(t, axis=-1)\n  # Return the PDF.\n  return pdf\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the step size.\n  dt = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n  # Pad the step size to match the shape of the weights.\n  dt = jnp.pad(dt, [(0, 0)] * (w.ndim - 1) + [(0, 1)])\n  # Divide the weights by the step size to obtain the PDF.\n  pdf = w / dt\n  return pdf\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF.\n  pdf = w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n  # Fix the last bin.\n  pdf = pdf.at[Ellipsis, -1].set(w[Ellipsis, -1])\n  return pdf\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / (t[Ellipsis, 1:] - t[Ellipsis, :-1])\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  return w / jnp.concatenate([t[Ellipsis, 1:] - t[Ellipsis, :-1],\n                              jnp.ones_like(t[Ellipsis, :1])], -1)\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Compute the difference between consecutive elements in t.\n  dt = jnp.concatenate([t[Ellipsis, :1] - t[Ellipsis, :1], t[Ellipsis, 1:] - t[Ellipsis, :-1]], axis=-1)\n  # Divide the weights by the difference between consecutive elements in t to obtain the PDF.\n  return w / dt\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the difference between consecutive elements in t.\n  dt = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n  # Divide the weights by the difference between consecutive elements in t to obtain the PDF.\n  return w[Ellipsis, :-1] / dt\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the step size.\n  dt = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n  # Pad the step size for the first and last elements.\n  dt = jnp.pad(dt, [(0, 0)] * (t.ndim - 1) + [(1, 1)])\n  # Compute the PDF.\n  p = w / dt\n  return p\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  # Calculate the difference between consecutive elements in t\n  dt = t[..., 1:] - t[..., :-1]\n\n  # Divide the weights by the difference between consecutive elements in t\n  pdf = w[..., :-1] / dt\n\n  # Append the last weight to the end of the PDF array\n  pdf = jnp.concatenate([pdf, w[..., -1:]], axis=-1)\n\n  # Return the resulting PDF\n  return pdf\n\n"}
{"namespace": "stepfun.weight_to_pdf", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the step size.\n  s = t[..., 1:] - t[..., :-1]\n  # Pad the step size with the first element, so that the first PDF value is\n  # consistent with the first weight.\n  s = jnp.concatenate([s[..., :1], s], axis=-1)\n  # Compute the PDF.\n  p = w / s\n  return p\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            # if not os.path.islink(fp):\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    for dirpath, _, filenames in os.walk(path):\n        for filename in filenames:\n            file_path = os.path.join(dirpath, filename)\n            try:\n                total_size += os.path.getsize(file_path)\n            except FileNotFoundError:\n                pass\n\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            try:\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    try:\n        for dirpath, _, filenames in os.walk(path):\n            for f in filenames:\n                try:\n                    fp = os.path.join(dirpath, f)\n                    total_size += os.path.getsize(fp)\n                except FileNotFoundError:\n                    pass\n    except FileNotFoundError:\n        pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n\n    # Walk through all files and subdirectories within the specified folder\n    for root, dirs, files in os.walk(path):\n\n        # Iterate through each file in the current directory\n        for file in files:\n\n            # Get the full path to the file\n            file_path = os.path.join(root, file)\n\n            # Try to get the size of the file\n            try:\n                total_size += os.path.getsize(file_path)\n\n            # If the file is not found, ignore the error and continue to the next file\n            except FileNotFoundError:\n                pass\n\n    # Return the total size of all files within the specified folder\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "litdata.streaming.reader._get_folder_size", "completion": "    total_size = 0\n    for dirpath, _, filenames in os.walk(path):\n        for f in filenames:\n            try:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n            except FileNotFoundError:\n                pass\n    return total_size\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    limited_val = val - torch.floor(val / period + offset) * period\n    return limited_val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    limited_val = val - torch.floor(val / period + offset) * period\n    return limited_val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_numpy = val, False\n    if isinstance(val, np.ndarray):\n        is_numpy = True\n    elif not isinstance(val, torch.Tensor):\n        raise ValueError(f'The value should be a tensor or numpy array, '\n                         f'but got {type(val)}.')\n    offset = val.new_tensor(offset)\n    period = val.new_tensor(period)\n    val = val - torch.floor(val / period + offset) * period\n    if is_numpy:\n        return val.numpy()\n\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_numpy = val, False\n    if isinstance(val, np.ndarray):\n        is_numpy = True\n    elif not isinstance(val, torch.Tensor):\n        raise TypeError(\n            f'The type of \"val\" must be np.ndarray or torch.Tensor, but got {type(val)}')\n    if offset < 0 or offset > 1:\n        raise ValueError(f'The value of \"offset\" should be in range [0, 1], '\n                         f'but got {offset}')\n    if period <= 0:\n        raise ValueError(f'The value of \"period\" should be above 0, '\n                         f'but got {period}')\n    val = val - torch.floor(val / period + offset) * period\n    if is_numpy:\n        return val.numpy()\n    else:\n        return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_numpy = val, False\n    if isinstance(val, np.ndarray):\n        is_numpy = True\n    elif not isinstance(val, torch.Tensor):\n        raise ValueError(f'The value should be a tensor or numpy array, '\n                         f'but got {type(val)}')\n    assert len(val.shape) == 1\n    val = val - torch.floor(val / period + offset) * period\n    if is_numpy:\n        return val.numpy()\n    else:\n        return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_numpy = val, False\n    if isinstance(val, np.ndarray):\n        is_numpy = True\n    elif not isinstance(val, torch.Tensor):\n        raise ValueError(\n            f'The value should be a tensor or numpy array, '\n            f'but got {type(val)}')\n    if isinstance(period, np.ndarray):\n        period = period.tolist()\n    if isinstance(period, torch.Tensor):\n        period = period.item()\n\n    val = val - torch.floor(val / period + offset) * period\n    if is_numpy:\n        return val.numpy()\n    else:\n        return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_numpy = val, False\n    if isinstance(val, np.ndarray):\n        is_numpy = True\n    elif not isinstance(val, torch.Tensor):\n        raise ValueError(f'The val type should be np.ndarray or torch.Tensor,'\n                         f'but got {type(val)}')\n    if isinstance(period, torch.Tensor):\n        period = period.item()\n    val = val - torch.floor(val / period + offset) * period\n    if is_numpy:\n        return val.numpy()\n\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_numpy = val, False\n    if isinstance(val, np.ndarray):\n        is_numpy = True\n    elif not isinstance(val, torch.Tensor):\n        raise ValueError(f'The val type is expected to be np.ndarray or torch.Tensor,'\n                         f' but got {type(val)}')\n    if offset > 0.5:\n        offset = offset - 1\n    val = val - torch.floor(val / period + offset) * period\n    if is_numpy:\n        return val.numpy()\n    else:\n        return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_numpy = val, False\n    if isinstance(val, np.ndarray):\n        is_numpy = True\n    elif not isinstance(val, torch.Tensor):\n        raise TypeError(\n            f'The type of \"val\" must be np.ndarray or torch.Tensor, but got {type(val)}')\n    if offset < 0 or offset > 1:\n        raise ValueError(f'The value of \"offset\" should be in range [0, 1], '\n                         f'but got {offset}')\n    if period < 0:\n        raise ValueError(f'The value of \"period\" should be a positive number, '\n                         f'but got {period}')\n    val = val - torch.floor(val / period + offset) * period\n    if is_numpy:\n        return val.numpy()\n    else:\n        return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    return val - torch.floor(val / period + offset) * period\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_numpy = val, False\n    if isinstance(val, np.ndarray):\n        is_numpy = True\n    elif not isinstance(val, torch.Tensor):\n        raise ValueError(f'The value should be a tensor or numpy array, '\n                         f'but got {type(val)}.')\n    if isinstance(period, torch.Tensor):\n        period = period.item()\n    if isinstance(val, torch.Tensor):\n        val = val - torch.floor(val / period + offset) * period\n    else:\n        val = val - np.floor(val / period + offset) * period\n    if is_numpy:\n        return val.astype(np.float32)\n    else:\n        return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_numpy = val, False\n    if isinstance(val, np.ndarray):\n        is_numpy = True\n    elif not isinstance(val, torch.Tensor):\n        raise ValueError(f'The value should be a tensor or numpy array, '\n                         f'but got {type(val)}')\n    if isinstance(period, np.ndarray):\n        period = period.tolist()\n    assert isinstance(period, (int, float))\n    val = val - torch.floor(val / period + offset) * period\n    if is_numpy:\n        return val.numpy()\n    else:\n        return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_numpy = val, False\n    if isinstance(val, np.ndarray):\n        is_numpy = True\n    elif not isinstance(val, torch.Tensor):\n        raise TypeError(\n            f'The type of \"val\" must be np.ndarray or torch.Tensor, but got {type(val)}')\n    t = offset + val / period\n    t = t - t.floor()\n    val = t * period - offset * period\n    if is_numpy:\n        val = val.numpy()\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    limited_val = val - torch.floor(val / period + offset) * period\n    return limited_val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_ndarray = val\n    normalized_val = val - torch.floor(val / period + offset) * period\n    if is_ndarray:\n        normalized_val = normalized_val.numpy()\n    return normalized_val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_numpy = val, False\n    if isinstance(val, np.ndarray):\n        is_numpy = True\n    elif not isinstance(val, torch.Tensor):\n        raise TypeError(\n            f'The type of \"val\" must be np.ndarray or torch.Tensor, but got {type(val)}')\n    limited_val = val - torch.floor(val / period + offset) * period\n    if is_numpy:\n        limited_val = limited_val.numpy()\n    return limited_val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_numpy = val, False\n    if isinstance(val, np.ndarray):\n        is_numpy = True\n    elif not isinstance(val, torch.Tensor):\n        raise ValueError(\n            f'The value should be a tensor or numpy array, '\n            f'but got {type(val)}')\n    if isinstance(period, np.ndarray):\n        period = period.tolist()\n    if isinstance(period, torch.Tensor):\n        period = period.item()\n\n    val = val - torch.floor(val / period + offset) * period\n    if is_numpy:\n        return val.numpy()\n\n    return val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_ndarray = val\n    normalized_val = val - torch.floor(val / period + offset) * period\n    if is_ndarray:\n        normalized_val = normalized_val.numpy()\n    return normalized_val\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.limit_period", "completion": "    val, is_numpy = val, False\n    if isinstance(val, np.ndarray):\n        is_numpy = True\n    elif not isinstance(val, torch.Tensor):\n        raise ValueError(\n            f'The value should be a tensor or numpy array, '\n            f'but got {type(val)}')\n    is_tensor = isinstance(val, torch.Tensor)\n    ori_shape = val.shape\n    val = val.reshape(-1)\n    val = val - torch.floor(val / period + offset) * period\n    if is_numpy:\n        return val.numpy().reshape(*ori_shape)\n    elif is_tensor:\n        return val.reshape(*ori_shape)\n    raise ValueError(\n        f'The value should be a tensor or numpy array, '\n        f'but got {type(val)}')\n\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # Convert the purpose_embedding from a numpy array to a list if necessary\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        # Create a dictionary representation of the MicroAgent instance\n        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist(),\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input,\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist(),\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input,\n        }\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # Convert the purpose_embedding from a numpy array to a list if necessary\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        # Create a dictionary representation of the MicroAgent instance\n        agent_dict = {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # Convert the purpose_embedding to a list if it is a numpy array\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        # Serialize the MicroAgent instance to a dictionary\n        agent_dict = {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        # Convert purpose_embedding to a list if necessary\n        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        # Create a dictionary representation of the MicroAgent instance\n        agent_dict = {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input\n        }\n\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input,\n            \"last_output\": agent.last_output,\n            \"last_execution_time\": agent.last_execution_time,\n            \"last_execution_success\": agent.last_execution_success,\n            \"last_execution_error\": agent.last_execution_error,\n            \"last_execution_output\": agent.last_execution_output,\n            \"last_execution_input\": agent.last_execution_input,\n            \"last_execution_agent_id\": agent.last_execution_agent_id,\n            \"last_execution_agent_name\": agent.last_execution_agent_name,\n            \"last_execution_agent_purpose\": agent.last_execution_agent_purpose,\n            \"last_execution_agent_depth\": agent.last_execution_agent_depth,\n            \"last_execution_agent_max_depth\": agent.last_execution_agent_max_depth,\n            \"last_execution_agent_usage_count\": agent.last_execution_agent_usage_count,\n            \"last_execution_agent_is_prime\": agent.last_execution_agent_is_prime,\n            \"last_execution_agent_evolve_count\": agent.last_execution_agent_evolve_count,\n            \"last_execution_agent_number_of_code_executions\": agent.last_execution_agent_number_of_code_executions,\n            \"last_execution_agent_last_input\": agent.last"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding.tolist() if isinstance(agent.purpose_embedding, np.ndarray) else agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input,\n        }\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return agent.__dict__\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        agent_dict = {\n            \"dynamic_prompt\": agent.dynamic_prompt,\n            \"purpose\": agent.purpose,\n            \"purpose_embedding\": agent.purpose_embedding,\n            \"depth\": agent.depth,\n            \"max_depth\": agent.max_depth,\n            \"usage_count\": agent.usage_count,\n            \"id\": agent.id,\n            \"parent_id\": agent.parent_id,\n            \"working_agent\": agent.working_agent,\n            \"is_prime\": agent.is_prime,\n            \"evolve_count\": agent.evolve_count,\n            \"number_of_code_executions\": agent.number_of_code_executions,\n            \"last_input\": agent.last_input\n        }\n\n        return agent_dict\n"}
{"namespace": "agent_serializer.AgentSerializer.to_dict", "completion": "        if isinstance(agent.purpose_embedding, np.ndarray):\n            agent.purpose_embedding = agent.purpose_embedding.tolist()\n\n        return {\n            'dynamic_prompt': agent.dynamic_prompt,\n            'purpose': agent.purpose,\n            'purpose_embedding': agent.purpose_embedding,\n            'depth': agent.depth,\n            'max_depth': agent.max_depth,\n            'usage_count': agent.usage_count,\n            'id': agent.id,\n            'parent_id': agent.parent_id,\n            'working_agent': agent.working_agent,\n            'is_prime': agent.is_prime,\n            'evolve_count': agent.evolve_count,\n            'number_of_code_executions': agent.number_of_code_executions,\n            'last_input': agent.last_input,\n            'last_output': agent.last_output,\n            'last_execution_successful': agent.last_execution_successful,\n            'last_execution_time': agent.last_execution_time\n        }\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Create a dictionary to store the items in each bin\n    bins = defaultdict(list)\n\n    # Create a dictionary to store the total weight of each bin\n    bin_weights = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Iterate over the sorted items\n    for item, weight in sorted_items:\n\n        # Find the bin with the lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n\n        # Add the item to the bin with the lowest total weight\n        bins[min_bin].append(item)\n\n        # Update the total weight of the bin\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check that the number of items and weights are equal\n    if len(items) != len(weights):\n        raise ValueError(\"The number of items and weights must be equal.\")\n\n    # Check that all weights are positive\n    if any(w < 0 for w in weights):\n        raise ValueError(\"All weights must be positive.\")\n\n    # Check that the number of bins is positive\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be positive.\")\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize the bins and their weights\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        # Find the bin with the current lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n\n        # Add the item to the bin and update its weight\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check that the number of items and weights are equal\n    assert len(items) == len(weights)\n\n    # Check that all weights are positive\n    assert all(weight >= 0 for weight in weights)\n\n    # Check that the number of bins is positive\n    assert num_bins > 0\n\n    # Create a dictionary to store the items in each bin\n    bins = defaultdict(list)\n\n    # Create a dictionary to store the total weight of each bin\n    bin_weights = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Iterate over the sorted items\n    for item, weight in sorted_items:\n\n        # Find the bin with the current lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n\n        # Add the item to the bin with the current lowest total weight\n        bins[min_bin].append(item)\n\n        # Update the total weight of the bin\n        bin_weights[min_bin] += weight\n\n    # Return the bins and bin weights\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check that the number of items and weights are equal\n    assert len(items) == len(weights)\n\n    # Check that all weights are positive\n    assert all(w >= 0 for w in weights)\n\n    # Sort the items by weight in descending order\n    items_sorted = [item for _, item in sorted(zip(weights, items), reverse=True)]\n    weights_sorted = sorted(weights, reverse=True)\n\n    # Initialize the bins and their total weights\n    bins = {i: [] for i in range(num_bins)}\n    bin_weights = {i: 0 for i in range(num_bins)}\n\n    # Distribute the items greedily into the bins\n    for item, weight in zip(items_sorted, weights_sorted):\n        # Find the bin with the current lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n\n        # Add the item to the bin and update its total weight\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights)\n    assert all(w > 0 for w in weights)\n    assert num_bins > 0\n\n    # Create a dictionary to store the items in each bin\n    bins = defaultdict(list)\n\n    # Create a dictionary to store the total weight of each bin\n    bin_weights = defaultdict(int)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Iterate over the sorted items\n    for item, weight in sorted_items:\n\n        # Find the bin with the current lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n\n        # Add the item to the bin\n        bins[min_bin].append(item)\n\n        # Update the total weight of the bin\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights)\n    assert all(w >= 0 for w in weights)\n    assert num_bins > 0\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize a dictionary to store the items in each bin\n    bins = defaultdict(list)\n\n    # Initialize a dictionary to store the total weight of each bin\n    bin_weights = defaultdict(int)\n\n    # Iterate over the sorted items and place them in the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        # Find the bin with the current lowest total weight\n        bin_index = min(bin_weights, key=bin_weights.get)\n\n        # Add the item to the bin\n        bins[bin_index].append(item)\n\n        # Update the total weight of the bin\n        bin_weights[bin_index] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights)\n    assert num_bins > 0\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize the bins and their weights\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Place each item into the bin with the current lowest total weight\n    for item, weight in sorted_items:\n        bin_index = min(bin_weights, key=bin_weights.get)\n        bins[bin_index].append(item)\n        bin_weights[bin_index] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize the bins and their total weights\n    bins = {i: [] for i in range(num_bins)}\n    bin_weights = {i: 0 for i in range(num_bins)}\n\n    # Distribute the items greedily\n    for item, weight in sorted_items:\n        # Find the bin with the lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n\n        # Add the item to the bin\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check that the number of items and weights are equal\n    if len(items) != len(weights):\n        raise ValueError(\"The number of items and weights must be equal.\")\n\n    # Check that all weights are positive\n    if any(w < 0 for w in weights):\n        raise ValueError(\"All weights must be positive.\")\n\n    # Check that the number of bins is positive\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be positive.\")\n\n    # Sort the items by weight in descending order\n    items_weights = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize the bins and their total weights\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Iterate over the sorted items and place them in the bin with the current lowest total weight\n    for item, weight in items_weights:\n        # Find the bin with the current lowest total weight\n        bin_idx = min(bin_weights, key=bin_weights.get)\n\n        # Add the item and its weight to the bin\n        bins[bin_idx].append(item)\n        bin_weights[bin_idx] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check that the number of items and weights are equal\n    if len(items) != len(weights):\n        raise ValueError(\"The number of items and weights must be equal.\")\n\n    # Check that all weights are positive\n    if any(w < 0 for w in weights):\n        raise ValueError(\"All weights must be positive.\")\n\n    # Check that num_bins is positive\n    if num_bins <= 0:\n        raise ValueError(\"num_bins must be positive.\")\n\n    # Sort items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize a dictionary to store the items in each bin\n    bins = defaultdict(list)\n\n    # Initialize a dictionary to store the total weight of each bin\n    bin_weights = defaultdict(int)\n\n    # Iterate over the sorted items\n    for item, weight in sorted_items:\n\n        # Find the bin with the current lowest total weight\n        bin_idx = min(bin_weights, key=bin_weights.get)\n\n        # Add the item to the bin\n        bins[bin_idx].append(item)\n\n        # Update the total weight of the bin\n        bin_weights[bin_idx] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check if the number of items and weights are equal\n    if len(items) != len(weights):\n        raise ValueError(\"The number of items and weights must be equal.\")\n\n    # Check if the number of bins is positive\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be positive.\")\n\n    # Check if all weights are positive\n    if any(weight <= 0 for weight in weights):\n        raise ValueError(\"All weights must be positive.\")\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize the bin dictionary and the bin weights dictionary\n    bin_dict = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Iterate over the sorted items\n    for item, weight in sorted_items:\n        # Find the bin with the current lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n\n        # Add the item to the bin with the current lowest total weight\n        bin_dict[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    # Return the bin dictionary and the bin weights dictionary\n    return bin_dict, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check that the number of items and weights match\n    assert len(items) == len(weights)\n\n    # Check that all weights are positive\n    assert all(w >= 0 for w in weights)\n\n    # Check that there are at least as many items as bins\n    assert len(items) >= num_bins\n\n    # Sort items by weight in descending order\n    items_sorted = [item for _, item in sorted(zip(weights, items), reverse=True)]\n    weights_sorted = sorted(weights, reverse=True)\n\n    # Initialize bins and total weights\n    bins = defaultdict(list)\n    total_weights = defaultdict(int)\n\n    # Distribute items greedily\n    for item, weight in zip(items_sorted, weights_sorted):\n        # Find the bin with the lowest total weight\n        min_bin = min(total_weights, key=total_weights.get)\n\n        # Add item to the bin with the lowest total weight\n        bins[min_bin].append(item)\n        total_weights[min_bin] += weight\n\n    return bins, total_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check that the lengths of items and weights are equal\n    assert len(items) == len(weights)\n\n    # Check that all weights are positive\n    assert all(w > 0 for w in weights)\n\n    # Check that num_bins is positive\n    assert num_bins > 0\n\n    # Create a dictionary to store the bins\n    bins = {i: [] for i in range(num_bins)}\n\n    # Create a dictionary to store the total weight of each bin\n    bin_weights = {i: 0 for i in range(num_bins)}\n\n    # Sort the items by weight in descending order\n    items_sorted = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Iterate over the sorted items\n    for item, weight in items_sorted:\n\n        # Find the bin with the lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n\n        # Add the item to the bin with the lowest total weight\n        bins[min_bin].append(item)\n\n        # Update the total weight of the bin\n        bin_weights[min_bin] += weight\n\n    # Return the bins and their weights\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights)\n    assert all(w > 0 for w in weights)\n    assert num_bins > 0\n\n    # Create a list of tuples containing the item and its weight\n    item_weights = list(zip(items, weights))\n\n    # Sort the items by weight in descending order\n    item_weights.sort(key=lambda x: x[1], reverse=True)\n\n    # Initialize the dictionary of bins and their weights\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Iterate over the items and place them into the bins\n    for item, weight in item_weights:\n        # Find the bin with the current lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n\n        # Place the item into the bin\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check that the number of items and weights are equal\n    if len(items) != len(weights):\n        raise ValueError(\"The number of items and weights must be equal.\")\n\n    # Check that all weights are positive\n    if any(weight <= 0 for weight in weights):\n        raise ValueError(\"All weights must be positive.\")\n\n    # Check that the number of bins is positive\n    if num_bins <= 0:\n        raise ValueError(\"The number of bins must be positive.\")\n\n    # Create a dictionary to store the items and weights\n    item_weights = dict(zip(items, weights))\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(item_weights.items(), key=lambda x: x[1], reverse=True)\n\n    # Initialize the bins and their weights\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Iterate over the sorted items and place them in the bins\n    for item, weight in sorted_items:\n        # Find the bin with the current lowest total weight\n        bin_index = min(bin_weights, key=bin_weights.get)\n\n        # Add the item and weight to the bin\n        bins[bin_index].append(item)\n        bin_weights[bin_index] += weight\n\n    # Return the bins and their weights\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights), \"The length of 'items' and 'weights' must be equal.\"\n    assert all(w > 0 for w in weights), \"All weights must be positive.\"\n    assert num_bins > 0, \"The number of bins must be positive.\"\n\n    # Sort items by weight in descending order\n    items_sorted = [x for _, x in sorted(zip(weights, items), reverse=True)]\n    weights_sorted = sorted(weights, reverse=True)\n\n    # Initialize bins and their weights\n    bins = {i: [] for i in range(num_bins)}\n    bin_weights = {i: 0 for i in range(num_bins)}\n\n    # Place items in bins greedily\n    for item, weight in zip(items_sorted, weights_sorted):\n        # Find the bin with the current lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n\n        # Place the item in the bin with the current lowest total weight\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    # Check that the lengths of the items and weights lists are the same\n    assert len(items) == len(weights)\n\n    # Create a dictionary to map each item to its weight\n    item_weights = {item: weight for item, weight in zip(items, weights)}\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(items, key=lambda x: item_weights[x], reverse=True)\n\n    # Initialize a dictionary to store the items in each bin\n    bins = defaultdict(list)\n\n    # Initialize a dictionary to store the total weight of each bin\n    bin_weights = defaultdict(int)\n\n    # Distribute the items into the bins\n    for item in sorted_items:\n        # Find the bin with the current lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get, default=0)\n\n        # Add the item to the bin and update the total weight of the bin\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += item_weights[item]\n\n    # Return the bins and their total weights\n    return bins, bin_weights"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights)\n    assert all(w > 0 for w in weights)\n    assert num_bins > 0\n\n    # Sort items by weight in descending order\n    items_weights = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize bins and their weights\n    bins = defaultdict(list)\n    bin_weights = defaultdict(int)\n\n    # Place items into bins greedily\n    for item, weight in items_weights:\n        # Find the bin with the current lowest total weight\n        min_bin = min(bin_weights, key=bin_weights.get)\n\n        # Add item to bin\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights)\n    assert all(w >= 0 for w in weights)\n\n    # Sort the items by weight in descending order\n    sorted_items = sorted(zip(items, weights), key=lambda x: x[1], reverse=True)\n\n    # Initialize the bins and their total weights\n    bins = {i: [] for i in range(num_bins)}\n    bin_weights = {i: 0 for i in range(num_bins)}\n\n    # Distribute the items greedily into the bins\n    for item, weight in sorted_items:\n        # Find the bin with the current lowest total weight\n        min_bin = min(bins, key=lambda i: bin_weights[i])\n        # Add the item to the bin and update its total weight\n        bins[min_bin].append(item)\n        bin_weights[min_bin] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "litdata.utilities.packing._pack_greedily", "completion": "    assert len(items) == len(weights)\n    assert all(w > 0 for w in weights)\n    assert num_bins > 0\n\n    # Sort items by weight in descending order\n    items, weights = zip(*sorted(zip(items, weights), key=lambda x: x[1], reverse=True))\n\n    # Initialize bins\n    bins = {i: [] for i in range(num_bins)}\n    bin_weights = {i: 0 for i in range(num_bins)}\n\n    # Distribute items greedily\n    for item, weight in zip(items, weights):\n        # Find the bin with the current lowest total weight\n        bin_index = min(bin_weights, key=bin_weights.get)\n        # Add item to bin\n        bins[bin_index].append(item)\n        bin_weights[bin_index] += weight\n\n    return bins, bin_weights\n\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        arg_hash = hashlib.sha256()\n        arg_hash.update(func_name.encode(\"utf-8\"))\n        arg_hash.update(json.dumps(args).encode(\"utf-8\"))\n        arg_hash.update(json.dumps(kwargs).encode(\"utf-8\"))\n        return arg_hash.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = json.dumps((func_name, args, kwargs))\n        return hashlib.sha256(data.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name,) + args + tuple(sorted(kwargs.items()))\n        data_string = json.dumps(data)\n        return hashlib.sha256(data_string.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        arg_data = json.dumps((func_name, args, kwargs))\n        arg_hash = hashlib.sha256(arg_data.encode(\"utf-8\")).hexdigest()\n        return arg_hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = func_name + json.dumps(args) + json.dumps(kwargs)\n        return hashlib.sha256(data.encode(\"utf-8\")).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_bytes = json.dumps(data).encode('utf-8')\n        return hashlib.sha256(data_bytes).hexdigest()"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name,) + args + tuple(sorted(kwargs.items()))\n        data_str = json.dumps(data, sort_keys=True)\n        data_bytes = data_str.encode(\"utf-8\")\n        return hashlib.sha256(data_bytes).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = func_name\n        for arg in args:\n            data += str(arg)\n        for key, value in kwargs.items():\n            data += str(key) + str(value)\n\n        return hashlib.sha256(data.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        arg_hash = hashlib.sha256()\n        arg_hash.update(func_name.encode('utf-8'))\n        arg_hash.update(json.dumps(args).encode('utf-8'))\n        arg_hash.update(json.dumps(kwargs).encode('utf-8'))\n        return arg_hash.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = {\"func_name\": func_name, \"args\": args, \"kwargs\": kwargs}\n        data_string = json.dumps(data, sort_keys=True)\n        arg_hash = hashlib.sha256(data_string.encode(\"utf-8\")).hexdigest()\n        return arg_hash"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name,) + args + tuple(kwargs.items())\n        data_str = json.dumps(data, sort_keys=True)\n        data_bytes = data_str.encode(\"utf-8\")\n        return hashlib.sha256(data_bytes).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        arg_data = (func_name,) + args + tuple(kwargs.items())\n        arg_data_bytes = json.dumps(arg_data).encode(\"utf-8\")\n        arg_hash = hashlib.sha256(arg_data_bytes).hexdigest()\n        return arg_hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        arg_dict = {\"args\": args, \"kwargs\": kwargs}\n        arg_str = json.dumps(arg_dict, sort_keys=True)\n        data = f\"{func_name}-{arg_str}\".encode(\"utf-8\")\n        arg_hash = hashlib.sha256(data).hexdigest()\n        return arg_hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        arg_hash = hashlib.sha256()\n        arg_hash.update(func_name.encode('utf-8'))\n        arg_hash.update(str(args).encode('utf-8'))\n        arg_hash.update(str(kwargs).encode('utf-8'))\n        return arg_hash.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = json.dumps({\n            \"func_name\": func_name,\n            \"args\": args,\n            \"kwargs\": kwargs,\n        }, sort_keys=True).encode(\"utf-8\")\n        return hashlib.sha256(data).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name,) + args + tuple(kwargs.items())\n        data_string = json.dumps(data)\n        data_bytes = data_string.encode(\"utf-8\")\n        hash_object = hashlib.sha256(data_bytes)\n        return hash_object.hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        arg_data = json.dumps((func_name, args, kwargs))\n        arg_hash = hashlib.sha256(arg_data.encode()).hexdigest()\n        return arg_hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = (func_name, args, kwargs)\n        data_json = json.dumps(data)\n        data_bytes = data_json.encode('utf-8')\n        return hashlib.sha256(data_bytes).hexdigest()\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        arg_str = json.dumps([func_name, list(args), kwargs])\n        arg_bytes = arg_str.encode(\"utf-8\")\n        arg_hash = hashlib.sha256(arg_bytes).hexdigest()\n        return arg_hash\n"}
{"namespace": "memoize.SQLiteMemoization._compute_hash", "completion": "        data = json.dumps((func_name, args, kwargs))\n        return hashlib.sha256(data.encode(\"utf-8\")).hexdigest()\n"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the Euclidean distance between consecutive points\n    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n\n    # Filter out distances that exceed the maximum point distance\n    filtered_distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the pairwise distances between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Filter out distances that exceed the maximum distance threshold\n    filtered_distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the Euclidean distance between consecutive points\n    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n\n    # Filter out distances that exceed the maximum point distance\n    filtered_distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the Euclidean distances between consecutive points\n    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n\n    # Filter out distances that exceed the maximum point distance\n    filtered_distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the distances between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Filter out distances that exceed the maximum threshold\n    filtered_distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the pairwise distances between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Filter out distances that exceed the maximum point distance\n    distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the Euclidean distance between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Filter out distances that exceed the maximum distance threshold\n    filtered_distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the Euclidean distance between consecutive points\n    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n\n    # Filter out distances that exceed the maximum distance\n    filtered_distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if len(polygon.shape) != 2 or polygon.shape[1] != 2:\n        raise ValueError(f\"Unable to determine the length of a polygon with shape {polygon.shape}. Expecting (_, 2).\")\n\n    # Compute the Euclidean distance between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Filter out distances that exceed the maximum point distance\n    filtered_distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the pairwise distances between all points in the polygon\n    distances = np.linalg.norm(polygon[:-1] - polygon[1:], axis=1)\n\n    # Compute the total length of the polygon by summing the distances between consecutive points, excluding distances that exceed the maximum point distance\n    total_length = np.sum(distances[distances <= max_point_distance])\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the pairwise distances between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Filter out distances that exceed the maximum point distance\n    filtered_distances = distances[distances <= max_point_distance]\n\n    # Sum the filtered distances to obtain the total length\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the Euclidean distance between consecutive points\n    distances = np.linalg.norm(np.diff(polygon, axis=0), axis=1)\n\n    # Filter out distances that exceed the maximum distance threshold\n    filtered_distances = distances[distances <= max_point_distance]\n\n    # Sum the remaining distances to obtain the total length\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the pairwise distances between all points in the polygon\n    pairwise_distances = np.linalg.norm(polygon[:-1, :] - polygon[1:, :], axis=1)\n\n    # Filter the distances that exceed the maximum point distance\n    filtered_distances = pairwise_distances[pairwise_distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the pairwise distances between all points in the polygon\n    distances = np.linalg.norm(polygon[:-1, :] - polygon[1:, :], axis=1)\n\n    # Filter out distances that exceed the maximum distance\n    filtered_distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon by summing the filtered distances\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if len(polygon.shape) != 2 or polygon.shape[1] != 2:\n        raise ValueError(f\"Unable to determine the area of a polygon with shape {polygon.shape}. Expecting (_, 2).\")\n\n    # Compute the Euclidean distance between consecutive points in the polygon\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Filter out distances that exceed the maximum point distance\n    filtered_distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon by summing the filtered distances\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the pairwise distances between all points in the polygon\n    distances = np.sqrt(np.sum((polygon[:-1] - polygon[1:]) ** 2, axis=1))\n\n    # Filter out distances that are above the maximum distance threshold\n    filtered_distances = distances[distances <= max_point_distance]\n\n    # Compute the total length of the polygon\n    total_length = np.sum(filtered_distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the Euclidean distances between consecutive points in the polygon\n    distances = np.sqrt(np.sum(np.diff(polygon, axis=0) ** 2, axis=1))\n\n    # Set distances that exceed the maximum to zero\n    distances[distances > max_point_distance] = 0\n\n    # Compute the total length of the polygon\n    total_length = np.sum(distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the pairwise distances between all points in the polygon\n    distances = np.sqrt(np.sum((polygon[:, np.newaxis, :] - polygon[np.newaxis, :, :]) ** 2, axis=-1))\n\n    # Set the diagonal elements to infinity to exclude self-distances\n    np.fill_diagonal(distances, np.inf)\n\n    # Set the distances between points that exceed the maximum distance to infinity\n    distances[distances > max_point_distance] = np.inf\n\n    # Compute the total length by summing the minimum distances between each point and its nearest neighbor\n    total_length = np.sum(np.min(distances, axis=1))\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    # Compute the pairwise distances between consecutive points\n    distances = np.linalg.norm(polygon[1:] - polygon[:-1], axis=1)\n\n    # Filter out distances that exceed the maximum threshold\n    distances = distances[distances <= max_point_distance]\n\n    # Sum the remaining distances to get the total length\n    total_length = np.sum(distances)\n\n    return total_length"}
{"namespace": "iris.utils.math.polygon_length", "completion": "    if len(polygon.shape) != 2 or polygon.shape[1] != 2:\n        raise ValueError(f\"Unable to determine the area of a polygon with shape {polygon.shape}. Expecting (_, 2).\")\n\n    distances = np.linalg.norm(polygon[:-1, :] - polygon[1:, :], axis=1)\n    distances = np.where(distances < max_point_distance, distances, 0)\n    return float(np.sum(distances))\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Check if the input list is empty\n    if not polygons:\n        return polygons\n\n    # Find the polygon with the largest area\n    largest_area = max(area(polygon) for polygon in polygons)\n\n    # Filter out polygons based on the area criteria\n    filtered_polygons = [\n        polygon\n        for polygon in polygons\n        if area(polygon) >= max(rel_tr * largest_area, abs_tr)\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Calculate the area of each polygon\n    areas = [area(polygon) for polygon in polygons]\n\n    # Find the index of the largest polygon\n    largest_idx = np.argmax(areas)\n\n    # Calculate the area of the largest polygon\n    largest_area = areas[largest_idx]\n\n    # Filter out polygons based on the area criteria\n    filtered_polygons = [\n        polygon\n        for i, polygon in enumerate(polygons)\n        if areas[i] > largest_area * rel_tr and areas[i] > abs_tr\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return polygons\n\n    # Calculate the areas of the polygons\n    areas = [area(polygon) for polygon in polygons]\n\n    # Find the largest polygon's area\n    max_area = max(areas)\n\n    # Filter out polygons based on the area criteria\n    filtered_polygons = [\n        polygon for polygon, area in zip(polygons, areas) if area > max(rel_tr * max_area, abs_tr)\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    return [\n        polygon\n        for polygon, area in zip(polygons, areas)\n        if area > max(rel_tr * max_area, abs_tr)\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if not polygons:\n        return []\n\n    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    return [polygon for polygon, area in zip(polygons, areas) if area > max(rel_tr * max_area, abs_tr)]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [\n        polygon for polygon, area in zip(polygons, areas) if area > rel_tr * max_area or area > abs_tr\n    ]\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if not polygons:\n        return []\n\n    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    rel_area = max_area * rel_tr\n    return [polygon for polygon, area in zip(polygons, areas) if area > max(rel_area, abs_tr)]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Find the largest polygon area\n    largest_area = max(area(polygon) for polygon in polygons)\n\n    # Filter out polygons based on the relative and absolute thresholds\n    filtered_polygons = [\n        polygon\n        for polygon in polygons\n        if area(polygon) > rel_tr * largest_area and area(polygon) > abs_tr\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    return [\n        polygon\n        for polygon, polygon_area in zip(polygons, areas)\n        if polygon_area > max(rel_tr * max_area, abs_tr)\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Calculate the areas of the polygons\n    areas = [area(polygon) for polygon in polygons]\n\n    # Calculate the maximum area\n    max_area = max(areas)\n\n    # Filter out polygons based on the relative and absolute thresholds\n    filtered_polygons = [\n        polygon\n        for polygon, area in zip(polygons, areas)\n        if area > max(rel_tr * max_area, abs_tr)\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Get the areas of all polygons\n    areas = [area(polygon) for polygon in polygons]\n\n    # Find the index of the largest polygon\n    largest_area_index = np.argmax(areas)\n\n    # Get the area of the largest polygon\n    largest_area = areas[largest_area_index]\n\n    # Filter out polygons with an area below the threshold\n    filtered_polygons = [\n        polygon\n        for i, polygon in enumerate(polygons)\n        if areas[i] > largest_area * rel_tr and areas[i] > abs_tr\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return polygons\n    areas = np.array([area(polygon) for polygon in polygons])\n    max_area = areas.max()\n    rel_tr = rel_tr * max_area\n    area_mask = np.logical_and(areas >= rel_tr, areas >= abs_tr)\n    return [polygon for polygon, mask in zip(polygons, area_mask) if mask]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return []\n\n    polygons_areas = [area(polygon) for polygon in polygons]\n    max_area = max(polygons_areas)\n\n    return [\n        polygon\n        for polygon, area in zip(polygons, polygons_areas)\n        if area >= rel_tr * max_area and area >= abs_tr\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    # Check if polygons is a list of numpy arrays\n    if not isinstance(polygons, list) or not all(isinstance(p, np.ndarray) for p in polygons):\n        raise TypeError(\"polygons must be a list of numpy arrays\")\n\n    # Check if rel_tr and abs_tr are non-negative floats\n    if not isinstance(rel_tr, (float, int)) or not isinstance(abs_tr, (float, int)):\n        raise TypeError(\"rel_tr and abs_tr must be non-negative floats\")\n    if rel_tr < 0 or abs_tr < 0:\n        raise ValueError(\"rel_tr and abs_tr must be non-negative\")\n\n    # Find the largest polygon area\n    largest_area = max(area(p) for p in polygons)\n\n    # Filter out polygons based on area\n    filtered_polygons = [\n        p\n        for p in polygons\n        if area(p) > max(rel_tr * largest_area, abs_tr)\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    filtered_polygons = [\n        polygon\n        for polygon, area in zip(polygons, areas)\n        if area > rel_tr * max_area and area > abs_tr\n    ]\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return polygons\n\n    # Calculate the area of each polygon\n    areas = [area(polygon) for polygon in polygons]\n\n    # Find the largest area\n    max_area = max(areas)\n\n    # Calculate the absolute threshold based on the largest area\n    abs_threshold = abs_tr * max_area\n\n    # Calculate the relative threshold based on the largest area\n    rel_threshold = rel_tr * max_area\n\n    # Filter out polygons with areas below the thresholds\n    filtered_polygons = [\n        polygon\n        for polygon, area in zip(polygons, areas)\n        if area >= abs_threshold and area >= rel_threshold\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return polygons\n\n    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n\n    return [\n        polygon\n        for polygon, area in zip(polygons, areas)\n        if area > max(rel_tr * max_area, abs_tr)\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if len(polygons) == 0:\n        return polygons\n\n    # Find the polygon with the largest area\n    largest_area = max(area(polygon) for polygon in polygons)\n\n    # Filter out polygons that have an area below the threshold\n    filtered_polygons = [\n        polygon\n        for polygon in polygons\n        if area(polygon) >= max(rel_tr * largest_area, abs_tr)\n    ]\n\n    return filtered_polygons\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    if not polygons:\n        return []\n\n    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n\n    return [\n        polygon\n        for polygon, area in zip(polygons, areas)\n        if area > max(rel_tr * max_area, abs_tr)\n    ]\n\n"}
{"namespace": "iris.nodes.vectorization.contouring.filter_polygon_areas", "completion": "    areas = [area(polygon) for polygon in polygons]\n    max_area = max(areas)\n    return [\n        polygon\n        for polygon, area in zip(polygons, areas)\n        if area > max_area * rel_tr or area > abs_tr\n    ]\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker_batch = num_samples_per_worker // batch_size\n    num_samples_per_worker_batch_remainder = num_samples_per_worker % batch_size\n\n    num_samples_per_worker_batch_remainder_per_worker = num_samples_per_worker_batch_remainder // num_workers\n    num_samples_per_worker_batch_remainder_remainder = num_samples_per_worker_batch_remainder % num_workers\n\n    num_samples_per_worker_batch_per_worker = [num_samples_per_worker_batch] * num_workers\n    for i in range(num_samples_per_worker_batch_remainder_remainder):\n        num_samples_per_worker_batch_per_worker[i] += 1\n\n    num_samples_per_worker_batch_per_worker = [\n        num_samples_per_worker_batch_per_worker[i] * batch_size + num_samples_per_worker_batch_remainder_per_worker\n        for i in range(num_workers)\n    ]\n\n    num_samples_per_worker_batch_per_worker = [\n        num_samples_per_worker_batch_per_worker[i] + num_samples_per_worker_batch_remainder_remainder\n        if i < num_samples_per_worker_batch_remainder_remainder\n        else num_samples_per_worker_batch_per_worker[i]\n        for i in range(num_workers)\n    ]\n\n    num_samples_per_worker_batch_per_worker = [\n        num_samples_per_worker_batch_per_worker[i] + num_samples_per_worker_batch_remainder_remainder\n        if i < num_samples_"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker_remainder = num_samples_yielded % num_workers\n\n    # Distribute any remaining samples among the workers\n    num_samples_per_worker += num_samples_per_worker_remainder // num_workers\n    num_samples_per_worker_remainder %= num_workers\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker_dict = {\n        i: num_samples_per_worker + (1 if i < num_samples_per_worker_remainder else 0) for i in range(num_workers)\n    }\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker_remainder = num_samples_yielded % num_workers\n\n    # Distribute any remaining samples among the workers\n    num_samples_per_worker += num_samples_per_worker_remainder // num_workers\n    num_samples_per_worker_remainder %= num_workers\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker_dict = {\n        i: num_samples_per_worker + (1 if i < num_samples_per_worker_remainder else 0) for i in range(num_workers)\n    }\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker_remainder = num_samples_yielded % num_workers\n\n    # Distribute any remaining samples among the workers\n    num_samples_per_worker += num_samples_per_worker_rem"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker_remainder = num_samples_yielded % num_workers\n\n    # Distribute any remaining samples among the workers\n    num_samples_per_worker += num_samples_per_worker_remainder // num_workers\n    num_samples_per_worker_remainder %= num_workers\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker_list = [num_samples_per_worker] * num_workers\n    for i in range(num_samples_per_worker_remainder):\n        num_samples_per_worker_list[i] += 1\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker_cumsum = np.cumsum(num_samples_per_worker_list)\n    num_samples_per_worker_cumsum = np.insert(num_samples_per_worker_cumsum, 0, 0)\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker_dict = {}\n    for i in range(num_workers):\n        num_samples_per_worker_dict[i] = num_samples_per_worker_cumsum[i + 1]\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker_dict = {\n        i: num_samples_per_worker_dict[i] // batch_size for i in num_samples_per_worker_dict\n    }\n\n    return num_samples_per_worker_dict\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker_remainder = num_samples_yielded % num_workers\n\n    # Calculate the number of batches each worker has processed\n    num_batches_per_worker = num_samples_per_worker // batch_size\n    num_batches_per_worker_remainder = num_samples_per_worker % batch_size\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_batches_per_worker * batch_size\n    num_samples_per_worker_remainder = num_batches_per_worker_remainder * batch_size\n\n    # Distribute any remaining samples among the workers\n    num_samples_per_worker += num_samples_per_worker_remainder // num_workers\n    num_samples_per_worker_remainder = num_samples_per_worker_remainder % num_workers\n\n    # Create a dictionary to store the number of samples each worker has processed\n    samples_per_worker = {}\n    for worker_idx in range(num_workers):\n        samples_per_worker[worker_idx] = num_samples_per_worker\n\n    # Distribute any remaining samples among the workers\n    for worker_idx in range(num_samples_per_worker_remainder):\n        samples_per_worker[worker_idx] += 1\n\n    return samples_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker_rounded = num_samples_per_worker // batch_size * batch_size\n    num_samples_per_worker_remainder = num_samples_per_worker % batch_size\n    num_samples_per_worker_rounded_per_worker = num_samples_per_worker_rounded // num_workers\n\n    num_samples_per_worker_remainder_per_worker = num_samples_per_worker_remainder // num_workers\n    num_samples_per_worker_remainder_per_worker_remainder = num_samples_per_worker_remainder % num_workers\n\n    num_samples_per_worker_per_worker = [num_samples_per_worker_rounded_per_worker] * num_workers\n    for i in range(num_samples_per_worker_remainder_per_worker_remainder):\n        num_samples_per_worker_per_worker[i] += 1\n\n    num_samples_per_worker_per_worker = [\n        num_samples_per_worker_rounded_per_worker + num_samples_per_worker_remainder_per_worker\n    ] * num_workers\n    for i in range(num_samples_per_worker_remainder_per_worker):\n        num_samples_per_worker_per_worker[i] += 1\n\n    num_samples_per_worker_per_worker = [\n        num_samples_per_worker_rounded_per_worker + num_samples_per_worker_remainder_per_worker\n    ] * num_workers\n    for i in range(num_samples_per_worker_remainder_per_worker_remainder):\n        num_samples_per_worker_per_worker[i] += 1\n\n    num_samples_per_worker_per_worker"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that have not been processed by any worker\n    remaining_samples = num_samples_yielded % num_workers\n\n    # Calculate the number of samples each worker has processed, taking into account the remaining samples\n    num_samples_per_worker_with_remainder = num_samples_per_worker + (remaining_samples // num_workers)\n\n    # Calculate the number of samples that have not been processed by any worker, taking into account the remaining samples\n    remaining_samples = remaining_samples % num_workers\n\n    # Distribute the remaining samples among the workers\n    for i in range(remaining_samples):\n        num_samples_per_worker_with_remainder[i] += 1\n\n    # Calculate the number of samples each worker has processed, given the batch size\n    num_samples_per_worker_with_batch_size = [\n        num_samples_per_worker_with_remainder[i] // batch_size for i in range(num_workers)\n    ]\n\n    # Calculate the number of samples that have not been processed by any worker, given the batch size\n    remaining_samples_with_batch_size = [\n        num_samples_per_worker_with_remainder[i] % batch_size for i in range(num_workers)\n    ]\n\n    # Distribute the remaining samples among the workers, given the batch size\n    for i in range(remaining_samples):\n        num_samples_per_worker_with_batch_size[i] += 1\n\n    # Calculate the number of samples each worker has processed, given the batch size and the number of samples yielded\n    num_samples_per_worker_with_batch_size_and_yielded = [\n        num_samples_per_worker_with_batch_size[i] * batch_size + remaining_samples_with_"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker_rounded = num_samples_per_worker // batch_size * batch_size\n\n    num_samples_per_worker_remainder = num_samples_per_worker - num_samples_per_worker_rounded\n\n    # Distribute any remaining samples among the workers\n    num_samples_per_worker_remainder_per_worker = num_samples_per_worker_remainder // num_workers\n    num_samples_per_worker_remainder_remainder = num_samples_per_worker_remainder % num_workers\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = [num_samples_per_worker_rounded + num_samples_per_worker_remainder_per_worker] * num_workers\n    for i in range(num_samples_per_worker_remainder_remainder):\n        num_samples_per_worker[i] += 1\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = [num_samples_per_worker_rounded + num_samples_per_worker_remainder_per_worker] * num_workers\n    for i in range(num_samples_per_worker_remainder_remainder):\n        num_samples_per_worker[i] += 1\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = [num_samples_per_worker_rounded + num_samples_per_worker_remainder_per_worker] * num_workers\n    for i in range(num_samples_per_worker_remainder_remainder):\n        num_samples_per_worker[i] += 1\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = [num_s"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of batches each worker has processed\n    num_batches_per_worker = num_samples_per_worker // batch_size\n\n    # Calculate the number of samples that have not been processed by any worker\n    remaining_samples = num_samples_yielded % num_workers\n\n    # Distribute the remaining samples among the workers\n    num_samples_per_worker += remaining_samples // num_workers\n\n    # Calculate the number of samples that each worker has processed\n    num_samples_per_worker = [num_samples_per_worker] * num_workers\n    for i in range(remaining_samples % num_workers):\n        num_samples_per_worker[i] += 1\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = [num_samples_per_worker[i] * batch_size for i in range(num_workers)]\n\n    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = [num_samples_per_worker[i] - (num_batches_per_worker[i] * batch_size) for i in range(num_workers)]\n\n    # Return the number of samples each worker has processed\n    return num_samples_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker_batch = num_samples_per_worker // batch_size\n    num_samples_per_worker_batch_remainder = num_samples_per_worker % batch_size\n\n    # Distribute the remaining samples evenly among the workers\n    num_samples_per_worker_batch_remainder_per_worker = num_samples_per_worker_batch_remainder // num_workers\n    num_samples_per_worker_batch_remainder_remainder = num_samples_per_worker_batch_remainder % num_workers\n\n    # Initialize a dictionary to store the number of samples processed by each worker\n    num_samples_processed = {}\n\n    # Iterate through the workers and calculate the number of samples processed by each\n    for worker_idx in range(num_workers):\n        # Calculate the number of samples processed by the current worker\n        num_samples_processed[worker_idx] = (\n            num_samples_per_worker_batch * batch_size\n            + num_samples_per_worker_batch_remainder_per_worker\n            + (1 if worker_idx < num_samples_per_worker_batch_remainder_remainder else 0)\n        )\n\n    return num_samples_processed\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples each worker has processed in the last batch\n    num_samples_per_worker_last_batch = num_samples_yielded % num_workers\n\n    # Calculate the number of samples each worker has processed in the previous batches\n    num_samples_per_worker_prev_batches = num_samples_per_worker * (num_workers - 1)\n\n    # Calculate the number of samples each worker has processed in the current batch\n    num_samples_per_worker_current_batch = num_samples_per_worker + num_samples_per_worker_last_batch\n\n    # Calculate the number of samples that have been processed in the previous batches\n    num_samples_processed_prev_batches = num_samples_per_worker_prev_batches * batch_size\n\n    # Calculate the number of samples that have been processed in the current batch\n    num_samples_processed_current_batch = num_samples_per_worker_current_batch * batch_size\n\n    # Calculate the total number of samples that have been processed\n    num_samples_processed_total = num_samples_processed_prev_batches + num_samples_processed_current_batch\n\n    # Calculate the number of samples that have been processed by each worker in the previous batches\n    num_samples_processed_per_worker_prev_batches = num_samples_per_worker_prev_batches // num_workers\n\n    # Calculate the number of samples that have been processed by each worker in the current batch\n    num_samples_processed_per_worker_current_batch = num_samples_per_worker_current_batch // num_workers\n\n    # Initialize a dictionary to store the number of samples processed by each worker\n    num_samples_processed_per_worker = {}\n\n    # Distribute any remaining samples among the"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    num_samples_per_worker = num_samples_yielded // num_workers\n    num_samples_per_worker = num_samples_per_worker // batch_size\n    num_samples_per_worker = num_samples_per_worker * batch_size\n    num_samples_per_worker = num_samples_per_worker + (num_samples_yielded - num_samples_per_worker * num_workers)\n\n    num_samples_per_worker = [num_samples_per_worker // num_workers for _ in range(num_workers)]\n    num_samples_per_worker[-1] += num_samples_per_worker[-1] % batch_size\n\n    num_samples_per_worker = [\n        num_samples_per_worker[i] // batch_size for i in range(len(num_samples_per_worker))\n    ]\n\n    num_samples_per_worker = [\n        num_samples_per_worker[i] + num_samples_per_worker[i - 1] if i > 0 else num_samples_per_worker[i]\n        for i in range(len(num_samples_per_worker))\n    ]\n\n    num_samples_per_worker = [\n        num_samples_per_worker[i] * batch_size for i in range(len(num_samples_per_worker))\n    ]\n\n    num_samples_per_worker = [\n        num_samples_per_worker[i] - num_samples_per_worker[i - 1] if i > 0 else num_samples_per_worker[i]\n        for i in range(len(num_samples_per_worker))\n    ]\n\n    return {i: num_samples_per_worker[i] for i in range(num_workers)}\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of batches each worker has processed\n    num_batches_per_worker = num_samples_per_worker // batch_size\n\n    # Calculate the number of samples that have not been processed by any worker\n    remaining_samples = num_samples_yielded - (num_samples_per_worker * num_workers)\n\n    # Distribute the remaining samples among the workers\n    remaining_samples_per_worker = remaining_samples // num_workers\n\n    # Calculate the number of samples each worker has processed after distributing the remaining samples\n    num_samples_per_worker += remaining_samples_per_worker\n\n    # Calculate the number of batches each worker has processed after distributing the remaining samples\n    num_batches_per_worker += remaining_samples_per_worker // batch_size\n\n    # Create a dictionary to store the number of samples each worker has processed\n    samples_per_worker = {}\n\n    # Loop through each worker and calculate the number of samples it has processed\n    for worker_idx in range(num_workers):\n        # Calculate the number of samples the current worker has processed\n        num_samples = num_samples_per_worker\n\n        # If the current worker is the last worker, add any remaining samples to it\n        if worker_idx == num_workers - 1:\n            num_samples += remaining_samples - (remaining_samples_per_worker * (num_workers - 1))\n\n        # Add the number of samples the current worker has processed to the dictionary\n        samples_per_worker[worker_idx] = num_samples\n\n    # Return the dictionary of samples per worker\n    return samples_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of batches each worker has processed\n    num_batches_per_worker = num_samples_per_worker // batch_size\n\n    # Calculate the number of remaining samples after distributing the batches evenly among workers\n    remaining_samples = num_samples_yielded - (num_batches_per_worker * batch_size * num_workers)\n\n    # Distribute the remaining samples among workers\n    remaining_samples_per_worker = remaining_samples // num_workers\n\n    # Calculate the number of samples each worker has processed after distributing the remaining samples\n    num_samples_per_worker += remaining_samples_per_worker\n\n    # Calculate the number of samples each worker has processed for each batch\n    num_samples_per_worker_per_batch = [num_samples_per_worker // num_workers] * num_workers\n\n    # Distribute the remaining samples among workers\n    remaining_samples = remaining_samples % num_workers\n    for i in range(remaining_samples):\n        num_samples_per_worker_per_batch[i] += 1\n\n    # Calculate the number of samples each worker has processed for each batch\n    num_samples_per_worker_per_batch = [\n        num_samples_per_worker_per_batch[i] * batch_size for i in range(num_workers)\n    ]\n\n    # Return the number of samples each worker has processed for each batch\n    return num_samples_per_worker_per_batch\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker should have processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of batches each worker should have processed\n    num_batches_per_worker = num_samples_per_worker // batch_size\n\n    # Calculate the number of samples that each worker has processed\n    num_samples_processed = {}\n    for worker_idx in range(num_workers):\n        num_samples_processed[worker_idx] = num_batches_per_worker * batch_size\n\n    # Calculate the remaining samples that need to be distributed among the workers\n    remaining_samples = num_samples_yielded - num_samples_per_worker * num_workers\n\n    # Distribute the remaining samples among the workers\n    for worker_idx in range(remaining_samples):\n        num_samples_processed[worker_idx] += 1\n\n    return num_samples_processed\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of remaining samples\n    remaining_samples = num_samples_yielded % num_workers\n\n    # Distribute the remaining samples among the workers\n    for i in range(remaining_samples):\n        worker_idx = i % num_workers\n        num_samples_per_worker[worker_idx] += 1\n\n    # Calculate the number of samples each worker has processed\n    num_samples_processed = {}\n    for i in range(num_workers):\n        num_samples_processed[i] = num_samples_per_worker[i] * batch_size\n\n    return num_samples_processed\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = (num_samples_yielded // batch_size) // num_workers\n\n    # Calculate the remaining samples to be distributed among the workers\n    remaining_samples = (num_samples_yielded // batch_size) % num_workers\n\n    # Initialize the dictionary to store the number of samples processed by each worker\n    samples_processed = {}\n\n    # Distribute the remaining samples among the workers\n    for i in range(num_workers):\n        if i < remaining_samples:\n            samples_processed[i] = num_samples_per_worker + 1\n        else:\n            samples_processed[i] = num_samples_per_worker\n\n    # Return the dictionary of samples processed by each worker\n    return samples_processed\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = (num_samples_yielded // num_workers) // batch_size\n\n    # Calculate the remaining samples\n    remaining_samples = num_samples_yielded % (num_samples_per_worker * batch_size * num_workers)\n\n    # Distribute the remaining samples among the workers\n    num_samples_per_worker_list = [num_samples_per_worker] * num_workers\n    for i in range(remaining_samples):\n        num_samples_per_worker_list[i % num_workers] += 1\n\n    # Create a dictionary with the number of samples each worker has processed\n    num_samples_per_worker_dict = {i: num_samples_per_worker_list[i] for i in range(num_workers)}\n\n    return num_samples_per_worker_dict\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = (num_samples_yielded // batch_size) // num_workers\n\n    # Calculate the number of samples that have not been distributed yet\n    num_samples_remaining = (num_samples_yielded // batch_size) % num_workers\n\n    # Initialize the dictionary to store the number of samples each worker has processed\n    samples_per_worker = {}\n\n    # Distribute the remaining samples among the workers\n    for worker_idx in range(num_workers):\n        # Calculate the number of samples this worker should process\n        num_samples = num_samples_per_worker + (1 if worker_idx < num_samples_remaining else 0)\n\n        # Add the number of samples to the dictionary\n        samples_per_worker[worker_idx] = num_samples\n\n    return samples_per_worker\n\n"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed so far\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the number of samples that have been yielded by each worker so far\n    num_samples_yielded_by_worker = [\n        num_samples_per_worker + (1 if i < num_samples_yielded % num_workers else 0) for i in range(num_workers)\n    ]\n\n    # Calculate the number of batches each worker has processed so far\n    num_batches_per_worker = [num_samples // batch_size for num_samples in num_samples_yielded_by_worker]\n\n    # Calculate the number of samples that each worker has processed in the current batch\n    num_samples_per_worker_in_batch = [\n        num_batches * batch_size - num_samples for num_batches, num_samples in zip(num_batches_per_worker, num_samples_yielded_by_worker)\n    ]\n\n    # Calculate the number of samples that each worker has processed in the current batch, taking into account the batch size\n    num_samples_per_worker_in_batch = [\n        num_samples if num_samples <= batch_size else batch_size for num_samples in num_samples_per_worker_in_batch\n    ]\n\n    # Calculate the number of samples that have been yielded by each worker in the current batch\n    num_samples_yielded_by_worker_in_batch = [\n        num_samples + num_samples_per_worker_in_batch[i] for i, num_samples in enumerate(num_samples_yielded_by_worker)\n    ]\n\n    # Calculate the number of samples that each worker has processed in the current batch, taking into account the number of samples yielded by each worker in the current batch\n    num_samples_per_worker_in_batch = [\n        num_samples_yield"}
{"namespace": "litdata.streaming.dataset._replay_sampling", "completion": "    # Calculate the number of samples each worker has processed\n    num_samples_per_worker = num_samples_yielded // num_workers\n\n    # Calculate the remaining samples that need to be distributed among the workers\n    remaining_samples = num_samples_yielded % num_workers\n\n    # Initialize a dictionary to store the number of samples each worker has processed\n    samples_per_worker = {}\n\n    # Distribute the remaining samples among the workers\n    for i in range(num_workers):\n        samples_per_worker[i] = num_samples_per_worker\n\n        # If there are remaining samples, distribute one to the current worker\n        if remaining_samples > 0:\n            samples_per_worker[i] += 1\n            remaining_samples -= 1\n\n    # Calculate the number of samples each worker has processed after dividing by the batch size\n    samples_per_worker = {i: samples_per_worker[i] // batch_size for i in samples_per_worker}\n\n    return samples_per_worker\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    return [result for result, value, metadata in zip(results, value, metadatas) if value <= threshold], [\n        metadata for result, value, metadata in zip(results, value, metadatas) if value <= threshold]\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n    for i, v in enumerate(value):\n        if v <= threshold:\n            filtered_results.append(results[i])\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n            else:\n                filtered_metadatas.append(None)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n    for i, v in enumerate(value):\n        if v <= threshold:\n            filtered_results.append(results[i])\n            if metadatas:\n                filtered_metadatas.append(metadatas[i])\n            else:\n                filtered_metadatas.append(None)\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n    for i, v in enumerate(value):\n        if v <= threshold:\n            filtered_results.append(results[i])\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n            else:\n                filtered_metadatas.append(None)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    if len(results) != len(value):\n        raise ValueError(\"The length of results and value must be the same.\")\n    if len(results) != len(metadatas):\n        raise ValueError(\"The length of results and metadatas must be the same.\")\n    filtered_results = []\n    filtered_metadatas = []\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            filtered_metadatas.append(metadatas[i])\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    filtered_results = [result for result, value in zip(results, value) if value <= threshold]\n    filtered_metadatas = [metadata for metadata, value in zip(metadatas, value) if value <= threshold]\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    assert len(results) == len(value) == len(metadatas)\n    return [results[i] for i in range(len(results)) if value[i] <= threshold], [metadatas[i] for i in range(len(results)) if value[i] <= threshold]\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    filtered_results = []\n    filtered_metadatas = []\n\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            filtered_metadatas.append(metadatas[i])\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n            else:\n                filtered_metadatas.append(None)\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    assert len(results) == len(value) == len(metadatas), \"The length of results, value and metadatas must be the same.\"\n    filtered_results = []\n    filtered_metadatas = []\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            filtered_metadatas.append(metadatas[i])\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n    for i, v in enumerate(value):\n        if v <= threshold:\n            filtered_results.append(results[i])\n            if metadatas:\n                filtered_metadatas.append(metadatas[i])\n            else:\n                filtered_metadatas.append(None)\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    if len(results) != len(value) or len(results) != len(metadatas):\n        raise ValueError(\"The length of results, value, and metadatas must be the same.\")\n\n    filtered_results = []\n    filtered_metadatas = []\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            filtered_metadatas.append(metadatas[i])\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    filtered_results = []\n    filtered_metadatas = []\n\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            if metadatas is not None:\n                filtered_metadatas.append(metadatas[i])\n            else:\n                filtered_metadatas.append(None)\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    filtered_results = []\n    filtered_metadatas = []\n    for i in range(len(results)):\n        if value[i] <= threshold:\n            filtered_results.append(results[i])\n            filtered_metadatas.append(metadatas[i])\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    assert len(results) == len(value) == len(metadatas), \"The length of results, value and metadatas must be the same.\"\n    return [results[i] for i in range(len(results)) if value[i] <= threshold], [metadatas[i] for i in range(len(results)) if\n                                                                                value[i] <= threshold]\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    if metadatas is None:\n        metadatas = [None] * len(results)\n    return [result for result, value in zip(results, value) if value <= threshold], [metadata for metadata, value in zip(metadatas, value) if\n                                                                                          value <= threshold]\n\n"}
{"namespace": "autorag.strategy.filter_by_threshold", "completion": "    # If no metadata is provided, create a list of None values with the same length as the results list\n    if metadatas is None:\n        metadatas = [None] * len(results)\n\n    # Filter the results and metadata based on the threshold\n    filtered_results = []\n    filtered_metadatas = []\n    for i, result in enumerate(results):\n        if value[i] <= threshold:\n            filtered_results.append(result)\n            filtered_metadatas.append(metadatas[i])\n\n    return filtered_results, filtered_metadatas\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Check if the input array has the expected shape\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    # Extract the x and y coordinates from the input array\n    x = array[:, 0]\n    y = array[:, 1]\n\n    # Calculate the area using the Shoelace formula\n    area = 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Check if the input array has the expected shape (_, 2)\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    # Extract x and y coordinates from the array\n    x = array[:, 0]\n    y = array[:, 1]\n\n    # Apply the Shoelace formula to calculate the area\n    area = 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(f\"Invalid shape: {array.shape}. Expected shape: (_, 2).\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\n            \"Input array must have shape (_, 2), where _ can be any number of points.\"\n        )\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    # Append the first point to the end to close the polygon\n    x = np.append(x, x[0])\n    y = np.append(y, y[0])\n\n    # Apply the Shoelace formula\n    area = 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Check if the input array has the expected shape\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    # Extract x and y coordinates from the array\n    x = array[:, 0]\n    y = array[:, 1]\n\n    # Implement the Shoelace formula\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Check if the input array has the expected shape\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    # Extract x and y coordinates from the array\n    x = array[:, 0]\n    y = array[:, 1]\n\n    # Calculate the area using the Shoelace formula\n    area = 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Check if the input array has the expected shape\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    # Extract x and y coordinates from the array\n    x = array[:, 0]\n    y = array[:, 1]\n\n    # Apply the Shoelace formula to calculate the area\n    area = 0.5 * np.abs(\n        np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1))\n    )\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    # Implementation of Shoelace formula\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    # Check if the input array has the expected shape (_, 2)\n    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    # Apply the Shoelace formula\n    x = array[:, 0]\n    y = array[:, 1]\n    area = 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    # Implementation of Shoelace formula\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\n            \"The input array must have shape (_, 2), where _ is the number of points.\"\n        )\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    # Append the first point to the end of the list to complete the polygon\n    x = np.append(x, x[0])\n    y = np.append(y, y[0])\n\n    # Calculate the area using the Shoelace formula\n    area = 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n    return area\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\"Input array must have shape (_, 2)\")\n\n    x = array[:, 0]\n    y = array[:, 1]\n\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "iris.utils.math.area", "completion": "    if array.shape[1] != 2:\n        raise ValueError(\n            f\"Input array must have shape (_, 2), but got {array.shape}\"\n        )\n\n    x = array[:, 0]\n    y = array[:, 1]\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.unsqueeze(-1)\n    idx = torch.searchsorted(a, v, right=True)\n    idx_lo = torch.max(idx - 1, torch.zeros_like(idx, device=idx.device))\n    idx_hi = torch.min(idx, torch.full_like(idx, a.shape[-1] - 1, device=idx.device))\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.unsqueeze(1)\n    idx_lo = torch.searchsorted(a, v - 1e-5)\n    idx_hi = torch.searchsorted(a, v + 1e-5)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.reshape([-1])\n    idx = torch.searchsorted(a, v)\n    idx_lo = torch.max(idx - 1, torch.zeros_like(idx))\n    idx_hi = torch.min(idx, torch.full_like(idx, a.shape[-1] - 1))\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx = torch.searchsorted(a, v, side='right')\n    idx_lo = torch.max(idx - 1, torch.zeros_like(idx))\n    idx_hi = torch.min(idx, torch.full_like(idx, a.shape[-1] - 1))\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx = torch.searchsorted(a, v)\n    idx_lo = torch.max(idx - 1, torch.zeros_like(idx, device=idx.device))\n    idx_hi = torch.min(idx, torch.full_like(idx, a.shape[-1] - 1, device=idx.device))\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.unsqueeze(-1)\n    a = a.unsqueeze(0)\n    return torch.searchsorted(a, v)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx = torch.searchsorted(a, v)\n    below = torch.max(torch.zeros_like(idx - 1), idx - 1)\n    above = torch.min((a.shape[-1] - 1) * torch.ones_like(idx), idx)\n    idx_lo = torch.stack([below, above], -1)\n    idx_hi = idx_lo + 1\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.contiguous()\n    a = a.contiguous()\n    return torch.searchsorted(a, v)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.reshape(-1)\n    idx = torch.searchsorted(a, v)\n    idx_lo = torch.max(idx - 1, torch.tensor(0, device=idx.device))\n    idx_hi = torch.min(idx, torch.tensor(len(a) - 1, device=idx.device))\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx = torch.searchsorted(a, v)\n    below = torch.max(torch.zeros_like(idx - 1), idx - 1)\n    above = torch.min((a.shape[-1] - 1) * torch.ones_like(idx), idx)\n    idx_lo = torch.stack([below, above], -1)\n    idx_hi = idx_lo + 1\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.unsqueeze(-1)\n    idx = torch.searchsorted(a, v, side='right')\n    idx_lo = torch.max(idx - 1, torch.zeros_like(idx))\n    idx_hi = torch.min(idx, torch.full_like(idx, a.shape[-1] - 1))\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.reshape(-1)\n    idx = torch.searchsorted(a, v)\n    idx_lo = torch.max(idx - 1, torch.zeros_like(idx))\n    idx_hi = torch.min(idx, torch.full_like(idx, a.shape[-1] - 1))\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.unsqueeze(-1)\n    idx_lo = torch.searchsorted(a, v, side='right') - 1\n    idx_hi = torch.searchsorted(a, v, side='left')\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.reshape(-1)\n    idx = torch.searchsorted(a, v)\n    idx_lo = torch.max(idx - 1, torch.zeros_like(idx, device=idx.device))\n    idx_hi = torch.min(idx, torch.full_like(idx, a.shape[-1] - 1, device=idx.device))\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.reshape(-1)\n    idx = torch.searchsorted(a, v)\n    idx_lo = torch.maximum(idx - 1, torch.zeros_like(idx))\n    idx_hi = torch.minimum(idx, torch.full_like(idx, a.shape[-1] - 1))\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.unsqueeze(-1)\n    idx = torch.searchsorted(a, v, right=False)\n    idx0 = torch.maximum(idx - 1, torch.zeros_like(idx, device=idx.device))\n    idx1 = torch.minimum(idx, (a.shape[-1] - 1) * torch.ones_like(idx, device=idx.device))\n    idx_g = torch.stack([idx0, idx, idx1], -1)\n    idx_lo = torch.gather(idx_g, 2, torch.argmin(torch.abs(v - torch.gather(a, 2, idx_g)), dim=-1, keepdim=False))\n    idx_hi = torch.gather(idx_g, 2, torch.argmin(torch.abs(v - torch.gather(a, 2, idx_g)), dim=-1, keepdim=False))\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.reshape([-1])\n    idx_lo = torch.searchsorted(a, v)\n    idx_hi = torch.minimum(torch.tensor(a.shape[0] - 1, device=a.device), torch.maximum(idx_lo, idx_lo - 1))\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v[..., None]\n    idx_lo = torch.searchsorted(a, v, side='right') - 1\n    idx_hi = torch.searchsorted(a, v, side='left')\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    idx = torch.searchsorted(a, v)\n    below = a[torch.maximum(idx - 1, torch.tensor(0))]\n    above = a[torch.minimum(idx, torch.tensor(a.shape[-1] - 1))]\n    idx_lo = torch.where(v - below < above - v, idx - 1, idx)\n    idx_hi = torch.where(v - below < above - v, idx, idx + 1)\n    return idx_lo, idx_hi\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.searchsorted", "completion": "    v = v.unsqueeze(0)\n    idx_lo = torch.searchsorted(a, v, side='left')\n    idx_hi = torch.searchsorted(a, v, side='right')\n    return idx_lo, idx_hi\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ]\n  )"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [\n          [fx, 0.0, cx],\n          [0.0, fy, cy],\n          [0.0, 0.0, 1.0],\n      ]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1],\n  ])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [\n          [fx, 0.0, cx],\n          [0.0, fy, cy],\n          [0.0, 0.0, 1.0],\n      ]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0.0, cx],\n      [0.0, fy, cy],\n      [0.0, 0.0, 1.0],\n  ])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([\n      [fx, 0, cx],\n      [0, fy, cy],\n      [0, 0, 1],\n  ])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  K = xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ],\n      dtype=xnp.float32,\n  )\n  return K\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  K = xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ]\n  )\n  return K\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array(\n      [\n          [fx, 0, cx],\n          [0, fy, cy],\n          [0, 0, 1],\n      ]\n  )\n\n"}
{"namespace": "camera_utils.intrinsic_matrix", "completion": "  return xnp.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.linalg.norm(x, axis=-1, keepdims=True) ** 2)\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.linalg.norm(x, axis=-1, keepdims=True) ** 2)\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sqrt(1 + jnp.sum(x**2, axis=-1, keepdims=True)))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sqrt(x[..., 0] ** 2 + x[..., 1] ** 2 + x[..., 2] ** 2))[..., None]\n\n"}
{"namespace": "coord.contract", "completion": "  return x * (1 - jnp.sqrt(1 + x ** 2)) / (1 + x ** 2)\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sqrt(math.safe_norm_sq(x)))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.linalg.norm(x, axis=-1, keepdims=True))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.linalg.norm(x, axis=-1, keepdims=True) ** 2)\n\n"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the input vector(s)\n  r2 = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Scale the input vector(s) based on the magnitude squared\n  return x * (1.0 - jnp.exp(-r2)) / (4.0 * jnp.pi)\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.linalg.norm(x, axis=-1, keepdims=True) ** 2)\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.linalg.norm(x, axis=-1, keepdims=True) ** 2)\n\n"}
{"namespace": "coord.contract", "completion": "  return x * (2 / (1 + x[..., 2:]))\n\n"}
{"namespace": "coord.contract", "completion": "  x_sq = math.safe_norm(x) ** 2\n  return x * (1.0 / 12.0) * (3.0 - x_sq)\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.linalg.norm(x, axis=-1, keepdims=True) ** 2)\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.linalg.norm(x, axis=-1, keepdims=True) ** 2)\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.linalg.norm(x, axis=-1, keepdims=True) ** 2)\n\n"}
{"namespace": "coord.contract", "completion": "  return x * (2 / (1 + x[..., 2:]))\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.linalg.norm(x, axis=-1, keepdims=True) ** 2 / 0.9)\n\n"}
{"namespace": "coord.contract", "completion": "  return x / (1 + jnp.sqrt(1 + jnp.sum(x**2, axis=-1, keepdims=True)))\n\n"}
{"namespace": "coord.contract", "completion": "  # Calculate the magnitude squared of the input array\n  magnitude_squared = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Scale the input array based on the magnitude squared\n  return x / (1 + 3 / 0.05 * magnitude_squared)\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n    unit_index = 0\n    while num_bytes >= 1000 and unit_index < len(units) - 1:\n        num_bytes /= 1000\n        unit_index += 1\n    return f\"{num_bytes:.2f} {units[unit_index]}\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1024.0:\n            return f\"{num_bytes:3.1f} {unit}\"\n        num_bytes /= 1024.0\n    return f\"{num_bytes:.1f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000:\n            return f\"{num_bytes:.1f} {unit}\"\n        num_bytes /= 1000\n    return f\"{num_bytes:.1f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000.0:\n            return f\"{num_bytes:3.1f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1024.0:\n            return f\"{num_bytes:.2f} {unit}\"\n        num_bytes /= 1024.0\n    return f\"{num_bytes:.2f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000.0:\n            return f\"{num_bytes:.1f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} PB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\", \"E\", \"Z\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f}{unit}B\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f}YB\""}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000.0:\n            return f\"{num_bytes:3.1f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1024.0:\n            return f\"{num_bytes:3.1f} {unit}\"\n        num_bytes /= 1024.0\n    return f\"{num_bytes:.1f} PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000.0 or unit == \"PB\":\n            return f\"{num_bytes:.1f} {unit}\"\n        num_bytes /= 1000.0\n    return \"{:.1f} {}\".format(num_bytes, \"PB\")"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]:\n        if num_bytes < 1000.0:\n            return f\"{num_bytes:.1f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000.0 or unit == \"PB\":\n            return f\"{num_bytes:3.1f} {unit}\"\n        num_bytes /= 1000.0\n    return \"{num_bytes:.1f} {unit}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000.0:\n            return f\"{num_bytes:3.1f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]:\n        if num_bytes < 1024.0:\n            return f\"{num_bytes:3.1f} {unit}\"\n        num_bytes /= 1024.0\n    return f\"{num_bytes:.1f} PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes < 0:\n        raise ValueError(\"num_bytes must be non-negative\")\n\n    if num_bytes < 1000:\n        return f\"{num_bytes} B\"\n\n    units = [\"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n    for unit in units:\n        num_bytes /= 1000\n        if num_bytes < 1000:\n            return f\"{num_bytes:.2f} {unit}\"\n\n    return f\"{num_bytes:.2f} PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    if num_bytes == 0:\n        return \"0B\"\n\n    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n    index = 0\n    while num_bytes >= 1000 and index < len(units) - 1:\n        num_bytes /= 1000\n        index += 1\n\n    return f\"{num_bytes:.2f}{units[index]}\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if num_bytes < 1000.0:\n            return f\"{num_bytes:.1f} {unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f} PB\"\n\n"}
{"namespace": "litdata.utilities.format._human_readable_bytes", "completion": "    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]:\n        if abs(num_bytes) < 1000.0:\n            return f\"{num_bytes:3.1f}{unit}\"\n        num_bytes /= 1000.0\n    return f\"{num_bytes:.1f}PB\"\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return is_array_n_dimensions_validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return _is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validate_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validate_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validate_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validate_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be {nb_dimensions}D array.\")\n\n        return v\n\n    return _is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return is_array_n_dimensions_"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validate_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be {nb_dimensions}D.\")\n\n        return v\n\n    return validate_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be {nb_dimensions}D array.\")\n\n        return v\n\n    return is_array_n_dimensions_validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {len(v.shape)}.\"\n            )\n\n        return v\n\n    return is_array_n_dimensions_validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {len(v.shape)}.\"\n            )\n\n        return v\n\n    return is_array_n_dimensions_validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Check that the array has `nb_dimensions` dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return is_array_n_dimensions_validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must be {nb_dimensions}D.\")\n\n        return v\n\n    return is_array_n_dimensions_"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def _is_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions. Got {len(v.shape)}\")\n\n        return v\n\n    return _is_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def is_array_n_dimensions_validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"\n        This function is the actual validator that checks if the array has the specified number of dimensions.\n\n        Input-Output Arguments\n        :param cls: Type. The class of the model being validated.\n        :param v: np.ndarray. The array being validated.\n        :param field: fields.ModelField. The field of the model that is being validated.\n        :return: np.ndarray. The validated array if it meets the specified number of dimensions.\n        \"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return is_array_n_dimensions_validator"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator\n\n"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validate_array_n_dimensions(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        \"\"\"Validate that the array has a specific number of dimensions.\"\"\"\n        if len(v.shape) != nb_dimensions:\n            raise ValueError(\n                f\"{cls.__name__}: {field.name} must be {nb_dimensions}D. Received {len(v.shape)}D.\"\n            )\n\n        return v\n\n    return validate_array_n_dimensions"}
{"namespace": "iris.io.validators.is_array_n_dimensions", "completion": "    def validator(cls: type, v: np.ndarray, field: fields.ModelField) -> np.ndarray:\n        if v.ndim != nb_dimensions:\n            raise ValueError(f\"{cls.__name__}: {field.name} must have {nb_dimensions} dimensions.\")\n\n        return v\n\n    return validator\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(cartesian_vector[..., 2:3] / (r + eps))\n  phi = jnp.arctan2(cartesian_vector[..., 1:2], cartesian_vector[..., 0:1])\n\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(jnp.clip(z / r, -1, 1))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(z / (r + eps))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(\n      jnp.clip(cartesian_vector[..., 2:3] / (r + eps), -1.0, 1.0))\n  phi = jnp.arctan2(cartesian_vector[..., 1:2], cartesian_vector[..., 0:1])\n  return r, theta, phi"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(jnp.clip(z / (r + eps), -1, 1))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(jnp.clip(z / (r + eps), -1, 1))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(jnp.clip(z / (r + eps), -1, 1))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2:3] / (r + eps), -1, 1))\n  phi = jnp.arctan2(cartesian_vector[..., 1:2], cartesian_vector[..., 0:1])\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(cartesian_vector[..., 2] / jnp.maximum(r, eps))\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0])\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n  theta = jnp.arccos(z / jnp.maximum(r, eps))\n  phi = jnp.arctan2(y, x)\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = cartesian_vector[..., 0], cartesian_vector[..., 1], cartesian_vector[..., 2]\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(jnp.clip(z / r, -1.0, 1.0))\n  phi = jnp.arctan2(y, x)\n  phi = jnp.where(phi < 0, phi + 2 * jnp.pi, phi)\n  return r, theta, phi  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(cartesian_vector[..., 2:3] / (r + eps))\n  phi = jnp.arctan2(cartesian_vector[..., 1:2], cartesian_vector[..., 0:1])\n  return r, theta, phi  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(cartesian_vector[..., 2:3] / (r + eps))\n  phi = jnp.arctan2(cartesian_vector[..., 1:2], cartesian_vector[..., 0:1])\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x = cartesian_vector[..., 0]\n  y = cartesian_vector[..., 1]\n  z = cartesian_vector[..., 2]\n\n  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(jnp.clip(z / (r + eps), -1, 1))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  # Calculate the radius (r) using the L2 norm of the cartesian vector\n  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n\n  # Calculate the inclination (theta) using the arccosine function and the ratio of the z-coordinate and the radius\n  theta = jnp.arccos(cartesian_vector[..., 2:3] / (r + eps))\n\n  # Calculate the azimuth (phi) using the arctangent function and the ratio of the x- and y-coordinates\n  phi = jnp.arctan2(cartesian_vector[..., 1:2], cartesian_vector[..., 0:1])\n\n  return r, theta, phi  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(jnp.clip(z / (r + eps), -1.0, 1.0))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1)\n  theta = jnp.arccos(jnp.clip(cartesian_vector[..., 2] / r, -1, 1))\n  phi = jnp.arctan2(cartesian_vector[..., 1], cartesian_vector[..., 0] + eps)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(cartesian_vector[..., 2:3] / (r + eps))\n  phi = jnp.arctan2(cartesian_vector[..., 1:2], cartesian_vector[..., 0:1])\n  return r, theta, phi  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  x, y, z = jnp.split(cartesian_vector, 3, axis=-1)\n\n  r = jnp.sqrt(x**2 + y**2 + z**2)\n  theta = jnp.arccos(jnp.clip(z / (r + eps), -1.0, 1.0))\n  phi = jnp.arctan2(y, x)\n\n  return r, theta, phi\n\n"}
{"namespace": "geometry.cartesian_to_spherical", "completion": "  r = jnp.linalg.norm(cartesian_vector, axis=-1, keepdims=True)\n  theta = jnp.arccos(cartesian_vector[..., 2:3] / (r + eps))\n  phi = jnp.arctan2(cartesian_vector[..., 1:2], cartesian_vector[..., 0:1])\n  return r, theta, phi\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    score = results['rougeL']\n    return score\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[[reference]], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "common.rougeL_score", "completion": "    f = lambda text: list(jieba.cut(text))\n    rouge = evaluate.load('uhgeval/.cache/huggingface/rouge')\n    results = rouge.compute(predictions=[continuation], references=[reference], tokenizer=f)\n    return results['rougeL']\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        # Fallback to a manual scan.\n        obj = pydoc.locate(name.split(\".\")[-1])\n        if obj is None:\n            raise ImportError(f\"Cannot locate object: {name}\")\n        return obj\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError as e:\n        if \".\" not in name:\n            raise e\n        module_name, attr_name = name.rsplit(\".\", 1)\n        module = pydoc.locate(module_name)\n        if module is None:\n            raise e\n        return getattr(module, attr_name)"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        raise ImportError(f\"Cannot locate {name}\")\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        obj = pydoc.locate(name)\n    except ImportError as e:\n        raise ImportError(f\"Cannot locate {name}: {e}\") from e\n    if obj is None:\n        raise ImportError(f\"Cannot locate {name}\")\n    return obj\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)  # first try full-qualified name (module.submodule.class_name)\n    except ImportError:\n        try:\n            return pydoc.locate(name.split(\".\")[-1])  # try just last component (class_name)\n        except ImportError:\n            raise ImportError(f\"Error: cannot locate object: {name}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        # Fallback to a manual scan.\n        obj = pydoc.locate(name)\n        if obj is None:\n            raise ImportError(\"Cannot locate object: {}\".format(name))\n        return obj\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError:\n        # Fallback to a manual scan.\n        obj = pydoc.locate(name.split(\".\")[-1])\n        if obj is None:\n            raise ImportError(\"Cannot locate object: {}\".format(name))\n        return obj\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        return pydoc.locate(name)\n    except ImportError as e:\n        # Fallback method to locate the object\n        try:\n            module_name, class_name = name.rsplit(\".\", 1)\n            module = __import__(module_name, fromlist=[class_name])\n            return getattr(module, class_name)\n        except (ImportError, AttributeError) as e:\n            raise ImportError(f\"Could not locate {name}: {e}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    try:\n        obj = pydoc.locate(name)\n    except ImportError as exc:\n        try:\n            obj = pydoc.locate(f\"{name.rsplit('.', 1)[0]}.{name.rsplit('.', 1)[1]}\")\n        except Exception as exc:\n            raise ImportError(exc)\n    return obj\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # try standard import\n    try:\n        return pydoc.locate(name)\n    except ImportError:\n        # try to import the modules in the search path\n        try:\n            return pydoc.locate(name, forceload=True)\n        except ImportError:\n            raise ImportError(f\"Cannot locate {name}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # first try importing the target module and getattr it.  If it's a class we\n    # can call it without instantiating.\n    try:\n        usable_name = name\n        if \":\" in usable_name:\n            usable_name = usable_name.split(\":\")[0]\n        obj = pydoc.locate(usable_name)\n\n        # Some classes like SC2GatherMineralAndGas don't seem to work for import so\n        # we just treat them as a string.\n        if inspect.isclass(obj):\n            obj = _convert_target_to_string(obj)\n\n    except ImportError:\n        obj = fallback_locate(name)\n\n    if obj is None:\n        raise ImportError(\"Cannot locate object: {}\".format(name))\n\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # first try importing the target module and getattr it.\n    try:\n        # Split the module path and target name by last dot.\n        module_name, target_name = name.rsplit(\".\", 1)\n        module = __import__(module_name, fromlist=[target_name])\n        target = getattr(module, target_name)\n    except Exception as e:\n        # maybe it's a built-in thing? Try that.\n        if name in globals():\n            return globals()[name]\n\n        # maybe a torch.nn.functional or torch.nn.Module? Try fully-qualified name\n        try:\n            return pydoc.locate(name)\n        except Exception:\n            raise ImportError(f\"cannot locate {name}\") from e\n    return target"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # First try importing the target module and getting the required attribute.\n    try:\n        # Split the module path and the class name\n        module_path, attr_name = name.rsplit(\".\", 1)\n\n        # Import the module\n        module = __import__(module_path, fromlist=[attr_name])\n\n        # Get the attribute\n        attr = getattr(module, attr_name)\n\n        # Return the attribute\n        return attr\n    except (ImportError, AttributeError):\n        # If the import fails or the attribute is not found, try using pydoc\n        try:\n            # Use pydoc to locate the object\n            attr = pydoc.locate(name)\n\n            # Return the attribute\n            return attr\n        except Exception as e:\n            # If pydoc fails, raise an exception\n            raise ImportError(f\"Error locating object '{name}': {e}\")"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # first try importing the target module and getattr it.\n    try:\n        return pydoc.locate(name)\n    except ImportError:\n        # the following is only a transition behavior and should be removed soon.\n        # Please use fully qualified name for builtin dataset, model, etc.\n        parts = name.split(\".\")\n        # make sure the module base is \".\".\n        base = \".\"\n        module = base\n        for part in parts:\n            module = module + \".\" + part\n            try:\n                obj = pydoc.locate(module)\n            except ImportError:\n                continue\n            if obj is None:\n                continue\n            return obj\n    raise ImportError(\"Cannot locate name: {}\".format(name))"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    if callable(name):\n        # name is already a callable\n        return name\n    try:\n        obj = pydoc.locate(name)\n    except ImportError as e:\n        raise ImportError(f\"Cannot locate object {name}\") from e\n    if obj is None:\n        raise ImportError(f\"Cannot locate object {name}\")\n    return obj\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    if callable(name):\n        return name\n\n    # Try to import the target object from its module.\n    try:\n        obj = pydoc.locate(name)\n    except ImportError:\n        # Fallback method 1: try to import the class but obtain the module first.\n        # This allows the use of the \"locate\" function when the target object's\n        # module is not yet imported, which is the case for some fvcore components.\n        module_name, qualname_separator, class_name = name.partition(\".\")\n        module = importlib.import_module(module_name)\n        obj = getattr(module, class_name)\n\n        # Fallback method 2: try to import the target object from the\n        # fvcore.common.registry._LOCAL_MAPPING dictionary. This dictionary\n        # contains all the classes that have been registered using the\n        # fvcore.common.registry.Registry.register() method.\n        if obj is None:\n            obj = _LOCAL_MAPPING.get(name)\n\n    if obj is None:\n        raise ImportError(f\"Cannot locate object: {name}\")\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # First try importing the target module and getting the required attribute.\n    try:\n        return pydoc.locate(name)\n    except ImportError:\n        # Fallback method 1: try to interpret `name` as a:\n        # module.class_name (assuming class_name is a subclass of `cls`)\n        module_name, _, class_name = name.rpartition(\".\")\n        if module_name == \"\":\n            return None\n        try:\n            ret = getattr(pydoc.locate(module_name), class_name)\n            if ret is None:\n                raise ImportError\n            return ret\n        except (AttributeError, ImportError):\n            # Fallback method 2: try to interpret `name` as a:\n            # module.submodule._impl.class_name (assuming _impl is a submodule\n            # that implements class_name)\n            try:\n                module_name, _, submodule_name = module_name.rpartition(\".\")\n                ret = getattr(getattr(pydoc.locate(module_name), submodule_name), class_name)\n                if ret is None:\n                    raise ImportError\n                return ret\n            except (AttributeError, ImportError, ValueError):\n                # If we failed to import the target, raise an ImportError.\n                raise ImportError(f\"{name} doesn't look like a module path\")\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    \"\"\"\n    Locate an object from a string, such as\n    \"my_module.MyClass\".\n\n    The object can be either a class or a callable.\n    \"\"\"\n    try:\n        obj = pydoc.locate(name)\n    except ImportError:\n        obj = None\n    if obj is None:\n        # The last few lines of pydoc.locate's source code:\n        #     try:\n        #         __import__(modname)\n        #     except ImportError:\n        #         if not dotted_path:\n        #             raise ImportError(\"Error locating object: %s\" % name)\n        #         else:\n        #             raise ImportError(\"Error locating object: %s\" %\n        #                               dotted_path[-1])\n        #\n        # When pydoc.locate fails to import the module, it attempts to locate the\n        # object without the module name. However, if the module name is a\n        # substring of the object name, importing the module will succeed.\n        # For example, if the module name is \"foo\" and the object name is\n        # \"foo.bar.Baz\", pydoc.locate will attempt to import module \"foo\"\n        # and locate the object \"bar.Baz\" within it. This will fail, but\n        # importing \"foo.bar\" will succeed.\n        #\n        # To fix this, we try importing the module and locating the object within\n        # it. If the module cannot be imported, we raise the original exception.\n        modulename = name.rsplit(\".\", 1)[0]\n        try:\n            __import__(modulename)\n        except ImportError:\n            raise\n        obj = pydoc.locate(name)\n        if obj is None:\n            raise ImportError(\"Error locating object: %s\" % name)\n    return obj"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    \"\"\"\n    Locate an object with the given name.\n    \"\"\"\n    if callable(name):\n        return name  # already an object\n    if not isinstance(name, str):\n        raise ValueError(\"locate() requires a string, got %s\" % type(name))\n\n    try:\n        obj = pydoc.locate(name)\n    except ImportError:\n        obj = None\n    if obj is None:\n        obj = _try_custom_locate(name)\n    if obj is None:\n        raise ImportError(\"cannot locate object: %s\" % name)\n    return obj\n\n"}
{"namespace": "detectron2.utils.registry.locate", "completion": "    # First try importing the target module and getting the required attribute.\n    try:\n        obj = pydoc.locate(name)\n    except ImportError as e:\n        # If the import fails, fall back to using the internal `locate()` method.\n        # This is a workaround for cases where the module is not importable, but can\n        # be located using the `locate()` method.\n        obj = _locate(name)\n\n    if obj is None:\n        raise ImportError(f\"Cannot locate object: {name}\")\n    return obj\n\n"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n    buffer.seek(0)\n    return torch.jit.load(buffer)"}
{"namespace": "detectron2.utils.testing.reload_script_model", "completion": "    # Save the module to an in-memory buffer\n    buffer = io.BytesIO()\n    torch.jit.save(module, buffer)\n\n    # Load the module from the buffer\n    buffer.seek(0)\n    module_reloaded = torch.jit.load(buffer)\n\n    return module_reloaded"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the length of the ids and scores tuples are equal\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids and scores tuples must be equal.\")\n\n    # Check that the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # Check that the sum of the weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Check that the length of the weights tuple is equal to the length of the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # Check that the length of the weights tuple is equal to the length of the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # Check that the length of the weights tuple is equal to the length of the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # Check that the length of the weights tuple is equal to the length of the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # Check that the length of the weights tuple is equal to the length of the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # Check that the length"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the scores\n    scores = [pd.Series(score) / sum(score) for score in scores]\n\n    # Combine the scores using a convex combination\n    combined_scores = sum([weight * score for weight, score in zip(weights, scores)])\n\n    # Sort the combined scores and select the top_k results\n    top_indices = combined_scores.sort_values(ascending=False).head(top_k).index\n\n    # Select the top_k ids and scores from each retrieval result\n    top_ids = [ids[i][top_indices] for i in range(len(ids))]\n    top_scores = [scores[i][top_indices] for i in range(len(scores))]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids and scores tuples must match.\")\n\n    # Check that the sum of the weights equals 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Check that the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # Normalize the scores\n    normalized_scores = [pd.Series(score) / sum(score) for score in scores]\n\n    # Combine the scores using a convex combination method\n    combined_scores = sum([weight * score for weight, score in zip(weights, normalized_scores)])\n\n    # Select the top_k results\n    top_k_indices = combined_scores.nlargest(top_k).index\n    top_k_ids = [ids[i][j] for i, j in enumerate(top_k_indices)]\n    top_k_scores = [scores[i][j] for i, j in enumerate(top_k_indices)]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the number of weights matches the number of scores and ids\n    if len(weights) != len(scores):\n        raise ValueError(\"The number of weights must match the number of scores and ids.\")\n\n    # Check if the sum of the weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Normalize the scores\n    normalized_scores = [pd.Series(score) / sum(score) for score in scores]\n\n    # Combine the scores using the convex combination method\n    combined_scores = sum(weight * normalized_score for weight, normalized_score in zip(weights, normalized_scores))\n\n    # Select the top k results\n    top_indices = combined_scores.nlargest(top_k).index\n    top_ids = [ids[i][j] for i, j in enumerate(top_indices)]\n    top_scores = [combined_scores[i] for i in top_indices]\n\n    return top_ids, top_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the scores\n    normalized_scores = []\n    for score in scores:\n        score = pd.Series(score)\n        normalized_score = (score - score.min()) / (score.max() - score.min())\n        normalized_scores.append(normalized_score)\n\n    # Combine the scores\n    combined_scores = pd.concat(normalized_scores, axis=1)\n    combined_scores = combined_scores.apply(lambda x: x * weights, axis=1)\n    combined_scores = combined_scores.sum(axis=1)\n\n    # Select the top k results\n    combined_scores = combined_scores.sort_values(ascending=False)\n    top_k_ids = combined_scores.head(top_k).index.tolist()\n    top_k_scores = combined_scores.head(top_k).tolist()\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the length of ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of ids and scores tuples must match.\")\n\n    # Check if the sum of weights equals 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of weights must equal 1.\")\n\n    # Check if the length of weights tuple matches the length of ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\"The length of weights tuple must match the length of ids and scores tuples.\")\n\n    # Normalize the scores\n    normalized_scores = []\n    for score in scores:\n        normalized_scores.append((score - min(score)) / (max(score) - min(score)))\n\n    # Combine the scores using the convex combination method\n    combined_scores = pd.DataFrame(normalized_scores).T\n    combined_scores = combined_scores.multiply(weights).sum(axis=1)\n\n    # Select the top_k results\n    top_k_indices = combined_scores.nlargest(top_k).index\n    top_k_ids = [ids[i][j] for i, j in enumerate(top_k_indices)]\n    top_k_scores = [combined_scores[i] for i in top_k_indices]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids and scores tuples must match.\")\n\n    # Check that the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # Check that the sum of the weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Normalize the scores\n    normalized_scores = []\n    for i in range(len(scores)):\n        scores_df = pd.DataFrame({\"scores\": scores[i]})\n        scores_df[\"scores\"] = (scores_df[\"scores\"] - scores_df[\"scores\"].min()) / (\n                scores_df[\"scores\"].max() - scores_df[\"scores\"].min())\n        normalized_scores.append(scores_df[\"scores\"].tolist())\n\n    # Combine the scores using the convex combination method\n    combined_scores = []\n    for i in range(len(normalized_scores[0])):\n        combined_score = 0\n        for j in range(len(normalized_scores)):\n            combined_score += normalized_scores[j][i] * weights[j]\n        combined_scores.append(combined_score)\n\n    # Select the top_k results based on the combined scores\n    top_k_indices = sorted(range(len(combined_scores)), key=lambda i: combined_scores[i], reverse=True)[:top_k]\n    top_k_ids = [ids[i][j] for i in range(len(ids)) for j in top_k_indices]\n    top_k_scores = [combined_scores[i] for i in top_k_indices]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the number of weights matches the number of scores and ids\n    if len(weights) != len(scores):\n        raise ValueError(\"The number of weights must match the number of scores and ids.\")\n\n    # Check if the sum of the weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Normalize the scores\n    normalized_scores = []\n    for score in scores:\n        normalized_scores.append(score / sum(score))\n\n    # Combine the scores using the convex combination method\n    combined_scores = sum([weight * score for weight, score in zip(weights, normalized_scores)])\n\n    # Sort the combined scores in descending order\n    sorted_indices = combined_scores.argsort()[::-1]\n\n    # Select the top_k ids and scores\n    top_k_ids = [ids[i][sorted_indices[:top_k]] for i in range(len(ids))]\n    top_k_scores = [combined_scores[sorted_indices[:top_k]] for _ in range(len(ids))]\n\n    return top_k_ids, top_k_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Assert that the weights are valid\n    assert len(weights) == len(ids), \"The number of weights must match the number of ids.\"\n    assert sum(weights) == 1, \"The sum of the weights must equal 1.\"\n\n    # Normalize the scores\n    normalized_scores = []\n    for score in scores:\n        normalized_scores.append(pd.Series(score).apply(lambda x: x / sum(score)).tolist())\n\n    # Combine the scores\n    combined_scores = []\n    for i in range(len(normalized_scores[0])):\n        combined_score = 0\n        for j in range(len(normalized_scores)):\n            combined_score += normalized_scores[j][i] * weights[j]\n        combined_scores.append(combined_score)\n\n    # Select the top k results\n    top_k_ids = []\n    top_k_scores = []\n    for i in range(top_k):\n        max_index = combined_scores.index(max(combined_scores))\n        top_k_ids.append(ids[max_index][i])\n        top_k_scores.append(combined_scores[max_index])\n        combined_scores[max_index] = -1\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize scores\n    normalized_scores = [pd.Series(score).apply(lambda x: x / sum(score)).tolist() for score in scores]\n\n    # Combine scores\n    combined_scores = [sum([weight * normalized_score for weight, normalized_score in zip(weights, normalized_scores)])\n                       for normalized_scores in zip(*normalized_scores)]\n\n    # Sort scores and select top_k\n    sorted_scores = sorted(zip(combined_scores, *ids), reverse=True)\n    top_k_scores, top_k_ids = zip(*sorted_scores[:top_k])\n\n    # Return top_k ids and scores\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the number of weights matches the number of scores\n    if len(weights) != len(scores):\n        raise ValueError(\n            \"The number of weights must match the number of scores\")\n\n    # Check if the sum of weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of weights must equal 1\")\n\n    # Normalize the scores\n    normalized_scores = []\n    for score in scores:\n        score = pd.Series(score)\n        normalized_score = (score - score.min()) / (score.max() - score.min())\n        normalized_scores.append(normalized_score)\n\n    # Combine the scores using the convex combination method\n    combined_scores = sum([weight * normalized_score for weight, normalized_score in zip(weights, normalized_scores)])\n\n    # Sort the combined scores in descending order\n    sorted_scores = combined_scores.sort_values(ascending=False)\n\n    # Select the top k scores\n    top_scores = sorted_scores.head(top_k)\n\n    # Get the ids corresponding to the top scores\n    top_ids = [ids[i][j] for i, j in top_scores.index]\n\n    # Return the top ids and scores\n    return top_ids, top_scores.values.tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    assert len(ids) == len(scores) == len(weights)\n    assert sum(weights) == 1\n\n    # Normalize scores\n    normalized_scores = []\n    for score in scores:\n        score = pd.Series(score)\n        normalized_score = (score - score.min()) / (score.max() - score.min())\n        normalized_scores.append(normalized_score)\n\n    # Combine scores\n    combined_scores = sum(\n        [weight * score for weight, score in zip(weights, normalized_scores)])\n\n    # Select top_k results\n    top_k_indices = combined_scores.nlargest(top_k).index\n    top_k_ids = [ids[i][j] for i, j in enumerate(top_k_indices)]\n    top_k_scores = [scores[i][j] for i, j in enumerate(top_k_indices)]\n\n    return top_k_ids, top_k_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\n            \"The length of the ids and scores tuples must match.\")\n\n    # Check that the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\n            \"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # Check that the sum of the weights equals 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Initialize a dictionary to store the combined scores\n    combined_scores = {}\n\n    # Iterate over the ids and scores of each retrieval result\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            # If the id is not in the combined_scores dictionary, add it with the weighted score\n            if ids[i][j] not in combined_scores:\n                combined_scores[ids[i][j]] = scores[i][j] * weights[i]\n            # If the id is already in the combined_scores dictionary, add the weighted score to the existing score\n            else:\n                combined_scores[ids[i][j]] += scores[i][j] * weights[i]\n\n    # Sort the combined scores in descending order\n    sorted_scores = sorted(\n        combined_scores.items(), key=lambda x: x[1], reverse=True)\n\n    # Select the top_k results\n    top_results = sorted_scores[:top_k]\n\n    # Extract the ids and scores of the top_k results\n    top_ids = [result[0] for result in top_results]\n    top_scores = [result[1] for result in top_results]\n\n    # Return the top_k ids and scores\n    return top_ids, top_scores\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the weights sum up to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Check if the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids and scores tuples must match.\")\n\n    # Check if the length of the ids and scores tuples match the length of the weights tuple\n    if len(ids) != len(weights):\n        raise ValueError(\"The length of the ids and scores tuples must match the length of the weights tuple.\")\n\n    # Create a DataFrame with the ids and scores\n    df = pd.DataFrame({\"ids\": ids[0], \"scores\": scores[0]})\n\n    # Normalize the scores\n    df[\"scores\"] = df[\"scores\"] / df[\"scores\"].sum()\n\n    # Iterate over the other retrieval results\n    for i in range(1, len(ids)):\n        # Create a DataFrame with the ids and scores\n        df_i = pd.DataFrame({\"ids\": ids[i], \"scores\": scores[i]})\n\n        # Normalize the scores\n        df_i[\"scores\"] = df_i[\"scores\"] / df_i[\"scores\"].sum()\n\n        # Merge the DataFrames based on the ids\n        df = pd.merge(df, df_i, on=\"ids\", how=\"outer\")\n\n        # Fill missing values with 0\n        df = df.fillna(0)\n\n        # Combine the scores using the convex combination method\n        df[\"scores\"] = weights[i] * df[\"scores_x\"] + (1 - weights[i]) * df[\"scores_y\"]\n\n        # Drop the old scores columns\n        df = df.drop(columns=[\"scores_x\", \"scores_y\"])\n\n    # Sort the DataFrame by the scores in descending order\n    df = df.sort_values(by=\""}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    assert len(ids) == len(scores) == len(weights), \"The number of ids, scores, and weights must be equal.\"\n    assert sum(weights) == 1, \"The sum of the weights must be equal to 1.\"\n\n    # Create a DataFrame from the ids and scores tuples\n    df = pd.DataFrame({'ids': ids, 'scores': scores})\n\n    # Explode the lists in the 'ids' and 'scores' columns\n    df_exploded = df.explode(['ids', 'scores'])\n\n    # Group by the 'ids' column and sum the scores\n    df_grouped = df_exploded.groupby('ids').sum().reset_index()\n\n    # Normalize the scores\n    df_grouped['scores'] = df_grouped['scores'] / df_grouped['scores'].sum()\n\n    # Sort the DataFrame by the scores in descending order\n    df_sorted = df_grouped.sort_values('scores', ascending=False)\n\n    # Select the top_k results\n    df_top_k = df_sorted.head(top_k)\n\n    # Return the top_k ids and scores as a tuple of lists\n    return df_top_k['ids'].tolist(), df_top_k['scores'].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the length of ids and scores match\n    if len(ids) != len(scores):\n        raise ValueError(\n            \"The length of ids and scores must match.\")\n\n    # Check that the length of weights matches the length of ids and scores\n    if len(weights) != len(ids):\n        raise ValueError(\n            \"The length of weights must match the length of ids and scores.\")\n\n    # Check that the sum of weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError(\n            \"The sum of weights must equal 1.\")\n\n    # Check that all weights are non-negative\n    if any(w < 0 for w in weights):\n        raise ValueError(\n            \"All weights must be non-negative.\")\n\n    # Check that all scores are non-negative\n    if any(s < 0 for s in scores):\n        raise ValueError(\n            \"All scores must be non-negative.\")\n\n    # Check that all ids are unique\n    if any(len(set(i)) != len(i) for i in ids):\n        raise ValueError(\n            \"All ids must be unique.\")\n\n    # Check that all ids are of the same length\n    if any(len(i) != len(ids[0]) for i in ids):\n        raise ValueError(\n            \"All ids must be of the same length.\")\n\n    # Check that all scores are of the same length\n    if any(len(s) != len(scores[0]) for s in scores):\n        raise ValueError(\n            \"All scores must be of the same length.\")\n\n    # Check that top_k is a positive integer\n    if top_k <= 0:\n        raise ValueError(\n            \"top_k must be a positive integer.\")\n\n    # Check that top_k is not greater than the length of the ids\n    if top_k > len(ids[0]):\n        raise ValueError(\n            \"top_k must be less than or equal to the length of the ids.\")\n\n    # Normalize the scores\n   "}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check if the length of the ids and scores tuples match\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of ids and scores tuples must match.\")\n\n    # Check if the sum of the weights equals 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # Check if the length of the weights tuple matches the length of the ids and scores tuples\n    if len(weights) != len(ids):\n        raise ValueError(\"The length of weights tuple must match the length of ids and scores tuples.\")\n\n    # Normalize the scores\n    normalized_scores = []\n    for score in scores:\n        normalized_scores.append((score - score.min()) / (score.max() - score.min()))\n\n    # Multiply the normalized scores with their respective weights\n    weighted_scores = []\n    for i in range(len(normalized_scores)):\n        weighted_scores.append(normalized_scores[i] * weights[i])\n\n    # Sum the weighted scores\n    fused_scores = sum(weighted_scores)\n\n    # Sort the scores in descending order and select the top_k results\n    sorted_indices = fused_scores.sort_values(ascending=False).head(top_k).index\n\n    # Select the top_k ids and scores\n    fused_ids = [ids[i][sorted_indices] for i in range(len(ids))]\n    fused_scores = [fused_scores[sorted_indices]]\n\n    return fused_ids, fused_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Check that the lengths of ids and scores match\n    if len(ids) != len(scores):\n        raise ValueError(\"The lengths of ids and scores must match.\")\n\n    # Check that the lengths of ids and weights match\n    if len(ids) != len(weights):\n        raise ValueError(\"The lengths of ids and weights must match.\")\n\n    # Check that the sum of weights is equal to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of weights must equal 1.\")\n\n    # Initialize a DataFrame with the first retrieval result\n    df = pd.DataFrame({'id': ids[0], 'score': scores[0]})\n\n    # Normalize the scores of the first retrieval result\n    df['score'] = df['score'] / df['score'].max()\n\n    # Loop through the remaining retrieval results\n    for i in range(1, len(ids)):\n        # Create a DataFrame for the current retrieval result\n        df_temp = pd.DataFrame({'id': ids[i], 'score': scores[i]})\n\n        # Normalize the scores of the current retrieval result\n        df_temp['score'] = df_temp['score'] / df_temp['score'].max()\n\n        # Merge the current retrieval result with the previous one\n        df = pd.merge(df, df_temp, on='id', how='outer')\n\n        # Fill missing values with 0\n        df = df.fillna(0)\n\n        # Combine the scores of the current retrieval result with the previous one\n        df['score'] = df['score_x'] * weights[i-1] + df['score_y'] * weights[i]\n\n        # Drop the temporary columns\n        df = df.drop(['score_x', 'score_y'], axis=1)\n\n    # Sort the DataFrame by score in descending order\n    df = df.sort_values(by='score', ascending=False)\n\n    # Select the top_k results\n    df = df.head"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # check if weights sum to 1\n    if sum(weights) != 1:\n        raise ValueError(\"The sum of the weights must equal 1.\")\n\n    # check if ids and scores have the same length\n    if len(ids) != len(scores):\n        raise ValueError(\"The length of the ids and scores tuples must match.\")\n\n    # check if weights have the same length as ids and scores\n    if len(weights) != len(ids):\n        raise ValueError(\"The length of the weights tuple must match the length of the ids and scores tuples.\")\n\n    # check if top_k is a positive integer\n    if not isinstance(top_k, int) or top_k <= 0:\n        raise ValueError(\"top_k must be a positive integer.\")\n\n    # normalize scores\n    scores = [pd.Series(score).clip(lower=0, upper=1) for score in scores]\n\n    # combine scores using convex combination method\n    fused_scores = sum([weight * score for weight, score in zip(weights, scores)])\n\n    # sort ids and scores by fused scores in descending order\n    sorted_ids = [id_ for _, id_ in sorted(zip(fused_scores, ids), key=lambda x: x[0], reverse=True)]\n    sorted_scores = [score for _, score in sorted(zip(fused_scores, scores), key=lambda x: x[0], reverse=True)]\n\n    # select top_k ids and scores\n    top_k_ids = [ids[:top_k] for ids in sorted_ids]\n    top_k_scores = [scores[:top_k] for scores in sorted_scores]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.hybrid_cc", "completion": "    # Normalize the scores\n    normalized_scores = []\n    for score in scores:\n        normalized_score = (score - min(score)) / (max(score) - min(score))\n        normalized_scores.append(normalized_score)\n\n    # Combine the scores using the convex combination method\n    fused_scores = sum([weight * normalized_score for weight, normalized_score in zip(weights, normalized_scores)])\n\n    # Sort the fused scores and select the top k results\n    sorted_indices = fused_scores.argsort()[::-1][:top_k]\n    fused_ids = [ids[i][sorted_indices] for i in range(len(ids))]\n    fused_scores = [fused_scores[sorted_indices]]\n\n    return fused_ids, fused_scores\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if abs(x) >= 1000:\n        return f\"{x:.0f}\"\n    if abs(x) >= 100:\n        return f\"{x:.1f}\"\n    if abs(x) >= 10:\n        return f\"{x:.2f}\"\n    return f\"{x:.3f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x < 1000:\n        return f\"{x:.2f}\"\n    if x < 10000:\n        return f\"{x:.1f}\"\n    if x < 100000:\n        return f\"{x:.0f}\"\n    if x < 1000000:\n        return f\"{x/1000:.2f}K\"\n    if x < 10000000:\n        return f\"{x/1000:.1f}K\"\n    if x < 100000000:\n        return f\"{x/1000:.0f}K\"\n    if x < 1000000000:\n        return f\"{x/1000000:.2f}M\"\n    if x < 10000000000:\n        return f\"{x/1000000:.1f}M\"\n    return f\"{x/1000000:.0f}M\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x == 0:\n        return \"0%\" if percent else \"0\"\n    if x < 0.001:\n        return \"<0.1%\" if percent else \"<0.1\"\n    if x < 1:\n        return f\"{x:.3f}%\" if percent else f\"{x:.3f}\"\n    if x < 100:\n        return f\"{x:.2f}%\" if percent else f\"{x:.2f}\"\n    return f\"{x:.1f}%\" if percent else f\"{x:.1f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x == 0:\n        return \"0\"\n    if abs(x) < 1e-3:\n        return f\"{x:.2e}\"\n    if abs(x) < 1e-1:\n        return f\"{x:.4f}\"\n    if abs(x) < 1e1:\n        return f\"{x:.2f}\"\n    return f\"{x:.1f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x >= 1000:\n        return f\"{x:.0f}\"\n    if x >= 100:\n        return f\"{x:.1f}\"\n    if x >= 10:\n        return f\"{x:.2f}\"\n    if x >= 1:\n        return f\"{x:.3f}\"\n    if x >= 0.1:\n        return f\"{x:.4f}\"\n    if x >= 0.01:\n        return f\"{x:.5f}\"\n    if x >= 0.001:\n        return f\"{x:.6f}\"\n    return f\"{x:.7f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x == 0:\n        return \"0\"\n    if abs(x) >= 1:\n        return f\"{x:.{0}f}\"\n    if abs(x) < 0.001:\n        return f\"{x:.{6}f}\"\n    if abs(x) < 0.01:\n        return f\"{x:.{5}f}\"\n    if abs(x) < 0.1:\n        return f\"{x:.{4}f}\"\n    if abs(x) < 1:\n        return f\"{x:.{3}f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x >= 1000000:\n        return f\"{x:.0f}\"\n    if x >= 10000:\n        return f\"{x:.1f}\"\n    if x >= 1000:\n        return f\"{x:.2f}\"\n    if x >= 100:\n        return f\"{x:.3f}\"\n    if x >= 10:\n        return f\"{x:.4f}\"\n    if x >= 1:\n        return f\"{x:.5f}\"\n    return f\"{x:.6f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x < 1000:\n        return f\"{x:.2f}\"\n    if x < 1000000:\n        return f\"{x:.0f}\"\n    return f\"{x:.2e}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x == 0:\n        return \"0%\" if percent else \"0\"\n    if x < 1e-3:\n        return f\"{x:.2e}\"\n    if x < 1:\n        return f\"{x:.2f}\"\n    if x < 1e3:\n        return f\"{x:.0f}\"\n    if x < 1e6:\n        return f\"{x/1e3:.0f}K\"\n    if x < 1e9:\n        return f\"{x/1e6:.0f}M\"\n    if x < 1e12:\n        return f\"{x/1e9:.0f}B\"\n    return f\"{x/1e12:.0f}T\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if abs(x) > 1000000000:\n        return f\"{x / 1000000000:.1f}B\"\n    if abs(x) > 1000000:\n        return f\"{x / 1000000:.1f}M\"\n    if abs(x) > 1000:\n        return f\"{x / 1000:.1f}K\"\n    if abs(x) < 0.0001:\n        return f\"{x:.1e}\"\n    if abs(x) < 0.01:\n        return f\"{x:.2f}\"\n    return f\"{x:.1f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x >= 1:\n        n_decimal = 0\n    elif x >= 0.1:\n        n_decimal = 1\n    elif x >= 0.01:\n        n_decimal = 2\n    elif x >= 0.001:\n        n_decimal = 3\n    else:\n        n_decimal = 4\n    return f\"{x:.{n_decimal}%}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x == 0:\n        return \"0\"\n    if x < 0.001:\n        return f\"{x:.2e}\"\n    if x < 1:\n        return f\"{x:.3f}\"\n    if x < 100:\n        return f\"{x:.2f}\"\n    return f\"{x:.1f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x < 1e-3:\n        return f\"{x:.2e}\"\n    if x < 1e-2:\n        return f\"{x:.3f}\"\n    if x < 1e-1:\n        return f\"{x:.4f}\"\n    if x < 1e0:\n        return f\"{x:.5f}\"\n    if x < 1e1:\n        return f\"{x:.6f}\"\n    if x < 1e2:\n        return f\"{x:.7f}\"\n    if x < 1e3:\n        return f\"{x:.8f}\"\n    return f\"{x:.9f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x >= 1000000000:\n        return f\"{x / 1000000000:.2f}B\"\n    elif x >= 1000000:\n        return f\"{x / 1000000:.2f}M\"\n    elif x >= 1000:\n        return f\"{x / 1000:.2f}K\"\n    elif x < 1000 and x > 1:\n        return f\"{x:.2f}\"\n    elif x < 1 and x > 0.001:\n        return f\"{x:.4f}\"\n    elif x < 0.001 and x > 0.000001:\n        return f\"{x:.6f}\"\n    elif x < 0.000001:\n        return \"0\"\n    else:\n        return f\"{x:.2f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if abs(x) < 1e-6:\n        return \"{:.2e}\".format(x)\n    if abs(x) < 1e-3:\n        return \"{:.4f}\".format(x)\n    if abs(x) < 1:\n        return \"{:.3f}\".format(x)\n    return \"{:.2f}\".format(x)\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x == 0:\n        return \"0\"\n    if x < 1:\n        return f\"{x:.3g}%\"\n    if x < 10:\n        return f\"{x:.3g}\"\n    if x < 100:\n        return f\"{x:.2f}\"\n    if x < 1000:\n        return f\"{x:.1f}\"\n    return f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x < 1e-3:\n        return f\"{x:.1e}\"\n    if x < 1:\n        return f\"{x:.2f}\"\n    if x < 10:\n        return f\"{x:.1f}\"\n    if x < 100:\n        return f\"{x:.0f}\"\n    return f\"{x:.1e}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x < 1e-4:\n        return f\"{x:.3e}\"\n    if x < 1e-2:\n        return f\"{x:.2f}\"\n    if x < 1:\n        return f\"{x:.3f}\"\n    if x < 1e3:\n        return f\"{x:.1f}\"\n    return f\"{x:.0f}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n\n    if percent:\n        x *= 100\n\n    if x < 1e-2:\n        return f\"{x:.2e}\"\n\n    if x < 1e-1:\n        return f\"{x:.3f}\"\n\n    if x < 1:\n        return f\"{x:.4f}\"\n\n    if x < 1e1:\n        return f\"{x:.3f}\"\n\n    if x < 1e2:\n        return f\"{x:.2f}\"\n\n    if x < 1e3:\n        return f\"{x:.1f}\"\n\n    if x < 1e4:\n        return f\"{x:.0f}\"\n\n    return f\"{x:.1e}\"\n\n"}
{"namespace": "skfolio.utils.tools.format_measure", "completion": "    if np.isnan(x):\n        return str(x)\n    if percent:\n        x *= 100\n    if x < 1e-2:\n        return f\"{x:.2e}\"\n    elif x < 1e-1:\n        return f\"{x:.3f}\"\n    elif x < 1e1:\n        return f\"{x:.2f}\"\n    elif x < 1e2:\n        return f\"{x:.1f}\"\n    else:\n        return f\"{x:.0f}\"\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_in_gb = free // (2**30)\n        if free_in_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space_in_gb = disk_usage.free / (1024**3)\n        if free_space_in_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space_in_gb = disk_usage.free // (1024**3)\n        if free_space_in_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            total, used, free = shutil.disk_usage(input_dir)\n            if free < threshold_in_gb * 1024 * 1024 * 1024:\n                sleep(sleep_time)\n            else:\n                return\n        except FileNotFoundError:\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        if free < threshold_in_gb * 1024 ** 3:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        if free / (1024 ** 3) < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            disk_usage = shutil.disk_usage(input_dir)\n            free_space_in_gb = disk_usage.free / 1024**3\n            if free_space_in_gb < threshold_in_gb:\n                sleep(sleep_time)\n            else:\n                return\n        except FileNotFoundError:\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            disk_usage = shutil.disk_usage(input_dir)\n            if disk_usage.free / (1024**3) < threshold_in_gb:\n                sleep(sleep_time)\n            else:\n                break\n        except Exception as e:\n            raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    # Convert the threshold to bytes\n    threshold_in_bytes = threshold_in_gb * 1024 * 1024 * 1024\n\n    # Loop until the free space is lower than the threshold\n    while True:\n        # Get the disk usage of the specified directory\n        disk_usage = shutil.disk_usage(input_dir)\n\n        # Check if the free space is lower than the threshold\n        if disk_usage.free < threshold_in_bytes:\n            # Sleep for the specified amount of time before checking the disk usage again\n            sleep(sleep_time)\n        else:\n            # Exit the loop if the free space is higher than the threshold\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space_in_gb = disk_usage.free // (1024**3)\n        if free_space_in_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_space_in_gb = free // (2**30)\n        if free_space_in_gb < threshold_in_gb:\n            logger.info(f\"Disk usage is {free_space_in_gb} GB. Waiting for {sleep_time} seconds...\")\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        statvfs = os.statvfs(input_dir)\n        free_space_in_bytes = statvfs.f_frsize * statvfs.f_bavail\n        free_space_in_gb = free_space_in_bytes / (1024**3)\n        if free_space_in_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space = disk_usage.free / (1024 ** 3)\n        if free_space < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    threshold_in_bytes = threshold_in_gb * 1024 * 1024 * 1024\n    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        if free < threshold_in_bytes:\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        total, used, free = shutil.disk_usage(input_dir)\n        free_gb = free // (2**30)\n        if free_gb < threshold_in_gb:\n            logger.info(f\"Free space on disk is below {threshold_in_gb}GB. Waiting for {sleep_time} seconds...\")\n            sleep(sleep_time)\n        else:\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        try:\n            disk_usage = shutil.disk_usage(input_dir)\n            free_space = disk_usage.free / (1024**3)  # Convert bytes to gigabytes\n            if free_space < threshold_in_gb:\n                logger.info(f\"Free disk space is {free_space:.2f} GB. Waiting for {sleep_time} seconds.\")\n                sleep(sleep_time)\n            else:\n                break\n        except FileNotFoundError:\n            logger.info(f\"Directory {input_dir} not found. Waiting for {sleep_time} seconds.\")\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    # Get the total and free disk space of the specified directory\n    total, used, free = shutil.disk_usage(input_dir)\n\n    # Calculate the free space in gigabytes\n    free_gb = free // (2**30)\n\n    # Keep checking the disk usage until the free space is lower than the specified threshold\n    while free_gb < threshold_in_gb:\n        # Sleep for the specified time before checking the disk usage again\n        sleep(sleep_time)\n\n        # Get the updated total and free disk space of the specified directory\n        total, used, free = shutil.disk_usage(input_dir)\n\n        # Calculate the updated free space in gigabytes\n        free_gb = free // (2**30)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    # Convert the threshold from gigabytes to bytes\n    threshold_in_bytes = threshold_in_gb * 1024 * 1024 * 1024\n\n    # Continuously check the disk usage of the directory\n    while True:\n        # Get the disk usage of the directory\n        disk_usage = shutil.disk_usage(input_dir)\n\n        # Check if the free space is lower than the threshold\n        if disk_usage.free < threshold_in_bytes:\n            # Wait for the specified time before checking the disk usage again\n            sleep(sleep_time)\n        else:\n            # Exit the loop if the free space is higher than the threshold\n            break\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    # Get the disk usage of the input directory\n    disk_usage = shutil.disk_usage(input_dir)\n\n    # Calculate the free space in gigabytes\n    free_space_gb = disk_usage.free / (1024 ** 3)\n\n    # Check if the free space is lower than the specified threshold\n    while free_space_gb < threshold_in_gb:\n        # Sleep for the specified time before checking the disk usage again\n        sleep(sleep_time)\n\n        # Get the disk usage of the input directory again\n        disk_usage = shutil.disk_usage(input_dir)\n\n        # Calculate the free space in gigabytes again\n        free_space_gb = disk_usage.free / (1024 ** 3)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_disk_usage_higher_than_threshold", "completion": "    while True:\n        disk_usage = shutil.disk_usage(input_dir)\n        free_space_in_gb = disk_usage.free / (1024**3)\n        if free_space_in_gb < threshold_in_gb:\n            sleep(sleep_time)\n        else:\n            return\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p * td, jnp.sum(p * td)))"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p * td, jnp.sum(p * td))"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td) * jnp.concatenate([td, td[-1:]], axis=-1)"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, p * td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  return jnp.diff(t) * (p[Ellipsis, :1] + p[Ellipsis, 1:]) / 2\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p * td, jnp.sum(p * td)))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return jnp.where(td < np.finfo(np.float32).tiny, 0, math.safe_div(p, td))\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  td = jnp.diff(t)\n  return math.safe_div(p, td)\n\n"}
{"namespace": "stepfun.pdf_to_weight", "completion": "  utils.assert_valid_stepfun(t, p)\n  return jnp.diff(t, prepend=t[Ellipsis, :1]) * p\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    tokens = nlm_tokenize(line_text)\n\n    # Join the tokens back into a single string\n    line_text = \" \".join(tokens)\n\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = su.segment(line_text)\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.replace(\"\\r\", \"\")\n    line_text = line_text.replace(\"\\f\", \"\")\n    line_text = line_text.replace(\"\\v\", \"\")\n    line_text = line_text.replace(\"\\u00A0\", \"\")\n    line_text = line_text.replace(\"\\u2000\", \"\")\n    line_text = line_text.replace(\"\\u2001\", \"\")\n    line_text = line_text.replace(\"\\u2002\", \"\")\n    line_text = line_text.replace(\"\\u2003\", \"\")\n    line_text = line_text.replace(\"\\u2004\", \"\")\n    line_text = line_text.replace(\"\\u2005\", \"\")\n    line_text = line_text.replace(\"\\u2006\", \"\")\n    line_text = line_text.replace(\"\\u2007\", \"\")\n    line_text = line_text.replace(\"\\u2008\", \"\")\n    line_text = line_text.replace(\"\\u2009\", \"\")\n    line_text = line_text.replace(\"\\u200A\", \"\")\n    line_text = line_text.replace(\"\\u202F\", \"\")\n    line_text = line_text.replace(\"\\u205F\", \"\")\n    line_text = line_text.replace(\"\\u3000\", \"\")\n    line_text = line_text.replace(\"\\u2028\", \"\")\n    line_text = line_text.replace(\"\\u2029\", \"\")\n    line_text = line_text.replace(\"\\u000B\", \"\")\n    line_text = line_text.replace(\"\\u000C\", \"\")\n    line_text = line_text.replace(\"\\u0085\", \"\")\n    line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    line_text = list(line_text)\n\n    # Join the tokens back into a single string\n    line_text = \"\".join(line_text)\n\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    line_text = su.segment(line_text)\n\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    modified_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    tokens = list(modified_text)\n\n    # Return the list of tokens\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.replace(\"\\r\", \"\")\n    line_text = line_text.replace(\"\\x0c\", \"\")\n    line_text = line_text.replace(\"\\x0b\", \"\")\n    line_text = line_text.replace(\"\\x07\", \"\")\n    line_text = line_text.replace(\"\\x08\", \"\")\n    line_text = line_text.replace(\"\\x1c\", \"\")\n    line_text = line_text.replace(\"\\x1d\", \"\")\n    line_text = line_text.replace(\"\\x1e\", \"\")\n    line_text = line_text.replace(\"\\x1f\", \"\")\n    line_text = line_text.replace(\"\\x85\", \"\")\n    line_text = line_text.replace(\"\\xa0\", \"\")\n    line_text = line_text.replace(\"\\u2000\", \"\")\n    line_text = line_text.replace(\"\\u2001\", \"\")\n    line_text = line_text.replace(\"\\u2002\", \"\")\n    line_text = line_text.replace(\"\\u2003\", \"\")\n    line_text = line_text.replace(\"\\u2004\", \"\")\n    line_text = line_text.replace(\"\\u2005\", \"\")\n    line_text = line_text.replace(\"\\u2006\", \"\")\n    line_text = line_text.replace(\"\\u2007\", \"\")\n    line_text = line_text.replace(\"\\u2008\", \"\")\n    line_text = line_text.replace(\"\\u2009\", \"\")\n    line_text = line_text.replace(\"\\u200a\", \"\")\n    line_text = line_text.replace(\"\\u200b\", \"\")\n    line_text = line_text.replace(\"\\u2028\","}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    modified_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    tokens = list(modified_text)\n\n    # Return the segmented parts of the modified input text\n    return \" \".join(tokens)"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    return su.segment(line_text)"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    line_text = \"\".join(line_text.split())\n\n    # Segment the modified text into smaller parts or tokens\n    tokens = su.segment(line_text)\n\n    # Return the segmented parts of the modified input text\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    modified_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    tokens = list(modified_text)\n\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    tokens = nlm_tokenize(line_text)\n\n    # Join the tokens back together into a single string\n    line_text = \" \".join(tokens)\n\n    return line_text"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    modified_text = \"\".join(line_text.split())\n\n    # Segment the modified text into smaller parts or tokens\n    tokens = nlm_tokenize(modified_text)\n\n    # Return the segmented parts of the modified text\n    return \" \".join(tokens)"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.replace(\"\\r\", \"\")\n    line_text = line_text.replace(\"\\f\", \"\")\n    line_text = line_text.replace(\"\\v\", \"\")\n    line_text = line_text.replace(\"\\u00A0\", \"\")\n    line_text = line_text.replace(\"\\u2000\", \"\")\n    line_text = line_text.replace(\"\\u2001\", \"\")\n    line_text = line_text.replace(\"\\u2002\", \"\")\n    line_text = line_text.replace(\"\\u2003\", \"\")\n    line_text = line_text.replace(\"\\u2004\", \"\")\n    line_text = line_text.replace(\"\\u2005\", \"\")\n    line_text = line_text.replace(\"\\u2006\", \"\")\n    line_text = line_text.replace(\"\\u2007\", \"\")\n    line_text = line_text.replace(\"\\u2008\", \"\")\n    line_text = line_text.replace(\"\\u2009\", \"\")\n    line_text = line_text.replace(\"\\u200A\", \"\")\n    line_text = line_text.replace(\"\\u202F\", \"\")\n    line_text = line_text.replace(\"\\u205F\", \"\")\n    line_text = line_text.replace(\"\\u3000\", \"\")\n    line_text = line_text.replace(\"\\uFEFF\", \"\")\n    line_text = line_text.replace(\"\\u2028\", \"\")\n    line_text = line_text.replace(\"\\u2029\", \"\")\n    line_text = line_text.replace(\"\\u2028\", \"\")\n    line_text = line_text.replace(\"\\u2029\", \"\")\n    line_text = line"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    modified_text = \"\".join(line_text.split())\n\n    # Segment the modified text into smaller parts or tokens\n    tokens = su.segment(modified_text)\n\n    # Return the segmented parts as a list of strings\n    return tokens"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    line_text = line_text.replace(\" \", \"\")\n\n    # Segment the modified text into smaller parts or tokens\n    line_text = line_text.split(\" \")\n\n    # Return the segmented parts of the modified input text\n    return line_text\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    # Remove all whitespace characters from the input text\n    modified_text = re.sub(r\"\\s+\", \"\", line_text)\n\n    # Segment the modified text into smaller parts or tokens\n    tokens = list(modified_text)\n\n    # Return the list of tokens\n    return tokens\n\n"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"-\", \"\")\n    line_text = line_text.replace(\"/\", \"\")\n    line_text = line_text.replace(\"\\\\\", \"\")\n    line_text = line_text.replace(\"(\", \"\")\n    line_text = line_text.replace(\")\", \"\")\n    line_text = line_text.replace(\".\", \"\")\n    line_text = line_text.replace(\",\", \"\")\n    line_text = line_text.replace(\":\", \"\")\n    line_text = line_text.replace(\";\", \"\")\n    line_text = line_text.replace(\"'\", \"\")\n    line_text = line_text.replace('\"', \"\")\n    line_text = line_text.replace(\"\u2019\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u27a2\", \"\")\n    line_text = line_text.replace(\"\u0192\", \"\")\n    line_text = line_text.replace(\"\uf0b7\", \"\")\n    line_text = line_text.replace(\"\u2013\", \"\")\n    line_text = line_text.replace(\"\u2014\", \"\")\n    line_text = line_text.replace(\"?\", \"\")\n    line_text = line_text.replace(\"*\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u27a2\", \"\")\n    line_text = line_text.replace(\"\u0192\", \"\")\n    line_text = line_text.replace(\"\uf0b7\", \"\")\n    line_text = line_text.replace(\"\u2013\", \"\")\n    line_text = line_text.replace(\"\u2014\", \"\")\n    line_text = line_text.replace(\"?\", \"\")\n    line_text = line_text.replace(\"*\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\""}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"-\", \"\")\n    line_text = line_text.replace(\"/\", \"\")\n    line_text = line_text.replace(\"\\\\\", \"\")\n    line_text = line_text.replace(\".\", \"\")\n    line_text = line_text.replace(\",\", \"\")\n    line_text = line_text.replace(\"(\", \"\")\n    line_text = line_text.replace(\")\", \"\")\n    line_text = line_text.replace(\"'\", \"\")\n    line_text = line_text.replace(\"\\\"\", \"\")\n    line_text = line_text.replace(\":\", \"\")\n    line_text = line_text.replace(\";\", \"\")\n    line_text = line_text.replace(\"?\", \"\")\n    line_text = line_text.replace(\"*\", \"\")\n    line_text = line_text.replace(\"\u2022\", \"\")\n    line_text = line_text.replace(\"\u0192\", \"\")\n    line_text = line_text.replace(\"\uf0b7\", \"\")\n    line_text = line_text.replace(\"\u2013\", \"\")\n    line_text = line_text.replace(\"\u2014\", \"\")\n    line_text = line_text.replace(\"\u201c\", \"\")\n    line_text = line_text.replace(\"\u201d\", \"\")\n    line_text = line_text.replace(\"\u2019\", \"\")\n    line_text = line_text.replace(\"\u2026\", \"\")\n    line_text = line_text.replace(\"\u2026\", \"\")\n    line_text = line_text.replace(\"\u27a2\", \"\")\n    line_text = line_text.replace(\"&\", \"\")\n    line_text = line_text.replace(\"+\", \"\")\n    line_text = line_text.replace(\"=\", \"\")\n    line_text = line_text.replace(\"<\", \"\")\n    line_text = line_text.replace(\">\", \"\")\n    line_text = line_text.replace(\"|\", \"\")\n    line"}
{"namespace": "nlm_ingestor.ingestor.processors.fix_spaced_characters", "completion": "    line_text = line_text.replace(\" \", \"\")\n    line_text = line_text.replace(\"\\n\", \"\")\n    line_text = line_text.replace(\"\\t\", \"\")\n    line_text = line_text.replace(\"\\r\", \"\")\n    line_text = line_text.replace(\"-\", \"\")\n    line_text = line_text.replace(\"/\", \"\")\n    line_text = line_text.replace(\"(\", \"\")\n    line_text = line_text.replace(\")\", \"\")\n    line_text = line_text.replace(\".\", \"\")\n    line_text = line_text.replace(\":\", \"\")\n    line_text = line_text.replace(\";\", \"\")\n    line_text = line_text.replace(\"_\", \"\")\n    line_text = line_text.replace(\"\\\\\", \"\")\n    line_text = line_text.replace(\"'\", \"\")\n    line_text = line_text.replace('\"', \"\")\n    line_text = line_text.replace(\"`\", \"\")\n    line_text = line_text.replace(\"*\", \"\")\n    line_text = line_text.replace(\"+\", \"\")\n    line_text = line_text.replace(\"~\", \"\")\n    line_text = line_text.replace(\"[\", \"\")\n    line_text = line_text.replace(\"]\", \"\")\n    line_text = line_text.replace(\"{\", \"\")\n    line_text = line_text.replace(\"}\", \"\")\n    line_text = line_text.replace(\"<\", \"\")\n    line_text = line_text.replace(\">\", \"\")\n    line_text = line_text.replace(\"|\", \"\")\n    line_text = line_text.replace(\"^\", \"\")\n    line_text = line_text.replace(\"=\", \"\")\n    line_text = line_text.replace(\"%\", \"\")\n    line_text = line_text.replace(\"$\", \"\")\n    line_text = line_text.replace(\"#\", \"\")\n    line_text = line_text."}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros >= n:\n        raise ValueError(\"The number of zero weights must be less than the total number of weights.\")\n\n    # Generate random weights that sum to one\n    weights = np.random.dirichlet(np.ones(n))\n\n    # Set the specified number of weights to zero\n    if zeros > 0:\n        zero_indices = np.random.choice(n, size=zeros, replace=False)\n        weights[zero_indices] = 0\n\n    # Normalize the weights to sum to one\n    weights /= np.sum(weights)\n\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must be less than or equal to n.\")\n\n    if zeros == 0:\n        return rand_weights_dirichlet(n)\n\n    weights = np.random.dirichlet(np.ones(n - zeros))\n    weights = np.append(weights, np.zeros(zeros))\n    np.random.shuffle(weights)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must be less than or equal to n.\")\n\n    if zeros == 0:\n        weights = np.random.dirichlet(np.ones(n))\n    else:\n        weights = np.random.dirichlet(np.ones(n - zeros))\n        weights = np.insert(weights, np.random.choice(n, size=zeros, replace=False), 0)\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros >= n:\n        raise ValueError(\"The number of zero weights cannot exceed the total number of weights.\")\n\n    weights = np.random.rand(n)\n    weights /= np.sum(weights)\n    weights[np.random.choice(np.arange(n), zeros, replace=False)] = 0\n    weights /= np.sum(weights)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    # Generate n random weights that sum up to 1\n    weights = np.random.random(n)\n    weights /= np.sum(weights)\n\n    # Set the specified number of weights to zero\n    if zeros > 0:\n        if zeros > n:\n            raise ValueError(\"Number of zero weights cannot exceed total number of weights.\")\n        zero_indices = np.random.choice(range(n), size=zeros, replace=False)\n        weights[zero_indices] = 0\n\n    # Normalize the weights so they sum up to 1\n    weights /= np.sum(weights)\n\n    return weights"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must be less than or equal to n.\")\n    if zeros == n:\n        return np.zeros(n)\n    weights = rand_weights_dirichlet(n - zeros)\n    weights = np.append(weights, np.zeros(zeros))\n    np.random.shuffle(weights)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights.\")\n\n    weights = np.random.uniform(0, 1, n)\n    weights /= np.sum(weights)\n    if zeros > 0:\n        idx = np.random.choice(n, zeros, replace=False)\n        weights[idx] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    weights = np.random.random(n)\n    if zeros > 0:\n        weights[np.random.choice(np.arange(n), zeros, replace=False)] = 0\n    weights /= weights.sum()\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot exceed the total number of weights\")\n    if zeros == n:\n        return np.zeros(n)\n    w = np.random.rand(n - zeros)\n    w = w / np.sum(w)\n    if zeros > 0:\n        w = np.concatenate((w, np.zeros(zeros)))\n        np.random.shuffle(w)\n    return w\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zero weights cannot exceed the total number of weights.\")\n\n    if zeros == 0:\n        return rand_weights_dirichlet(n)\n\n    weights = np.random.dirichlet(np.ones(n - zeros))\n    weights = np.append(weights, np.zeros(zeros))\n    np.random.shuffle(weights)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zero-weight elements must not exceed the total number of weights.\")\n\n    if zeros == 0:\n        return rand_weights_dirichlet(n)\n\n    weights = rand_weights_dirichlet(n - zeros)\n    weights = np.insert(weights, np.random.choice(n - 1, zeros, replace=False), 0)\n    weights = np.sort(weights)\n    weights = np.diff(weights, prepend=0)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"Number of zero weights cannot exceed total number of weights\")\n\n    if zeros == 0:\n        return rand_weights_dirichlet(n)\n\n    weights = np.random.rand(n)\n    weights /= weights.sum()\n    weights[np.random.choice(np.arange(n), size=zeros, replace=False)] = 0\n    weights /= weights.sum()\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    assert zeros <= n, \"The number of zeros must be less than or equal to the total number of weights.\"\n    if zeros == 0:\n        return rand_weights_dirichlet(n)\n    else:\n        w = rand_weights_dirichlet(n - zeros)\n        w = np.append(w, np.zeros(zeros))\n        np.random.shuffle(w)\n        return w\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"`zeros` must be less than or equal to `n`\")\n\n    weights = np.random.rand(n)\n    weights /= np.sum(weights)\n    weights[np.random.choice(range(n), zeros, replace=False)] = 0\n    weights /= np.sum(weights)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must not exceed the total number of weights.\")\n\n    if zeros == 0:\n        return rand_weights_dirichlet(n)\n\n    weights = np.random.rand(n - zeros)\n    weights = weights / np.sum(weights)\n    weights = np.append(weights, np.zeros(zeros))\n    np.random.shuffle(weights)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros must be less than or equal to n.\")\n\n    if zeros == 0:\n        return rand_weights_dirichlet(n)\n\n    weights = np.random.rand(n)\n    weights = weights / np.sum(weights)\n    weights[np.random.choice(n, zeros, replace=False)] = 0\n    weights = weights / np.sum(weights)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zeros cannot be greater than the number of weights.\")\n    weights = np.random.rand(n)\n    weights = weights / np.sum(weights)\n    if zeros > 0:\n        weights[np.random.choice(np.arange(n), size=zeros, replace=False)] = 0\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    assert n >= zeros, \"The number of zeros must be less than or equal to n.\"\n\n    weights = np.random.uniform(size=n)\n    weights = weights / np.sum(weights)\n    weights[np.random.choice(range(n), zeros, replace=False)] = 0\n    weights = weights / np.sum(weights)\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    # Check if zeros is not greater than n\n    if zeros > n:\n        raise ValueError(\"The number of zeros cannot be greater than n.\")\n\n    # Generate random weights that sum to one\n    weights = np.random.dirichlet(np.ones(n))\n\n    # Set the specified number of weights to zero\n    weights[:zeros] = 0\n\n    return weights\n\n"}
{"namespace": "skfolio.utils.stats.rand_weights", "completion": "    if zeros > n:\n        raise ValueError(\"The number of zero weights cannot exceed the total number of weights.\")\n\n    weights = np.random.random(n)\n    weights /= np.sum(weights)\n\n    if zeros > 0:\n        zero_indices = np.random.choice(np.arange(n), size=zeros, replace=False)\n        weights[zero_indices] = 0\n\n    return weights\n\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        module_param = deepcopy(module_dict)\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_dict = deepcopy(module_dict)\n        module_type = module_dict.pop('module_type')\n        return cls(module_type, module_dict)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop('module_type')\n        module_param = module_dict\n        return cls(module_type, module_param)\n"}
{"namespace": "autorag.schema.module.Module.from_dict", "completion": "        module_type = module_dict.pop(\"module_type\")\n        module_param = module_dict\n        return cls(module_type, module_param)\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n\n    assert (\n        image_size[0] >= center_y >= crop_size[0]\n        and image_size[1] >= center_x >= crop_size[1]\n    ), \"The annotation bounding box is outside of the image!\"\n\n    min_y = center_y - crop_size[0]\n    min_x = center_x - crop_size[1]\n    max_y = center_y + crop_size[0]\n    max_x = center_x + crop_size[1]\n    min_y = max(0, min_y)\n    min_x = max(0, min_x)\n    max_y = min(image_size[0], max_y)\n    max_x = min(image_size[1], max_x)\n\n    crop = T.CropTransform(min_x, min_y, max_x, max_y, image_size[1], image_size[0])\n    return crop\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n\n    image_height, image_width = image_size\n    crop_height, crop_width = crop_size\n    assert (\n        image_height >= crop_height\n    ), f\"Crop height {crop_height} is larger than image height {image_height}\"\n    assert (\n        image_width >= crop_width\n    ), f\"Crop width {crop_width} is larger than image width {image_width}\"\n\n    if (image_height - crop_height) % 2 == 0:\n        crop_y = int((image_height - crop_height) * center_y / image_height)\n    else:\n        crop_y = int(\n            (image_height - crop_height) * center_y / image_height + 0.5\n        )\n    if (image_width - crop_width) % 2 == 0:\n        crop_x = int((image_width - crop_width) * center_x / image_width)\n    else:\n        crop_x = int((image_width - crop_width) * center_x / image_width + 0.5)\n\n    return T.CropTransform(crop_x, crop_y, crop_width, crop_height)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n\n    assert (\n        image_size[0] >= center_y >= crop_size[0] - 1\n        and image_size[1] >= center_x >= crop_size[1] - 1\n    ), \"The annotation bounding box is outside of the image!\"\n\n    min_y = center_y - (crop_size[0] - 1)\n    min_x = center_x - (crop_size[1] - 1)\n    max_y = center_y + 1\n    max_x = center_x + 1\n    crop_y = int(min_y)\n    crop_x = int(min_x)\n    crop_h = max_y - min_y\n    crop_w = max_x - min_x\n\n    assert crop_h > 0 and crop_w > 0, \"The crop size is wrong!\"\n\n    return T.CropTransform(crop_y, crop_x, crop_h, crop_w)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n    image_height, image_width = image_size\n    crop_height, crop_width = crop_size\n    assert (\n        image_height >= crop_height\n    ), \"Crop region is larger than input image in height dimension\"\n    assert (\n        image_width >= crop_width\n    ), \"Crop region is larger than input image in width dimension\"\n    min_y = center_y - (crop_height / 2.0)\n    min_x = center_x - (crop_width / 2.0)\n    if min_y < 0:\n        min_y = 0\n    if min_x < 0:\n        min_x = 0\n    max_y = min_y + crop_height\n    max_x = min_x + crop_width\n    if max_y > image_height:\n        max_y = image_height\n        min_y = image_height - crop_height\n    if max_x > image_width:\n        max_x = image_width\n        min_x = image_width - crop_width\n    crop_tfm = T.CropTransform(min_x, min_y, max_x, max_y, image_height, image_width)\n    return crop_tfm\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Convert the instance's bounding box to XYXY_ABS mode\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # Calculate the center of the bounding box\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n\n    # Calculate the height and width of the crop\n    height, width = crop_size\n\n    # Calculate the top-left corner of the crop\n    y0 = center_y - 0.5 * height\n    x0 = center_x - 0.5 * width\n\n    # Adjust the top-left corner if it goes out of bounds\n    y0 = max(0, y0)\n    x0 = max(0, x0)\n\n    # Adjust the height and width if they go out of bounds\n    if y0 + height > image_size[0]:\n        height = image_size[0] - y0\n    if x0 + width > image_size[1]:\n        width = image_size[1] - x0\n\n    # Return the CropTransform object\n    return T.CropTransform(x0, y0, width, height)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Convert the instance's bounding box to XYXY_ABS mode\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # Calculate the center of the bounding box\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n\n    # Adjust the crop region to ensure it fits within the image boundaries\n    crop_y = max(0, center_y - crop_size[0] * 0.5)\n    crop_y = min(image_size[0] - crop_size[0], crop_y)\n    crop_x = max(0, center_x - crop_size[1] * 0.5)\n    crop_x = min(image_size[1] - crop_size[1], crop_x)\n\n    # Create the CropTransform object with the adjusted crop region\n    crop = T.CropTransform(crop_y, crop_x, crop_size[0], crop_size[1])\n\n    return crop\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n\n    image_height, image_width = image_size[0], image_size[1]\n    crop_height, crop_width = crop_size[0], crop_size[1]\n\n    y0 = max(0, round(center_y - crop_height / 2.0))\n    y1 = max(0, round(center_y + crop_height / 2.0))\n    x0 = max(0, round(center_x - crop_width / 2.0))\n    x1 = max(0, round(center_x + crop_width / 2.0))\n\n    if y0 == 0:\n        y1 = min(image_height, y1 + crop_height)\n        y0 = y1 - crop_height\n    elif y1 == image_height:\n        y0 = max(0, y0 - crop_height)\n        y1 = y0 + crop_height\n\n    if x0 == 0:\n        x1 = min(image_width, x1 + crop_width)\n        x0 = x1 - crop_width\n    elif x1 == image_width:\n        x0 = max(0, x0 - crop_width)\n        x1 = x0 + crop_width\n\n    return T.CropTransform(0, 0, y0, x0, y1, x1)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n\n    assert (\n        image_size[0] >= center_y >= crop_size[0]\n    ), \"Crop size is larger than image height\"\n    assert (\n        image_size[1] >= center_x >= crop_size[1]\n    ), \"Crop size is larger than image width\"\n\n    min_y = center_y - crop_size[0] * 0.5\n    min_x = center_x - crop_size[1] * 0.5\n\n    if min_y < 0:\n        min_y = 0\n    if min_x < 0:\n        min_x = 0\n\n    max_y = min_y + crop_size[0]\n    max_x = min_x + crop_size[1]\n\n    crop = T.CropTransform(min_x, min_y, max_x, max_y, crop_size[1], crop_size[0])\n    return crop\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Convert the instance's bounding box to XYXY_ABS mode\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # Calculate the center of the instance's bounding box\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n\n    # Calculate the height and width of the crop\n    height, width = crop_size\n\n    # Calculate the top-left corner of the crop\n    y0 = max(0, center_y - 0.5 * height)\n    x0 = max(0, center_x - 0.5 * width)\n\n    # Adjust the top-left corner if the crop extends beyond the image boundaries\n    if y0 + height > image_size[0]:\n        y0 = image_size[0] - height\n    if x0 + width > image_size[1]:\n        x0 = image_size[1] - width\n\n    # Create the CropTransform object with the calculated parameters\n    return T.CropTransform(x0, y0, width, height)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Convert the instance's bounding box to the desired format\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # Calculate the center of the bounding box\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n\n    # Adjust the crop region to ensure it fits within the image boundaries\n    crop_y0 = max(0, int(center_y - crop_size[0] / 2))\n    crop_y1 = min(image_size[0], int(center_y + crop_size[0] / 2))\n    crop_x0 = max(0, int(center_x - crop_size[1] / 2))\n    crop_x1 = min(image_size[1], int(center_x + crop_size[1] / 2))\n\n    # Create a CropTransform object with the calculated crop parameters\n    crop = T.CropTransform(crop_y0, crop_x0, crop_y1, crop_x1, image_size[0], image_size[1])\n\n    return crop\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n    image_height, image_width = image_size\n    crop_height, crop_width = crop_size\n    assert (\n        image_height >= crop_height\n    ), \"Crop region is larger than input image in height dimension\"\n    assert (\n        image_width >= crop_width\n    ), \"Crop region is larger than input image in width dimension\"\n\n    min_y = center_y - (crop_height / 2.0)\n    min_x = center_x - (crop_width / 2.0)\n\n    if min_y < 0:\n        min_y = 0\n    if min_x < 0:\n        min_x = 0\n\n    max_y = min_y + crop_height\n    max_x = min_x + crop_width\n    if max_y > image_height:\n        max_y = image_height\n        min_y = max_y - crop_height\n\n    if max_x > image_width:\n        max_x = image_width\n        min_x = max_x - crop_width\n\n    crop_y = int(min_y)\n    crop_x = int(min_x)\n    crop_h = int(max_y) - crop_y\n    crop_w = int(max_x) - crop_x\n    assert crop_h > 0\n    assert crop_w > 0\n\n    return T.CropTransform(crop_y, crop_x, crop_h, crop_w)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Convert the instance's bounding box to XYXY_ABS mode\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # Calculate the center of the bounding box\n    center_y = 0.5 * (bbox[0] + bbox[2])\n    center_x = 0.5 * (bbox[1] + bbox[3])\n\n    # Calculate the crop region\n    image_height, image_width = image_size\n    crop_height, crop_width = crop_size\n\n    # Adjust the crop region to ensure it fits within the image boundaries\n    crop_top = center_y - crop_height // 2\n    crop_top = max(0, crop_top)\n    crop_top = min(image_height - crop_height, crop_top)\n\n    crop_left = center_x - crop_width // 2\n    crop_left = max(0, crop_left)\n    crop_left = min(image_width - crop_width, crop_left)\n\n    # Create the CropTransform object\n    crop_tfm = T.CropTransform(crop_top, crop_left, crop_height, crop_width, image_height, image_width)\n\n    return crop_tfm\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n\n    image_height, image_width = image_size[0], image_size[1]\n    crop_height, crop_width = crop_size[0], crop_size[1]\n\n    if center_y - crop_height / 2 < 0:\n        crop_y = 0\n    elif center_y + crop_height / 2 > image_height:\n        crop_y = image_height - crop_height\n    else:\n        crop_y = center_y - crop_height / 2\n\n    if center_x - crop_width / 2 < 0:\n        crop_x = 0\n    elif center_x + crop_width / 2 > image_width:\n        crop_x = image_width - crop_width\n    else:\n        crop_x = center_x - crop_width / 2\n\n    return T.CropTransform(int(crop_x), int(crop_y), crop_width, crop_height)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n    image_height, image_width = image_size[0], image_size[1]\n    crop_height, crop_width = crop_size[0], crop_size[1]\n\n    # Adjust crop size if needed\n    if center_y - crop_height / 2 < 0:\n        crop_height = center_y\n        if center_y + crop_height / 2 > image_height:\n            crop_height = image_height - center_y\n    elif center_y + crop_height / 2 > image_height:\n        crop_height = image_height - center_y\n\n    if center_x - crop_width / 2 < 0:\n        crop_width = center_x\n        if center_x + crop_width / 2 > image_width:\n            crop_width = image_width - center_x\n    elif center_x + crop_width / 2 > image_width:\n        crop_width = image_width - center_x\n\n    # Adjust top-left corner of the crop\n    crop_y = center_y - crop_height / 2\n    crop_x = center_x - crop_width / 2\n\n    return T.CropTransform(int(crop_x), int(crop_y), int(crop_width), int(crop_height))\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n    h, w = image_size\n    crop_size = np.asarray(crop_size, dtype=np.int32)\n    crop_size = np.where(crop_size <= 0, image_size, crop_size)\n    min_i = np.maximum(crop_size[0] * 0.5 - center_yx[0], 0)\n    min_j = np.maximum(crop_size[1] * 0.5 - center_yx[1], 0)\n    max_i = h - np.maximum(center_yx[0] + crop_size[0] * 0.5, h)\n    max_j = w - np.maximum(center_yx[1] + crop_size[1] * 0.5, w)\n    crop_y0 = int(np.random.randint(min_i, max_i) - crop_size[0] * 0.5)\n    crop_x0 = int(np.random.randint(min_j, max_j) - crop_size[1] * 0.5)\n    return T.CropTransform(crop_x0, crop_y0, crop_size[1], crop_size[0])\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n\n    # Ensure that the crop dimensions are not larger than the image dimensions.\n    crop_size = np.asarray(crop_size, dtype=np.int32)\n    crop_size = np.minimum(crop_size, image_size)\n\n    # Adjust the crop dimensions if the desired aspect ratio is different from the instance's.\n    image_size = np.asarray(image_size, dtype=np.int32)\n    if image_size[0] < image_size[1]:\n        crop_size[0] = int(crop_size[1] * image_size[0] / image_size[1])\n    else:\n        crop_size[1] = int(crop_size[0] * image_size[1] / image_size[0])\n\n    # Define the cropping region.\n    crop_tl = np.array([center_x - crop_size[1] / 2, center_y - crop_size[0] / 2], dtype=np.int32)\n    crop_br = np.array([center_x + crop_size[1] / 2, center_y + crop_size[0] / 2], dtype=np.int32)\n\n    # Ensure that the crop region is within the image boundaries.\n    crop_br = np.minimum(crop_br, image_size - 1)\n    crop_tl = np.maximum(crop_tl, np.array([0, 0]))\n\n    # Compute the translation offset for the crop region.\n    offset = -crop_tl\n\n    return T.CropTransform(*crop_tl.tolist(), *crop_size.tolist(), image_size[1], image_size[0], offset"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Convert the instance's bounding box to the XYXY_ABS mode\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n\n    # Calculate the center of the bounding box\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n\n    # Adjust the crop region based on the bounding box center and the crop size\n    crop_y = center_y - 0.5 * crop_size[0]\n    crop_x = center_x - 0.5 * crop_size[1]\n\n    # Ensure the crop region is within the image boundaries\n    crop_y = max(0, crop_y)\n    crop_x = max(0, crop_x)\n\n    # Adjust the crop region dimensions if it exceeds the image boundaries\n    crop_y2 = min(image_size[0], crop_y + crop_size[0])\n    crop_x2 = min(image_size[1], crop_x + crop_size[1])\n\n    # Create a CropTransform object with the adjusted crop region\n    crop = T.CropTransform(0, 0, crop_y, crop_x, crop_y2, crop_x2)\n\n    return crop\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    # Convert instance bounding box to XYXY_ABS mode\n    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_yx = (bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5\n    # Check that points are within image\n    assert (\n        center_yx[0] < image_size[0] and center_yx[1] < image_size[1]\n    ), \"The center of bbox must be within image\"\n    assert (\n        center_yx[0] >= 0 and center_yx[1] >= 0\n    ), \"The center of bbox must be within image\"\n\n    # Generate crop coordinates\n    tl_yx = [max(0, center_yx[0] - crop_size[0] * 0.5), max(0, center_yx[1] - crop_size[1] * 0.5)]\n    br_yx = [min(image_size[0], center_yx[0] + crop_size[0] * 0.5), min(image_size[1], center_yx[1] + crop_size[1] * 0.5)]\n\n    src_box = [tl_yx[1], tl_yx[0], br_yx[1], br_yx[0]]\n    dst_box = [0, 0, crop_size[1], crop_size[0]]\n\n    crop = T.CropTransform(*src_box, True)\n    crop.src_box = src_box\n    crop.dst_box = dst_box\n    return crop\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n\n    image_height, image_width = image_size\n    crop_height, crop_width = crop_size\n\n    # Ensure bbox is within crop\n    crop_height = min(crop_height, bbox[3] - bbox[1])\n    crop_width = min(crop_width, bbox[2] - bbox[0])\n\n    # Compute the crop top-left corner\n    crop_y = center_y - crop_height / 2\n    crop_x = center_x - crop_width / 2\n\n    # Adjust the crop if it goes out of image boundaries\n    crop_y = max(0, crop_y)\n    crop_y = min(image_height - crop_height, crop_y)\n    crop_x = max(0, crop_x)\n    crop_x = min(image_width - crop_width, crop_x)\n\n    return T.CropTransform(int(crop_y), int(crop_x), crop_height, crop_width)\n\n"}
{"namespace": "detectron2.data.detection_utils.gen_crop_transform_with_instance", "completion": "    bbox = BoxMode.convert(instance[\"bbox\"], instance[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    center_y = 0.5 * (bbox[1] + bbox[3])\n    center_x = 0.5 * (bbox[0] + bbox[2])\n    image_height, image_width = image_size[0], image_size[1]\n    crop_height, crop_width = crop_size[0], crop_size[1]\n    # Check if the desired crop size is larger than the image size\n    if crop_height > image_height or crop_width > image_width:\n        raise ValueError(\n            f\"Crop size {crop_size} is larger than input image size {image_size}.\"\n        )\n    # Adjust the crop dimensions if they are larger than the image dimensions\n    crop_height = min(crop_height, image_height)\n    crop_width = min(crop_width, image_width)\n    # Calculate the top-left corner of the crop\n    top = center_y - crop_height * 0.5\n    left = center_x - crop_width * 0.5\n    # Adjust the top-left corner if it goes out of the image boundaries\n    if top < 0:\n        top = 0\n    if left < 0:\n        left = 0\n    # Return the CropTransform object\n    return T.CropTransform(top, left, crop_height, crop_width)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  return x / jnp.sqrt(jnp.maximum(jnp.sum(x**2, axis=-1, keepdims=True), grad_eps))\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm = jnp.maximum(x_norm, grad_eps)\n  x_norm = jnp.minimum(x_norm, 1.0 / grad_eps)\n  return x / x_norm\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of x.\n  squared_norm = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Compute the inverse square root of the squared norm.\n  inv_sqrt = jnp.sqrt(jnp.maximum(squared_norm, grad_eps))\n\n  # Normalize x by multiplying it with the inverse square root.\n  x_normalized = x / inv_sqrt\n\n  # Return the normalized array.\n  return x_normalized"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Clamp the squared norm to a minimum value to prevent exploding gradients.\n  x_norm = jnp.maximum(jnp.linalg.norm(x, axis=-1, keepdims=True), grad_eps)\n\n  # Divide the input by the clamped norm to get the normalized output.\n  x_norm = x / x_norm\n\n  return x_norm"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Forward pass\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm = jnp.maximum(x_norm, grad_eps)\n  x_norm = jnp.minimum(x_norm, 1.0 / grad_eps)\n  x_norm = x / x_norm\n\n  # Backward pass\n  x_norm_grad = jnp.linalg.norm(x_norm, axis=-1, keepdims=True)\n  x_norm_grad = jnp.maximum(x_norm_grad, 1.0 / grad_eps)\n  x_norm_grad = jnp.minimum(x_norm_grad, grad_eps)\n  x_norm_grad = x_norm_grad * x_norm\n\n  return x_norm, x_norm_grad\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x = jnp.asarray(x)\n  x_norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x_norm_sq = x_norm**2\n  x_norm_sq_clamped = jnp.maximum(x_norm_sq, grad_eps)\n  return x / jnp.sqrt(x_norm_sq_clamped)\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of x.\n  squared_norm = jnp.sum(x ** 2, axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value to prevent division by zero in the forward pass.\n  squared_norm = jnp.maximum(squared_norm, grad_eps)\n\n  # Compute the inverse square root of the squared norm.\n  inv_sqrt_squared_norm = jnp.sqrt(1.0 / squared_norm)\n\n  # Clamp the inverse square root of the squared norm to a maximum value to prevent exploding gradients in the backward pass.\n  inv_sqrt_squared_norm = jnp.minimum(inv_sqrt_squared_norm, 1.0 / grad_eps)\n\n  # Normalize x by multiplying it with the inverse square root of the squared norm.\n  normalized_x = x * inv_sqrt_squared_norm\n\n  # Return the normalized array.\n  return normalized_x"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input array.\n  squared_norm = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Compute the inverse square root of the squared norm.\n  inv_sqrt = jnp.sqrt(jnp.maximum(squared_norm, grad_eps))\n\n  # Normalize the input array by dividing it by the inverse square root.\n  x_inv_sqrt = x / inv_sqrt\n\n  # Return the normalized array.\n  return x_inv_sqrt\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Clamp the squared norm to a minimum value to prevent division by zero or exploding gradients in the backward pass.\n  grad_eps = jnp.array(grad_eps)\n  denom = jnp.maximum(jnp.sqrt(jnp.sum(x * x, axis=-1, keepdims=True)), grad_eps)\n  # Normalize the input vector(s) by dividing by the clamped squared norm.\n  x = x / denom\n  # Clamp the squared norm to a minimum value to prevent division by zero or exploding gradients in the forward pass.\n  denom = jnp.maximum(jnp.sqrt(jnp.sum(x * x, axis=-1, keepdims=True)), grad_eps)\n  # Normalize the input vector(s) by dividing by the clamped squared norm.\n  x = x / denom\n  # Return the normalized array.\n  return x"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Clamp the squared norm to a minimum value to prevent division by zero in the forward pass.\n  clamped_squared_norm = jnp.maximum(jnp.sum(x * x, axis=-1, keepdims=True), grad_eps)\n  # Normalize the input vector(s) using the clamped squared norm.\n  x_normed = x * jnp.sqrt(1.0 / clamped_squared_norm)\n\n  # Clamp the squared norm to a different minimum value to prevent division by zero in the backward pass.\n  clamped_squared_norm = jnp.maximum(jnp.sum(x_normed * x_normed, axis=-1, keepdims=True), grad_eps)\n  # Normalize the normalized vector(s) using the clamped squared norm.\n  x_normed = x_normed * jnp.sqrt(1.0 / clamped_squared_norm)\n\n  return x_normed\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of x along the last axis.\n  squared_norm = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Compute the inverse square root of the squared norm, with a clamp to prevent division by zero or small values.\n  inv_sqrt = jnp.sqrt(jnp.maximum(squared_norm, grad_eps))\n\n  # Compute the normalized array by dividing x by the inverse square root.\n  normalized_array = x / inv_sqrt\n\n  # Return the normalized array.\n  return normalized_array\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of x along the last axis.\n  sq_norm = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Compute the inverse square root of the squared norm, clamped to avoid division by zero or exploding gradients.\n  safe_norm = jnp.sqrt(jnp.maximum(sq_norm, grad_eps))\n  inv_safe_norm = 1.0 / safe_norm\n\n  # Compute the clamped inverse square root of the squared norm, clamped to avoid division by zero or exploding gradients in the backward pass.\n  safe_inv_norm = jnp.where(sq_norm > grad_eps, inv_safe_norm, 0.0)\n\n  # Normalize x by multiplying it with the clamped inverse square root of the squared norm.\n  x_normalized = x * safe_inv_norm\n\n  # Return the normalized array.\n  return x_normalized\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  x_sq_norm = jnp.maximum(math_lib.safe_sum(x**2, axis=-1, keepdims=True), grad_eps)\n  x_inv_norm = jnp.rsqrt(x_sq_norm)\n  return x * x_inv_norm\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of x along the last axis.\n  squared_norm = jnp.sum(x * x, axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value in the forward pass.\n  squared_norm = jnp.maximum(squared_norm, grad_eps)\n\n  # Compute the inverse square root of the clamped squared norm.\n  inv_sqrt = jnp.sqrt(squared_norm)\n\n  # Clamp the inverse square root to a maximum value in the backward pass.\n  inv_sqrt = jnp.where(inv_sqrt < grad_eps, grad_eps, inv_sqrt)\n\n  # Normalize the input array by dividing it by the inverse square root.\n  return x * inv_sqrt\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input array\n  sqr_norm = jnp.sum(x ** 2, axis=-1, keepdims=True)\n\n  # Clamp the squared norm to a minimum value in the forward pass\n  sqr_norm = jnp.maximum(sqr_norm, grad_eps)\n\n  # Compute the normalization factor for the forward pass\n  x_inv_norm = jnp.sqrt(sqr_norm)\n\n  # Compute the normalized array for the forward pass\n  y = x * (x_inv_norm ** -1)\n\n  # Clamp the squared norm to a minimum value in the backward pass\n  sqr_norm = jnp.maximum(sqr_norm, 1e-12)\n\n  # Compute the normalization factor for the backward pass\n  x_inv_norm = jnp.sqrt(sqr_norm)\n\n  # Compute the gradient of the normalized array with respect to the input array\n  dy_dx = jnp.eye(x.shape[-1]) - (x[..., :, None] * x_inv_norm[..., None]) / sqr_norm[..., None]\n\n  # Return the normalized array and its gradient\n  return y, dy_dx\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Forward pass: normalize x to unit length along its last axis.\n  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x = x / jnp.maximum(norm, grad_eps)\n\n  # Backward pass: clamp the squared norm to grad_eps before division to prevent exploding gradients.\n  def grad_fn(dout):\n    dnorm = jnp.sum(x * dout, axis=-1, keepdims=True)\n    dnorm = jnp.maximum(dnorm, grad_eps)\n    return dout * (x / dnorm) - dout * jnp.sum(\n        x * dout, axis=-1, keepdims=True\n    ) * x / (dnorm * norm)\n\n  return x, grad_fn\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Forward pass\n  norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n  x = x / jnp.maximum(norm, grad_eps)\n\n  # Backward pass\n  def f(x):\n    # This function is used to compute the gradient of the normalized array x with respect to the original array x.\n    # It first computes the squared norm of x, then clamps it to a minimum value of grad_eps to prevent exploding gradients.\n    # Finally, it returns the gradient of the normalized array x with respect to the original array x.\n    g = jnp.sum(x * x, axis=-1, keepdims=True)\n    g = jnp.maximum(g, grad_eps)\n    return x * (g ** -0.5)\n\n  return x, f\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Clamp the squared norm to a minimum value to prevent exploding gradients in the backward pass\n  squared_norm = jnp.maximum(jnp.sum(x**2, axis=-1, keepdims=True), grad_eps)\n  # Normalize the input vector(s)\n  x_normed = x / jnp.sqrt(squared_norm)\n  return x_normed\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # Compute the squared norm of the input vector(s).\n  squared_norm = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # Compute the gradient-safe denominator for the forward pass.\n  forward_denom = jnp.maximum(squared_norm, grad_eps)\n\n  # Compute the gradient-safe denominator for the backward pass.\n  backward_denom = jnp.maximum(squared_norm, grad_eps**2)\n\n  # Normalize the input vector(s) using the forward denominator in the forward pass.\n  x_forward = x / jnp.sqrt(forward_denom)\n\n  # Normalize the input vector(s) using the backward denominator in the backward pass.\n  x_backward = x / jnp.sqrt(backward_denom)\n\n  # Use a jax.custom_vjp to define the custom gradient computation for the backward pass.\n  def l2_normalize_fwd(x):\n    return x_forward, (x_backward, backward_denom)\n\n  def l2_normalize_bwd(res, g):\n    x_backward, backward_denom = res\n    return jnp.where(\n        backward_denom > grad_eps**2,\n        g * x_backward / jnp.sqrt(backward_denom),\n        jnp.zeros_like(x),\n    )\n\n  l2_normalize_fwd.defvjp(l2_normalize_bwd)\n\n  # Return the normalized array, with the custom gradient computation defined using jax.custom_vjp.\n  return l2_normalize_fwd(x)[0]\n\n"}
{"namespace": "ref_utils.l2_normalize", "completion": "  # The epsilon value used in the backward pass of the function.\n  # It is used to prevent the gradients from exploding during the backward pass.\n  # It is a very small value, typically on the order of 1e-7.\n  eps = 1e-6\n\n  # The square of the norm of the input vector(s).\n  # This is calculated using the jnp.sum function, which sums the elements of the input array along the last axis.\n  # The square of the norm is calculated by squaring the result of the jnp.sum function.\n  norm_sq = jnp.sum(x**2, axis=-1, keepdims=True)\n\n  # The square of the norm of the input vector(s) clamped to a minimum value.\n  # This is done to prevent the gradients from exploding during the backward pass.\n  # The jnp.maximum function is used to ensure that the clamped value is greater than the minimum value of grad_eps.\n  # The jnp.sqrt function is then applied to the clamped value to obtain the square root of the clamped value.\n  norm_sq_clamped = jnp.sqrt(jnp.maximum(norm_sq, grad_eps**2))\n\n  # The normalized array, with each vector along the last axis of x normalized to unit length.\n  # This is calculated by dividing the input array by the square root of the clamped norm.\n  # The jnp.where function is used to ensure that the gradients are not exploding during the backward pass.\n  # If the norm is less than the minimum value of grad_eps, the gradient is set to zero.\n  # Otherwise, the gradient is set to the normalized array divided by the square root of the clamped norm.\n  x_normalized = jnp.where(\n      norm_sq > grad_eps**2, x / norm_sq_clamped, jnp.zeros_like(x)\n  )\n\n  # The normalized array, with each vector along the last axis of x normalized to unit length.\n  # This is calculated by dividing the input array by the square root of the clamped norm.\n  # The j"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, agent_input = agent_info.split(\":\")\n        return agent_name, agent_input\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[1].split(']')[0]\n        agent_name, input_text = agent_info.split(':')\n        input_text = input_text.strip()\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        input_text = agent_info.split(\":\")[1] if \":\" in agent_info else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1].strip() if \":\" in response else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_input = response.split(\":\")[1].strip() if \":\" in response else \"\"\n        return agent_name, agent_input\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\":\")[1].strip() if \":\" in response else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        input_text = agent_info.split(\":\")[1] if \":\" in agent_info else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name = agent_info.split(\":\")[0]\n        input_text = agent_info.split(\":\")[1] if len(agent_info.split(\":\")) > 1 else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\"Use Agent[\")[1].split(\"]\")[1].split(\":\")[1].strip() if \":\" in response else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        start_index = response.find(\"Use Agent[\")\n        end_index = response.find(\"]\")\n\n        if start_index == -1 or end_index == -1:\n            return \"\", \"\"\n\n        agent_info = response[start_index + 9:end_index]\n        agent_name, agent_input_text = agent_info.split(\":\")\n        return agent_name.strip(), agent_input_text.strip()\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        start_index = response.find(\"Use Agent[\")\n        end_index = response.find(\"]\")\n        agent_info = response[start_index + 9:end_index]\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        start = response.find(\"Use Agent[\")\n        end = response.find(\"]\")\n        agent_info = response[start + len(\"Use Agent[\"):end].strip()\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name.strip(), input_text.strip()\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        start_index = response.index('Use Agent[') + len('Use Agent[')\n        end_index = response.index(']')\n        agent_info = response[start_index:end_index]\n        agent_name, input_text = agent_info.split(':')\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_name = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        input_text = response.split(\":\")[1] if \":\" in response else \"\"\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        response_parts = response.split('Use Agent[')[1].split(']')\n        agent_name = response_parts[0].strip()\n        input_text = response_parts[1].split(':')[1].strip() if ':' in response_parts[1] else ''\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split(\"Use Agent[\")[1].split(\"]\")[0]\n        agent_name, input_text = agent_info.split(\":\")\n        return agent_name, input_text\n"}
{"namespace": "agent_response.AgentResponse._parse_agent_info", "completion": "        agent_info = response.split('Use Agent[')[1].split(']')[0]\n        agent_name, input_text = agent_info.split(':')\n        return agent_name.strip(), input_text.strip()\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects a 3-dimensional mask, got {segm.ndim}.\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoint"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects a 3-dimensional mask, got {segm.ndim}.\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoint"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects a 3-dimensional mask, got {segm.ndim}.\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoint"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects a 3-dimensional mask, got {segm.ndim}.\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoint"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects a 3-dimensional mask, got {segm.ndim}.\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keyp"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects an array of 3 dimensions, got {segm.ndim}.\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoint"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expects a binary mask with 'L' layout.\"\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n            )\n        target.gt_masks = masks\n\n    if len(annos) and \"ke"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects a 3-dimensional mask, got {segm.ndim}!\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoint"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects an array of 3 dimensions, got {segm.ndim}.\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoint"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects an array of 3 dimensions, got {segm.ndim}.\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoint"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects a 3-dimensional mask, got {segm.ndim}.\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        kpts = Keypoint"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 2, \"Expects a binary mask with 'L' layout.\"\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot convert segmentation of type '{}' to BitMasks!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n            )\n        target.gt_masks = masks\n\n    if len(annos) and \""}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects an array of 3 dimensions, got {segm.ndim}.\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            # TODO put the if/else above in a function\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            masks = []\n            for polygons in segms:\n                rles = mask_util.frPyObjects(polygons, *image_size)\n                rle = mask_util.merge(rles)\n                masks.append(mask_util.decode(rle))\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        kpts = Instances.gt_keypoints = Keypoints(kpts)\n\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects 3-dimensional mask, got {segm.ndim}.\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        kpts = Keypoint"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects a 3-dimensional mask, got {segm.ndim}!\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            # torch.from_numpy does not support array with negative stride.\n            masks = BitMasks(\n                torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n            )\n        target.gt_masks = masks"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects an array of 3 dimensions, got {segm.ndim}.\"\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation of type '{}'!\"\n                        \"Supported types are: polygons as list[list[float] or ndarray],\"\n                        \" COCO-style RLE as a dict.\".format(type(segm))\n                    )\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        kpts = Keypoints(kpts"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects a 3-dimensional mask, got {segm.ndim}.\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        f\"Cannot process {type(segm)} type {segm} for binary mask\"\n                    )\n            masks = BitMasks(masks)\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", []) for obj in annos]\n        target.gt_keypoints = Keypoints(kpts)\n\n    target = target.remove(\"gt_sem_seg\")\n    return target\n\n"}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects an array of 3 dimensions, got {segm.ndim}.\"\n                    masks.append(segm)\n                else:\n                    raise ValueError(f\"Cannot process {type(segm)} type {segm}.\")\n            # take first dim as mask data and reverse the channels to keep\n            # them in the same format as the default pycocotools load\n            masks = BitMasks(\n                torch.from_numpy(np.stack(masks, axis=0))[:, ::-1, :, :]\n            )\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\" in annos[0]:\n        kpts = [obj.get(\"keypoints\", ["}
{"namespace": "detectron2.data.detection_utils.annotations_to_instances", "completion": "    boxes = [BoxMode.convert(obj[\"bbox\"], obj[\"bbox_mode\"], BoxMode.XYXY_ABS) for obj in annos]\n    target = Instances(image_size)\n    boxes = target.gt_boxes = Boxes(boxes)\n    boxes.clip(image_size)\n\n    classes = [obj[\"category_id\"] for obj in annos]\n    classes = torch.tensor(classes, dtype=torch.int64)\n    target.gt_classes = classes\n\n    if len(annos) and \"segmentation\" in annos[0]:\n        segms = [obj[\"segmentation\"] for obj in annos]\n        if mask_format == \"polygon\":\n            masks = PolygonMasks(segms)\n        else:\n            assert mask_format == \"bitmask\", mask_format\n            masks = []\n            for segm in segms:\n                if isinstance(segm, list):\n                    # polygon\n                    masks.append(polygons_to_bitmask(segm, *image_size))\n                elif isinstance(segm, dict):\n                    # COCO RLE\n                    masks.append(mask_util.decode(segm))\n                elif isinstance(segm, np.ndarray):\n                    assert segm.ndim == 3, f\"Expects 3-dimensional masks for each instance, got {segm.ndim}!\"\n                    # mask array\n                    masks.append(segm)\n                else:\n                    raise ValueError(\n                        \"Cannot process segmentation for {}\".format(\n                            \"box in dataset_dict.annotations. \"\n                            \"Supported types are: polygons as list[list[float] or ndarray],\"\n                            \" COCO-style RLE as a dict.\"\n                        )\n                    )\n            # TODO add support for keypoints\n            masks = BitMasks.from_masks(masks, *image_size, padding_mode=\"zeros\")\n        target.gt_masks = masks\n\n    if len(annos) and \"keypoints\""}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n    data_home = os.path.expanduser(data_home)\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\")\n        )\n    data_home = str(Path(data_home).expanduser())\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n    data_home = str(Path(data_home).expanduser())\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\")\n        )\n    data_home = os.path.expanduser(data_home)\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\")\n        )\n    data_home = str(Path(data_home).expanduser())\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\")\n        )\n    data_home = str(Path(data_home).expanduser())\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\")\n        )\n    data_home = str(Path(data_home).expanduser())\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n    data_home = os.path.expanduser(data_home)\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n    data_home = Path(data_home)\n    data_home.mkdir(exist_ok=True, parents=True)\n    return str(data_home)\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\")\n        )\n    data_home = str(Path(data_home).expanduser())\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\")\n        )\n    data_home = str(Path(data_home).expanduser())\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n    data_home = os.path.expanduser(data_home)\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n    data_home = str(Path(data_home).expanduser())\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\")\n        )\n    data_home = str(Path(data_home).expanduser().resolve())\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\")\n        )\n    data_home = str(Path(data_home).expanduser().resolve())\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n    data_home = str(Path(data_home).expanduser().resolve())\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\"))\n    data_home = str(Path(data_home).expanduser())\n    if not os.path.exists(data_home):\n        os.makedirs(data_home)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\")\n        )\n    data_home = str(Path(data_home).expanduser().absolute())\n    os.makedirs(data_home, exist_ok=True)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\")\n        )\n    data_home = str(Path(data_home).expanduser().absolute())\n    os.makedirs(data_home, exist_ok=True)\n    return data_home\n\n"}
{"namespace": "skfolio.datasets._base.get_data_home", "completion": "    if data_home is None:\n        data_home = os.environ.get(\n            \"SKFOLIO_DATA\", os.path.join(\"~\", \"skfolio_data\")\n        )\n    data_home = Path(data_home).expanduser()\n\n    if not data_home.exists():\n        data_home.mkdir(parents=True)\n\n    return data_home.as_posix()\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"The covariance matrix must be a 2D array.\")\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1  # numerical error\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1  # numerical error\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1  # numerical error\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1  # numerical error\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1  # handle numerical errors\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1  # numerical error\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1  # numerical error\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    cov = np.asarray(cov)\n    assert_is_square(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1  # numerical error\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1  # numerical error\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2d-array\")\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_square(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1  # numerical error\n    return corr, std\n\n"}
{"namespace": "skfolio.utils.stats.cov_to_corr", "completion": "    assert_is_symmetric(cov)\n    std = np.sqrt(np.diag(cov))\n    corr = cov / np.outer(std, std)\n    corr[corr < -1], corr[corr > 1] = -1, 1  # handle numerical errors\n    return corr, std\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes\n    import detectron2\n\n    # TODO: find a more automatic way to enable import of other classes"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    training_mode = model.training\n    for m in model.modules():\n        m.__training__ = training_mode\n    yield\n    for m in model.modules():\n        delattr(m, \"__training__\")"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def freeze_training_mode(model):\n        for module in model.modules():\n            if hasattr(module, \"training\"):\n                module.training = False\n\n    freeze_training_mode(model)\n    yield\n    freeze_training_mode(model)"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: find a more automatic way to enable import of other classes\n    modules = [\n        \"detectron2.modeling.backbone\",\n        \"detectron2.modeling.roi_heads\",\n        \"detectron2.modeling.postprocessing\",\n        \"detectron2.modeling.proposal_generator\",\n        \"detectron2.modeling.anchor_generator\",\n        \"detectron2.modeling.meta_arch\",\n        \"detectron2.modeling.box_regression\",\n        \"detectron2.modeling.matcher\",\n        \"detectron2.modeling.poolers\",\n        \"detectron2.modeling.roi_heads.fast_rcnn\",\n        \"detectron2.modeling.roi_heads.mask_head\",\n        \"detectron2.modeling.roi_heads.keypoint_head\",\n        \"detectron2.modeling.roi_heads.roi_heads\",\n        \"detectron2.modeling.roi_heads.roi_box_head\",\n        \"detectron2.modeling.roi_heads.roi_mask_head\",\n        \"detectron2.modeling.roi_heads.roi_keypoint_head\",\n        \"detectron2.modeling.roi_heads.fast_rcnn\",\n        \"detectron2.modeling.roi_heads.mask_head\",\n        \"detectron2.modeling.roi_heads.keypoint_head\",\n        \"detectron2.modeling.roi_heads.roi_heads\",\n        \"detectron2.modeling.roi_heads.roi_box_head\",\n        \"detectron2.modeling.roi_heads.roi_mask_head\",\n        \"detectron2.modeling.roi_heads.roi_keypoint_head\",\n        \"detectron2.modeling.roi_heads."}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: support more types\n    if not isinstance(model, nn.Module):\n        raise TypeError(\"Only support nn.Module for now\")\n    # TODO: support more types\n    if not hasattr(model, \"state_dict\"):\n        raise TypeError(\"Only support nn.Module with state_dict for now\")\n    # TODO: support more types\n    if not hasattr(model, \"named_modules\"):\n        raise TypeError(\"Only support nn.Module with named_modules for now\")\n\n    # TODO: support more types\n    if not hasattr(model, \"named_parameters\"):\n        raise TypeError(\"Only support nn.Module with named_parameters for now\")\n\n    # TODO: support more types\n    if not hasattr(model, \"named_buffers\"):\n        raise TypeError(\"Only support nn.Module with named_buffers for now\")\n\n    # TODO: support more types\n    if not hasattr(model, \"named_children\"):\n        raise TypeError(\"Only support nn.Module with named_children for now\")\n\n    # TODO: support more types\n    if not hasattr(model, \"named_modules\"):\n        raise TypeError(\"Only support nn.Module with named_modules for now\")\n\n    # TODO: support more types\n    if not hasattr(model, \"named_parameters\"):\n        raise TypeError(\"Only support nn.Module with named_parameters for now\")\n\n    # TODO: support more types\n    if not hasattr(model, \"named_buffers\"):\n        raise TypeError(\"Only support nn.Module with named_buffers for now\")\n\n    # TODO: support more types\n    if not hasattr(model, \"named_children\"):\n        raise TypeError(\"Only support nn.Module with named_children for now\")\n\n    # TODO: support more types\n    if not hasattr(model, \"named_modules\"):\n        raise TypeError(\"Only support nn.Module with named_modules for now\")\n\n    # TODO: support more types\n    if not hasattr(model, \"named_parameters\"):\n        raise TypeError(\"Only"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: find a more automatic way to enable import of other classes\n    with ExitStack() as stack:\n        MODULES = [\n            \"detectron2.modeling.backbone\",\n            \"detectron2.modeling.meta_arch\",\n            \"detectron2.modeling.proposal_generator\",\n            \"detectron2.modeling.roi_heads\",\n            \"detectron2.modeling.anchor_generator\",\n            \"detectron2.modeling.box_regression\",\n            \"detectron2.modeling.matcher\",\n            \"detectron2.modeling.poolers\",\n            \"detectron2.modeling.postprocessing\",\n            \"detectron2.modeling.roi_heads.fast_rcnn\",\n            \"detectron2.modeling.roi_heads.mask_head\",\n            \"detectron2.modeling.roi_heads.keypoint_head\",\n            \"detectron2.modeling.roi_heads.roi_heads\",\n            \"detectron2.modeling.roi_heads.roi_box_head\",\n            \"detectron2.modeling.roi_heads.roi_mask_head\",\n            \"detectron2.modeling.roi_heads.roi_keypoint_head\",\n            \"detectron2.modeling.rpn\",\n            \"detectron2.modeling.box_regression\",\n            \"detectron2.modeling.matcher\",\n            \"detectron2.modeling.roi_heads.fast_rcnn\",\n            \"detectron2.modeling.roi_heads.mask_head\",\n            \"detectron2.modeling.roi_heads.keypoint_head\",\n            \"detectron2.modeling.roi_heads.roi_heads\",\n            \"detectron2.modeling.roi_heads.roi_box_head\",\n            \"detectron2.modeling"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Save the original training state of each submodule\n    original_training_states = {}\n    for name, module in model.named_modules():\n        if hasattr(module, \"training\"):\n            original_training_states[name] = module.training\n\n    # Set the training state of each submodule to a constant value\n    for name, module in model.named_modules():\n        if hasattr(module, \"training\"):\n            module.training = False\n\n    # Execute the context\n    try:\n        yield\n    finally:\n        # Restore the original training state of each submodule\n        for name, module in model.named_modules():\n            if hasattr(module, \"training\"):\n                module.training = original_training_states[name]\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    training_mode = model.training\n    for module in model.modules():\n        module.__class__.__annotations__[\"training\"] = torch.jit.Final[bool]\n        module.training = training_mode\n    yield\n    for module in model.modules():\n        del module.__class__.__annotations__[\"training\"]\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def freeze_training_mode_for_module(module):\n        \"\"\"\n        This function sets the \"training\" attribute of a given module to a constant value, allowing for optimization by meta-compilation. It is used as a callback function when iterating through all submodules in a model.\n        Input-Output Arguments\n        :param module: The module whose \"training\" attribute is to be annotated as a constant.\n        :return: No return values. This function operates by side effects, modifying the class definition of the module.\n        \"\"\"\n        if hasattr(module, \"training\"):\n            module.training = torch.jit.Final[bool]()\n\n    with torch.jit.frozen_attribute(model, \"training\"):\n        model.apply(freeze_training_mode_for_module)\n        yield"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: find a more automatic way to enable import of other classes\n    MODULES = [\n        \"detectron2.modeling.backbone\",\n        \"detectron2.modeling.proposal_generator\",\n        \"detectron2.modeling.roi_heads\",\n        \"detectron2.modeling.meta_arch\",\n        \"detectron2.modeling.anchor_generator\",\n        \"detectron2.modeling.box_regression\",\n        \"detectron2.modeling.matcher\",\n        \"detectron2.modeling.roi_heads.fast_rcnn\",\n        \"detectron2.modeling.roi_heads.mask_head\",\n        \"detectron2.modeling.roi_heads.keypoint_head\",\n        \"detectron2.modeling.poolers\",\n        \"detectron2.modeling.postprocessing\",\n    ]\n\n    with ExitStack() as stack:\n        ctxs = [stack.enter_context(mock.patch(mod + \".training\")) for mod in MODULES]\n        for m in ctxs:\n            m.side_effect = lambda: True\n        yield\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # Save the original training attribute values of all submodules in the model\n    original_training_values = {name: module.training for name, module in model.named_modules()}\n\n    # Create a new class definition for each submodule in the model\n    for name, module in model.named_modules():\n        # Create a new class definition with the same attributes as the original class definition\n        new_class = type(module.__class__.__name__, module.__class__.__bases__, dict(module.__class__.__dict__))\n        # Set the \"training\" attribute of the new class definition to be a constant\n        new_class.training = torch.jit.Final[bool]\n        # Replace the original class definition with the new class definition\n        module.__class__ = new_class\n\n    # Yield control back to the calling function\n    yield\n\n    # Restore the original training attribute values of all submodules in the model\n    for name, module in model.named_modules():\n        module.training = original_training_values[name]\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def freeze_training_mode(module):\n        \"\"\"\n        This function takes a module as input and modifies its class definition to annotate the \"training\" attribute as a constant.\n        Input-Output Arguments\n        :param module: The module whose class definition is to be modified.\n        :return: No return values. This function operates by side effects, modifying the class definition of the module.\n        \"\"\"\n        if hasattr(module, \"training\"):\n            module.training = torch.jit.Final[bool]\n\n    for submodule in model.modules():\n        freeze_training_mode(submodule)\n    yield\n\n    def unfreeze_training_mode(module):\n        \"\"\"\n        This function takes a module as input and modifies its class definition to remove the annotation of the \"training\" attribute as a constant.\n        Input-Output Arguments\n        :param module: The module whose class definition is to be modified.\n        :return: No return values. This function operates by side effects, modifying the class definition of the module.\n        \"\"\"\n        if hasattr(module, \"training\"):\n            del module.training\n\n    for submodule in model.modules():\n        unfreeze_training_mode(submodule)\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: find a more automatic way to enable import of other classes\n    MODULES = [\n        \"detectron2.modeling.roi_heads.fast_rcnn\",\n        \"detectron2.modeling.roi_heads.mask_head\",\n        \"detectron2.modeling.roi_heads.keypoint_head\",\n    ]\n\n    def _new_len(obj):\n        return obj.__len__()\n\n    with ExitStack() as stack:\n        ctxs = [stack.enter_context(mock.patch(mod + \".len\")) for mod in MODULES]\n        for m in ctxs:\n            m.side_effect = _new_len\n        yield\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: this is a temporary workaround to avoid a bug in torchscript.\n    # It should be removed once the bug is fixed.\n    # https://github.com/pytorch/pytorch/issues/44881\n    # https://github.com/pytorch/pytorch/issues/44881#issuecomment-715028297\n    # https://github.com/pytorch/pytorch/issues/44881#issuecomment-715028297\n    # https://github.com/pytorch/pytorch/issues/44881#issuecomment-715028297\n    # https://github.com/pytorch/pytorch/issues/44881#issuecomment-715028297\n    # https://github.com/pytorch/pytorch/issues/44881#issuecomment-715028297\n    # https://github.com/pytorch/pytorch/issues/44881#issuecomment-715028297\n    # https://github.com/pytorch/pytorch/issues/44881#issuecomment-715028297\n    # https://github.com/pytorch/pytorch/issues/44881#issuecomment-715028297\n    # https://github.com/pytorch/pytorch/issues/44881#issuecomment-715028297\n    # https://github.com/pytorch/pytorch/issues/44881#issuecomment-715028297\n    # https://github.com/pytorch/pytorch/issues/44881#issuecomment-715028297\n    # https://github.com/pytorch/pytorch/issues/44881#issuecomment-715028297"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    training_state = {}\n    for name, m in model.named_modules():\n        training_state[name] = m.training\n        m.training = False\n    yield\n    for name, m in model.named_modules():\n        m.training = training_state[name]\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    def _set_training(self, mode):\n        if isinstance(mode, torch.Tensor):\n            mode = bool(mode.item())\n        else:\n            mode = bool(mode)\n        self.training = mode\n        for module in self.children():\n            set_training(module, mode)\n\n    def set_training(module, mode):\n        cls, self_training = type(module), module.training\n\n        # Avoid this recursive redefinition\n        if hasattr(cls, \"__old_set_training\"):\n            cls.__old_set_training(module, mode)\n            return\n\n        # We only need to redefine if training != mode, otherwise keep it the same.\n        # If we do not do this, scripting will fail with an error like this:\n        #   AttributeError: 'ROIHeads' object has no attribute 'training'\n        if self_training != mode:\n            cls.__old_set_training = cls.train\n            cls.train = lambda self, mode=mode: _set_training(self, mode)\n\n    try:\n        for module in model.modules():\n            set_training(module, True)\n        yield\n    finally:\n        for module in model.modules():\n            module.train = torch.nn.Module.train\n            if hasattr(module, \"__old_set_training\"):\n                delattr(module, \"__old_set_training\")\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # This function is used to temporarily set the \"training\" attribute of every submodule in a given model to a constant value, allowing for optimization by meta-compilation.\n    # It uses a context manager to ensure that these changes are reverted back to their original state after the context manager exits.\n    # Input-Output Arguments\n    # :param model: The model whose submodules' \"training\" attributes are to be temporarily annotated as constants. It is used to iterate through all submodules and modify their class definitions.\n    # :return: No return values. This function operates by side effects, modifying the class definitions of the model's submodules within the context.\n\n    # Create a copy of the original class definitions for each submodule in the model.\n    orig_classes = {}\n    for name, module in model.named_modules():\n        orig_classes[name] = deepcopy(module.__class__)\n\n    # Define a new class that overrides the \"training\" attribute with a constant value.\n    class FreezeTrainingMode(type(model)):\n        def __init__(self, *args, **kwargs):\n            super().__init__(*args, **kwargs)\n            self.training = False\n\n    # Replace the original class definitions with the new class for each submodule in the model.\n    for name, module in model.named_modules():\n        module.__class__ = FreezeTrainingMode\n\n    # Yield control back to the calling function.\n    yield\n\n    # Revert the class definitions back to their original state.\n    for name, module in model.named_modules():\n        module.__class__ = orig_classes[name]\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: this is a workaround for the bug in torch.jit.script\n    # https://github.com/pytorch/pytorch/issues/46843\n    # we should remove this function once the bug is fixed\n    class _FrozenTrainingMode:\n        def __init__(self, training):\n            self.training = training\n\n        def __call__(self, self_, *args, **kwargs):\n            self_.training = self.training\n            return self_(*args, **kwargs)\n\n    for module in model.modules():\n        module.__class__.__call__ = _FrozenTrainingMode(module.training)\n    yield\n    for module in model.modules():\n        module.__class__.__call__ = module.__call__\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # TODO: this is a temporary fix, we should implement a proper way to freeze training mode\n    # for each module.\n    # See https://github.com/pytorch/pytorch/issues/38964\n\n    # freeze training mode for each module\n    for m in model.modules():\n        if hasattr(m, \"training\"):\n            m.training = torch.jit.annotate(bool, m.training)\n    yield\n    # unfreeze training mode for each module\n    for m in model.modules():\n        if hasattr(m, \"training\"):\n            del m.training\n\n"}
{"namespace": "detectron2.export.torchscript_patch.freeze_training_mode", "completion": "    # This is a workaround for https://github.com/pytorch/pytorch/issues/46138\n    # The issue is that the \"training\" attribute of a module is not considered a constant\n    # during meta-compilation, and therefore it is not possible to optimize it away.\n    # By annotating it as a constant, we can force it to be treated as a constant\n    # during meta-compilation, which allows for optimization.\n    # The context manager is used to ensure that the changes are reverted back to their\n    # original state after the context manager exits.\n\n    # Define a function to modify the class definition of a module\n    def freeze_training_mode(module):\n        # If the module is a submodule of the model, modify its class definition\n        if isinstance(module, torch.nn.Module) and module is not model:\n            # Get the class definition of the module\n            cls = type(module)\n            # If the class definition has a \"training\" attribute, annotate it as a constant\n            if hasattr(cls, \"training\"):\n                cls.training = torch.jit.Final[bool]\n\n    # Iterate through all submodules in the model and modify their class definitions\n    for m in model.modules():\n        freeze_training_mode(m)\n\n    # Return the modified model\n    yield\n\n    # Revert the changes made to the model's submodules\n    for m in model.modules():\n        freeze_training_mode(m)\n"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of the two fields are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if field1 and field2 have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of the two fields are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of the two fields are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shape of field1 equals the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the two fields have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shape of field1 equals the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the two fields have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the two fields have the same shape.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if shape of field1 equals shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of two fields are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shape of field1 is equal to the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shapes of field1 and field2 are equal.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shape of field1 equals field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Check if the shape of field1 is equal to field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[Any]]) -> Dict[str, List[Any]]:\n        \"\"\"Check if the shape of field1 is equal to the shape of field2.\"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"\n        This function is a validator function that is used within a Pydantic model to ensure the shapes of field1 and field2 match. If the shapes do not match, it raises a ValueError indicating the mismatch.\n\n        Input-Output Arguments\n        :param cls: type, The class of the Pydantic model that contains the validator.\n        :param values: Dict[str, np.ndarray], A dictionary containing the values of the fields to be checked.\n        :return: Dict[str, np.ndarray], The input values dictionary is returned after the validation is performed.\n        \"\"\"\n        if values[field1].shape != values[field2].shape:\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} shape mismatch, \"\n                f\"resp. {values[field1].shape} and {values[field2].shape}\"\n            )\n\n        return values\n\n    return __root_validator"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, str):\n        metrics = [metrics]\n\n    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric[\"name\"])\n            metric_params.append(deepcopy(metric))\n            metric_params[-1].pop(\"name\")\n        else:\n            raise ValueError(f\"Invalid metric format: {metric}\")\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if len(metrics) == 0:\n        return [], []\n\n    if isinstance(metrics[0], str):\n        return metrics, [{} for _ in metrics]\n\n    metric_names = []\n    metric_params = []\n    for metric in metrics:\n        metric_names.append(metric[\"name\"])\n        metric_params.append(deepcopy(metric))\n        metric_params[-1].pop(\"name\")\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        if all(isinstance(metric, str) for metric in metrics):\n            return metrics, [{} for _ in metrics]\n        elif all(isinstance(metric, dict) for metric in metrics):\n            return [metric.pop(\"name\") for metric in metrics], metrics\n        else:\n            raise ValueError(\"Invalid input format. Metrics must be either a list of strings or a list of dictionaries.\")\n    else:\n        raise TypeError(\"Invalid input type. Metrics must be a list.\")\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, str):\n        metrics = [metrics]\n    if isinstance(metrics, dict):\n        metrics = [metrics]\n    metric_names = []\n    metric_params = []\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric[\"name\"])\n            metric_params.append(metric)\n        else:\n            raise ValueError(\"Invalid metric format\")\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if len(metrics) == 0:\n        raise ValueError(\"No metrics provided.\")\n\n    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric[\"name\"])\n            metric_params.append(metric.get(\"params\", {}))\n        else:\n            raise ValueError(\n                f\"Invalid metric format: {metric}. Metrics must be strings or dictionaries.\"\n            )\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if len(metrics) == 0:\n        return [], []\n\n    if isinstance(metrics[0], str):\n        return metrics, [{} for _ in metrics]\n\n    metric_names = []\n    metric_params = []\n    for metric in metrics:\n        metric_names.append(metric[\"name\"])\n        metric_params.append(metric[\"params\"])\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Initialize empty lists to store metric names and parameters\n    metric_names = []\n    metric_params = []\n\n    # Iterate over the input list of metrics\n    for metric in metrics:\n        if isinstance(metric, str):\n            # If the metric is a string, it is assumed to be a metric name\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            # If the metric is a dictionary, it is assumed to contain metric details\n            metric_name = metric.pop(\"name\")\n            metric_names.append(metric_name)\n            metric_params.append(metric)\n        else:\n            # Raise an error if the metric is not a string or dictionary\n            raise ValueError(f\"Invalid metric type: {type(metric)}\")\n\n    # Return the list of metric names and parameters as a tuple\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Initialize variables\n    metric_names = []\n    metric_params = []\n\n    # Process the input metrics\n    for metric in metrics:\n        if isinstance(metric, str):\n            # If the metric is a string, add it to the list of metric names\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            # If the metric is a dictionary, extract the metric name and parameters\n            metric_name = list(metric.keys())[0]\n            metric_params.append(metric[metric_name])\n            metric_names.append(metric_name)\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Initialize lists to store metric names and parameters\n    metric_names = []\n    metric_params = []\n\n    # Iterate over the input metrics\n    for metric in metrics:\n        # If the metric is a string, it represents a simple metric name\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        # If the metric is a dictionary, it represents a complex metric with parameters\n        elif isinstance(metric, dict):\n            # Extract the metric name and parameters from the dictionary\n            metric_name = list(metric.keys())[0]\n            metric_param = metric[metric_name]\n            metric_names.append(metric_name)\n            metric_params.append(metric_param)\n        else:\n            raise ValueError(f\"Invalid metric format: {metric}\")\n\n    # Return the extracted metric names and parameters\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, str):\n        metrics = [metrics]\n\n    metric_names = []\n    metric_params = []\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric[\"name\"])\n            metric_params.append(deepcopy(metric))\n            metric_params[-1].pop(\"name\")\n        else:\n            raise ValueError(\"Invalid metric format\")\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if not isinstance(metrics, list):\n        raise TypeError(\n            f\"Expected a list of metrics, but got {type(metrics)}. Please provide a list of metrics.\"\n        )\n\n    if len(metrics) == 0:\n        raise ValueError(\"The list of metrics is empty. Please provide at least one metric.\")\n\n    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            if \"name\" in metric:\n                metric_names.append(metric[\"name\"])\n                metric_params.append(metric.copy())\n                metric_params[-1].pop(\"name\")\n            else:\n                raise ValueError(\n                    \"The metric dictionary does not contain a 'name' key. Please provide a metric name.\"\n                )\n        else:\n            raise TypeError(\n                f\"The metric {metric} is not a string or dictionary. Please provide a valid metric.\"\n            )\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names: List[str] = []\n    metric_params: List[Dict[str, Any]] = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric[\"name\"])\n            metric_params.append(metric.get(\"params\", {}))\n        else:\n            raise ValueError(f\"Invalid metric type: {type(metric)}\")\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Initialize empty lists for metric names and parameters\n    metric_names = []\n    metric_params = []\n\n    # Iterate over the input list of metrics\n    for metric in metrics:\n        # If the metric is a string, it represents a metric name\n        if isinstance(metric, str):\n            # Append the metric name to the list of names\n            metric_names.append(metric)\n            # Append an empty dictionary as placeholder for metric parameters\n            metric_params.append({})\n        # If the metric is a dictionary, it contains metric details\n        elif isinstance(metric, dict):\n            # Extract the metric name from the dictionary\n            metric_name = metric.pop(\"name\")\n            # Append the metric name to the list of names\n            metric_names.append(metric_name)\n            # Append the dictionary containing metric parameters to the list of parameters\n            metric_params.append(metric)\n\n    # Return the list of metric names and the list of dictionaries containing metric parameters\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Initialize empty lists to store metric names and parameters\n    metric_names = []\n    metric_params = []\n\n    # Iterate over each metric in the input list\n    for metric in metrics:\n        if isinstance(metric, str):\n            # If the metric is a string, it represents a metric name\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            # If the metric is a dictionary, it contains metric details\n            metric_names.append(metric[\"name\"])\n            metric_params.append(metric)\n        else:\n            raise ValueError(\"Invalid metric format. Metrics should be either strings or dictionaries.\")\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    metric_names = []\n    metric_params = []\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            metric_names.append(metric[\"name\"])\n            metric_params.append(metric.get(\"params\", {}))\n        else:\n            raise ValueError(\n                f\"Invalid metric format: {metric}. Metrics must be strings or dictionaries with 'name' and optional 'params' keys.\"\n            )\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, list):\n        metric_names = []\n        metric_params = []\n        for metric in metrics:\n            if isinstance(metric, str):\n                metric_names.append(metric)\n                metric_params.append({})\n            elif isinstance(metric, dict):\n                metric_names.append(metric[\"name\"])\n                metric_params.append(metric)\n            else:\n                raise ValueError(\n                    \"Invalid metric format. Metrics must be either strings or dictionaries.\"\n                )\n        return metric_names, metric_params\n    else:\n        raise ValueError(\n            \"Invalid input format. Metrics must be a list of strings or dictionaries.\"\n        )\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Check if the input is a list of strings or dictionaries\n    if isinstance(metrics, list):\n        if all(isinstance(metric, str) for metric in metrics):\n            # If all elements are strings, return a list of metric names and an empty list for metric parameters\n            return metrics, []\n        elif all(isinstance(metric, dict) for metric in metrics):\n            # If all elements are dictionaries, extract metric names and parameters\n            metric_names = []\n            metric_params = []\n            for metric in metrics:\n                metric_names.append(metric[\"metric_name\"])\n                metric_params.append(metric)\n            return metric_names, metric_params\n        else:\n            raise ValueError(\"Invalid input format. Metrics should be either a list of strings or a list of dictionaries.\")\n    else:\n        raise ValueError(\"Invalid input format. Metrics should be a list.\")\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Initialize lists to store metric names and parameters\n    metric_names = []\n    metric_params = []\n\n    # Iterate over the input metrics\n    for metric in metrics:\n        if isinstance(metric, str):\n            # If the metric is a string, it represents a single metric name\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            # If the metric is a dictionary, it contains a metric name and parameters\n            metric_name = metric.pop(\"name\")\n            metric_names.append(metric_name)\n            metric_params.append(metric)\n        else:\n            raise ValueError(\n                \"Invalid metric format. Metric must be either a string or a dictionary.\"\n            )\n\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    # Initialize empty lists to store metric names and parameters\n    metric_names = []\n    metric_params = []\n\n    # Iterate over the list of metrics\n    for metric in metrics:\n        if isinstance(metric, str):\n            # If the metric is a string, it represents a metric name\n            metric_names.append(metric)\n            metric_params.append({})\n        elif isinstance(metric, dict):\n            # If the metric is a dictionary, it contains a metric name and parameters\n            metric_names.append(metric[\"name\"])\n            metric_params.append(deepcopy(metric))\n            metric_params[-1].pop(\"name\")\n        else:\n            # If the metric is neither a string nor a dictionary, raise a ValueError\n            raise ValueError(\n                \"Metric must be either a string or a dictionary with a 'name' key.\"\n            )\n\n    # Return the list of metric names and list of dictionaries with metric parameters\n    return metric_names, metric_params\n\n"}
{"namespace": "autorag.evaluate.util.cast_metrics", "completion": "    if isinstance(metrics, str):\n        metrics = [metrics]\n\n    if isinstance(metrics[0], str):\n        metrics_names = deepcopy(metrics)\n        metrics_params = [{} for _ in range(len(metrics))]\n    elif isinstance(metrics[0], dict):\n        metrics_names = []\n        metrics_params = []\n        for metric in metrics:\n            if \"name\" not in metric:\n                raise ValueError(\"Metric dictionary must contain a 'name' key.\")\n            metrics_names.append(metric[\"name\"])\n            metrics_params.append(deepcopy(metric))\n    else:\n        raise ValueError(\"Metrics must be provided as a list of strings or dictionaries.\")\n\n    return metrics_names, metrics_params\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Define a dictionary that maps functions to their inverses\n  fn_inv_dict = {\n      contract: inv_contract,\n      contract3_isoscale: lambda x: x / contract3_isoscale(x),\n  }\n\n  # If fn_inv is not provided, try to automatically determine the inverse\n  if fn_inv is None:\n    if fn not in fn_inv_dict:\n      raise ValueError(f'Cannot automatically determine inverse of {fn}.')\n    fn_inv = fn_inv_dict[fn]\n\n  # Define the forward mapping from metric to normalized distances\n  def t_to_s(t):\n    t_clipped = jnp.clip(t, t_near, t_far)\n    s_clipped = fn(t_clipped)\n    return s_clipped / fn(t_far)\n\n  # Define the backward mapping from normalized to metric distances\n  def s_to_t(s):\n    return fn_inv(s * fn(t_far))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        contract: inv_contract,\n        contract3_isoscale: lambda x: inv_contract(x) / contract3_isoscale(x),\n    }[fn]\n\n  def t_to_s(t):\n    t_clipped = jnp.clip(t, t_near, t_far)\n    t_scaled = (t_clipped - t_near) / (t_far - t_near)\n    s_unclipped = fn(t_scaled)\n    return jnp.clip(s_unclipped, 0, 1)\n\n  def s_to_t(s):\n    s_clipped = jnp.clip(s, 0, 1)\n    t_scaled = fn_inv(s_clipped)\n    t_unscaled = t_near + t_scaled * (t_far - t_near)\n    return jnp.clip(t_unscaled, t_near, t_far)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        contract: inv_contract,\n        contract3_isoscale: lambda x: inv_contract(x)\n    }.get(fn)\n\n  if fn_inv is None:\n    raise ValueError(f'fn_inv is not provided and cannot be inferred for {fn}.')\n\n  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n    \"\"\"\n    t_clipped = jnp.clip(t, t_near, t_far)\n    t_scaled = (t_clipped - t_near) / (t_far - t_near)\n    return fn(t_scaled)\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] to metric distances.\n    \"\"\"\n    t_scaled = fn_inv(s)\n    t = t_near + t_scaled * (t_far - t_near)\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    # TODO(jiawen): Automatically determine fn_inv.\n    raise NotImplementedError('fn_inv must be provided.')\n\n  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in [0, 1].\"\"\"\n    # Clamp t to [t_near, t_far] to avoid numerical issues at t_near and t_far.\n    t = jnp.clip(t, t_near, t_far)\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return s\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances in [0, 1] to metric distances.\"\"\"\n    t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n    # Clamp t to [t_near, t_far] to avoid numerical issues at t_near and t_far.\n    t = jnp.clip(t, t_near, t_far)\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract:\n      fn_inv = inv_contract\n    elif fn == contract3_isoscale:\n      fn_inv = lambda x: 1 / (1 + 2 / (3 * x))\n    else:\n      raise ValueError(f'Unknown fn_inv for {fn}')\n\n  def t_to_s(t):\n    \"\"\"Maps distances `t` to normalized distances `s`.\"\"\"\n    t_clipped = jnp.clip(t, t_near, t_far)\n    t_scaled = (t_clipped - t_near) / (t_far - t_near)\n    s_unclipped = fn(t_scaled)\n    return jnp.clip(s_unclipped, 0, 1)\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances `s` to distances `t`.\"\"\"\n    s_clipped = jnp.clip(s, 0, 1)\n    s_scaled = fn_inv(s_clipped)\n    t_unclipped = t_near + (t_far - t_near) * s_scaled\n    return jnp.clip(t_unclipped, t_near, t_far)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Define a dictionary that maps functions to their inverses.\n  fn_inv_dict = {\n      contract: inv_contract,\n      contract3_isoscale: lambda x: x / contract3_isoscale(x),\n  }\n\n  # If `fn_inv` is not provided, try to look it up in the dictionary.\n  if fn_inv is None:\n    if fn not in fn_inv_dict:\n      raise ValueError(f'fn_inv must be provided for {fn}')\n    fn_inv = fn_inv_dict[fn]\n\n  # Define a function that maps metric distances to normalized distances.\n  def t_to_s(t):\n    t = jnp.clip(t, t_near, t_far)\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return s\n\n  # Define a function that maps normalized distances back to metric distances.\n  def s_to_t(s):\n    t = fn_inv(fn(t_near) + (fn(t_far) - fn(t_near)) * s)\n    return t\n\n  # Return the tuple of functions.\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Define a dictionary mapping functions to their inverses.\n  inverse_map = {\n      jnp.tanh: jnp.arctanh,\n      jnp.exp: jnp.log,\n      jnp.log: jnp.exp,\n      jnp.sin: jnp.arcsin,\n      jnp.cos: jnp.arccos,\n      jnp.arcsin: jnp.sin,\n      jnp.arccos: jnp.cos,\n      jnp.arctanh: jnp.tanh,\n      jnp.square: jnp.sqrt,\n      jnp.sqrt: jnp.square,\n      jnp.cbrt: jnp.power,\n      jnp.power: jnp.cbrt,\n      jnp.sinh: jnp.arcsinh,\n      jnp.cosh: jnp.arccosh,\n      jnp.arcsinh: jnp.sinh,\n      jnp.arccosh: jnp.cosh,\n      jnp.tan: jnp.arctan,\n      jnp.arctan: jnp.tan,\n  }\n\n  # If `fn_inv` is not provided, try to automatically determine the inverse from the `inverse_map`.\n  if fn_inv is None:\n    if fn not in inverse_map:\n      raise ValueError(f'Cannot automatically determine inverse of {fn}.')\n    fn_inv = inverse_map[fn]\n\n  # Define the forward mapping from metric to normalized distances.\n  def t_to_s(t):\n    t = jnp.clip(t, t_near, t_far)\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return jnp.clip(s, 0, 1)\n\n  # Define the backward mapping from normalized to metric distances.\n  def s_to_t(s):\n    s = jnp.clip(s, 0, 1)\n    t = fn_inv(s * (fn(t_"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"\n    Maps metric distances to normalized distances in the range [0, 1].\n\n    :param t: Tensor. Represents the metric distances to be mapped.\n    :return: Tensor. The normalized distances corresponding to the input metric distances.\n    \"\"\"\n    t_clip = jnp.clip(t, t_near, t_far)\n    t_clip_fn = fn(t_clip)\n    return (t_clip_fn - t_near) / (t_far - t_near)\n\n  def s_to_t(s):\n    \"\"\"\n    Maps normalized distances in the range [0, 1] to metric distances.\n\n    :param s: Tensor. Represents the normalized distances to be mapped.\n    :return: Tensor. The metric distances corresponding to the input normalized distances.\n    \"\"\"\n    s_clip = jnp.clip(s, 0, 1)\n    s_clip_fn_inv = fn_inv(s_clip * (t_far - t_near) + t_near)\n    return jnp.clip(s_clip_fn_inv, t_near, t_far)\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        contract: inv_contract,\n        contract3_isoscale: lambda x: x / contract3_isoscale(x),\n    }.get(fn)\n    if fn_inv is None:\n      raise ValueError('fn_inv must be provided for fn={fn}')\n\n  def t_to_s(t):\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Define a dictionary that maps functions to their inverses\n  inverse_fn_dict = {\n      jnp.tanh: jnp.arctanh,\n      jnp.tanh: jnp.arctanh,\n      jnp.exp: jnp.log,\n      jnp.log: jnp.exp,\n      jnp.expm1: jnp.log1p,\n      jnp.log1p: jnp.expm1,\n      jnp.cos: jnp.arccos,\n      jnp.arccos: jnp.cos,\n      jnp.sin: jnp.arcsin,\n      jnp.arcsin: jnp.sin,\n      jnp.sqrt: jnp.square,\n      jnp.square: jnp.sqrt,\n      jnp.cbrt: jnp.power(3),\n      jnp.power(3): jnp.cbrt,\n      jnp.reciprocal: jnp.reciprocal,\n      jnp.reciprocal: jnp.reciprocal,\n      jnp.abs: jnp.abs,\n      jnp.abs: jnp.abs,\n      jnp.sign: jnp.sign,\n      jnp.sign: jnp.sign,\n      jnp.negative: jnp.negative,\n      jnp.negative: jnp.negative,\n      jnp.floor: jnp.ceil,\n      jnp.ceil: jnp.floor,\n      jnp.rint: jnp.round,\n      jnp.round: jnp.rint,\n      jnp.trunc: jnp.ceil,\n      jnp.ceil: jnp.trunc,\n      jnp.fix: jnp.fix,\n      jnp.fix: jnp.fix,\n      jnp.ceil: jnp.ceil,\n      jnp.ceil: jnp.ceil,\n      jnp.floor: jnp.floor,\n      jnp.floor: jnp.floor,\n      jnp.rint: jnp.rint,\n      jnp.rint:"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    # Use a predefined mapping of functions to their inverses.\n    fn_inv_dict = {\n        contract: inv_contract,\n        contract3_isoscale: lambda x: x / contract3_isoscale(x),\n        lambda x: jnp.exp(x),\n        lambda x: jnp.log(x),\n    }\n    fn_inv = fn_inv_dict.get(fn)\n    if fn_inv is None:\n      raise ValueError(\n          f'fn_inv must be provided for fn={fn}, which is not in fn_inv_dict.'\n      )\n\n  # Construct the forward mapping from metric to normalized distances.\n  def t_to_s(t):\n    t_clipped = jnp.clip(t, t_near, t_far)\n    s = (fn(t_clipped) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return s\n\n  # Construct the backward mapping from normalized to metric distances.\n  def s_to_t(s):\n    t = fn_inv((fn(t_far) - fn(t_near)) * s + fn(t_near))\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  def t_to_s(t):\n    \"\"\"Maps distances `t` in [t_near, t_far] to normalized distances in [0, 1].\"\"\"\n    # Clamp `t` to the nearest bound when it's outside the valid range.\n    t = jnp.clip(t, t_near, t_far)\n    # Normalize `t` to [0, 1].\n    t_norm = (t - t_near) / (t_far - t_near)\n    # Apply the function `fn`.\n    s_norm = fn(t_norm)\n    # Scale the normalized distances to ensure they're in [0, 1].\n    s = s_norm * t_far\n    return s\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances `s` in [0, t_far] to metric distances in [t_near, t_far].\"\"\"\n    # Clamp `s` to the nearest bound when it's outside the valid range.\n    s = jnp.clip(s, 0, t_far)\n    # Normalize `s` to [0, 1].\n    s_norm = s / t_far\n    # Apply the inverse of the function `fn`.\n    if fn_inv is None:\n      t_norm = {\n          contract: inv_contract,\n          contract3_isoscale: lambda x: inv_contract(x * contract3_isoscale(1.0)),\n      }[fn](s_norm)\n    else:\n      t_norm = fn_inv(s_norm)\n    # Scale the normalized distances back to metric space.\n    t = t_norm * (t_far - t_near) + t_near\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Define a mapping of functions to their inverses\n  fn_inv_map = {\n      contract: inv_contract,\n      jnp.tanh: jax.nn.atanh,\n      jnp.sin: jnp.arcsin,\n      jnp.exp: jnp.log,\n      jnp.log: jnp.exp,\n      jnp.cbrt: lambda x: x**3,\n  }\n\n  # If fn_inv is not provided, try to find it in the fn_inv_map\n  if fn_inv is None:\n    if fn not in fn_inv_map:\n      raise ValueError(\n          f'fn_inv is not provided and {fn} is not in the predefined mapping.'\n      )\n    fn_inv = fn_inv_map[fn]\n\n  # Define the forward and backward mapping functions\n  def t_to_s(t):\n    return (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n\n  def s_to_t(s):\n    return fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        contract: inv_contract,\n        contract3_isoscale: lambda s: contract(s),\n    }[fn]\n\n  def t_to_s(t):\n    \"\"\"Maps distances `t` in [t_near, t_far] to normalized distances in [0, 1].\"\"\"\n    # Clamp `t` to the nearest bound when it's outside the valid range.\n    t = jnp.clip(t, t_near, t_far)\n    # Normalize `t` to [0, 1].\n    t_normalized = (t - t_near) / (t_far - t_near)\n    # Apply the forward function.\n    s_normalized = fn(t_normalized)\n    return s_normalized\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances `s` in [0, 1] to metric distances in [t_near, t_far].\"\"\"\n    # Apply the inverse function.\n    t_normalized = fn_inv(s)\n    # Denormalize `t` from [0, 1].\n    t = t_normalized * (t_far - t_near) + t_near\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        contract: inv_contract,\n        contract3_isoscale: lambda x: inv_contract(x)\n    }[fn]\n\n  def t_to_s(t):\n    \"\"\"Maps distances `t` in [`t_near`, `t_far`] to distances `s` in [0, 1].\"\"\"\n    # Clamp `t` to the nearest bound when it's outside the valid range.\n    t = jnp.clip(t, t_near, t_far)\n    # Normalize `t` to [0, 1] range by inverting the `fn` function.\n    s = fn_inv((t - t_near) / (t_far - t_near))\n    # Finally, renormalize so that the values cover the range [0, 1].\n    s = jnp.clip(s * (t_far - t_near), 0, 1)\n    return s\n\n  def s_to_t(s):\n    \"\"\"Maps distances `s` in [0, 1] to distances `t` in [`t_near`, `t_far`].\"\"\"\n    # First, undo the final renormalization of `s`.\n    s = s / (t_far - t_near)\n    # Now apply the `fn` function to map `s` to distances `t` in metric space.\n    t = fn(s) * (t_far - t_near) + t_near\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Define a dictionary that maps functions to their inverses\n  fn_inv_dict = {\n      contract: inv_contract,\n      contract3_isoscale: lambda x: 1 / contract3_isoscale(x),\n      jnp.exp: jnp.log,\n      jnp.log: jnp.exp,\n      jnp.reciprocal: lambda x: 1 / x,\n  }\n\n  # If `fn_inv` is not provided, try to find it in the `fn_inv_dict`\n  if fn_inv is None:\n    fn_inv = fn_inv_dict.get(fn)\n    if fn_inv is None:\n      raise ValueError(f'Unknown inverse of {fn}.')\n\n  # Define the forward and backward mappings\n  def t_to_s(t):\n    return fn(t) / fn(t_far)\n\n  def s_to_t(s):\n    return fn_inv(s * fn(t_far))\n\n  # Clip the input distances to the valid range\n  t_near = jnp.broadcast_to(t_near, t_far.shape)\n  t_far = jnp.broadcast_to(t_far, t_near.shape)\n\n  # Return the forward and backward mappings\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Define a dictionary that maps functions to their inverses\n  fn_inv_dict = {\n      contract: inv_contract,\n      contract3_isoscale: lambda x: 1 / (contract3_isoscale(x) + 1e-8),\n      jnp.tanh: jnp.arctanh,\n      jnp.sin: jnp.arcsin,\n      jnp.cos: jnp.arccos,\n      jnp.exp: jnp.log,\n      jnp.log: jnp.exp,\n  }\n\n  # If fn_inv is not provided, try to automatically determine the inverse from fn_inv_dict\n  if fn_inv is None:\n    if fn not in fn_inv_dict:\n      raise ValueError(f'fn_inv must be provided for fn={fn}')\n    else:\n      fn_inv = fn_inv_dict[fn]\n\n  # Define a function that maps metric distances to normalized distances\n  def t_to_s(t):\n    t = jnp.clip(t, t_near, t_far)\n    s = (fn(t) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return jnp.clip(s, 0.0, 1.0)\n\n  # Define a function that maps normalized distances to metric distances\n  def s_to_t(s):\n    s = jnp.clip(s, 0.0, 1.0)\n    t = fn_inv((fn(t_far) - fn(t_near)) * s + fn(t_near))\n    return jnp.clip(t, t_near, t_far)\n\n  # Return the pair of functions\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    fn_inv = {\n        contract: inv_contract,\n        contract3_isoscale: lambda x: inv_contract(x) * 2,\n    }.get(fn)\n    if fn_inv is None:\n      raise ValueError(f'fn_inv not provided and {fn} is not known to be invertible.')\n\n  # Construct the forward and backward mappings.\n  def t_to_s(t):\n    # Map distances to normalized distances in [0, 1]\n    t_clipped = jnp.clip(t, t_near, t_far)\n    s = (fn(t_clipped) - fn(t_near)) / (fn(t_far) - fn(t_near))\n    return s\n\n  def s_to_t(s):\n    # Map normalized distances in [0, 1] back to distances.\n    t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  # Define a dictionary mapping functions to their inverses\n  fn_inv_dict = {\n      contract: inv_contract,\n      contract3_isoscale: lambda s: inv_contract(s) / 2,\n  }\n\n  # If `fn_inv` is not provided, try to automatically determine it based on the `fn_inv_dict`\n  if fn_inv is None:\n    fn_inv = fn_inv_dict.get(fn)\n    if fn_inv is None:\n      raise ValueError(f'fn_inv not provided and no inverse found for {fn}.')\n\n  # Define the forward and backward mapping functions\n  def t_to_s(t):\n    # Clip the input distances to the valid range [t_near, t_far]\n    t_clipped = jnp.clip(t, t_near, t_far)\n    # Apply the forward mapping function `fn` to the clipped distances\n    s = fn(t_clipped)\n    # Normalize the distances to the range [0, 1]\n    s = (s - fn(t_near)) / (fn(t_far) - fn(t_near))\n    # Clip the normalized distances to the range [0, 1]\n    s = jnp.clip(s, 0, 1)\n    return s\n\n  def s_to_t(s):\n    # Apply the inverse mapping function `fn_inv` to the normalized distances\n    t = fn_inv(s * (fn(t_far) - fn(t_near)) + fn(t_near))\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "coord.construct_ray_warps", "completion": "  if fn_inv is None:\n    if fn == contract:\n      fn_inv = inv_contract\n    elif fn == contract3_isoscale:\n      fn_inv = lambda x: inv_contract(x)\n    else:\n      raise ValueError(\n          f'fn_inv is None, but no known inverse for {fn}.'\n      )\n\n  def t_to_s(t):\n    \"\"\"Maps metric distances to normalized distances in the range [0, 1].\"\"\"\n    # Clamp to the near and far planes.\n    t = jnp.clip(t, t_near, t_far)\n    # Compute the distance from the near plane.\n    t_rel = t - t_near\n    # Compute the normalized distance using the function fn.\n    s = fn(t_rel)\n    # Clamp to the range [0, 1].\n    s = jnp.clip(s, 0, 1)\n    return s\n\n  def s_to_t(s):\n    \"\"\"Maps normalized distances in the range [0, 1] to metric distances.\"\"\"\n    # Clamp to the range [0, 1].\n    s = jnp.clip(s, 0, 1)\n    # Compute the metric distance using the inverse of the function fn.\n    t_rel = fn_inv(s)\n    # Compute the distance from the near plane.\n    t = t_rel + t_near\n    return t\n\n  return t_to_s, s_to_t\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)\n\n"}
{"namespace": "geometry.spherical_to_cartesian", "completion": "  x = r * jnp.sin(theta) * jnp.cos(phi)\n  y = r * jnp.sin(theta) * jnp.sin(phi)\n  z = r * jnp.cos(theta)\n  return jnp.stack([x, y, z], axis=-1)  # pytype: disable=bad-return-type  # jax-ndarray\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, x=t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, x=t, axis=-1)"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "linspline.integrate", "completion": "  utils.assert_valid_linspline(t, w)\n  return jnp.trapz(w, t)\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    id_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([id_df, score_df], axis=1)\n\n    def cc_pure_apply(row):\n        ids_tuple = tuple(row[[f'id_{i}' for i in range(len(ids))]].values)\n        scores_tuple = tuple(row[[f'score_{i}' for i in range(len(scores))]].values)\n        return pd.Series(cc_pure(ids_tuple, scores_tuple, weights, top_k))\n\n    df[['cc_id', 'cc_score']] = df.apply(cc_pure_apply, axis=1)\n    return df['cc_id'].tolist(), df['cc_score'].tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    id_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([id_df, score_df], axis=1)\n\n    def cc_pure_apply(row):\n        ids_tuple = tuple(row[[f'id_{i}' for i in range(len(ids))]].values)\n        scores_tuple = tuple(row[[f'score_{i}' for i in range(len(scores))]].values)\n        return pd.Series(cc_pure(ids_tuple, scores_tuple, weights, top_k))\n\n    df[['cc_id', 'cc_score']] = df.apply(cc_pure_apply, axis=1)\n    return df['cc_id'].tolist(), df['cc_score'].tolist()\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    id_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([id_df, score_df], axis=1)\n\n    def cc_pure_apply(row):\n        ids_tuple = tuple(row[[f'id_{i}' for i in range(len(ids))]].values)\n        scores_tuple = tuple(row[[f'score_{i}' for i in range(len(scores))]].values)\n        return pd.Series(cc_pure(ids_tuple, scores_tuple, weights, top_k))\n\n    df[['cc_id', 'cc_score']] = df.apply(cc_pure_apply, axis=1)\n    return df['cc_id'].tolist(), df['cc_score'].tolist()\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    id_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([id_df, score_df], axis=1)\n\n    def cc_pure_apply(row):\n        ids_tuple = tuple(row[[f'id_{i}' for i in range(len(ids))]].values)\n        scores_tuple = tuple(row[[f'score_{i}' for i in range(len(scores))]].values)\n        return pd.Series(cc_pure(ids_tuple, scores_tuple, weights, top_k))\n\n    df[['cc_id', 'cc_score']] = df.apply(cc_pure_apply, axis=1)\n    return df['cc_id'].tolist(), df['cc_score'].tolist()\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    id_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([id_df, score_df], axis=1)\n\n    def cc_pure_apply(row):\n        ids_tuple = tuple(row[[f'id_{i}' for i in range(len(ids))]].values)\n        scores_tuple = tuple(row[[f'score_{i}' for i in range(len(scores))]].values)\n        return pd.Series(cc_pure(ids_tuple, scores_tuple, weights, top_k))\n\n    df[['cc_id', 'cc_score']] = df.apply(cc_pure_apply, axis=1)\n    return df['cc_id'].tolist(), df['cc_score'].tolist()\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    id_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([id_df, score_df], axis=1)\n\n    def cc_pure_apply(row):\n        ids_tuple = tuple(row[[f'id_{i}' for i in range(len(ids))]].values)\n        scores_tuple = tuple(row[[f'score_{i}' for i in range(len(scores))]].values)\n        return pd.Series(cc_pure(ids_tuple, scores_tuple, weights, top_k))\n\n    df[['cc_id', 'cc_score']] = df.apply(cc_pure_apply, axis=1)\n    return df['cc_id'].tolist(), df['cc_score'].tolist()\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    id_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([id_df, score_df], axis=1)\n\n    def cc_pure_apply(row):\n        ids_tuple = tuple(row[[f'id_{i}' for i in range(len(ids))]].values)\n        scores_tuple = tuple(row[[f'score_{i}' for i in range(len(scores))]].values)\n        return pd.Series(cc_pure(ids_tuple, scores_tuple, weights, top_k))\n\n    df[['cc_id', 'cc_score']] = df.apply(cc_pure_apply, axis=1)\n    return df['cc_id'].tolist(), df['cc_score'].tolist()\n\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    id_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([id_df, score_df], axis=1)\n\n    def cc_pure_apply(row):\n        ids_tuple = tuple(row[[f'id_{i}' for i in range(len(ids))]].values)\n        scores_tuple = tuple(row[[f'score_{i}' for i in range(len(scores))]].values)\n        return pd.Series(cc_pure(ids_tuple, scores_tuple, weights, top_k))\n\n    df[['cc_id', 'cc_score']] = df.apply(cc_pure_apply, axis=1)\n    return df['cc_id'].tolist(), df['cc_score'].tolist()\n"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Create a DataFrame with the IDs and scores for each category or group\n    id_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([id_df, score_df], axis=1)\n\n    # Calculate the weighted sum of scores for each ID\n    df['weighted_sum'] = df[[f'score_{i}' for i in range(len(scores))]].multiply(weights, axis=1).sum(axis=1)\n\n    # Normalize the weighted sum of scores\n    df['normalized_score'] = df['weighted_sum'] / df['weighted_sum'].sum()\n\n    # Sort the DataFrame by the normalized scores in descending order\n    df = df.sort_values(by='normalized_score', ascending=False)\n\n    # Return the top K IDs and their corresponding scores\n    return df['id'].head(top_k).tolist(), df['normalized_score'].head(top_k).tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Create a dictionary to store the weighted sum of scores for each ID\n    weighted_sums = {}\n\n    # Iterate through each ID and score in each category or group\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            # If the ID is not in the dictionary, add it with its weighted score\n            if ids[i][j] not in weighted_sums:\n                weighted_sums[ids[i][j]] = scores[i][j] * weights[i]\n            # If the ID is already in the dictionary, add its weighted score to the existing sum\n            else:\n                weighted_sums[ids[i][j]] += scores[i][j] * weights[i]\n\n    # Sort the IDs based on their weighted sum in descending order\n    sorted_ids = sorted(weighted_sums.items(), key=lambda x: x[1], reverse=True)\n\n    # Return the top K IDs and their corresponding scores\n    return [x[0] for x in sorted_ids[:top_k]], [x[1] for x in sorted_ids[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = {}\n    for i, (id_list, score_list) in enumerate(zip(ids, scores)):\n        for j, id_ in enumerate(id_list):\n            if id_ not in weighted_sums:\n                weighted_sums[id_] = 0\n            weighted_sums[id_] += score_list[j] * weights[i]\n\n    # Sort the IDs by their weighted sum in descending order\n    sorted_ids = sorted(weighted_sums.keys(), key=lambda x: weighted_sums[x], reverse=True)\n\n    # Return the top K IDs and their corresponding scores\n    return sorted_ids[:top_k], [weighted_sums[id_] for id_ in sorted_ids[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Create a dictionary to store the weighted sum of scores for each ID\n    weighted_sum = {}\n\n    # Iterate over each category or group\n    for i in range(len(ids)):\n        # Iterate over each ID in the current category or group\n        for j, id in enumerate(ids[i]):\n            # If the ID is not in the dictionary, add it with its weighted score\n            if id not in weighted_sum:\n                weighted_sum[id] = scores[i][j] * weights[i]\n            # If the ID is already in the dictionary, add its weighted score to the existing sum\n            else:\n                weighted_sum[id] += scores[i][j] * weights[i]\n\n    # Sort the dictionary by the weighted sum of scores in descending order\n    sorted_weighted_sum = sorted(weighted_sum.items(), key=lambda x: x[1], reverse=True)\n\n    # Get the top K IDs and their corresponding weighted sums\n    top_k_ids = [x[0] for x in sorted_weighted_sum[:top_k]]\n    top_k_scores = [x[1] for x in sorted_weighted_sum[:top_k]]\n\n    # Return the top K IDs and their corresponding weighted sums\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Convert the input data into a DataFrame\n    id_df = pd.DataFrame({f'id_{i}': id_list for i, id_list in enumerate(ids)})\n    score_df = pd.DataFrame({f'score_{i}': score_list for i, score_list in enumerate(scores)})\n    df = pd.concat([id_df, score_df], axis=1)\n\n    # Calculate the weighted sum of scores for each ID\n    df['weighted_sum'] = df[[f'score_{i}' for i in range(len(scores))]].dot(weights)\n\n    # Normalize the weighted sum of scores\n    df['normalized_weighted_sum'] = df['weighted_sum'] / df['weighted_sum'].max()\n\n    # Sort the DataFrame by the normalized weighted sum in descending order\n    df = df.sort_values('normalized_weighted_sum', ascending=False)\n\n    # Return the top K IDs and their corresponding scores\n    return df['id_0'].head(top_k).tolist(), df['normalized_weighted_sum'].head(top_k).tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Initialize a dictionary to store the weighted sum of scores for each ID\n    id_score_dict = {}\n\n    # Iterate through each category or group of IDs\n    for i in range(len(ids)):\n        # Iterate through each ID in the current category or group\n        for j in range(len(ids[i])):\n            # Get the current ID and its corresponding score\n            id = ids[i][j]\n            score = scores[i][j]\n\n            # If the ID is not in the dictionary, add it with its weighted score\n            if id not in id_score_dict:\n                id_score_dict[id] = score * weights[i]\n            # If the ID is already in the dictionary, add its weighted score to the existing value\n            else:\n                id_score_dict[id] += score * weights[i]\n\n    # Sort the dictionary by the weighted sum of scores in descending order\n    sorted_id_score_dict = dict(sorted(id_score_dict.items(), key=lambda item: item[1], reverse=True))\n\n    # Get the top K IDs and their corresponding scores\n    top_k_ids = list(sorted_id_score_dict.keys())[:top_k]\n    top_k_scores = list(sorted_id_score_dict.values())[:top_k]\n\n    return top_k_ids, top_k_scores"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Create a dictionary to store the weighted sum of scores for each ID\n    id_score_dict = {}\n\n    # Iterate over each ID in the first list of IDs\n    for i, id_list in enumerate(ids):\n        # Iterate over each ID in the current list of IDs\n        for j, id in enumerate(id_list):\n            # If the ID is not in the dictionary, add it with the weighted score\n            if id not in id_score_dict:\n                id_score_dict[id] = scores[i][j] * weights[i]\n            # If the ID is already in the dictionary, add the weighted score to the existing value\n            else:\n                id_score_dict[id] += scores[i][j] * weights[i]\n\n    # Sort the IDs by their weighted sum in descending order\n    sorted_ids = sorted(id_score_dict.keys(), key=lambda x: id_score_dict[x], reverse=True)\n\n    # Return the top K IDs and their corresponding weighted sums\n    return sorted_ids[:top_k], [id_score_dict[id] for id in sorted_ids[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Create a DataFrame from the input tuples\n    df = pd.DataFrame({\n        'id': [id for id_list in ids for id in id_list],\n        'score': [score for score_list in scores for score in score_list]\n    })\n\n    # Group the DataFrame by ID and calculate the weighted sum of scores\n    df = df.groupby('id').sum().reset_index()\n    df['weighted_score'] = df['score'] * weights[0]\n    for i in range(1, len(weights)):\n        df['weighted_score'] += df['score'] * weights[i]\n\n    # Normalize the weighted scores\n    df['normalized_score'] = df['weighted_score'] / df['weighted_score'].sum()\n\n    # Sort the DataFrame by the normalized scores in descending order\n    df = df.sort_values('normalized_score', ascending=False)\n\n    # Return the top K IDs and their corresponding scores\n    return df['id'].head(top_k).tolist(), df['normalized_score'].head(top_k).tolist()"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Initialize an empty dictionary to store the weighted sum of scores for each ID\n    id_to_score = {}\n\n    # Iterate over the IDs and scores for each category or group\n    for i in range(len(ids)):\n        # For each ID in the current category or group\n        for j, id in enumerate(ids[i]):\n            # If the ID is not in the dictionary yet, add it with a score of 0\n            if id not in id_to_score:\n                id_to_score[id] = 0\n            # Add the weighted score of the current ID to the total score for that ID\n            id_to_score[id] += scores[i][j] * weights[i]\n\n    # Normalize the scores by dividing them by the number of categories or groups\n    id_to_score = {id: score / len(ids) for id, score in id_to_score.items()}\n\n    # Sort the IDs by their weighted sum in descending order\n    sorted_ids = sorted(id_to_score.keys(), key=lambda x: id_to_score[x], reverse=True)\n\n    # Return the top K IDs and their corresponding scores\n    return sorted_ids[:top_k], [id_to_score[id] for id in sorted_ids[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check if the number of IDs and scores match\n    assert len(ids) == len(scores), \"The number of IDs and scores must match.\"\n\n    # Check if the number of IDs and weights match\n    assert len(ids) == len(weights), \"The number of IDs and weights must match.\"\n\n    # Check if the sum of weights is equal to 1\n    assert sum(weights) == 1, \"The sum of weights must be equal to 1.\"\n\n    # Check if top_k is a positive integer\n    assert top_k > 0, \"top_k must be a positive integer.\"\n\n    # Check if the number of IDs and scores in each category or group is the same\n    for i in range(len(ids)):\n        assert len(ids[i]) == len(scores[i]), f\"The number of IDs and scores in category {i} must match.\"\n\n    # Calculate the weighted sum of scores for each ID\n    weighted_sums = {}\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            if ids[i][j] not in weighted_sums:\n                weighted_sums[ids[i][j]] = scores[i][j] * weights[i]\n            else:\n                weighted_sums[ids[i][j]] += scores[i][j] * weights[i]\n\n    # Normalize the weighted sums\n    total_sum = sum(weighted_sums.values())\n    normalized_sums = {k: v / total_sum for k, v in weighted_sums.items()}\n\n    # Sort the IDs by their weighted sums in descending order\n    sorted_ids = sorted(normalized_sums.keys(), key=lambda x: normalized_sums[x], reverse=True)\n\n    # Return the top K IDs and their corresponding scores\n    return sorted_ids[:top_k], [normalized_sums[k] for k in sorted_ids[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Assertions to check the integrity of the input data\n    assert len(ids) == len(scores), \"The length of ids and scores must be the same.\"\n    assert len(ids) == len(weights), \"The length of weights must be the same as the length of ids.\"\n    assert len(ids) > 1, \"You must input more than one retrieval results.\"\n    assert top_k > 0, \"top_k must be greater than 0.\"\n    assert sum(weights) == 1, \"The sum of weights must be 1.\"\n\n    # Initialize a dictionary to store the weighted sum of scores for each ID\n    weighted_sum = {}\n\n    # Iterate through each category or group of IDs\n    for i in range(len(ids)):\n        # Iterate through each ID in the current category or group\n        for j in range(len(ids[i])):\n            # If the ID is not already in the dictionary, add it with its weighted score\n            if ids[i][j] not in weighted_sum:\n                weighted_sum[ids[i][j]] = scores[i][j] * weights[i]\n            # If the ID is already in the dictionary, update its weighted score\n            else:\n                weighted_sum[ids[i][j]] += scores[i][j] * weights[i]\n\n    # Sort the IDs based on their weighted sum in descending order\n    sorted_ids = sorted(weighted_sum, key=weighted_sum.get, reverse=True)\n\n    # Return the top K IDs and their corresponding weighted sums\n    return sorted_ids[:top_k], [weighted_sum[i] for i in sorted_ids[:top_k]]"}
{"namespace": "autorag.nodes.retrieval.hybrid_cc.cc_pure", "completion": "    # Check that the lengths of the input tuples are equal\n    assert len(ids) == len(scores) == len(weights), \"The lengths of the input tuples must be equal.\"\n\n    # Check that the weights sum to 1\n    assert sum(weights) == 1, \"The weights must sum to 1.\"\n\n    # Check that the top_k value is positive\n    assert top_k > 0, \"top_k must be positive.\"\n\n    # Initialize a dictionary to store the weighted sum of scores for each ID\n    weighted_sums = {}\n\n    # Iterate over the IDs, scores, and weights\n    for i in range(len(ids)):\n        for j in range(len(ids[i])):\n            # If the ID is not in the dictionary, add it with its weighted score\n            if ids[i][j] not in weighted_sums:\n                weighted_sums[ids[i][j]] = scores[i][j] * weights[i]\n            # If the ID is already in the dictionary, add the weighted score to the existing value\n            else:\n                weighted_sums[ids[i][j]] += scores[i][j] * weights[i]\n\n    # Sort the IDs by their weighted sum in descending order\n    sorted_ids = sorted(weighted_sums, key=weighted_sums.get, reverse=True)\n\n    # Return the top K IDs and their corresponding scores\n    return sorted_ids[:top_k], [weighted_sums[id] for id in sorted_ids[:top_k]]"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed means\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances\n  fn_cov = jnp.einsum('...ij,...jk,...kl->...il', jac, cov, jac)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  j = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed means by applying the function to the mean\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances using the Jacobian and the covariances\n  fn_cov = j @ cov @ j.T\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Apply the function to the mean and get the Jacobian matrix\n  fn_mean, jac = jax.vjp(fn, mean)\n\n  # Transform the covariances using the Jacobian matrix\n  fn_cov = jnp.matmul(jnp.matmul(jac, cov), jac.T)\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian matrix of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed means by applying the function to the mean\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances using the Jacobian matrix and the covariances\n  fn_cov = jnp.einsum(\"...ij,...jk,...kl->...il\", jac, cov, jac)\n\n  # Return the transformed means and covariances\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Get the Jacobian of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed means by applying the function to the mean\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances using the Jacobian and the original covariances\n  fn_cov = jnp.matmul(jac, cov) @ jac.T\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize fn around mean\n  fn_mean = fn(mean)\n  # Jacobian of fn at mean\n  jac = jax.jacfwd(fn)(mean)\n  # Covariance of fn(mean)\n  fn_cov = jnp.matmul(jac, cov, jac.T)\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  J = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed covariances using the linearized function and the Jacobian\n  fn_cov = J @ cov @ J.T\n\n  return fn_mean, fn_cov"}
{"namespace": "coord.track_linearize", "completion": "  mean_shape = mean.shape\n  cov_shape = cov.shape\n  mean = jnp.reshape(mean, [-1, mean_shape[-1]])\n  cov = jnp.reshape(cov, [-1, cov_shape[-2], cov_shape[-1]])\n  fn_mean = fn(mean)\n  j_fn = jax.vmap(jax.jacfwd(fn))(mean)\n  fn_cov = jnp.matmul(j_fn, cov)\n  fn_cov = jnp.matmul(cov, jnp.swapaxes(j_fn, -1, -2))\n  fn_mean = jnp.reshape(fn_mean, mean_shape)\n  fn_cov = jnp.reshape(fn_cov, cov_shape)\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Apply the function to the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed covariance\n  fn_cov = jnp.einsum('...ij,...jk,...kl->...il', jacobian, cov, jacobian)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n\n  # Apply the function to the mean\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances\n  fn_cov = jnp.einsum(\"...ij,...jk,...lk->...il\", jac, cov, jac)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed means\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances\n  fn_cov = jnp.einsum(\"...ij,...jk,...kl->...il\", jac, cov, jac)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed means\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances\n  fn_cov = jnp.einsum('...ij, ...jk, ...kl -> ...il', jacobian, cov, jacobian)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian matrix of the function at the mean point\n  j = jax.jacobian(fn)(mean)\n  # Compute the transformed means\n  fn_mean = fn(mean)\n  # Compute the transformed covariances\n  fn_cov = j @ cov @ j.T\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Calculate the Jacobian of the function\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Transform the covariances\n  fn_cov = jnp.matmul(jnp.matmul(jacobian, cov), jacobian.T)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Apply the function to the mean and get the Jacobian of the function at the mean\n  fn_mean, jac = jax.vjp(fn, mean)\n\n  # Transform the covariances using the Jacobian\n  fn_cov = jnp.matmul(jac[0], cov, jac[0].T)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed means\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances\n  fn_cov = jnp.einsum(\"...ij,...jk->...ik\", jacobian, cov)\n  fn_cov = jnp.einsum(\"...ij,...jk->...ik\", fn_cov, jacobian.T)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Linearize the function around the mean\n  fn_mean = fn(mean)\n\n  # Compute the Jacobian of the function at the mean\n  jacobian = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed covariances\n  fn_cov = jnp.matmul(jnp.matmul(jacobian, cov), jacobian.T)\n\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  mean_shape = mean.shape\n  cov_shape = cov.shape\n  fn_mean = fn(mean)\n  fn_jac = jax.jacfwd(fn)(mean)\n  fn_cov = jnp.matmul(fn_jac, cov)\n  fn_cov = jnp.matmul(cov, fn_jac.T)\n  fn_cov = fn_cov.reshape(mean_shape[:-1] + fn_cov.shape[-2:])\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Compute the Jacobian matrix of the function at the mean\n  jac = jax.jacfwd(fn)(mean)\n\n  # Compute the transformed means by applying the function to the mean\n  fn_mean = fn(mean)\n\n  # Compute the transformed covariances using the Jacobian matrix\n  fn_cov = jnp.matmul(jnp.matmul(jac, cov), jac.T)\n\n  # Return the transformed means and covariances\n  return fn_mean, fn_cov\n\n"}
{"namespace": "coord.track_linearize", "completion": "  # Apply the function to the mean and get the Jacobian of the function at the mean\n  fn_mean, fn_jac = jax.vjp(fn, mean)\n  # Calculate the transformed covariance matrix\n  fn_cov = jnp.matmul(fn_jac[0], cov)\n  fn_cov = jnp.matmul(cov, fn_jac[0].T) + fn_cov\n  return fn_mean, fn_cov\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if x[i].shape[0] > 1:\n            yield [x[i][: x[i].shape[0] // 2], x[i][x[i].shape[0] // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.shape[0] > 1:\n            yield [i[: i.shape[0] // 2], i[i.shape[0] // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for xn in x:\n        if xn.size > 1:\n            yield [xn[: xn.size // 2], xn[xn.size // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.size > 1:\n            yield np.split(i, 2)\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for a in x:\n        if a.size > 1:\n            yield [a[: a.size // 2], a[a.size // 2 :]]\n        else:\n            yield [a, np.array([])]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for xi in x:\n        if xi.size > 1:\n            yield [xi[: xi.size // 2], xi[xi.size // 2 :]]\n        else:\n            yield [xi, xi]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i, xi in enumerate(x):\n        if xi.shape[0] > 1:\n            x1, x2 = np.array_split(xi, 2)\n            yield [x1, x2]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if arr.size > 1:\n            yield [arr[: arr.size // 2], arr[arr.size // 2 :]]\n        else:\n            yield [arr, np.array([])]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for xi in x:\n        if xi.size > 1:\n            yield [xi[: xi.size // 2], xi[xi.size // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield [i[: len(i) // 2], i[len(i) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for arr in x:\n        if arr.size > 1:\n            yield [arr[: arr.size // 2], arr[arr.size // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.size > 1:\n            yield [i[: i.size // 2], i[i.size // 2 :]]\n        else:\n            yield [i, np.array([])]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if len(i) > 1:\n            yield [i[: len(i) // 2], i[len(i) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in range(len(x)):\n        if len(x[i]) > 1:\n            yield [x[i][: len(x[i]) // 2], x[i][len(x[i]) // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for xi in x:\n        if xi.size > 1:\n            yield [xi[: xi.size // 2], xi[xi.size // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i, xi in enumerate(x):\n        if xi.size > 1:\n            yield x[:i] + [xi[: xi.size // 2], xi[xi.size // 2 :]] + x[i + 1 :]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i, xi in enumerate(x):\n        if xi.shape[0] > 1:\n            yield x[:i] + [xi[: xi.shape[0] // 2], xi[xi.shape[0] // 2 :]] + x[i + 1 :]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.size > 1:\n            yield [i[: i.size // 2], i[i.size // 2 :]]\n        else:\n            yield [i, np.array([])]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for i in x:\n        if i.size > 1:\n            yield [i[: i.size // 2], i[i.size // 2 :]]\n\n"}
{"namespace": "skfolio.utils.tools.bisection", "completion": "    for xi in x:\n        if xi.size > 1:\n            yield [xi[: xi.size // 2], xi[xi.size // 2 :]]\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"`x` must be a 2d-array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"`x` must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"`x` must be a 2d-array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"`x` must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"`x` must be a 2d-array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"`x` must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The input array must be a 2D matrix.\")\n\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The input array must be a square matrix.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The matrix is not square\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The matrix must be a 2-dimensional array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be a square matrix.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The input array must be a matrix\")\n\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The input array must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The matrix must be a 2-dimensional array\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix is not square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The matrix must be a 2-dimensional array.\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square.\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be a square matrix\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2:\n        raise ValueError(\"The matrix must be 2-dimensional\")\n    if x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_square", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be a square matrix.\")\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x = jnp.sin(jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-1))\n  if append_identity:\n    x = jnp.concatenate([x, x[Ellipsis, :1]], axis=-1)\n  return x"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x = jnp.sin(jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-1))\n  if append_identity:\n    x = jnp.concatenate([x, x[Ellipsis, :1]], axis=-1)\n  return x"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x = jnp.sin(jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-1))\n  if append_identity:\n    x = jnp.concatenate([x, x[Ellipsis, :1]], axis=-1)\n  return x"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x = jnp.sin(jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-1))\n  if append_identity:\n    x = jnp.concatenate([x, x[Ellipsis, :1]], axis=-1)\n  return x"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x = jnp.concatenate([jnp.sin(x), jnp.cos(x)], axis=-1)\n  if append_identity:\n    x = jnp.concatenate([x, x[Ellipsis, :1]], axis=-1)\n  return x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x_scaled = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x_sin = jnp.sin(jnp.concatenate([x_scaled, x_scaled + 0.5 * jnp.pi], axis=-1))\n  if append_identity:\n    x_sin = jnp.concatenate([x_sin, x[Ellipsis, None]], axis=-1)\n  return x_sin"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x = jnp.concatenate(\n      [jnp.sin(x), jnp.cos(x)], axis=-1\n  )\n  if append_identity:\n    x = jnp.concatenate([x, x[Ellipsis, :1]], axis=-1)\n  return x"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x_scaled = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x_sin = jnp.sin(jnp.concatenate([x_scaled, x_scaled + 0.5 * jnp.pi], axis=-1))\n  if append_identity:\n    return jnp.concatenate([x_sin, x[Ellipsis, None] * jnp.ones_like(x_sin[Ellipsis, :1])], axis=-1)\n  else:\n    return x_sin\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x = jnp.sin(jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-1))\n  if append_identity:\n    return jnp.concatenate([x, x[Ellipsis, :1], jnp.cos(x[Ellipsis, :1])], axis=-1)\n  else:\n    return x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x_scaled = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x_sin = jnp.sin(\n      jnp.concatenate([x_scaled, x_scaled + 0.5 * jnp.pi], axis=-1)\n  )\n  return jnp.concatenate([x_sin, x], axis=-1) if append_identity else x_sin"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x = jnp.sin(jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-1))\n  if append_identity:\n    return jnp.concatenate([x, x[Ellipsis, 0:1], jnp.cos(x[Ellipsis, 0:1])], axis=-1)\n  else:\n    return x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x = jnp.sin(jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-1))\n  if append_identity:\n    return jnp.concatenate([x, x[Ellipsis, 0:1], x[Ellipsis, 1:2]], axis=-1)\n  else:\n    return x"}
{"namespace": "coord.pos_enc", "completion": "  # Scaling the input\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  # Applying sine function\n  sin_x = jnp.sin(scaled_x)\n\n  # Concatenating the original input with the encoded features\n  if append_identity:\n    return jnp.concatenate([sin_x, x[Ellipsis, None]], axis=-1)\n  else:\n    return sin_x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x = jnp.concatenate(\n      [jnp.sin(x), jnp.cos(x)], axis=-1\n  )  # 2 * min_deg + max_deg - 1\n  if append_identity:\n    x = jnp.concatenate([x, x[Ellipsis, :1]], axis=-1)\n  return x\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x_scaled = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  x_sin = jnp.sin(\n      jnp.concatenate([x_scaled, x_scaled + 0.5 * jnp.pi], axis=-1)\n  )\n  if append_identity:\n    return jnp.concatenate([x_sin, x[Ellipsis, None]], axis=-1)\n  else:\n    return x_sin\n\n"}
{"namespace": "coord.pos_enc", "completion": "  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  scaled_x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  # Apply sin function to the scaled input\n  sin_x = jnp.sin(scaled_x)\n  # Concatenate the original input with the encoded features\n  if append_identity:\n    return jnp.concatenate([sin_x, x], axis=-1)\n  else:\n    return sin_x"}
{"namespace": "coord.pos_enc", "completion": "  # Compute the scales as powers of 2 from min_deg to max_deg\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  # Reshape the input array to match the scales\n  shape = x.shape[:-1] + (-1,)\n  x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  # Apply the sine function to the input array\n  x = jnp.sin(jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-1))\n  # If append_identity is True, concatenate the original input with the encoded features\n  if append_identity:\n    x = jnp.concatenate([x, x[Ellipsis, :1]], axis=-1)\n  return x"}
{"namespace": "coord.pos_enc", "completion": "  # Scaling the input\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n\n  # Applying sine function\n  x = jnp.sin(jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-1))\n\n  # Concatenating with original input if specified\n  if append_identity:\n    x = jnp.concatenate([x, x[Ellipsis, :1]], axis=-1)\n\n  return x"}
{"namespace": "coord.pos_enc", "completion": "  # Scaling the input by powers of 2 from min_deg to max_deg\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  shape = x.shape[:-1] + (-1,)\n  # Reshaping the input and scaling it by the scales\n  x = jnp.reshape(x[Ellipsis, None, :] * scales[:, None], shape)\n  # Applying the sine function to the scaled input\n  x = jnp.sin(jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-1))\n  if append_identity:\n    # Concatenating the original input with the encoded features\n    return jnp.concatenate([x, x[Ellipsis, :1], x[Ellipsis, 1:]], axis=-1)\n  else:\n    return x"}
{"namespace": "coord.pos_enc", "completion": "  # Compute the scales for each degree exponent\n  scales = 2.0 ** jnp.arange(min_deg, max_deg)\n  # Scale the input array\n  x = x[Ellipsis, None, :] * scales[:, None]\n  # Apply the sine function to the scaled input\n  x = jnp.sin(jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-1))\n  # If append_identity is True, concatenate the original input with the encoded features\n  if append_identity:\n    x = jnp.concatenate([x, x[Ellipsis, :1]], axis=-1)\n  return x.reshape(x.shape[:-2] + (-1,))\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2) and if each pair of arrays have the same shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2) and if each pair of arrays have the same shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2) and if each array in field1 has the same shape as the corresponding array in field2.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if all shapes are equal.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if all shapes are equal.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2) and if each pair of arrays within the lists have the same shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for array1, array2 in zip(values[field1], values[field2]):\n            if array1.shape != array2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if len(field1) equals len(field2) and if each pair of arrays in field1 and field2 have the same shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for v1, v2 in zip(values[field1], values[field2]):\n            if v1.shape != v2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if field1.shape equals field2.shape.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n        for i, (v1, v2) in enumerate(zip(values[field1], values[field2])):\n            if v1.shape != v2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch at index {i}.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"Check if all shapes in field1 and field2 are equal.\"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"\n        This function checks if two lists of numpy arrays have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type of the object being validated.\n        :param values: Dict[str, List[np.ndarray]]. A dictionary containing the values of the fields to be validated.\n        :return: Dict[str, List[np.ndarray]]. The validated values of the fields.\n\n        \"\"\"\n        list1 = values[field1]\n        list2 = values[field2]\n\n        if len(list1) != len(list2):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, resp. {len(list1)} and {len(list2)}\")\n\n        for arr1, arr2 in zip(list1, list2):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"\n        This function is the actual Pydantic validator that checks if two lists of numpy arrays have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type of the model being validated.\n        :param values: Dict[str, List[np.ndarray]]. A dictionary containing the values of the fields to be validated.\n        :return: Dict[str, List[np.ndarray]]. The validated values if the check passes.\n\n        \"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"\n        This function is a Pydantic model validator that checks if two lists of numpy arrays have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type of the model being validated.\n        :param values: Dict[str, np.ndarray]. A dictionary containing the values of the fields to be validated.\n        :return: Dict[str, np.ndarray]. The validated values.\n        \"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(\n                f\"{cls.__name__}: {field1} and {field2} length mismatch, \"\n                f\"resp. {len(values[field1])} and {len(values[field2])}\"\n            )\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"\n        This function checks if the length of the two lists of numpy arrays (specified by field names) is equal and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type of the validator function.\n        :param values: Dict[str, List[np.ndarray]]. A dictionary containing the values of the fields to be validated.\n        :return: Dict[str, List[np.ndarray]]. The validated values of the fields.\n        \"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch, resp. {len(values[field1])} and {len(values[field2])}\")\n        for i in range(len(values[field1])):\n            if values[field1][i].shape != values[field2][i].shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"\n        This function is a Pydantic validator that checks if two lists of numpy arrays (specified by field names) have the same length and if each corresponding pair of arrays within these lists has the same shape.\n\n        Input-Output Arguments\n        :param cls: type. The class type of the validator.\n        :param values: Dict[str, List[np.ndarray]]. A dictionary containing the values of the fields to be validated.\n        :return: Dict[str, List[np.ndarray]]. The validated values if the shape check passes.\n        \"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n        return values\n\n    return __root_validator\n\n"}
{"namespace": "iris.io.validators.are_all_shapes_equal", "completion": "    def __root_validator(cls: type, values: Dict[str, List[np.ndarray]]) -> Dict[str, List[np.ndarray]]:\n        \"\"\"\n        This is the actual validator function that is returned by the factory function.\n        It checks if the length of the first list of numpy arrays is equal to the length of the second list of numpy arrays, and if each corresponding pair of arrays has the same shape.\n        If the check passes, it returns the validated values.\n        \"\"\"\n        if len(values[field1]) != len(values[field2]):\n            raise ValueError(f\"{cls.__name__}: {field1} and {field2} length mismatch.\")\n\n        for arr1, arr2 in zip(values[field1], values[field2]):\n            if arr1.shape != arr2.shape:\n                raise ValueError(f\"{cls.__name__}: {field1} and {field2} shape mismatch.\")\n\n        return values\n\n    return __root_validator"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n\n        # Reset the rendering context to its original dimensions\n        eglctx.resize(eglctx.width, eglctx.height)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n\n        # TODO: Add support for offscreen rendering\n        pass"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n\n        # TODO: Implement the offscreen rendering functionality here"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Use the program point size\n        gl.glEnable(gl.GL_PROGRAM_POINT_SIZE)\n\n        # Performs face culling\n        gl.glEnable(gl.GL_CULL_FACE)\n        gl.glCullFace(gl.GL_BACK)\n\n        # Performs alpha trans testing\n        gl.glEnable(gl.GL_ALPHA_TEST)\n\n        # Performs z-buffer testing\n        gl.glEnable(gl.GL_DEPTH_TEST)\n        gl.glDepthMask(gl.GL_TRUE)\n        gl.glDepthFunc(gl.GL_LEQUAL)\n        gl.glDepthRange(-1.0, 1.0)\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Enable some masking tests\n        gl.glEnable(gl.GL_SCISSOR_TEST)\n\n        # Enable this to correctly render points\n        # https://community.khronos.org/t/gl-point-sprite-gone-in-3-2/59310\n        gl.glEnable(gl.GL_POINT_SPRITE)  # MARK: ONLY SPRITE IS WORKING FOR NOW\n        gl.glEnable(gl.GL_POINT_SMOOTH)  # MARK: ONLY SPRITE IS WORKING FOR NOW\n\n        # Configure how we store the pixels in memory for our subsequent reading of the FBO to store the rendering into memory.\n        # The second argument specifies that our pixels will be in bytes.\n        gl.glPixelStorei(gl.GL_PACK_ALIGNMENT, 1)\n\n        # Render the mesh\n        self.render(camera)\n\n        # Read the pixels from the FBO\n        # gl.glReadBuffer(gl.GL_COLOR_ATTACHMENT0)\n        # gl.glRead"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Set up the camera settings for rendering\n        self.uniforms.camera_position = camera.position\n        self.uniforms.camera_lookat = camera.lookat\n        self.uniforms.camera_up = camera.up\n        self.uniforms.camera_fov = camera.fov\n        self.uniforms.camera_aspect = camera.aspect\n        self.uniforms.camera_near = camera.near\n        self.uniforms.camera_far = camera.far\n\n        # Render the Mesh instance using the camera settings\n        self.render()\n\n        # Reset the rendering context to its original size\n        eglctx.resize(eglctx.width, eglctx.height)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Set the viewport to match the camera's dimensions\n        gl.glViewport(0, 0, camera.width, camera.height)\n\n        # Set the projection matrix\n        gl.glMatrixMode(gl.GL_PROJECTION)\n        gl.glLoadMatrixf(camera.projection.T.ravel())\n\n        # Set the modelview matrix\n        gl.glMatrixMode(gl.GL_MODELVIEW)\n        gl.glLoadMatrixf(camera.modelview.T.ravel())\n\n        # Clear the color and depth buffers\n        gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)\n\n        # Render the mesh\n        self.render()\n\n        # Read the rendered image from the framebuffer\n        img = eglctx.read_framebuffer(camera.width, camera.height)\n\n        # Return the rendered image\n        return img\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        eglctx.resize(camera.width, camera.height)\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n\n        # Return the rendered image as a numpy array\n        return eglctx.read_pixels(camera.width, camera.height)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh using the camera's settings\n        self.render(camera)\n\n        # Reset the rendering context to its original size\n        eglctx.resize(eglctx.width, eglctx.height)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n\n        # Reset the rendering context to its original size\n        eglctx.reset()\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize_context(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the Mesh instance using the camera's settings\n        self.render(camera)\n\n        # Get the rendered image from the rendering context\n        # image = eglctx.get_image()\n\n        # Return the rendered image\n        # return image\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's width and height\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh using the camera's settings\n        self.render(camera)\n\n        # TODO: Add support for offscreen rendering\n        # eglctx.render()\n        # eglctx.read_pixels()\n        # eglctx.save_screenshot(f'{self.name}.png')\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.offscreen_render", "completion": "        # Resize the rendering context to match the camera's dimensions\n        eglctx.resize(camera.width, camera.height)\n\n        # Render the mesh using the camera's settings\n        self.render(camera)\n"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        mask_token_id=bert_config.mask_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        num_labels=bert_config.num_labels,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_past=bert_config.output_past,\n        pruned_heads=bert_config.pruned_heads,\n        is_decoder=bert_config.is_decoder,\n        add_cross_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new NomicBertConfig object with inherited settings from the BertConfig\n    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_past=bert_config.output_past,\n        pruned_heads=bert_config.pruned_heads,\n        is_decoder=bert_config.is_decoder,\n        add_cross_attention=bert_config.add_cross_attention,\n        is_encoder_decoder=bert_config.is_encoder"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        attention_dropout=bert_config.attention_dropout,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        num_labels=bert_config.num_labels,\n        id2label=bert_config.id2label,\n        label2id=bert_config.label2id,\n        is_encoder_decoder=bert_config.is_encoder_decoder,\n        add_cross_attention=bert_config.add_cross_attention,\n        pruned_heads"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new NomicBertConfig object\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        attention_window=bert_config.attention_window,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_past=bert_config.output_past,\n        pruned_heads=bert_config.pruned_heads,\n        is_decoder=bert_config.is_decoder,\n        add_cross_attention=bert_config.add_cross_attention,\n        is_encoder_decoder"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        mask_token_id=bert_config.mask_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        add_cross_attention=bert_config.add_cross_attention,\n        num_labels=bert_config.num_labels,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_logits=bert_config.output_logits,\n        return_dict=bert_config.return_dict,\n        use_return_dict="}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        is_encoder_decoder=bert_config.is_encoder_decoder,\n        add_cross_attention=bert_config.add_cross_attention,\n        pruned_heads=bert_config.pruned_heads,\n        torch_dtype=bert_config.torch_dtype,\n        use_bfloat16=bert_config.use_bfloat16,\n        use_quantized_variable=bert_config.use_quantized_variable,\n        trust_remote_code=bert_config.trust_remote_code,\n        mask_token_id=bert_config.mask_token_id,\n        extra_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new NomicBertConfig object with inherited settings from the BertConfig\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        tie_word_embeddings=bert_config.tie_word_embeddings,\n        problem_type=bert_config.problem_type,\n        num_labels=bert_config.num_labels,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        use_return_dict=bert_config.use_return_dict,\n        pruned_heads=bert_config.pruned_heads,\n        is_decoder=bert_config.is_dec"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new NomicBertConfig object with the settings from the BertConfig\n    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        unk_token_id=bert_config.unk_token_id,\n        mask_token_id=bert_config.mask_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_attentions=bert_config.output_attentions,\n        pruned_heads=bert_config.pruned_heads,\n        use_bfloat16=bert"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new NomicBertConfig object by copying attributes from the BertConfig\n    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        mask_token_id=bert_config.mask_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        num_labels=bert_config.num_labels,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        pruned_heads=bert_config.pruned_heads,\n        is_decoder=bert_config.is_decoder,"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig()\n    config.vocab_size = bert_config.vocab_size\n    config.hidden_size = bert_config.hidden_size\n    config.num_hidden_layers = bert_config.num_hidden_layers\n    config.num_attention_heads = bert_config.num_attention_heads\n    config.intermediate_size = bert_config.intermediate_size\n    config.hidden_act = bert_config.hidden_act\n    config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    config.max_position_embeddings = bert_config.max_position_embeddings\n    config.type_vocab_size = bert_config.type_vocab_size\n    config.initializer_range = bert_config.initializer_range\n    config.layer_norm_eps = bert_config.layer_norm_eps\n    config.position_embedding_type = bert_config.position_embedding_type\n    config.use_cache = bert_config.use_cache\n    config.classifier_dropout = bert_config.classifier_dropout\n    config.pad_token_id = bert_config.pad_token_id\n    config.bos_token_id = bert_config.bos_token_id\n    config.eos_token_id = bert_config.eos_token_id\n    config.add_cross_attention = True\n    config.is_decoder = False\n    config.summary_type = \"first\"\n    config.summary_use_proj = True\n    config.summary_activation = None\n    config.summary_proj_to_labels = True\n    config.summary_first_dropout = 0.1\n    config.scale_attn_weights = True\n    config.use_cache = False\n    config.use_return_dict = True\n    config.use_memory_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new NomicBertConfig object based on the BertConfig\n    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        max_entity_tokens=bert_config.max_entity_tokens,\n        max_mention_tokens=bert_config.max_mention_tokens,\n        max_entity_mention_tokens=bert_config.max_entity_mention_tokens,\n        max_mention_mention_tokens=bert_config.max_mention_mention_tokens,\n        max_entity_mention_mention_tokens=bert_config.max_entity_mention_mention"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new NomicBertConfig object with the inherited settings from the BertConfig\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        num_labels=bert_config.num_labels,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        use_return_dict=bert_config.use_return_dict,\n        output_past=bert_config.output_past,\n        output_attentions_only=bert_config.output_attentions_only,\n        output_hidden_states_only=bert_config.output_hidden_states_only,\n        output_past_and_future=bert_config.output_past_and_future,\n        output_only_past=bert"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        output_past=bert_config.output_past,\n        use_nomic_model=True,\n        num_nomic_layers=bert_config.num_hidden_layers,\n        nomic_layer_norm_eps=bert_config.layer_norm_eps,\n        nomic_hidden_act=bert_config.hidden_act,\n        nomic_intermediate_size=bert_config.intermediate_size,\n        nomic_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Initialize a new NomicBertConfig object\n    config = NomicBertConfig()\n\n    # Copy the settings from the BertConfig object\n    config.vocab_size = bert_config.vocab_size\n    config.hidden_size = bert_config.hidden_size\n    config.num_hidden_layers = bert_config.num_hidden_layers\n    config.num_attention_heads = bert_config.num_attention_heads\n    config.intermediate_size = bert_config.intermediate_size\n    config.hidden_act = bert_config.hidden_act\n    config.hidden_dropout_prob = bert_config.hidden_dropout_prob\n    config.attention_probs_dropout_prob = bert_config.attention_probs_dropout_prob\n    config.max_position_embeddings = bert_config.max_position_embeddings\n    config.type_vocab_size = bert_config.type_vocab_size\n\n    # Additional configurations specific to the Nomic model\n    config.initializer_range = bert_config.initializer_range\n    config.layer_norm_eps = bert_config.layer_norm_eps\n    config.position_embedding_type = bert_config.position_embedding_type\n    config.use_cache = bert_config.use_cache\n    config.classifier_dropout = bert_config.classifier_dropout\n    config.pad_token_id = bert_config.pad_token_id\n    config.bos_token_id = bert_config.bos_token_id\n    config.eos_token_id = bert_config.eos_token_id\n    config.is_encoder_decoder = bert_config.is_encoder_decoder\n    config.add_cross_attention = bert_config.add_cross_attention\n    config.pruned_heads = bert_config.pruned_heads\n    config.output_attentions = bert_config.output_"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        use_embeddings=bert_config.use_embeddings,\n        use_attention=bert_config.use_attention,\n        use_intermediate=bert_config.use_intermediate,\n        use_output=bert_config.use_output,\n        use_residual=bert_config.use_residual,\n        use_pooler=bert_config.use_pooler,\n        use_mask_token=bert_config.use_mask_token,\n        use_embeddings_layer_norm=bert_config.use_embeddings_layer_norm,\n        use_embeddings_project"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        pad_token_id=bert_config.pad_token_id,\n        bos_token_id=bert_config.bos_token_id,\n        eos_token_id=bert_config.eos_token_id,\n        sep_token_id=bert_config.sep_token_id,\n        mask_token_id=bert_config.mask_token_id,\n        model_type=bert_config.model_type,\n        num_labels=bert_config.num_labels,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        use_return_dict=bert_config.use_return_dict,\n        num_context_vectors=bert_config.num_context_vectors,\n        num_attention_heads_per_vector=bert_config.num_attention_head"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig.from_dict(bert_config.to_dict())\n\n    config.max_position_embeddings = 1024\n    config.vocab_size = 10000\n    config.type_vocab_size = 1\n    config.max_position_embeddings = 1024\n    config.num_hidden_layers = 12\n    config.num_attention_heads = 12\n    config.hidden_size = 768\n    config.intermediate_size = 3072\n    config.hidden_act = \"gelu\"\n    config.hidden_dropout_prob = 0.1\n    config.attention_probs_dropout_prob = 0.1\n    config.initializer_range = 0.02\n    config.layer_norm_eps = 1e-12\n    config.pad_token_id = 0\n    config.bos_token_id = 0\n    config.eos_token_id = 0\n    config.gradient_checkpointing = False\n    config.position_embedding_type = \"absolute\"\n    config.classifier_dropout = None\n    config.use_cache = False\n    config.num_labels = 1\n    config.tie_word_embeddings = False\n    config.problem_type = \"regression\"\n    config.torch_dtype = \"float32\"\n    config.use_bfloat16 = False\n    config.resid_pdrop = 0.1\n    config.embd_pdrop = 0.1\n    config.attn_pdrop = 0.1\n    config.layer_norm_epsilon = 1e-5\n    config.initializer_range = 0.02\n    config.summary_type = \"cls_index\"\n    config.summary_use_proj = True\n    config.summary_activation = None\n    config.summary_proj_to_labels = True\n    config.summary_first_dropout = 0.1\n    config.scale_attn_weights = True\n    config.use_cache = False\n    config.use"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new NomicBertConfig object\n    nomic_config = NomicBertConfig(\n        vocab_size=bert_config.vocab_size,\n        hidden_size=bert_config.hidden_size,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        num_attention_heads=bert_config.num_attention_heads,\n        intermediate_size=bert_config.intermediate_size,\n        hidden_act=bert_config.hidden_act,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        attention_probs_dropout_prob=bert_config.attention_probs_dropout_prob,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        initializer_range=bert_config.initializer_range,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        pad_token_id=bert_config.pad_token_id,\n        gradient_checkpointing=bert_config.gradient_checkpointing,\n        position_embedding_type=bert_config.position_embedding_type,\n        use_cache=bert_config.use_cache,\n        classifier_dropout=bert_config.classifier_dropout,\n        num_labels=bert_config.num_labels,\n        add_cross_attention=bert_config.add_cross_attention,\n        output_attentions=bert_config.output_attentions,\n        output_hidden_states=bert_config.output_hidden_states,\n        use_return_dict=bert_config.use_return_dict,\n        **bert_config.to_dict()\n    )\n\n    # Additional configurations for NomicBertConfig\n    nomic_config.nomic_config = {\n        \"nomic_hidden_size\": bert_config.hidden_size,\n        \"nomic_num_hidden_layers\": bert_config.num_hidden_layers"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    # Create a new NomicBertConfig object by copying the attributes from the BertConfig\n    nomic_config = NomicBertConfig(**bert_config.to_dict())\n\n    # Set the 'max_position_embeddings' attribute of the NomicBertConfig\n    # The value is set to 1024, which is the maximum number of tokens that can be processed by the Nomic model\n    nomic_config.max_position_embeddings = 1024\n\n    # Set the 'num_attention_heads' attribute of the NomicBertConfig\n    # The value is set to 12, which is the number of attention heads in the Nomic model\n    nomic_config.num_attention_heads = 12\n\n    # Set the 'hidden_size' attribute of the NomicBertConfig\n    # The value is set to 768, which is the hidden size of the Nomic model\n    nomic_config.hidden_size = 768\n\n    # Set the 'intermediate_size' attribute of the NomicBertConfig\n    # The value is set to 3072, which is the intermediate size of the Nomic model\n    nomic_config.intermediate_size = 3072\n\n    # Set the 'num_hidden_layers' attribute of the NomicBertConfig\n    # The value is set to 12, which is the number of hidden layers in the Nomic model\n    nomic_config.num_hidden_layers = 12\n\n    # Set the 'num_labels' attribute of the NomicBertConfig\n    # The value is set to 1, which is the number of labels in the Nomic model\n    nomic_config.num_labels = 1\n\n    # Set the 'type_vocab_size' attribute of the NomicBertConfig\n    # The value is set to 2, which is the number of token types in the Nomic model\n    nomic_config.type_vocab_size = 2\n\n    # Set the 'vocab_size' attribute of the NomicBertConfig\n    # The value is set to 305"}
{"namespace": "contrastors.models.encoder.bert.bert_config_to_nomic_config", "completion": "    config = NomicBertConfig.from_pretrained(\n        \"bert-base-uncased\",\n        num_labels=bert_config.num_labels,\n        finetuning_task=bert_config.finetuning_task,\n        hidden_dropout_prob=bert_config.hidden_dropout_prob,\n        layer_norm_eps=bert_config.layer_norm_eps,\n        initializer_range=bert_config.initializer_range,\n        use_cache=bert_config.use_cache,\n        num_hidden_layers=bert_config.num_hidden_layers,\n        hidden_size=bert_config.hidden_size,\n        intermediate_size=bert_config.intermediate_size,\n        num_attention_heads=bert_config.num_attention_heads,\n        hidden_act=bert_config.hidden_act,\n        max_position_embeddings=bert_config.max_position_embeddings,\n        type_vocab_size=bert_config.type_vocab_size,\n        vocab_size=bert_config.vocab_size,\n        pad_token_id=bert_config.pad_token_id,\n        position_embedding_type=bert_config.position_embedding_type,\n        add_pooling_layer=bert_config.add_pooling_layer,\n        add_cross_attention=bert_config.add_cross_attention,\n        use_nomic_mlp=bert_config.use_nomic_mlp,\n        use_nomic_attention=bert_config.use_nomic_attention,\n        use_nomic_residual=bert_config.use_nomic_residual,\n        use_nomic_layernorm=bert_config.use_nomic_layernorm,\n        use_nomic_head=bert_config.use_nomic_head,\n        use_nomic_pre_layernorm=bert_config.use_nomic_pre_layernorm,\n        use_nomic_post_layernorm=bert_config.use_nomic_"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Select the appropriate shader program based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload necessary uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object of the mesh\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the appropriate OpenGL draw call based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.indexed:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.indexed:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.indexed:\n                gl.glDrawElements(gl.GL_QUADS, self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_QUADS, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if self.indexed:\n                gl."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n        self.upload_gl_uniforms(camera)\n        gl.glBindVertexArray(self.vao)\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int32:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int32:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int32:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UN"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n            gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n            gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, None)\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER,"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n            gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n            gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n            gl.glDrawElements(gl.GL_QUADS, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n            gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glBindBuffer(gl"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n        self.upload_gl_uniforms(camera)\n\n        # Bind VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_LINES, 0, self.n_verts)\n            else:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.n_verts)\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_QUADS, 0, self.n_verts)\n            else:\n                gl.glDrawElements(gl.GL_QUADS, self.n_faces, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            if self.faces is None:\n                gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, self.n_verts)\n            else:\n                gl.glDrawElements(gl"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Select the appropriate shader program based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload necessary uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object of the mesh\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the appropriate OpenGL draw call based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            # Draw points\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            # Draw lines\n            gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            # Draw triangles\n            if self.faces is not None:\n                # Indexed drawing\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n            else:\n                # Non-indexed drawing\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            # Draw quads\n            if self.faces is not None:\n                # Indexed drawing\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, None)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Select the appropriate shader program based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Bind the shader program\n        gl.glUseProgram(program)\n\n        # Upload necessary uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object of the mesh\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the appropriate OpenGL draw call based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.dtype == torch.int32:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int32:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.dtype == torch.int"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.is_cuda:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.is_cuda:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.is_cuda:\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_QUAD"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.shape[-1] == 2:\n                gl.glDrawArrays(gl.GL_LINES, 0, self.n_verts)\n            else:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.shape[-1] == 3:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.n_verts)\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.shape[-1] == 4:\n                gl.glDrawArrays(gl.GL_QUADS, 0, self.n_verts)\n            else:\n                gl.glDrawElements(gl.GL_QUADS, self.n_faces, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n        elif self.render_type == Mesh.RenderType.STRIPS"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind VAO\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            # Draw points\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            # Draw lines\n            gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            # Draw triangles\n            if self.faces.dtype == torch.int32:\n                # Indexed drawing\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n            else:\n                # Non-indexed drawing\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.QUADS:\n            # Draw quads\n            if self.faces.dtype == torch.int32:\n                # Indexed drawing\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_QUADS, len(self.faces) * 4, gl.GL_UNSIGNED_INT, None)\n            else:\n                # Non-indexed drawing\n                gl.glDrawArrays(gl.GL"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Select the appropriate shader program based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload necessary uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object of the mesh\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the appropriate OpenGL draw call based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            # Draw points\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.verts.shape[0])\n        elif self.render_type == Mesh.RenderType.LINES:\n            # Draw lines\n            gl.glDrawArrays(gl.GL_LINES, 0, self.verts.shape[0])\n        elif self.render_type == Mesh.RenderType.TRIS:\n            # Draw triangles\n            if self.faces.shape[-1] == 3:\n                # Indexed drawing\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_TRIANGLES, self.faces.shape[0] * 3, gl.GL_UNSIGNED_INT, None)\n            else:\n                # Non-indexed drawing\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.verts.shape[0])\n        elif self.render_type == Mesh.RenderType.QUADS:\n            # Draw quads\n            if self.faces.shape[-1] == 4:\n                # Indexed drawing\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_QUADS, self.faces.shape[0]"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Select the appropriate shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            self.program = self.point_program\n        else:\n            self.program = self.mesh_program\n\n        # Bind the shader program\n        gl.glUseProgram(self.program)\n\n        # Upload necessary uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object of the mesh\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the appropriate OpenGL draw call based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.shape[-1] == 2:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n            else:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.shape[-1] == 3:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n            else:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n                gl.glBindBuffer(gl."}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        # Bind the VAO\n        gl.glBindVertexArray(self.vao)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.shape[1] == 2:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n            else:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.faces.shape[1], gl.GL_UNSIGNED_INT, None)\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.shape[1] == 3:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n            else:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.faces.shape[1], gl.GL_UNSIGNED_INT, None)\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.shape[1] == 4"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible:\n            return\n\n        # Select the appropriate shader program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n\n        # Bind the shader program\n        use_gl_program(program)\n\n        # Upload necessary uniforms to the GPU\n        self.upload_gl_uniforms(camera)\n\n        # Bind the vertex array object of the mesh\n        gl.glBindVertexArray(self.vao)\n\n        # Issue the appropriate OpenGL draw call based on the render type\n        if self.render_type == Mesh.RenderType.POINTS:\n            # Draw points\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            # Draw lines\n            if self.faces.ndim == 2:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n            else:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            # Draw triangles\n            if self.faces.ndim == 2:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n            else:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * self.face_size, gl.GL_UNSIGNED_INT, None)\n               "}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind the mesh\n        gl.glBindVertexArray(self.VAO)\n\n        # Draw the mesh\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts)\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.is_cuda:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_LINES, self.n_faces, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.is_cuda:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, self.n_faces, gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.is_cuda:\n                gl.glDrawElements(gl.GL_QUADS, self.n_faces, gl.GL_UNSIGNED_INT, ctypes.c_void_p(0))\n            else:\n                gl.glDrawElements(gl.GL_QUADS, self.n_faces, gl.GL_UNSIGNED_INT, None)"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        # Select program\n        if self.render_type == Mesh.RenderType.POINTS:\n            program = self.point_program\n        else:\n            program = self.mesh_program\n        use_gl_program(program)\n\n        # Upload uniforms\n        self.upload_gl_uniforms(camera)\n\n        # Bind vertex array object\n        gl.glBindVertexArray(self.vao)\n\n        # Render\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.LINES:\n            if self.faces.shape[0] == 0:\n                gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n            else:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_LINES, len(self.faces) * 2, gl.GL_UNSIGNED_INT, None)\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.shape[0] == 0:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, len(self.verts))\n            else:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, None)\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, 0)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            if self.faces.shape[0] == "}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.dtype == torch.int64:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, self.faces.data_ptr())\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, self.faces.data_ptr())\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n        else:\n            raise ValueError(f'Unsupported render type: {self.render_type}')\n\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawArrays(gl.GL_LINES, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.is_cuda:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, self.faces.data_ptr())\n            else:\n                gl.glDrawElements(gl.GL_TRIANGLES, len(self.faces) * 3, gl.GL_UNSIGNED_INT, self.faces.numpy().ctypes.data)\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawArrays(gl.GL_QUADS, 0, len(self.verts))\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n        else:\n            gl.glPointSize(self.point_radius)\n            gl.glDrawArrays(gl.GL_POINTS, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n        if self.render_type == Mesh.RenderType.POINTS:\n            gl.glDrawArrays(gl.GL_POINTS, 0, self.n_verts)\n        else:\n            if self.faces.dtype == torch.int32:\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(self.render_type.value, self.n_faces, gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(self.render_type.value, 0, self.n_verts)\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Mesh.render", "completion": "        if not self.visible: return\n        if self.render_type == Mesh.RenderType.POINTS:\n            use_gl_program(self.point_program)\n        else:\n            use_gl_program(self.mesh_program)\n\n        self.upload_gl_uniforms(camera)\n\n        gl.glBindVertexArray(self.vao)\n\n        if self.render_type == Mesh.RenderType.LINES:\n            gl.glDrawElements(gl.GL_LINES, self.faces.numel(), gl.GL_UNSIGNED_INT, None)\n        elif self.render_type == Mesh.RenderType.TRIS:\n            if self.faces.numel():\n                gl.glBindBuffer(gl.GL_ELEMENT_ARRAY_BUFFER, self.ebo)\n                gl.glDrawElements(gl.GL_TRIANGLES, self.faces.numel(), gl.GL_UNSIGNED_INT, None)\n            else:\n                gl.glDrawArrays(gl.GL_TRIANGLES, 0, self.verts.shape[0])\n        elif self.render_type == Mesh.RenderType.QUADS:\n            gl.glDrawArrays(gl.GL_QUADS, 0, self.verts.shape[0])\n        elif self.render_type == Mesh.RenderType.STRIPS:\n            gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, self.verts.shape[0])\n\n        gl.glBindVertexArray(0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if not self.use_quad_cuda:\n            self.upload_to_texture_cpu(ptr, x, y, w, h)\n            return\n\n        if not hasattr(self, 'cu_tex'):\n            self.init_texture()\n\n        # assert self.use_quad_cuda, \"Need to enable cuda-opengl interop to copy from device to device, check creation of this Quad\"\n        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = torch.cat([ptr, ptr.new_ones(ptr.shape[:-1] + (1,)) * 255], dim=-1)  # add alpha channel\n\n        from cuda import cudart\n        kind = cudart.cudaMemcpyKind.cudaMemcpyDeviceToDevice\n        CHECK_CUDART_ERROR(cudart.cudaGraphicsMapResources(1, self.cu_tex, torch.cuda.current_stream().cuda_stream))\n        cu_tex_arr = CHECK_CUDART_ERROR(cudart.cudaGraphicsSubResourceGetMappedArray(self.cu_tex, 0, 0))\n\n        if self.compose:\n            \"\"\"\n            Blit current framebuffer to this texture (self.tex)\n            Read content of this texture into a cuda buffer\n            Perform alpha blending based on the frame's alpha channel\n            Copy the blended image back into the texture (self.tex)\n            \"\"\"\n            old = gl.glGetInteger(gl.GL_DRAW_FRAMEBUFFER_BINDING)\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n            gl.glBlitFramebuffer(x, y, w, h,\n                                 x, y, w, h,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)  # now self.tex contains the content of the already rendered frame"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones(ptr.shape[:-1] + (1,)) * 255], axis=-1)  # add alpha channel\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones(ptr.shape[:-1] + (1,)) * 255], axis=-1)  # add alpha channel\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n        w = w or self.W\n        h = h or self.H\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones(ptr.shape[:-1] + (1,)) * 255], axis=-1)  # add alpha channel\n\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n        w = w or self.W\n        h = h or self.H\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n        w = w or self.W\n        h = h or self.H\n\n        # Bind the texture object to the current context\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Upload the pixel data to the texture\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n\n        # Unbind the texture object from the current context\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        w = w or self.W\n        h = h or self.H\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.cpu().numpy()\n        assert ptr.shape[-1] in [3, 4], \"Only support RGB or RGBA\"\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        # Convert PyTorch tensor to numpy array if necessary\n        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n\n        # Ensure ptr is a numpy array\n        assert isinstance(ptr, np.ndarray), \"ptr must be a numpy array or a PyTorch tensor\"\n\n        # Get the width and height of the portion to be updated\n        w = w or self.W\n        h = h or self.H\n\n        # Ensure the data source is of the correct shape\n        assert ptr.shape == (h, w, 4), f\"ptr must have shape ({h}, {w}, 4), but got {ptr.shape}\"\n\n        # Ensure the data source is of the correct dtype\n        assert ptr.dtype == np.uint8, f\"ptr must have dtype np.uint8, but got {ptr.dtype}\"\n\n        # Ensure the data source is contiguous\n        assert ptr.flags['C_CONTIGUOUS'], \"ptr must be contiguous\"\n\n        # Ensure the data source is in RGBA format\n        assert ptr.shape[-1] == 4, \"ptr must have 4 channels (RGBA)\"\n\n        # Ensure the data source is in the correct range\n        assert np.all(ptr >= 0) and np.all(ptr <= 255), \"ptr must be in the range [0, 255]\"\n\n        # Ensure the data source is in the correct order\n        assert ptr.shape[-1] == 4 and ptr.shape[-2] == 3, \"ptr must be in the order (height, width, channels)\"\n\n        # Ensure the data source is in the correct dtype\n        assert ptr.dtype == np.uint8, \"ptr must be of type np.uint8\"\n\n        # Ensure the data source is in the correct range\n        assert np.all(ptr >= 0) and np.all(ptr <= 255), \"ptr must be in the range [0, 255]\"\n\n        # Ensure the data source"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.upload_to_texture", "completion": "        if isinstance(ptr, torch.Tensor):\n            ptr = ptr.detach().cpu().numpy()\n        if ptr.shape[-1] == 3:\n            ptr = np.concatenate([ptr, np.ones_like(ptr[..., :1]) * 255], axis=-1)  # add alpha channel\n        w = w or self.W\n        h = h or self.H\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, w, h, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, ptr)\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure all inputs are batched\n    R = R.view(-1, 3, 3)\n    tvec = tvec.view(-1, 3, 1)\n    camera_matrix = camera_matrix.view(-1, 3, 3)\n    image_size = image_size.view(-1, 2)\n\n    # Validate inputs\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0], \"All inputs must have the same batch size.\"\n    assert R.shape[1:] == (3, 3), \"Rotation matrix must be of shape (3, 3).\"\n    assert tvec.shape[1:] == (3, 1), \"Translation vector must be of shape (3, 1).\"\n    assert camera_matrix.shape[1:] == (3, 3), \"Camera matrix must be of shape (3, 3).\"\n    assert image_size.shape[1:] == (2,), \"Image size must be of shape (2,).\"\n\n    # Compute camera position\n    cam_pos = -R.transpose(-1, -2) @ tvec\n\n    # Compute camera rotation\n    cam_rot = matrix_to_rotation_6d(R)\n\n    # Compute focal length and principal point\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Adjust focal length and principal point for Pulsar\n    fx = fx * image_size[..., 0] / (2 * znear)\n    fy = fy * image_size[..., 1] / (2 * znear)\n    cx = cx * image_size[..., 0] - 0.5\n    cy = cy * image_size[..., 1] - 0.5\n\n    # Check"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure all inputs are batched\n    R = R.view(-1, 3, 3)\n    tvec = tvec.view(-1, 3, 1)\n    camera_matrix = camera_matrix.view(-1, 3, 3)\n    image_size = image_size.view(-1, 2)\n\n    # Validate input shapes\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n    assert R.shape[1] == R.shape[2] == 3\n    assert tvec.shape[1] == 3 and tvec.shape[2] == 1\n    assert camera_matrix.shape[1] == camera_matrix.shape[2] == 3\n    assert image_size.shape[1] == 2\n\n    # Compute camera position\n    cam_pos = -R.transpose(-1, -2) @ tvec\n\n    # Compute rotation\n    rot = matrix_to_rotation_6d(R)\n\n    # Compute focal lengths\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    fx_mean = fx.mean(-1, keepdim=True)\n    fy_mean = fy.mean(-1, keepdim=True)\n    fx_ratio = fx / fx_mean\n    fy_ratio = fy / fy_mean\n    fx_diff = (fx_ratio - 1).abs().max(-1)[0]\n    fy_diff = (fy_ratio - 1).abs().max(-1)[0]\n    if (fx_diff > 0.01).any() or (fy_diff > 0.01).any():\n        warn_once_about_pulsar_fxfy()\n    fx = fx_mean\n    fy = fy_mean\n\n    # Compute principal points\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..."}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check if all inputs are batched\n    assert R.ndim == 3 and R.shape[1] == 3 and R.shape[2] == 3\n    assert tvec.ndim == 2 and tvec.shape[1] == 3\n    assert camera_matrix.ndim == 3 and camera_matrix.shape[1] == 3 and camera_matrix.shape[2] == 3\n    assert image_size.ndim == 2 and image_size.shape[1] == 2\n\n    # Check if all inputs have the same batch size\n    batch_size = R.shape[0]\n    assert tvec.shape[0] == batch_size\n    assert camera_matrix.shape[0] == batch_size\n    assert image_size.shape[0] == batch_size\n\n    # Check if all inputs have valid values\n    assert torch.all(R[..., 2, 2] == 1.0)\n    assert torch.all(camera_matrix[..., 0, 1] == 0.0)\n    assert torch.all(camera_matrix[..., 1, 0] == 0.0)\n    assert torch.all(camera_matrix[..., 2, 0] == 0.0)\n    assert torch.all(camera_matrix[..., 2, 1] == 0.0)\n    assert torch.all(camera_matrix[..., 2, 2] == 1.0)\n    assert torch.all(image_size > 0)\n\n    # Calculate focal lengths\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    fx_mean = fx.mean()\n    fy_mean = fy.mean()\n    if abs(fx_mean - fy_mean) / fx_mean > 0.01:\n        warn_once_about_pulsar_fxfy()\n    f = (fx_mean + fy_mean) * 0.5\n\n    # Calculate principal points\n    cx = camera_"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check that all inputs are batched.\n    assert R.ndim >= 2, \"R must be batched\"\n    assert tvec.ndim >= 2, \"tvec must be batched\"\n    assert camera_matrix.ndim >= 2, \"camera_matrix must be batched\"\n    assert image_size.ndim >= 2, \"image_size must be batched\"\n\n    # Check that all inputs have the same batch size.\n    assert R.shape[0] == tvec.shape[0], \"R and tvec must have the same batch size\"\n    assert R.shape[0] == camera_matrix.shape[0], \"R and camera_matrix must have the same batch size\"\n    assert R.shape[0] == image_size.shape[0], \"R and image_size must have the same batch size\"\n\n    # Check that all inputs have the correct shape.\n    assert R.shape[-2:] == (3, 3), \"R must have shape (..., 3, 3)\"\n    assert tvec.shape[-1] == 3, \"tvec must have shape (..., 3)\"\n    assert camera_matrix.shape[-2:] == (3, 3), \"camera_matrix must have shape (..., 3, 3)\"\n    assert image_size.shape[-1] == 2, \"image_size must have shape (..., 2)\"\n\n    # Check that all inputs have valid values.\n    assert torch.allclose(R @ R.transpose(-2, -1), torch.eye(3), atol=1e-4), \"R must be a valid rotation matrix\"\n    assert torch.all(image_size > 0), \"image_size must be positive\"\n\n    # Extract the focal lengths from the camera matrix.\n    fx, fy = camera_matrix[..., 0, 0], camera_matrix[..., 1, 1]\n\n    # Compute the principal points from the camera matrix.\n    cx, cy = camera_matrix[..., 0, 2], camera_matrix[..., 1, 2]\n\n    #"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if R.ndim == 2:\n        R = R[None]\n    if tvec.ndim == 2:\n        tvec = tvec[None]\n    if camera_matrix.ndim == 2:\n        camera_matrix = camera_matrix[None]\n    if image_size.ndim == 1:\n        image_size = image_size[None, :]\n\n    # Make sure the inputs are batched\n    assert R.ndim == 3 and tvec.ndim == 3 and camera_matrix.ndim == 3 and image_size.ndim == 2\n\n    # Make sure the batch sizes match\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n\n    # Make sure the batch sizes match\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n\n    # Make sure the batch sizes match\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n\n    # Make sure the batch sizes match\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n\n    # Make sure the batch sizes match\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n\n    # Make sure the batch sizes match\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n\n    # Make sure the batch sizes match\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n\n    # Make sure the batch sizes match\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n\n    # Make"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check batch shapes\n    assert R.ndim == tvec.ndim == camera_matrix.ndim == image_size.ndim == 2\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n\n    # Check camera matrix and image size shape\n    assert camera_matrix.shape[1] == 3 and camera_matrix.shape[2] == 3\n    assert image_size.shape[1] == 2\n\n    # Check image size values\n    assert (image_size > 0).all()\n\n    # Check camera matrix values\n    assert (camera_matrix[..., 0, 0] > 0).all()\n    assert (camera_matrix[..., 1, 1] > 0).all()\n    assert (camera_matrix[..., 0, 2] > 0).all()\n    assert (camera_matrix[..., 0, 2] < image_size[..., 0]).all()\n    assert (camera_matrix[..., 1, 2] > 0).all()\n    assert (camera_matrix[..., 1, 2] < image_size[..., 1]).all()\n\n    # Check focal lengths\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    fx_fy_ratio = fx / fy\n    if not torch.allclose(fx_fy_ratio, fx_fy_ratio[0], atol=0.01):\n        warn_once_about_pulsar_fxfy()\n    fx = fy = (fx + fy) / 2\n\n    # Check principal points\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n    cx_cy_ratio = cx / cy\n    if not torch.allclose(cx_cy_ratio, cx_cy_ratio[0], atol=0.01"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check that all inputs are batched and have the correct shape\n    assert R.ndim >= 2 and R.shape[-2:] == (3, 3)\n    assert tvec.ndim >= 2 and tvec.shape[-1] == 3\n    assert camera_matrix.ndim >= 2 and camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.ndim >= 1 and image_size.shape[-1] == 2\n\n    # Ensure that all inputs have the same batch size\n    assert R.shape[:-2] == tvec.shape[:-1] == camera_matrix.shape[:-2] == image_size.shape[:-1]\n\n    # Extract the batch size from the input shapes\n    batch_size = R.shape[:-2]\n\n    # Check that the camera matrix is valid\n    assert torch.all(camera_matrix[..., 0, 0] > 0)\n    assert torch.all(camera_matrix[..., 1, 1] > 0)\n    assert torch.all(camera_matrix[..., 2, 2] == 1)\n\n    # Check that the image size is valid\n    assert torch.all(image_size > 0)\n\n    # Compute the focal length from the camera matrix\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    if not torch.allclose(fx, fy, rtol=0.01):\n        warn_once_about_pulsar_fxfy()\n    f = (fx + fy) / 2\n\n    # Compute the principal point offset from the camera matrix and image size\n    cx = camera_matrix[..., 0, 2] - image_size[..., 0] / 2\n    cy = camera_matrix[..., 1, 2] - image_size[..., 1] / 2\n\n    # Compute the sensor width from the focal length and image size\n    sensor_width = 2 * torch.atan(image"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check that all inputs are batched and of the correct shape\n    assert R.ndim == 3 and R.shape[-2:] == (3, 3)\n    assert tvec.ndim == 2 and tvec.shape[-1] == 3\n    assert camera_matrix.ndim == 3 and camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.ndim == 2 and image_size.shape[-1] == 2\n\n    # Check that the batch sizes of all inputs are the same\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n\n    # Check that the focal lengths in the camera matrix are valid\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    assert torch.allclose(fx, fy, rtol=0.01)\n\n    # Compute the camera position\n    cam_pos = -R.transpose(-1, -2) @ tvec[..., None]\n\n    # Compute the camera rotation\n    cam_rot = matrix_to_rotation_6d(R)\n\n    # Compute the focal length and sensor width\n    f = fx[..., 0]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n    w = f * znear\n    h = w * image_size[..., 1] / image_size[..., 0]\n\n    # Adjust the principal point offset and normalize the focal length\n    cx = (cx - image_size[..., 0] / 2) / image_size[..., 0]\n    cy = (cy - image_size[..., 1] / 2) / image_size[..., 1]\n    f = f / image_size[..., 0]\n\n    # Warn if the focal lengths for x and y differ by more than 1%\n    if not tor"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Ensure all inputs are batched and valid\n    assert R.ndim == 3 and R.shape[-2:] == (3, 3)\n    assert tvec.ndim == 2 and tvec.shape[-1] == 3\n    assert camera_matrix.ndim == 3 and camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.ndim == 2 and image_size.shape[-1] == 2\n\n    # Compute camera position\n    cam_pos = -R.transpose(-1, -2) @ tvec[..., None]  # (B, 3, 1)\n\n    # Compute camera rotation\n    cam_rot = matrix_to_rotation_6d(R)  # (B, 6)\n\n    # Compute camera focal lengths\n    fx = camera_matrix[..., 0, 0] / image_size[..., 0]  # (B,)\n    fy = camera_matrix[..., 1, 1] / image_size[..., 1]  # (B,)\n    fx_mean = fx.mean()\n    fy_mean = fy.mean()\n    if (fx - fx_mean).abs().max() / fx_mean > 0.01 or (fy - fy_mean).abs().max() / fy_mean > 0.01:\n        warn_once_about_pulsar_fxfy()\n    fx = fx_mean\n    fy = fy_mean\n\n    # Compute camera principal point offsets\n    cx = camera_matrix[..., 0, 2] / image_size[..., 0] - 0.5  # (B,)\n    cy = camera_matrix[..., 1, 2] / image_size[..., 1] - 0.5  # (B,)\n\n    # Compute camera sensor width\n    sensor_width = 2 * fx.mean() * znear  # (B,)\n\n    # Stack camera parameters into a single tensor\n    cam_params = torch.cat([cam_pos"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    assert R.ndim == 3, \"R must be a batch of rotation matrices\"\n    assert tvec.ndim == 2, \"tvec must be a batch of translation vectors\"\n    assert camera_matrix.ndim == 3, \"camera_matrix must be a batch of camera intrinsic matrices\"\n    assert image_size.ndim == 2, \"image_size must be a batch of image sizes\"\n\n    # Extract focal lengths and principal points from the camera matrix\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Adjust principal points for the image size\n    cx = cx - image_size[..., 0] / 2\n    cy = cy - image_size[..., 1] / 2\n\n    # Normalize the focal lengths\n    fx = fx / image_size[..., 0]\n    fy = fy / image_size[..., 1]\n\n    # Compute the camera position\n    t = -R.transpose(-1, -2) @ tvec[..., None]\n\n    # Compute the camera rotation\n    rot = matrix_to_rotation_6d(R)\n\n    # Compute the focal length\n    f = (fx + fy) / 2\n    f = f / znear\n\n    # Compute the principal point offsets\n    ox = (cx / image_size[..., 0]) * 2 - 1\n    oy = (cy / image_size[..., 1]) * 2 - 1\n\n    # Compute the sensor width\n    sx = 2 * torch.arctan(image_size[..., 0] / (2 * fx))\n    sy = 2 * torch.arctan(image_size[..., 1] / (2 * fy))\n\n    # Concatenate the camera parameters\n    camera_params = torch.cat"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate inputs\n    if R.ndim != 3 or tvec.ndim != 2 or camera_matrix.ndim != 2 or image_size.ndim != 1:\n        raise ValueError(\"All inputs must be batched.\")\n    if R.shape[-1] != 3 or R.shape[-2] != 3 or tvec.shape[-1] != 3:\n        raise ValueError(\"Invalid rotation matrix shape.\")\n    if camera_matrix.shape[-1] != 3 or camera_matrix.shape[-2] != 3:\n        raise ValueError(\"Invalid camera matrix shape.\")\n    if image_size.shape[0] != 2:\n        raise ValueError(\"Invalid image size shape.\")\n\n    # Extract focal lengths and principal points from camera matrix\n    fx, fy = camera_matrix[..., 0, 0], camera_matrix[..., 1, 1]\n    cx, cy = camera_matrix[..., 0, 2], camera_matrix[..., 1, 2]\n\n    # Compute focal length and sensor width\n    focal_length = (fx + fy) / 2\n    sensor_width = focal_length * image_size[0] / max(fx, fy)\n\n    # Adjust principal point offsets and normalize focal length\n    if (abs(fx - fy) / focal_length) > 0.01:\n        warn_once_about_pulsar_fxfy()\n    cx = cx - image_size[0] / 2\n    cy = cy - image_size[1] / 2\n    focal_length = focal_length / max(image_size)\n\n    # Compute camera position and rotation\n    camera_position = -R.transpose(-1, -2) @ tvec[..., None]\n    camera_rotation = matrix_to_rotation_6d(R.transpose(-1, -2))\n\n    # Combine camera parameters into a single tensor\n    camera_params = torch.cat(\n        (\n            camera_position[..., 0],\n            camera_rot"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate inputs\n    assert R.ndim == 3 and R.shape[-2:] == (3, 3)\n    assert tvec.ndim == 2 and tvec.shape[-1] == 3\n    assert camera_matrix.ndim == 3 and camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.ndim == 2 and image_size.shape[-1] == 2\n\n    # Calculate focal lengths\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    if not torch.allclose(fx, fy, rtol=0.01):\n        warn_once_about_pulsar_fxfy()\n    f = (fx + fy) / 2\n\n    # Calculate principal point offsets\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n    px = (cx / f - image_size[..., 0] / 2) / image_size[..., 0]\n    py = (cy / f - image_size[..., 1] / 2) / image_size[..., 1]\n\n    # Calculate camera rotation\n    R = matrix_to_rotation_6d(R)\n\n    # Calculate camera position\n    t = tvec\n\n    # Calculate sensor width\n    sw = torch.tensor(0.032, dtype=tvec.dtype, device=tvec.device)\n\n    # Stack camera parameters into a single tensor\n    camera_params = torch.stack([f, px, py, R, t, sw], dim=-1)\n\n    return camera_params\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Check if all inputs are batched\n    assert R.ndim >= 2\n    assert tvec.ndim >= 2\n    assert camera_matrix.ndim >= 2\n    assert image_size.ndim >= 1\n\n    # Check if all inputs have the same batch size\n    assert R.shape[0] == tvec.shape[0]\n    assert R.shape[0] == camera_matrix.shape[0]\n\n    # Check if the batch sizes of camera_matrix and image_size are the same\n    assert camera_matrix.shape[0] == image_size.shape[0]\n\n    # Check if the last two dimensions of R are 3x3\n    assert R.shape[-2:] == (3, 3)\n\n    # Check if the last dimension of tvec is 3\n    assert tvec.shape[-1] == 3\n\n    # Check if the last two dimensions of camera_matrix are 3x3\n    assert camera_matrix.shape[-2:] == (3, 3)\n\n    # Check if the last dimension of image_size is 2\n    assert image_size.shape[-1] == 2\n\n    # Check if znear is a positive scalar\n    assert znear > 0\n\n    # Check if the first element of image_size is greater than 0\n    assert image_size[..., 0] > 0\n    assert image_size[..., 1] > 0\n\n    # Check if the diagonal elements of camera_matrix are positive\n    assert torch.all(torch.diagonal(camera_matrix, dim1=-2, dim2=-1) > 0)\n\n    # Check if the first two elements of the diagonal elements of camera_matrix are equal\n    assert torch.allclose(camera_matrix[..., 0, 0], camera_matrix[..., 1, 1], atol=1e-2)\n\n    # Check if the elements of tvec are finite\n    assert torch.isfinite(tvec).all()\n\n    # Check if the elements of camera_matrix are finite\n    assert torch.isfinite(camera_matrix).all()"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if R.ndim == 2:\n        R = R[None, ...]\n    if tvec.ndim == 2:\n        tvec = tvec[None, ...]\n    if camera_matrix.ndim == 2:\n        camera_matrix = camera_matrix[None, ...]\n    if image_size.ndim == 1:\n        image_size = image_size[None, ...]\n\n    # Ensure the batch dimensions match\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n    assert R.shape[1] == R.shape[2] == 3\n    assert tvec.shape[1] == 3\n    assert camera_matrix.shape[1] == camera_matrix.shape[2] == 3\n    assert image_size.shape[1] == 2\n\n    # Get the focal lengths\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    fx_mean = fx.mean(dim=-1, keepdim=True)\n    fy_mean = fy.mean(dim=-1, keepdim=True)\n    if torch.any(torch.abs(fx - fx_mean) > 0.01 * fx_mean) or torch.any(torch.abs(fy - fy_mean) > 0.01 * fy_mean):\n        warn_once_about_pulsar_fxfy()\n    fx = fx_mean\n    fy = fy_mean\n\n    # Get the principal points\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Get the sensor width\n    sensor_width = camera_matrix[..., 0, 2] * 2\n\n    # Adjust the principal point offsets\n    cx = cx - (image_size[..., 0] - 1) / 2\n    cy = cy - (image_size"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    assert R.ndim == 3 and tvec.ndim == 2 and camera_matrix.ndim == 3 and image_size.ndim == 2\n    assert R.shape[0] == tvec.shape[0] == camera_matrix.shape[0] == image_size.shape[0]\n    assert R.shape[1] == R.shape[2] == 3\n    assert tvec.shape[1] == 3\n    assert camera_matrix.shape[1] == camera_matrix.shape[2] == 3\n    assert image_size.shape[1] == 2\n\n    # Compute the camera position\n    # The camera position is calculated by multiplying the rotation matrix with the translation vector and negating the result.\n    camera_position = -R @ tvec\n\n    # Compute the camera rotation\n    # The camera rotation is calculated by converting the rotation matrix to a 6D representation using the matrix_to_rotation_6d function.\n    camera_rotation = matrix_to_rotation_6d(R)\n\n    # Compute the focal length and principal point\n    # The focal length is calculated by taking the average of the focal lengths in the x and y directions of the camera matrix, and normalizing it by the image width. The principal point is calculated by taking the principal points in the x and y directions of the camera matrix, and normalizing them by the image size.\n    fx, fy = (camera_matrix[..., 0, 0] + camera_matrix[..., 1, 1]) / 2, (camera_matrix[..., 0, 0] + camera_matrix[..., 1, 1]) / 2\n    cx, cy = camera_matrix[..., 0, 2] / image_size[..., 0], camera_matrix[..., 1, 2] / image_size[..., 1]\n\n    # Compute the sensor width\n    # The sensor width is calculated by multiplying the focal length by the image width and dividing it by the image height.\n    sensor_width = fx * image_size[..., 0] / image_size[..., 1"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    assert R.ndim == 3 and R.shape[-2:] == (3, 3)\n    assert tvec.ndim == 2 and tvec.shape[-1] == 3\n    assert camera_matrix.ndim == 3 and camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.ndim == 2 and image_size.shape[-1] == 2\n    assert znear > 0\n\n    # get the focal lengths and principal points\n    fx, fy = camera_matrix[..., 0, 0], camera_matrix[..., 1, 1]\n    cx, cy = camera_matrix[..., 0, 2], camera_matrix[..., 1, 2]\n\n    # get the image width and height\n    width, height = image_size[..., 0], image_size[..., 1]\n\n    # calculate the focal length and sensor width\n    focal_length = (fx + fy) / 2\n    sensor_width = focal_length * max(width, height)\n\n    # adjust the principal point offsets and normalize the focal length\n    cx = cx - width / 2\n    cy = cy - height / 2\n    focal_length = focal_length / max(width, height)\n\n    # check if the focal lengths for x and y differ by more than 1%\n    if abs(fx - fy) / max(fx, fy) > 0.01:\n        warn_once_about_pulsar_fxfy()\n\n    # calculate the camera position\n    cam_pos = -R.transpose(-2, -1) @ tvec[..., None]\n    cam_pos = cam_pos[..., 0]\n\n    # calculate the camera rotation\n    cam_rot = matrix_to_rotation_6d(R)\n\n    # calculate the camera intrinsic parameters\n    cam_intrinsics = torch.stack(\n        [focal_length, cx, cy, znear, sensor_width], dim=-1\n    )\n\n    # concatenate the camera parameters into a single tensor"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    # Validate inputs\n    assert R.ndim == 3 and R.shape[-2:] == (3, 3)\n    assert tvec.ndim == 2 and tvec.shape[-1] == 3\n    assert camera_matrix.ndim == 3 and camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.ndim == 2 and image_size.shape[-1] == 2\n\n    # Extract camera parameters from camera matrix\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Compute focal length and sensor width\n    f = (fx + fy) * 0.5\n    sensor_width = 2 * (cx - 0.5 * image_size[..., 0]).abs() / f\n\n    # Compute camera position\n    camera_pos = -R.transpose(-1, -2) @ tvec[..., None]\n\n    # Compute camera rotation\n    camera_rot = matrix_to_rotation_6d(R)\n\n    # Compute focal length and principal point offsets\n    fx = fy = f\n    cx = -(cx - 0.5 * image_size[..., 0]) / f\n    cy = (cy - 0.5 * image_size[..., 1]) / f\n\n    # Adjust focal length based on znear\n    f = f * znear / (0.5 * image_size[..., 0] / f)\n\n    # Normalize focal length\n    fx = fx / f\n    fy = fy / f\n\n    # Stack camera parameters into a single tensor\n    camera_params = torch.cat(\n        [camera_pos, camera_rot, fx[..., None], fy[..., None], cx[..., None], cy[..., None], sensor_width[..., None]], dim="}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    batch_size = R.shape[0]\n    assert R.shape == (batch_size, 3, 3)\n    assert tvec.shape == (batch_size, 3, 1)\n    assert camera_matrix.shape == (batch_size, 3, 3)\n    assert image_size.shape == (batch_size, 2)\n\n    # Compute focal length from camera intrinsic matrix\n    fx = camera_matrix[:, 0, 0]\n    fy = camera_matrix[:, 1, 1]\n    fx_mean = fx.mean()\n    fy_mean = fy.mean()\n    if abs(fx_mean - fy_mean) / fx_mean > 0.01:\n        warn_once_about_pulsar_fxfy()\n    f = 0.5 * (fx + fy)\n    f = f[:, None]\n\n    # Compute principal point from camera intrinsic matrix\n    cx = camera_matrix[:, 0, 2]\n    cy = camera_matrix[:, 1, 2]\n    cx = cx - image_size[:, 0] / 2.0 + 0.5\n    cy = cy - image_size[:, 1] / 2.0 + 0.5\n    cx = cx[:, None]\n    cy = cy[:, None]\n\n    # Compute sensor width from camera intrinsic matrix\n    sensor_width = 2.0 * (image_size[:, 0] / 2.0) / f\n    sensor_width = sensor_width[:, None]\n\n    # Compute camera position from translation vector\n    campos = -R.transpose(-1, -2) @ tvec\n    campos = campos[:, :, 0]\n\n    # Compute camera rotation from rotation matrix\n    R_flat = R.reshape(-1, 9)\n    R_flat = R_flat[:, [0, 3, 6, 1, 4, 7, 2, 5, 8]]\n    R_flat = R_flat.resh"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    if R.ndim == 2:\n        R = R.unsqueeze(0)\n    if tvec.ndim == 1:\n        tvec = tvec.unsqueeze(0)\n    if camera_matrix.ndim == 2:\n        camera_matrix = camera_matrix.unsqueeze(0)\n    if image_size.ndim == 1:\n        image_size = image_size.unsqueeze(0)\n    assert R.ndim == 3 and R.shape[1:] == (3, 3)\n    assert tvec.ndim == 2 and tvec.shape[1] == 3\n    assert camera_matrix.ndim == 3 and camera_matrix.shape[1:] == (3, 3)\n    assert image_size.ndim == 2 and image_size.shape[1] == 2\n\n    # We assume that the camera is facing the -z axis.\n    R_world2cv = R.transpose(-1, -2)\n    camera_position = -R_world2cv @ tvec.unsqueeze(-1)\n\n    # Rotation is represented as 6D vector.\n    # We use the representation by Zhou et al. [1]\n    # (https://github.com/facebookresearch/pulsar/issues/11#issuecomment-489735490)\n    # but invert x and y axes by multiplying by -1.\n    # [1] Zhou, Y., Barnes, C., Lu, J., Yang, J., & Li, H.\n    # On the Continuity of Rotation Representations in Neural Networks.\n    # IEEE Conference on Computer Vision and Pattern Recognition, 2019.\n    # Retrieved from http://arxiv.org/abs/1812.07035\n    camera_rotation = matrix_to_rotation_6d(R_world2cv)\n\n    # Camera focal length is the first diagonal element of the camera matrix.\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pulsar_camera_params", "completion": "    assert R.ndim == 3 and R.shape[-2:] == (3, 3)\n    assert tvec.ndim == 2 and tvec.shape[-1] == 3\n    assert camera_matrix.ndim == 3 and camera_matrix.shape[-2:] == (3, 3)\n    assert image_size.ndim == 2 and image_size.shape[-1] == 2\n\n    # Calculate focal length from camera intrinsic matrix\n    fx = camera_matrix[..., 0, 0]\n    fy = camera_matrix[..., 1, 1]\n    cx = camera_matrix[..., 0, 2]\n    cy = camera_matrix[..., 1, 2]\n\n    # Calculate sensor width from focal length and image size\n    sensor_width = fx * image_size[..., 0] / fy\n\n    # Calculate principal point offset from image size and focal length\n    px = (cx - image_size[..., 0] / 2) / fx\n    py = (image_size[..., 1] / 2 - cy) / fy\n\n    # Calculate camera position from rotation and translation vectors\n    cam_pos = torch.cat([tvec, torch.ones_like(tvec[..., :1])], dim=-1) @ R.mT\n\n    # Calculate rotation in 6D representation\n    cam_rot = matrix_to_rotation_6d(R)\n\n    # Calculate focal length in Pulsar format\n    f = fx.new_zeros(fx.shape + (6,))\n    f[..., 0] = fx\n    f[..., 1] = fy\n    f[..., 2] = fx\n    f[..., 3] = fy\n    f[..., 4] = cx\n    f[..., 5] = cy\n\n    # Calculate znear and zfar based on camera position and focal length\n    zfar = cam_pos[..., 2] + znear\n\n    # Normalize focal length"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        w = w or self.W\n        h = h or self.H\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        use_gl_program(self.quad_program)\n        gl.glBindVertexArray(self.vao)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n        gl.glBindVertexArray(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit()\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        # Set up viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Activate shader program and bind texture\n        gl.glUseProgram(self.quad_program)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw quadrilateral\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n        gl.glBindVertexArray(0)\n\n        # Restore viewport and scissor box\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor_box)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            old_fbo = gl.glGetIntegerv(gl.GL_FRAMEBUFFER_BINDING)\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, self.fbo)\n            gl.glBlitFramebuffer(x, y, w or self.W, h or self.H,\n                                 x, y, w or self.W, h or self.H,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n            gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, old_fbo)\n            return\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w or self.W, h or self.H)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n        gl.glBindVertexArray(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit()\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        # Setup viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Activate shader program and bind texture\n        gl.glUseProgram(self.quad_program)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw quadrilateral\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n        gl.glBindVertexArray(0)\n\n        # Restore viewport and scissor box\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glBindVertexArray(0)\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit()\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        use_gl_program(self.quad_program)\n        gl.glBindVertexArray(self.vao)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        # Set up viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Activate shader program\n        use_gl_program(self.quad_program)\n\n        # Bind texture\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw quad\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n        gl.glBindVertexArray(0)\n\n        # Restore viewport and scissor box\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit()\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        use_gl_program(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        gl.glBindVertexArray(0)\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit()\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        # Set up the viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor_box = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Use the quad shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind the texture\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n        gl.glBindVertexArray(0)\n\n        # Restore the viewport and scissor box\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor_box)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit(x, y, w, h)\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n\n        if not self.use_quad_draw:\n            self.blit()\n            return\n\n        # Setup viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Activate shader program\n        gl.glUseProgram(self.quad_program)\n\n        # Bind texture\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw quadrilateral\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n        gl.glBindVertexArray(0)\n\n        # Restore viewport and scissor box\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit()\n            return\n\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n\n        w = w or self.W\n        h = h or self.H\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        use_gl_program(self.quad_program)\n\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit()\n            return\n\n        w = w or self.W\n        h = h or self.H\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit()  # no uploading needed\n            return\n\n        w = w or self.W\n        h = h or self.H\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glEnable(gl.GL_SCISSOR_TEST)\n\n        gl.glUseProgram(self.quad_program)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)\n        gl.glDisable(gl.GL_SCISSOR_TEST)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit()\n            return\n\n        # Set up viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        w = w or self.W\n        h = h or self.H\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Use shader program\n        use_gl_program(self.quad_program)\n\n        # Bind texture\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw quadrilateral\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n        gl.glBindVertexArray(0)\n\n        # Restore viewport and scissor box\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n\n        if not self.use_quad_draw:\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, self.fbo)\n            gl.glBlitFramebuffer(x, y, w, h,\n                                 x, y, w, h,\n                                 gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n            gl.glBindFramebuffer(gl.GL_DRAW_FRAMEBUFFER, 0)\n            return\n\n        # Setup viewport and scissor box\n        old_vp = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_sc = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Draw the quad\n        gl.glUseProgram(self.quad_program)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n        gl.glBindVertexArray(0)\n\n        # Restore viewport and scissor box\n        gl.glViewport(*old_vp)\n        gl.glScissor(*old_sc)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit()\n            return\n\n        # Set the viewport and scissor box\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w or self.W, h or self.H)\n        gl.glScissor(x, y, w or self.W, h or self.H)\n\n        # Activate the shader program and bind the texture\n        gl.glUseProgram(self.quad_program)\n        gl.glActiveTexture(gl.GL_TEXTURE0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n\n        if not self.use_quad_draw:\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glCopyTexSubImage2D(gl.GL_TEXTURE_2D, 0, x, y, x, y, w, h)\n            return\n\n        # Set up the viewport and scissor box for rendering\n        old_viewport = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        old_scissor = gl.glGetIntegerv(gl.GL_SCISSOR_BOX)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n\n        # Activate the shader program and bind the texture\n        use_gl_program(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n\n        # Draw the quadrilateral using vertex data\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n\n        # Restore the viewport and scissor box to their original sizes\n        gl.glViewport(*old_viewport)\n        gl.glScissor(*old_scissor)\n\n        # Restore the OpenGL state\n        gl.glBindVertexArray(0)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        if not self.use_quad_draw:\n            self.blit()\n            return\n\n        w = w or self.W\n        h = h or self.H\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        use_gl_program(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, len(self.verts))\n        gl.glBindVertexArray(0)\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.draw", "completion": "        w = w or self.W\n        h = h or self.H\n        if not self.use_quad_draw:\n            gl.glViewport(x, y, w, h)\n            gl.glScissor(x, y, w, h)\n            gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n            gl.glBlitFramebuffer(0, 0, w, h, x, y, w, h, gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n            return\n\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)\n        gl.glUseProgram(self.quad_program)\n        gl.glBindTexture(gl.GL_TEXTURE_2D, self.tex)\n        gl.glBindVertexArray(self.vao)\n        gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)\n        gl.glBindVertexArray(0)\n        gl.glViewport(0, 0, self.W, self.H)\n        gl.glScissor(0, 0, self.W, self.H)\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    R[..., 0] *= -1  # flip x\n    R[..., 1] *= -1  # flip y\n    R[..., 2] *= -1  # flip z\n    T[..., 0] *= -1  # flip x\n    T[..., 1] *= -1  # flip y\n    T[..., 2] *= -1  # flip z\n    K[..., 0, 0] *= -1  # flip x\n    K[..., 0, 2] *= -1  # flip x\n    K[..., 1, 1] *= -1  # flip y\n    K[..., 1, 2] *= -1  # flip y\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # !: BATCH\n    R[..., 0] *= -1  # flip x\n    R[..., 1] *= -1  # flip y\n    R[..., 2] *= -1  # flip z\n    T[..., 0] *= -1  # flip x\n    T[..., 1] *= -1  # flip y\n    T[..., 2] *= -1  # flip z\n\n    # !: BATCH\n    K[..., 0, 2] = W - K[..., 0, 2]  # flip x\n    K[..., 1, 2] = H - K[..., 1, 2]  # flip y\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # R = R.mT\n    # T = -R.mT @ T\n    K[..., 0, 0] *= W\n    K[..., 1, 1] *= H\n    K[..., 0, 2] *= W\n    K[..., 1, 2] *= H\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # !: BATCH\n    K[..., 0, 0] = K[..., 0, 0] / W\n    K[..., 1, 1] = K[..., 1, 1] / H\n    K[..., 0, 2] = K[..., 0, 2] / W\n    K[..., 1, 2] = K[..., 1, 2] / H\n    K[..., 0, 1] = 0\n    K[..., 1, 0] = 0\n    K[..., 2, 0] = 0\n    K[..., 2, 1] = 0\n    K[..., 2, 2] = 1\n    R[..., 0, 1] *= -1\n    R[..., 1, 0] *= -1\n    R[..., 0, 2] *= -1\n    R[..., 2, 0] *= -1\n    R[..., 1, 2] *= -1\n    R[..., 2, 1] *= -1\n    T[..., 0] *= -1\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R and T for PyTorch3D\n    R = R.permute(0, 2, 1)\n    T = T * -1\n\n    # Compute intrinsic matrix for NDC\n    K = K.clone()\n    K[..., 0, 0] = K[..., 0, 0] / W\n    K[..., 1, 1] = K[..., 1, 1] / H\n    K[..., 0, 2] = K[..., 0, 2] / W - 0.5\n    K[..., 1, 2] = K[..., 1, 2] / H - 0.5\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust rotation matrix for PyTorch3D\n    R = R.permute(0, 2, 1)  # B, 3, 3\n    R[:, 0, :] *= -1\n    R[:, 1, :] *= -1\n\n    # Adjust translation vector for PyTorch3D\n    T = T * -1\n\n    # Recalculate intrinsic matrix for NDC\n    ixt = get_ndc_perspective_matrix(K, H, W, 1, 1).to(R.dtype)  # to opengl, remove last dim of n and f\n    K = ixt[..., :3, :3]\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust rotation and translation\n    R = R.mT  # B, 3, 3\n    T = T * -1  # B, 3, 1\n\n    # Compute intrinsic matrix for NDC\n    K = K.clone()\n    K[..., 0, 0] = 2 / W\n    K[..., 1, 1] = 2 / H\n    K[..., 0, 2] = -1\n    K[..., 1, 2] = -1\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Convert to pytorch3d coordinate system\n    # R = R.mT\n    # T = -R @ T\n    # K = K.clone()\n    # K[..., 0, 2] = W / 2 - K[..., 0, 2]\n    # K[..., 1, 2] = H / 2 - K[..., 1, 2]\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Transform from OpenCV camera coordinates to PyTorch3D camera coordinates\n    R[..., 0] *= -1\n    R[..., 1] *= -1\n    T[..., 0] *= -1\n    T[..., 1] *= -1\n\n    # Compute the intrinsic matrix for normalized device coordinates (NDC)\n    K = get_ndc_perspective_matrix(K, H, W, 1, 1).to(R.dtype)\n\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # !: BATCH\n    # R = R.permute(0, 2, 1)  # !: BATCH\n    # T = -R.mT @ T  # B, 3, 1\n    # K[..., 0, 2] -= W / 2\n    # K[..., 1, 2] -= H / 2\n    # K[..., 0, 0] /= W\n    # K[..., 1, 1] /= H\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # R = R.mT\n    # T = -R.mT @ T\n    K = K.clone()\n    K[..., 0, 0] *= 2 / W\n    K[..., 1, 1] *= 2 / H\n    K[..., 0, 2] = -2 * K[..., 0, 2] / W + 1\n    K[..., 1, 2] = -2 * K[..., 1, 2] / H + 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    K[..., 0] *= W / 2  # !: BATCH\n    K[..., 1] *= H / 2  # !: BATCH\n    K[..., 2] = K[..., 2] - 0.5 + W / 2  # !: BATCH\n    K[..., 3] = K[..., 3] - 0.5 + H / 2  # !: BATCH\n    K[..., 0, 0] /= W  # !: BATCH\n    K[..., 1, 1] /= H  # !: BATCH\n    K[..., 0, 2] /= W  # !: BATCH\n    K[..., 1, 2] /= H  # !: BATCH\n    R = R.mT  # B, 3, 3\n    T = T.mT  # B, 3, 1\n    C = C.mT  # B, 3, 1\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # !: BATCH\n    # !: BATCH\n    # B, 3, 3\n    # B, 3, 3\n    # B, 3, 1\n\n    # Adjust rotation matrix (R)\n    R = R.permute(0, 2, 1)  # B, 3, 3\n    # Adjust translation vector (T)\n    T = T * -1  # B, 3, 1\n    # Compute camera intrinsic matrix for NDC\n    K = get_ndc_perspective_matrix(K, H, W, 1, 1)  # B, 3, 3\n    K = K[..., :2, :]  # B, 3, 2\n    # Return the adjusted parameters\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Transform to pytorch3d convention\n    R = R.permute(0, 2, 1)\n    T = T.permute(0, 2, 1)\n    K = K.permute(0, 2, 1)\n    K[..., 0] *= -1\n    K[..., 1] *= -1\n    K[..., 2] *= -1\n    K[..., 0, 2] *= -1\n    K[..., 1, 2] *= -1\n    K[..., 2, 2] *= -1\n    K[..., 2, 0] *= -1\n    K[..., 2, 1] *= -1\n    K[..., 2, 2] *= -1\n    K[..., 2, 2] += 1\n    K[..., 2, 2] *= 0.5\n    K[..., 2, 0] += 0.5\n    K[..., 2, 1] += 0.5\n    return H, W, K, R, T, C"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n\n    # Adjust R to match PyTorch3D's requirements\n    R_trans = R.permute(0, 2, 1)  # B, 3, 3\n\n    # Adjust T to match PyTorch3D's requirements\n    T_trans = -T  # B, 3, 1\n\n    # Compute intrinsic matrix for NDC\n    K_ndc = get_ndc_perspective_matrix(K, H, W)\n\n    return H, W, K_ndc, R_trans, T_trans, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # Transformations\n    R = R.permute(0, 2, 1)  # B, 3, 3\n    R[:, 0] *= -1\n    R[:, 1] *= -1\n    T[:, 0] *= -1\n    T[:, 1] *= -1\n    C = C.permute(0, 2, 1)\n    # Intrinsic matrix\n    K = K.clone()\n    K[:, 0, 2] = W / 2\n    K[:, 1, 2] = H / 2\n    K[:, 0, 0] = K[:, 0, 0] / W\n    K[:, 1, 1] = K[:, 1, 1] / H\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.fcds_utils.get_pytorch3d_camera_params", "completion": "    H = batch.meta.H[0].item()  # !: BATCH\n    W = batch.meta.W[0].item()  # !: BATCH\n    K = batch.K\n    R = batch.R\n    T = batch.T\n    C = -batch.R.mT @ batch.T  # B, 3, 1\n    # !: BATCH\n    # R = torch.cat([R, torch.zeros_like(R[..., :1])], dim=-1)\n    # R = torch.cat([R, torch.zeros_like(R[..., :1, :1])], dim=-2)\n    # R[..., -1, -1] = 1\n    # R[..., -1, -2] = 0\n    # R[..., -2, -1] = 0\n    # R[..., -2, -2] = 1\n    # T[..., -1] = 0\n    # K = torch.eye(4, device=K.device, dtype=K.dtype)\n    # K[..., :2, :3] = K\n    # K[..., :2, 2] = K[..., :2, 2] / 2\n    # K[..., :2, :2] *= -1\n    # K[..., :2, 2] += 1\n    # K[..., 2, 2] = 1\n    # K[..., 2, 3] = -1\n    # K[..., 3, 3] = 1\n    return H, W, K, R, T, C\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        _, _, W, H = gl.glGetIntegerv(gl.GL_VIEWPORT)\n        gl.glViewport(x, y, w, h)\n        gl.glScissor(x, y, w, h)  # only render in this small region of the viewport\n\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(0, 0, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n\n        # Some house keepings\n        gl.glViewport(0, 0, W, H)\n        gl.glScissor(0, 0, W, H)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n\n        old_read_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_read_fbo)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old = gl.glGetInteger(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old)\n"}
{"namespace": "easyvolcap.utils.gl_utils.Quad.blit", "completion": "        w = w or self.W\n        h = h or self.H\n        old_fbo = gl.glGetIntegerv(gl.GL_READ_FRAMEBUFFER_BINDING)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, self.fbo)  # read buffer defaults to 0\n        gl.glBlitFramebuffer(x, y, w, h,\n                             x, y, w, h,\n                             gl.GL_COLOR_BUFFER_BIT, gl.GL_NEAREST)\n        gl.glBindFramebuffer(gl.GL_READ_FRAMEBUFFER, old_fbo)\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of y1\n    cumulative_y1 = torch.cumsum(y1, dim=-1)\n\n    # Find the indices of t1 that are less than or equal to t0\n    indices = searchsorted(t1, t0)\n\n    # Compute the inner measure using the cumulative sum of y1\n    inner = torch.gather(cumulative_y1, -1, indices)\n\n    # Compute the outer measure using the cumulative sum of y1 and the indices\n    outer = torch.gather(cumulative_y1, -1, torch.clamp(indices - 1, min=0))\n\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Calculate the cumulative sum of y1\n    cumulative_y1 = torch.cumsum(y1, dim=-1)\n\n    # Find the indices where t1 is less than t0\n    indices = searchsorted(t1, t0)\n\n    # Construct the inner measure\n    inner_measure = torch.take_along_dim(cumulative_y1, indices.unsqueeze(-1), dim=-1)\n\n    # Construct the outer measure\n    outer_measure = torch.cat([torch.zeros_like(inner_measure[..., :1]), inner_measure], dim=-1)\n\n    return inner_measure, outer_measure"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of y1\n    cumulative_sum = torch.cumsum(y1, dim=-1)\n\n    # Compute the inner and outer measures\n    inner = torch.searchsorted(t1, t0[..., :, None], side='right') - 1\n    inner = torch.clamp(inner, min=0)\n    outer = inner + 1\n\n    # Compute the inner and outer measures\n    inner_measure = torch.gather(cumulative_sum, dim=-1, index=inner)\n    outer_measure = torch.gather(cumulative_sum, dim=-1, index=outer)\n\n    return inner_measure, outer_measure"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of y1\n    y1_cum = torch.cumsum(y1, dim=-1)\n\n    # Compute the cumulative sum of y1_cum\n    y1_cum_cum = torch.cumsum(y1_cum, dim=-1)\n\n    # Compute the inner measure\n    inner = torch.searchsorted(t1, t0, side='right')\n    inner = torch.clamp(inner - 1, min=0)\n    inner = y1_cum_cum.gather(-1, inner)\n\n    # Compute the outer measure\n    outer = torch.searchsorted(t1, t0, side='left')\n    outer = torch.clamp(outer - 1, min=0)\n    outer = y1_cum_cum.gather(-1, outer)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the inner and outer measures\n    # The inner measure is the cumulative sum of y1 up to the index of the first t1 value that is greater than t0\n    # The outer measure is the cumulative sum of y1 up to the index of the last t1 value that is less than t0\n    inner = torch.searchsorted(t1, t0, side=\"right\")\n    outer = torch.searchsorted(t1, t0, side=\"left\")\n\n    # Return the inner and outer measures as a tuple\n    return inner, outer"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    with torch.no_grad():\n        s_inner = torch.minimum(t1, t0[..., :, None])\n        s_outer = torch.maximum(t1, t0[..., :, None])\n\n        y0_inner = torch.cumsum(s_inner * y1, dim=-1)\n        y0_outer = torch.cumsum(s_outer * y1, dim=-1)\n\n        dt = torch.clip(t1[..., 1:] - t1[..., :-1], 1e-8, None)\n        y0_outer = torch.nan_to_num(y0_outer[..., 1:] / dt, nan=0.0)\n\n    return y0_inner, y0_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of y1\n    y1_cum = torch.cumsum(y1, dim=-1)\n\n    # Compute the inner measure\n    y0 = torch.zeros_like(t0)\n    y0[..., 1:] = torch.diff(y1_cum, dim=-1)\n\n    # Compute the outer measure\n    y0_cum = torch.cumsum(y0, dim=-1)\n    y0_outer = torch.zeros_like(y0_cum)\n    y0_outer[..., 1:] = y0_cum[..., :-1]\n    y0_outer = y0_cum - y0_outer\n\n    return y0, y0_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of the source values\n    y1_cum = torch.cumsum(y1, dim=-1)\n\n    # Compute the index of the source time that is closest to the target time\n    idx = searchsorted(t1, t0)\n\n    # Compute the inner measure\n    y0_inner = y1_cum[..., idx]\n\n    # Compute the outer measure\n    y0_outer = torch.cat([y1_cum[..., :-1], torch.zeros_like(y1_cum[..., :1])], dim=-1)[..., idx]\n\n    return y0_inner, y0_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the inner measure\n    inner = torch.where((t0[..., :, None] >= t1[..., None, :]) & (t0[..., :, None] < t1[..., None, :]), y1[..., None, :], 0.0)\n    inner = torch.sum(inner, dim=-1)\n\n    # Compute the outer measure\n    outer = torch.where((t0[..., :, None] >= t1[..., None, :]) & (t0[..., :, None] < t1[..., None, :]), y1[..., None, :], y1[..., None, -1:])\n    outer = torch.sum(outer, dim=-1)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of the values (y1)\n    y1_cum = torch.cumsum(y1, dim=-1)\n\n    # Compute the inner measure using cumulative sum\n    y0_inner = torch.zeros_like(t0)\n    y0_inner[t0 >= t1[..., :1]] = y1_cum[..., -1]\n    inds = searchsorted(t1, t0)\n    inds = torch.maximum(torch.zeros_like(inds), inds - 1)\n    y0_inner[t0 < t1[..., :1]] = torch.gather(y1_cum, -1, inds)\n\n    # Compute the outer measure using cumulative sum\n    y0_outer = torch.zeros_like(t0)\n    y0_outer[t0 <= t1[..., :1]] = y1_cum[..., 0]\n    inds = searchsorted(t1, t0)\n    y0_outer[t0 > t1[..., :1]] = torch.gather(y1_cum, -1, inds)\n\n    return y0_inner, y0_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the inner measure using cumulative sums\n    inner = (t0 - t1).abs().min(dim=-1, keepdim=True)[0]\n\n    # Compute the outer measure using cumulative sums\n    outer = ((t0 - t1).abs().sum(dim=-1, keepdim=True) - inner).relu()\n\n    # Return the inner and outer measures\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of y1.\n    y1_cum = torch.cumsum(y1, dim=-1)\n    # Compute the cumulative sum of y1, but shifted by one element to the right.\n    y1_cum_shift = F.pad(y1_cum, (1, 0), mode=\"constant\", value=0.0)\n\n    # Compute the indices of t0 in t1 using searchsorted.\n    t0_idx = searchsorted(t1, t0)\n    # Compute the indices of t0 in t1, but shifted by one element to the right, using searchsorted.\n    t0_idx_shift = searchsorted(t1, t0, side=\"right\")\n\n    # Compute the inner measure using the cumulative sum of y1 and the indices of t0 in t1.\n    y0_inner = y1_cum[..., t0_idx]\n    # Compute the outer measure using the cumulative sum of y1, the indices of t0 in t1, and the indices of t0 in t1, but shifted by one element to the right.\n    y0_outer = (y1_cum_shift[..., t0_idx_shift] - y1_cum_shift[..., t0_idx]) / (\n        t1[..., t0_idx_shift] - t1[..., t0_idx] + 1e-10\n    )\n\n    return y0_inner, y0_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of the values (y1)\n    cumulative_y1 = torch.cumsum(y1, dim=-1)\n\n    # Compute the inner measure for the target time (t0)\n    # by finding the nearest time (t1) that is less than or equal to t0\n    # and using the corresponding cumulative sum (cumulative_y1) as the inner measure\n    inner = torch.searchsorted(t1, t0[..., :, None], side='right') - 1\n    inner = torch.clip(inner, min=0)\n    inner = torch.gather(cumulative_y1, dim=-1, index=inner)\n\n    # Compute the outer measure for the target time (t0)\n    # by finding the nearest time (t1) that is greater than t0\n    # and using the corresponding cumulative sum (cumulative_y1) as the outer measure\n    outer = torch.searchsorted(t1, t0[..., :, None], side='left')\n    outer = torch.clip(outer, max=y1.shape[-1] - 1)\n    outer = torch.gather(cumulative_y1, dim=-1, index=outer)\n\n    return inner, outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    with torch.cuda.amp.autocast(enabled=False):\n        # Compute the inner measure using cumulative sum\n        y0_inner = torch.cat([torch.zeros_like(y1[..., :1]), torch.cumsum(y1, dim=-1)], dim=-1)\n\n        # Compute the outer measure using cumulative sum\n        y0_outer = torch.cat([torch.zeros_like(y1[..., :1]), torch.cumsum(y1, dim=-1)], dim=-1)\n\n        # Interpolate the outer measure using linear interpolation\n        y0_outer = torch.lerp(y0_outer[..., :-1], y0_outer[..., 1:], t0[..., None])\n\n    return y0_inner, y0_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the inner measure using cumulative sums\n    y0 = torch.cumsum(y1, dim=-1)\n    y0 = torch.cat([torch.zeros_like(y0[..., :1]), y0], dim=-1)\n    y0 = y0[..., :-1]\n\n    # Compute the outer measure using cumulative sums\n    y1 = torch.cumsum(y1, dim=-1)\n    y1 = torch.cat([torch.zeros_like(y1[..., :1]), y1], dim=-1)\n    y1 = y1[..., :-1]\n\n    return y0, y1\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Calculate the cumulative sum of y1.\n    y1_cum = torch.cumsum(y1, dim=-1)\n\n    # Calculate the inner measure by subtracting the cumulative sum of y1 from y1.\n    y0_inner = y1 - torch.cat([torch.zeros_like(y1_cum[..., :1]), y1_cum[..., :-1]], dim=-1)\n\n    # Calculate the outer measure by subtracting the cumulative sum of y1 from the target time (t0).\n    y0_outer = t0 - torch.cat([torch.zeros_like(y1_cum[..., :1]), y1_cum[..., :-1]], dim=-1)\n\n    return y0_inner, y0_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Calculate the cumulative sum of y1\n    cumulative_y1 = torch.cumsum(y1, dim=-1)\n    # Add a zero at the beginning of the cumulative sum\n    cumulative_y1 = torch.cat([torch.zeros_like(cumulative_y1[..., :1]), cumulative_y1], dim=-1)\n\n    # Find the indices where t0 is greater than t1\n    indices = searchsorted(t1, t0)\n    # Calculate the inner measure using the cumulative sum of y1\n    inner_measure = torch.gather(cumulative_y1, -1, indices[..., None])\n    # Calculate the outer measure using the cumulative sum of y1\n    outer_measure = torch.gather(cumulative_y1, -1, indices[..., None] + 1)\n\n    return inner_measure, outer_measure\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of the source values\n    c1 = torch.cumsum(y1, dim=-1)\n\n    # Compute the inner measure\n    y0 = torch.interp(t0, t1, y1)\n\n    # Compute the outer measure\n    y0_outer = torch.interp(t0, t1, c1)\n\n    # Return the inner and outer measures\n    return y0, y0_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    t0 = t0.reshape(-1)\n    t1 = t1.reshape(-1)\n    y1 = y1.reshape(-1)\n\n    assert t0.shape == t1.shape\n    assert t0.shape == y1.shape\n\n    # Construct inner and outer measures\n    inner, _ = torch.sort(torch.cat([t0.unsqueeze(-1), t1.unsqueeze(-1)], dim=-1), dim=-1)\n    outer = torch.cat([inner[:, :-1], inner[:, -1:]], dim=-1)\n\n    # Compute the difference between consecutive elements in the sorted tensor\n    diff = torch.diff(inner, n=1, dim=-1)\n\n    # Compute the cumulative sum of the difference tensor\n    cumsum = torch.cumsum(diff, dim=-1)\n\n    # Compute the inner measure\n    inner_measure = torch.cat([cumsum, torch.zeros_like(cumsum[:, :1])], dim=-1)\n\n    # Compute the outer measure\n    outer_measure = torch.cat([torch.zeros_like(cumsum[:, :1]), cumsum], dim=-1)\n\n    # Interpolate the values at the target times using the inner and outer measures\n    inner_values = torch.sum(inner_measure * y1.unsqueeze(-1), dim=-1) / torch.sum(\n        inner_measure, dim=-1\n    )\n    outer_values = torch.sum(outer_measure * y1.unsqueeze(-1), dim=-1) / torch.sum(\n        outer_measure, dim=-1\n    )\n\n    # Interpolate the values at the target times using the inner and outer measures\n    inner_values = torch.sum(inner_measure * y1.unsqueeze(-1), dim=-1) / torch.sum(\n        inner_measure, dim=-1\n    )\n    outer_values = tor"}
{"namespace": "easyvolcap.utils.loss_utils.inner_outer", "completion": "    # Compute the cumulative sum of y1\n    cumulative_sum = torch.cumsum(y1, dim=-1)\n\n    # Compute the inner measure\n    inner_measure = torch.zeros_like(t0)\n    for i in range(t0.shape[0]):\n        for j in range(t0.shape[1]):\n            inner_measure[i, j] = torch.sum(\n                y1[i, j, : searchsorted(t1[i, j], t0[i, j])], dim=-1\n            )\n\n    # Compute the outer measure\n    outer_measure = torch.zeros_like(t0)\n    for i in range(t0.shape[0]):\n        for j in range(t0.shape[1]):\n            outer_measure[i, j] = torch.sum(\n                y1[i, j, searchsorted(t1[i, j], t0[i, j]) :], dim=-1\n            )\n\n    return inner_measure, outer_measure\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_outer_left, w_outer_right = inner_outer(t, t_env, w_env)\n    w_outer = torch.where(w_outer_left < w_outer_right, w_outer_left, w_outer_right)\n    loss_outer = torch.where(w < w_outer, torch.square(w - w_outer) / 4, torch.zeros_like(w))\n    loss_outer = torch.sum(loss_outer, dim=-1) / (torch.sum(w_outer, dim=-1) + eps)\n    return loss_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the inner and outer measures on (t_env, w_env) for t\n    w0_inner, w0_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the half-quadratic loss\n    loss_outer = torch.where(w0_outer > 0, 1 - w / (w0_outer + eps), torch.zeros_like(w0_outer)) ** 2\n    loss_outer = torch.sum(loss_outer * w0_outer, dim=-1) / (torch.sum(w0_outer, dim=-1) + eps)\n\n    return loss_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_outer, _ = inner_outer(t, t_env, w_env)\n    w_outer = w_outer[..., :-1]\n    w_outer = torch.maximum(w_outer, torch.zeros_like(w_outer))\n    w_outer = torch.minimum(w_outer, w[..., :-1])\n    loss_outer = (w_outer - w[..., :-1]) ** 2 * (0.5 * (t[..., 1:] - t[..., :-1]) / (w[..., :-1] + eps))\n    return loss_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate upper envelope\n    _, w_outer = inner_outer(t, t_env, w_env)\n\n    # calculate loss\n    loss_outer = (w - w_outer) ** 2 / (w_outer + eps)\n    loss_outer = loss_outer.sum(dim=-1)\n    return loss_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_outer_left, w_outer_right = inner_outer(t, t_env, w_env)\n\n    # calculate loss\n    loss_outer = w_outer_left - w_outer_right\n    loss_outer = loss_outer.abs()\n    loss_outer = loss_outer / (w + eps)\n    loss_outer = loss_outer.mean(dim=-1)\n\n    return loss_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the envelope weights\n    w_outer, _ = inner_outer(t, t_env, w_env)\n\n    # calculate the loss based on the difference between the target weights and the envelope weights\n    loss_outer = torch.where(w_outer < w, torch.square(w - w_outer), torch.zeros_like(w))\n\n    # scale the loss by a half-quadratic function\n    loss_outer = loss_outer / (w_outer + eps)\n\n    return loss_outer.sum(dim=-1)\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_env = w_env + eps\n    w_outer, _ = inner_outer(t, t_env, w_env)\n    loss_outer = torch.mean((w_outer - w) ** 2) / (2 * w_outer.mean())\n    return loss_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_outer, w_outer = inner_outer(t, t_env, w_env)\n    w_outer = torch.maximum(w_outer, torch.zeros_like(w_outer))\n    w_outer = torch.where(w_outer > 0, torch.maximum(w_outer, w[..., :-1]), torch.zeros_like(w_outer))\n    loss_outer = torch.mean(w_outer * torch.square(torch.relu(w - w_outer)) / 2)\n    return loss_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n    y0 = y0_inner + y0_outer\n    loss_outer = torch.where(y0 > 0, (1 - w / y0) ** 2, torch.zeros_like(y0))\n    loss_outer = torch.sum(loss_outer, dim=-1) / (torch.sum(y0 > 0, dim=-1) + eps)\n    return loss_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_outer, _ = inner_outer(t, t_env, w_env)\n    w_outer = w_outer.clip(0, 1)\n    w_outer = w_outer[..., None]\n\n    loss_outer = (w_outer - w[..., None, :]) ** 2\n    loss_outer = loss_outer.mean(dim=-1)\n    loss_outer = loss_outer * (1 / (2 * eps)) * (w_outer + eps)\n    return loss_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the upper envelope weights\n    w_outer = inner_outer(t, t_env, w_env)[1]\n    w_outer = w_outer / (torch.max(w_outer, dim=-1, keepdim=True)[0] + eps)\n\n    # calculate the loss based on the difference between target weights and the upper envelope\n    loss_outer = torch.mean(torch.square(torch.nn.functional.relu(w - w_outer)))\n\n    # scale the loss by a half-quadratic function\n    loss_outer = loss_outer * (1 - torch.sqrt(torch.clamp(w_outer, 0, 1)))\n\n    return loss_outer"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_outer = w[..., 1:] - w[..., :-1]\n    _, w_outer_env = inner_outer(t[..., 1:-1], t_env, w_env)\n    w_outer_env = torch.where(w_outer_env < 0, w_outer_env, 0)\n    w_outer = w_outer - w_outer_env\n    loss_outer = w_outer ** 2 / (w[..., :-1] + eps)\n    loss_outer = torch.where(w_outer < 0, loss_outer, 0)\n    loss_outer = loss_outer.sum(dim=-1)\n    return loss_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_outer = w[..., 1:] - w[..., :-1]\n    w_outer = torch.cat([w_outer, torch.zeros_like(w_outer[..., :1])], dim=-1)\n    w_outer = w_outer / (torch.max(torch.abs(w_outer), dim=-1, keepdim=True).values + eps)\n    w_outer = w_outer * (torch.abs(w_outer) > 1e-5).float()\n\n    y0_inner, y0_outer = inner_outer(t, t_env, w_env)\n    y0_outer = y0_outer / (torch.max(torch.abs(y0_outer), dim=-1, keepdim=True).values + eps)\n    y0_outer = y0_outer * (torch.abs(y0_outer) > 1e-5).float()\n\n    loss_outer = torch.sum(w_outer * torch.square(y0_outer - y0_inner), dim=-1)\n    return loss_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_outer, w_outer = inner_outer(t, t_env, w_env)\n    # t_outer: 128, w_outer: 128\n\n    # Calculate the difference between target weights and the upper envelope\n    w_diff = w - w_outer\n\n    # Calculate the half-quadratic loss\n    loss_outer = w_diff * w_diff / (4 * t_outer + eps)\n\n    # Scale the loss by the target weights\n    loss_outer = loss_outer * w\n\n    # Return the loss\n    return loss_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_outer, _ = inner_outer(t, t_env, w_env)\n    w_outer = w_outer.clamp(min=0)\n    w_outer = w_outer.max(dim=-1, keepdim=True).values\n    w_outer = w_outer[..., :-1]\n\n    w_diff = w - w_outer\n    w_diff = torch.where(w_diff > 0, w_diff, torch.zeros_like(w_diff))\n    w_diff = w_diff / (w + eps)\n    return w_diff.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    t_outer, w_outer = inner_outer(t, t_env, w_env)\n    w_outer = w_outer.detach()\n    loss_outer = (w_outer - w) ** 2 / (2 * w_outer + eps)\n    loss_outer = torch.where(w_outer > 0, loss_outer, 0)\n    return loss_outer.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_outer = w[..., 1:] - w[..., :-1]\n    w_inner, _ = inner_outer(t, t_env, w_env)\n    w_inner = torch.where(w_inner < 0, torch.zeros_like(w_inner), w_inner)\n    w_inner = torch.where(w_inner > 1, torch.ones_like(w_inner), w_inner)\n    w_inner = w_inner[..., :-1]\n    w_outer = torch.where(w_outer < 0, torch.zeros_like(w_outer), w_outer)\n    w_outer = torch.where(w_outer > 1, torch.ones_like(w_outer), w_outer)\n    w_outer = torch.cat([w_inner, w_outer], dim=-1)\n    w_outer = w_outer[..., :-1]\n    w_loss = w_outer * (w - w_outer)\n    w_loss = w_loss / (w_outer + eps)\n    w_loss = w_loss.sum(dim=-1)\n    return w_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_outer = (w - w_env[..., :-1])[..., :-1]  # 127\n    w_outer = torch.where(w_outer > 0, w_outer, torch.zeros_like(w_outer))  # 127\n    w_outer = torch.cat([torch.zeros_like(w_outer[..., :1]), w_outer, torch.zeros_like(w_outer[..., :1])], dim=-1)  # 130\n\n    s = (t[..., 1:] - t[..., :-1]) / (t_env[..., 1:] - t_env[..., :-1] + eps)\n    s = torch.cat([torch.ones_like(s[..., :1]), s, torch.ones_like(s[..., :1])], dim=-1)  # 130\n\n    loss_outer = (w_outer * (s - 1) ** 2).sum(dim=-1) / 2\n\n    return loss_outer"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    w_outer = w[..., :-1] + w[..., 1:]\n    w_outer = torch.cat([w_outer, w_outer[..., -1:]], dim=-1)\n\n    w_outer_env = w_env[..., :-1] + w_env[..., 1:]\n    w_outer_env = torch.cat([w_outer_env, w_outer_env[..., -1:]], dim=-1)\n\n    w_outer_env = torch.maximum(w_outer_env, w_outer)\n\n    w_outer_env = w_outer_env / (eps + torch.max(w_outer_env[..., :-1], dim=-1, keepdim=True).values)\n\n    t_outer = (t[..., 1:] + t[..., :-1]) / 2\n    t_outer = torch.cat([t[..., :1], t_outer, t[..., -1:]], dim=-1)\n\n    w_outer_env_inner, w_outer_env_outer = inner_outer(t_outer, t_env, w_outer_env)\n\n    loss_outer = (w_outer_env_outer - w_outer_env_inner) ** 2 / 4\n    loss_outer = loss_outer[..., :-1]\n\n    loss_outer = loss_outer.sum(dim=-1)\n\n    return loss_outer\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_outer", "completion": "    # calculate the inner and outer measures on the environment weights\n    w_env_inner, w_env_outer = inner_outer(t, t_env, w_env)\n\n    # calculate the inner and outer measures on the target weights\n    w_inner, w_outer = inner_outer(t_env, t, w)\n\n    # calculate the scaled half-quadratic loss based on the difference between target weights and the upper envelope\n    loss_outer = (torch.abs(w - w_env_outer) * w_env_outer) ** 2 / 4\n\n    # calculate the scaled half-quadratic loss based on the difference between target weights and the inner envelope\n    loss_inner = (torch.abs(w - w_env_inner) * w_env_inner) ** 2 / 4\n\n    # calculate the scaled half-quadratic loss based on the difference between target weights and the outer envelope\n    loss_outer = (torch.abs(w - w_outer) * w_outer) ** 2 / 4\n\n    # calculate the scaled half-quadratic loss based on the difference between target weights and the inner envelope\n    loss_inner = (torch.abs(w - w_inner) * w_inner) ** 2 / 4\n\n    # calculate the loss by adding the scaled half-quadratic losses for the outer and inner envelopes\n    loss = loss_outer + loss_inner\n\n    # return the calculated loss\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # inter-interval loss\n    loss_inter = lossfun_outer(t, w, t, w)\n\n    # intra-interval loss\n    loss_intra = lossfun_zip_outer(t, w, t, w, pulse_width=1.0)\n\n    return loss_inter + loss_intra"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # Compute the inter-interval loss\n    inter_interval_loss = lossfun_outer(t, w, t, w)\n\n    # Compute the intra-interval loss\n    intra_interval_loss = (w[..., 1:] - w[..., :-1]).clip(0.).pow(2) / (w[..., 1:] + w[..., :-1] + torch.finfo(torch.float32).eps)\n\n    # Combine the inter-interval and intra-interval losses\n    distortion_loss = inter_interval_loss + intra_interval_loss\n\n    return distortion_loss.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # inter-interval loss\n    loss_inter = (w[..., 1:] - w[..., :-1]).abs()\n\n    # intra-interval loss\n    loss_intra = (w[..., 1:] + w[..., :-1]).abs()\n\n    # combine the losses\n    loss = loss_inter + loss_intra\n\n    return loss.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # Inter-interval loss\n    t_inter = (t[..., 1:] + t[..., :-1]) / 2\n    w_inter = torch.abs(w[..., 1:] - w[..., :-1])\n    loss_inter = w_inter * torch.abs(t_inter - t[..., :-1])\n\n    # Intra-interval loss\n    t_intra = t[..., 1:] - t[..., :-1]\n    w_intra = w[..., 1:] + w[..., :-1]\n    loss_intra = w_intra * torch.abs(t_intra - (t[..., 1:] - t[..., :-1]))\n\n    # Combine the losses\n    loss = loss_inter + loss_intra\n\n    return loss.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    # Inter-interval loss\n    loss_inter = (w[..., 1:] - w[..., :-1]).clip(0.).pow(2)\n\n    # Intra-interval loss\n    loss_intra = (w[..., 1:] * (t[..., 1:] - t[..., :-1])).clip(0.).pow(2)\n\n    # Combine the losses\n    loss = loss_inter + loss_intra\n\n    return loss.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # Ensure that the tensors have the same number of dimensions\n    assert t.shape[:-1] == w.shape[:-1]\n\n    # Ensure that the last dimension of 't' is one more than that of 'w'\n    assert t.shape[-1] == w.shape[-1] + 1\n\n    # Match the channels of 't' and 'w'\n    t, w = matchup_channels(t, w)\n\n    # Calculate the inter-interval loss\n    inter_loss = lossfun_outer(t, w, t, w)\n\n    # Calculate the intra-interval loss\n    intra_loss = lossfun_zip_outer(t, w, t, w, 0.01)\n\n    # Combine the inter-interval and intra-interval losses\n    loss = inter_loss + intra_loss\n\n    # Return the calculated distortion loss\n    return loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    w_normalize = w / torch.clamp_min(t[..., 1:] - t[..., :-1], torch.finfo(torch.float32).eps)\n\n    t_, w_ = blur_stepfun(t, w_normalize, 0.01)\n    w_ = torch.clip(w_, min=0.)\n    assert (w_ >= 0.0).all()\n\n    # piecewise linear pdf to piecewise quadratic cdf\n    area = 0.5 * (w_[..., 1:] + w_[..., :-1]) * (t_[..., 1:] - t_[..., :-1])\n\n    cdf = torch.cat([torch.zeros_like(area[..., :1]), torch.cumsum(area, dim=-1)], dim=-1)\n\n    # query piecewise quadratic interpolation\n    cdf_interp = sorted_interp_quad(t, t_, w_, cdf)\n    # difference between adjacent interpolated values\n    w_s = torch.diff(cdf_interp, dim=-1)\n\n    # inter-interval loss\n    loss_inter = ((w_s - w_normalize).clip(0.).pow(2) / (w_normalize + torch.finfo(torch.float32).eps)).mean()\n\n    # intra-interval loss\n    loss_intra = ((w_normalize - w).clip(0.).pow(2) / (w + torch.finfo(torch.float32).eps)).mean()\n\n    return loss_inter + loss_intra\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    # Calculate the inter-interval loss\n    t_inter, w_inter = inner_outer(t, t, w)\n    loss_inter = (w_inter - w).clip(0.).pow(2) / (w + 1e-6)\n\n    # Calculate the intra-interval loss\n    t_intra, w_intra = inner_outer(t, t, w)\n    loss_intra = (w_intra - w).clip(0.).pow(2) / (w + 1e-6)\n\n    # Combine the inter- and intra-interval losses\n    loss_distortion = loss_inter + loss_intra\n\n    return loss_distortion"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # Compute inter-interval loss\n    inter_loss = ((w[..., 1:] - w[..., :-1])**2).sum(-1)\n\n    # Compute intra-interval loss\n    intra_loss = ((w[..., 1:] + w[..., :-1]) *\n                  (t[..., 1:] - t[..., :-1])).sum(-1)\n\n    # Combine inter- and intra-interval losses\n    loss = inter_loss + intra_loss\n\n    return loss.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # compute inter-interval loss\n    _, w_outer = inner_outer(t, t, w)\n    loss_inter = (w - w_outer).clip(0.).pow(2) / (w + 1e-6)\n    loss_inter = loss_inter.sum(-1)\n\n    # compute intra-interval loss\n    w_inner, _ = inner_outer(t, t, w)\n    loss_intra = (w - w_inner).clip(0.).pow(2) / (w + 1e-6)\n    loss_intra = loss_intra.sum(-1)\n\n    # combine both losses\n    loss = loss_inter + loss_intra\n\n    return loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # inter-interval\n    w_outer = inner_outer(t, t, w)[1]\n    w_outer = w_outer.clamp_min(0.)\n\n    # intra-interval\n    w_inner = inner_outer(t, t, w)[0]\n    w_inner = w_inner.clamp_min(0.)\n\n    # combine\n    w_outer = w_outer.pow(2) / (w_inner + w_outer + 1e-6)\n    return w_outer.mean()"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # Calculate the inter-interval loss\n    w_outer = inner_outer(t, t, w)[1]\n    w_outer = torch.where(w_outer < 0, w_outer, 0.)\n    w_outer = w_outer.clip(0.)\n\n    # Calculate the intra-interval loss\n    w_inner = inner_outer(t, t, w)[0]\n    w_inner = torch.where(w_inner > 0, w_inner, 0.)\n    w_inner = w_inner.clip(0.)\n\n    # Combine the inter-interval and intra-interval losses\n    w_distortion = w_inner + w_outer\n\n    return w_distortion"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # inter-interval loss\n    w_outer = inner_outer(t, t, w)[1]\n    w_outer = w_outer[..., 1:-1]\n    w_outer = torch.clip(w_outer, min=0.)\n    assert (w_outer >= 0.0).all()\n\n    # intra-interval loss\n    w_inner = inner_outer(t, t, w)[0]\n    w_inner = w_inner[..., 1:-1]\n    w_inner = torch.clip(w_inner, min=0.)\n    assert (w_inner >= 0.0).all()\n\n    # combine\n    loss_distortion = w_inner.pow(2) / (w_outer + torch.finfo(torch.float32).eps)\n    return loss_distortion.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # inter-interval loss\n    t_inter = (t[..., 1:] + t[..., :-1]) / 2\n    w_inter = w[..., 1:] + w[..., :-1]\n    w_inter = torch.clamp_min(w_inter, 0)\n    loss_inter = torch.abs(t_inter * w_inter).sum(-1)\n\n    # intra-interval loss\n    t_intra = t[..., 1:] - t[..., :-1]\n    w_intra = w[..., 1:] + w[..., :-1]\n    w_intra = torch.clamp_min(w_intra, 0)\n    loss_intra = torch.abs(t_intra * w_intra).sum(-1)\n\n    return loss_inter + loss_intra"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # Ensure 't' and 'w' have the same number of dimensions.\n    t, w = matchup_channels(t, w)\n\n    # Calculate the inter-interval loss.\n    # The inter-interval loss is the sum of the squares of the differences between adjacent elements of 'w' multiplied by the differences between adjacent elements of 't'.\n    inter_loss = (w[..., 1:] - w[..., :-1]).pow(2) * (t[..., 1:] - t[..., :-1])\n\n    # Calculate the intra-interval loss.\n    # The intra-interval loss is the sum of the squares of the differences between adjacent elements of 'w' multiplied by the differences between adjacent elements of 't'.\n    intra_loss = (w[..., 1:] + w[..., :-1]).pow(2) * (t[..., 1:] - t[..., :-1])\n\n    # Combine the inter-interval and intra-interval losses to produce the total distortion loss.\n    # The total loss is the sum of the inter-interval and intra-interval losses.\n    loss = (inter_loss + intra_loss).sum(-1)\n\n    # Return the calculated distortion loss as a tensor.\n    return loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    \"\"\"\n    Computes the inter-interval and intra-interval losses for a given tensor of targets and weights. The inter-interval loss is calculated by taking the difference between adjacent elements in 'w' and squaring the result. The intra-interval loss is calculated by taking the difference between adjacent elements in 't' and squaring the result. The total distortion loss is obtained by summing the inter-interval and intra-interval losses.\n\n    Input-Output Arguments\n    :param t: torch.Tensor. The target tensor for which the distortion loss is to be calculated. It is expected that the last dimension of 't' is one more than that of 'w'.\n    :param w: torch.Tensor. The weights tensor, used to weight the distortion loss calculation. The last dimension of 'w' should be one less than that of 't'.\n    :return: torch.Tensor. The calculated distortion loss as a tensor. This combines both inter-interval and intra-interval losses.\n    \"\"\"\n\n    # inter-interval loss\n    loss_inter = (w[..., 1:] - w[..., :-1]).pow(2)\n\n    # intra-interval loss\n    loss_intra = (t[..., 1:] - t[..., :-1]).pow(2)\n\n    # total distortion loss\n    loss = loss_inter + loss_intra\n\n    return loss.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # Inter-interval loss\n    # Compute the outer measures of the proposal weights on the nerf weights\n    w_outer = inner_outer(t, t, w)[1]\n    # Compute the loss based on the outer measures\n    w_outer_loss = (w_outer - w).clip(0.).pow(2) / (w + 1e-6)\n\n    # Intra-interval loss\n    # Compute the inner measures of the proposal weights on the nerf weights\n    w_inner = inner_outer(t, t, w)[0]\n    # Compute the loss based on the inner measures\n    w_inner_loss = (w_inner - w).clip(0.).pow(2) / (w + 1e-6)\n\n    # Combine the inter-interval and intra-interval losses\n    distortion_loss = (w_outer_loss + w_inner_loss).mean()\n\n    return distortion_loss"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    # Ensure the tensors have the same number of dimensions\n    assert t.ndim == w.ndim\n\n    # Match the number of channels of 't' and 'w'\n    t, w = matchup_channels(t, w)\n\n    # Calculate the inter-interval loss\n    inter_loss = lossfun_outer(t, w, t[..., 1:], w[..., :-1])\n\n    # Calculate the intra-interval loss\n    intra_loss = lossfun_zip_outer(t, w, t[..., 1:], w[..., :-1], 0.5 * (t[..., 1:] - t[..., :-1]))\n\n    # Combine the inter-interval and intra-interval losses\n    distortion_loss = inter_loss + intra_loss\n\n    # Return the total distortion loss\n    return distortion_loss\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n\n    # Calculate the inter-interval loss\n    inter_loss = (w[..., :-1] - w[..., 1:]).abs()\n\n    # Calculate the intra-interval loss\n    intra_loss = (w[..., 1:] - w[..., :-1]).abs()\n\n    # Combine the inter-interval and intra-interval losses\n    distortion_loss = inter_loss + intra_loss\n\n    return distortion_loss.mean()\n\n"}
{"namespace": "easyvolcap.utils.loss_utils.lossfun_distortion", "completion": "    t, w = matchup_channels(t, w)\n    # Interval loss\n    # ---------------\n    # We use the outer function to compute the interval loss.\n    # The outer function computes the upper envelope of the proposal weights\n    # and calculates the loss between the proposal weights and the envelope.\n    # The interval loss is calculated as the mean of the loss values across all dimensions.\n    interval_loss = lossfun_outer(t, w, t, w).mean()\n\n    # Intra-interval loss\n    # ------------------\n    # We use the zip_outer function to compute the intra-interval loss.\n    # The zip_outer function computes the upper envelope of the proposal weights\n    # and calculates the loss between the proposal weights and the envelope.\n    # The intra-interval loss is calculated as the mean of the loss values across all dimensions.\n    intra_interval_loss = lossfun_zip_outer(t, w, t, w, 0.01).mean()\n\n    # Combine the interval and intra-interval losses\n    # ---------------------------------------------\n    # The total distortion loss is computed as the sum of the interval and intra-interval losses.\n    distortion_loss = interval_loss + intra_interval_loss\n\n    return distortion_loss"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device), w, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw0 = integrate_weights(w)\n    return interpolate(ps, cw0, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    cw_s = cw.new_tensor(ps)\n    return interpolate(cw_s, cw, t)"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = integrate_weights(w)\n    return interpolate(ps, w, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device), cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = w.contiguous()\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w_shape = w.shape\n    w = w.reshape(-1, w_shape[-1])\n    cw = integrate_weights(w)\n    cw_shape = cw.shape\n    cw = cw.reshape(-1, cw_shape[-1])\n    out = interpolate(ps, cw, t)\n    out = out.reshape(w_shape[:-1] + (len(ps),))\n    return out\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = w.contiguous()\n    cw = integrate_weights(w)\n    cw_diff = torch.cat([cw[..., 1:] - cw[..., :-1], cw.new_ones(cw[..., :1].shape)], dim=-1)\n    index = torch.searchsorted(cw, ps, side='right') - 1\n    index = torch.clip(index, 0, cw.shape[-1] - 1)\n    lower = torch.gather(cw, dim=-1, index=index)\n    upper = torch.gather(cw, dim=-1, index=index + 1)\n    weight = (ps - lower) / cw_diff.gather(dim=-1, index=index)\n    t0 = torch.gather(t, dim=-1, index=index)\n    t1 = torch.gather(t, dim=-1, index=index + 1)\n    return lower + weight * (upper - lower)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device), w, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw0 = integrate_weights(w)\n    return interpolate(torch.tensor(ps, device=t.device), cw0, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    return interpolate(ps, cw, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = integrate_weights(w)\n    return interpolate(ps, w, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    cw_diff = cw[..., 1:] - cw[..., :-1]\n    assert (cw_diff >= 0).all(), \"weights must be non-negative and sum to 1\"\n    indices = torch.searchsorted(cw[..., 1:].contiguous(), ps)\n    w_below = (cw_diff > 0).float()\n    cp = (ps - cw[..., indices].contiguous()) / cw_diff\n    w_below = w_below[..., indices].contiguous()\n    t0 = t[..., indices].contiguous()\n    t1 = t[..., indices + 1].contiguous()\n    return w_below * (t0 + cp * (t1 - t0)) + (1 - w_below) * t0\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = w / torch.sum(w, dim=-1, keepdim=True)\n    cw0 = integrate_weights(w)\n    cw1 = torch.cat([cw0[..., 1:2], cw0[..., 1:]], dim=-1)\n    ps = torch.tensor(ps, device=cw0.device, dtype=cw0.dtype)\n    return interpolate(ps[None, None], cw0, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    cw0 = integrate_weights(w)\n    cw1 = cw0[..., 1:]\n    cw0 = cw0[..., :-1]\n    t0, t1 = t[..., :-1], t[..., 1:]\n    cw_total = cw1 - cw0\n    w0_interp = (cw0 - cw_total * t0) / (t1 - t0 + 1e-8)\n    w1_interp = (cw1 - cw_total * t1) / (t1 - t0 + 1e-8)\n    t_interp = torch.lerp(t0, t1, ps[..., None])\n    w_interp = torch.lerp(w0_interp, w1_interp, ps[..., None])\n    w_interp = w_interp.clip(0.0, 1.0)\n    return interpolate(t_interp, cw0, t)\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w = w.contiguous()\n    cw0 = integrate_weights(w)\n    cw1 = cw0[..., 1:]\n    cw0 = cw0[..., :-1]\n    t0 = t[..., :-1]\n    t1 = t[..., 1:]\n    w0 = w[..., :-1]\n    w1 = w[..., 1:]\n    # Interpolate it all.\n    bins_smaller = cw0\n    bins_larger = cw1\n    # gather(dim, index)\n    # dim (int) \u2013 the dimension along which to index\n    # index (LongTensor or IntTensor) \u2013 the indices of elements to gather\n    # out = bins_smaller.gather(dim=-1, index=indices)\n    # bins_smaller.shape: torch.Size([1, 1, 1, 64])\n    # indices.shape: torch.Size([1, 1, 1, 3])\n    # out.shape: torch.Size([1, 1, 1, 3])\n    indices = torch.searchsorted(bins_smaller, ps[..., None]).clip(max=bins_smaller.shape[-1] - 1)\n    out = bins_smaller.gather(dim=-1, index=indices)\n    # out.shape: torch.Size([1, 1, 1, 3])\n    # bins_larger.shape: torch.Size([1, 1, 1, 64])\n    # indices.shape: torch.Size([1, 1, 1, 3])\n    # out.shape: torch.Size([1, 1, 1, 3])\n    out += (bins_larger - bins_smaller).gather(dim=-1, index=indices)\n    # out.shape: torch.Size([1, 1, 1, 3])"}
{"namespace": "easyvolcap.utils.prop_utils.weighted_percentile", "completion": "    t, w = matchup_channels(t, w)\n    w_shape = w.shape\n    w = w.reshape(-1, w_shape[-1])\n    cw = integrate_weights(w)\n    cw_shape = cw.shape\n    cw = cw.reshape(-1, cw_shape[-1])\n    t = t.reshape(-1, t.shape[-1])\n    t_new = interpolate(torch.tensor(ps, device=t.device), cw, t)\n    t_new = t_new.reshape(*w_shape[:-1], len(ps))\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Generate 'batch_size' intervals.\n    batch_size = t.shape[0]\n\n    # Get pdf\n    pmf = w / torch.sum(w, -1, keepdim=True)\n    cdf = torch.cumsum(pmf, -1)\n    cdf = torch.cat([torch.zeros_like(cdf[..., :1]), cdf], -1)\n    cdf = cdf.contiguous()\n\n    # Take uniform samples\n    if perturb:\n        u = torch.rand(batch_size, num_samples, device=t.device)\n        u = u.contiguous()\n    else:\n        u = torch.linspace(0., 1., num_samples, device=t.device)\n        u = u.expand(batch_size, num_samples)\n        u = u.contiguous()\n\n    # Invert CDF. This takes advantage of the fact that `u` is sorted.\n    indices = torch.searchsorted(cdf, u, right=True)\n    below = torch.max(torch.zeros_like(indices - 1), indices - 1)\n    above = torch.min((cdf.shape[-1] - 1) * torch.ones_like(indices), indices)\n    indices_g = torch.stack([below, above], -1)\n\n    matched_shape = [indices_g.shape[0], indices_g.shape[1], cdf.shape[-1]]\n    cdf_g = torch.gather(cdf.unsqueeze(1).expand(matched_shape), 2, indices_g)\n    bins_g = torch.gather(t.unsqueeze(1).expand(matched_shape), 2, indices_g)\n\n    denom = (cdf_g[..., 1] - cdf_g[..., 0])\n    denom = torch.where(denom < 1e-5, torch.ones_like(denom), denom"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Draw uniform samples.\n    u = torch.linspace(0.0, 1.0, num_samples, device=t.device)\n    # Draw samples from the PDF.\n    t_new = invert_cdf(u, t, w)\n    # Perturb and apply padding.\n    if perturb:\n        t_new = perturb_and_pad_samples(t_new, t, w)\n    # Apply the same jitter to every sample along each dimension.\n    if single_jitter:\n        t_new = apply_single_jitter(t_new)\n    # Otherwise, apply independent jitter to each sample.\n    else:\n        t_new = apply_independent_jitter(t_new)\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Draw uniform samples.\n    if perturb:\n        # Uniformly sample without replacement from the bins.\n        u = torch.linspace(0. + 1e-5, 1. - 1e-5, num_samples, device=t.device)\n        u = u + (torch.rand_like(u) - 0.5) * (1. / num_samples)\n    else:\n        # Uniformly sample with replacement from the bins.\n        u = torch.rand(num_samples, device=t.device)\n    # Invert the CDF.\n    t_new = invert_cdf(u, t, w)\n    if single_jitter:\n        # Apply the same jitter to every sample.\n        jitter = (torch.rand_like(t_new[..., :1]) - 0.5) * (1. / num_samples)\n        t_new = t_new + jitter\n    else:\n        # Apply independent jitter to each sample.\n        jitter = (torch.rand_like(t_new) - 0.5) * (1. / num_samples)\n        t_new = t_new + jitter\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Draw uniform samples.\n    u = torch.linspace(0.0, 1.0, num_samples, device=t.device)\n    # Invert the CDF.\n    t_new = invert_cdf(u, t, w)\n    # Perturb the samples.\n    if perturb:\n        # Get the indices of the original samples.\n        t_new_idx = searchsorted(t, t_new)[0]\n        # Get the fractional part of the samples.\n        t_new_frac = (t_new - t[..., t_new_idx]) / (t[..., t_new_idx + 1] - t[..., t_new_idx])\n        # Apply perturbation.\n        t_new = t_new_frac + torch.rand_like(t_new) * (1.0 / num_samples)\n    # Jitter the samples.\n    if single_jitter:\n        t_new = t_new + torch.rand_like(t_new) * (1.0 / num_samples)\n    else:\n        t_new = t_new + torch.rand_like(t_new) * (t_new[..., 1] - t_new[..., 0])\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    cw = integrate_weights(w)\n    u = torch.linspace(0., 1., num_samples + 1, device=t.device)[:-1]\n    if perturb:\n        # Get the inverse CDF for a uniform distribution.\n        u = u + (torch.rand(list(u.shape), device=u.device) - 0.5) / num_samples\n        u = u.clip(0., 1.)\n    else:\n        u = u.clip(0., 1.)\n\n    # Invert the CDF.\n    t_new = invert_cdf(u, t, w)\n\n    if single_jitter:\n        # Apply the same jitter to every sample.\n        jitter = (torch.rand(t_new.shape[:-1] + (1,), device=t_new.device) - 0.5) * (t_new[..., 1:] - t_new[..., :-1]) / num_samples\n        t_new = t_new + jitter\n    else:\n        # Apply independent jitter to each sample.\n        jitter = (torch.rand(*t_new.shape, device=t_new.device) - 0.5) * (t_new[..., 1:] - t_new[..., :-1]) / num_samples\n        t_new = t_new + jitter\n\n    return t_new.clip(torch.min(t), torch.max(t))"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    if perturb:\n        # Get PDF/CDF\n        cw = integrate_weights(w)\n        # Take uniform samples\n        u = torch.linspace(0., 1., steps=num_samples, device=t.device)\n        # Invert CDF. This step takes inverse transform sampling, which is the\n        # key step of importance sampling.\n        t_new = invert_cdf(u, t, w)\n        # Draw uniform samples\n        shape = list(t_new.shape[:-1]) + [num_samples]\n        if not single_jitter:\n            u = torch.rand(shape, device=t.device)\n        else:\n            u = torch.zeros(shape, device=t.device)\n            u[..., 0] = torch.rand(shape[:-1], device=t.device)\n        # Invert CDF again & transform samples\n        t_new = invert_cdf(u, t_new, w)\n    else:\n        # Take uniform samples\n        u = torch.linspace(0., 1., steps=num_samples, device=t.device)\n        # Invert CDF.\n        t_new = invert_cdf(u, t, w)\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Match the shapes of `t` and `w` and add a leading dimension if necessary.\n    t, w = matchup_channels(t, w)\n\n    # Compute the PDF and CDF for each weight vector.\n    pdf = w / torch.sum(w, dim=-1, keepdim=True)\n    cdf = integrate_weights(w)\n\n    # Compute the inverse CDF.\n    u = torch.linspace(0.0, 1.0, num_samples, device=t.device)\n    t_new = invert_cdf(u, t, w)\n\n    # Perturb the samples and apply the same jitter to all sample dimensions.\n    if perturb:\n        mids = 0.5 * (t_new[..., 1:] + t_new[..., :-1])\n        upper = torch.cat([mids, t_new[..., -1:]], dim=-1)\n        lower = torch.cat([t_new[..., :1], mids], dim=-1)\n        t_new = torch.lerp(upper, lower, torch.rand(list(t.shape[:-1]) + [num_samples], device=t.device))\n    else:\n        mids = 0.5 * (t_new[..., 1:] + t_new[..., :-1])\n        t_new = torch.lerp(mids, t_new, torch.rand(list(t.shape[:-1]) + [num_samples], device=t.device))\n\n    # Return the samples.\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Get the shape of the input tensors\n    shape = t.shape[:-1] + (num_samples,)\n\n    # Generate uniform samples in [0, 1)\n    if perturb:\n        u = torch.rand(shape, device=t.device)\n    else:\n        u = torch.linspace(0.0, 1.0 - 1e-8, num_samples, device=t.device)\n        u = torch.broadcast_to(u, shape)\n\n    # Invert the CDF to get the samples\n    t_new = invert_cdf(u, t, w)\n\n    # Apply perturbation\n    if perturb:\n        # Get the CDF at the samples\n        cdf = integrate_weights(w)\n        cdf = torch.gather(cdf, -1, torch.searchsorted(t, t_new))\n\n        # Apply perturbation using the CDF\n        u = torch.rand(shape, device=t.device)\n        u = (u - cdf) / (1 - cdf + 1e-8)\n        t_new = invert_cdf(u, t, w)\n\n    # Apply jitter\n    if single_jitter:\n        jitter = torch.rand(shape, device=t.device) * (1.0 / num_samples)\n        t_new = t_new + jitter\n    else:\n        jitter = torch.rand(shape + (1,), device=t.device) * (1.0 / num_samples)\n        t_new = t_new + jitter\n\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Draw uniform samples.\n    u = torch.linspace(0., 1., num_samples, device=t.device)\n    # Invert the CDF.\n    t_new = invert_cdf(u, t, w)\n    # Perturb the samples.\n    if perturb:\n        # Take a finite difference of the CDF to get the PDF.\n        t0 = torch.cat([t[..., :1], t], dim=-1)\n        t1 = torch.cat([t, t[..., -1:]], dim=-1)\n        cdf_delta = torch.cumsum(w, dim=-1)\n        cdf_delta = torch.cat([torch.zeros_like(cdf_delta[..., :1]), cdf_delta], dim=-1)\n        cdf_delta = (cdf_delta - cdf_delta[..., :-1]) / (t1 - t0)\n        # Draw uniform samples.\n        u = torch.linspace(0., 1., num_samples, device=t.device)\n        # Sample the PDF and take a running sum.\n        cdf_delta = cdf_delta[..., None, :]\n        u = u[..., None, :]\n        inds = torch.searchsorted(cdf_delta, u, side='right')\n        below = torch.maximum(torch.zeros_like(inds - 1), inds - 1)\n        above = torch.minimum(cdf_delta.shape[-1] - 1, inds)\n        inds_g = torch.stack([below, above], dim=-1)\n\n        matched_shape = [inds_g.shape[0], inds_g.shape[1], cdf_delta.shape[-1]]\n        cdf_g = torch.gather(cdf_delta, -1, inds_g.view(-1, 2)).view(matched_shape)\n       "}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Match the shape of `t` and `w` and ensure that the last dimension of `t` is larger by 1.\n    t, w = matchup_channels(t, w)\n\n    # Compute the CDF and its total mass.\n    cw = integrate_weights(w)\n    cw_total = cw[..., -1]\n\n    # Draw uniform samples and invert the CDF.\n    if perturb:\n        # Uniformly sample.\n        u = torch.linspace(0. + 1e-5, 1. - 1e-5, num_samples, device=cw.device)\n        # Perturb the samples to avoid numerical issues with `searchsorted`.\n        u = u + (torch.rand(list(u.shape[:-1]) + [num_samples], device=cw.device) - 0.5) * (1. / num_samples)\n        # Clip the samples to the unit interval.\n        u = torch.clip(u, 0., 1.)\n    else:\n        # Uniformly sample.\n        u = torch.linspace(0., 1., num_samples, device=cw.device)\n        # Clip the samples to the unit interval.\n        u = torch.clip(u, 0., 1.)\n\n    # Invert the CDF.\n    t_new = invert_cdf(u, t, w)\n\n    # Draw new samples and return the combined result.\n    if perturb:\n        t_new_extra = torch.rand(list(t_new.shape[:-1]) + [num_samples], device=cw.device)\n        if not single_jitter:\n            t_new_extra = t_new_extra * (t_new[..., 1:] - t_new[..., :-1])\n        else:\n            t_new_extra = t_new_extra * (torch.max(t_new, dim=-1)[0] - torch.min(t_new, dim=-1)[0])"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Draw uniform samples.\n    u = torch.linspace(0., 1., num_samples, device=t.device)\n    # Draw samples from the PDF.\n    t_new = invert_cdf(u, t, w)\n    # Perturb samples.\n    if perturb:\n        # Don't perturb the first or last interval.\n        u = torch.linspace(0., 1., num_samples + 2, device=t.device)\n        t_lo = invert_cdf(u[..., :-2], t, w)\n        t_hi = invert_cdf(u[..., 2:], t, w)\n        t_mid = 0.5 * (t_lo + t_hi)\n        # Find which original samples correspond to the new samples.\n        idx_lo, idx_hi = searchsorted(t, t_mid)\n        t_mid = torch.gather(t, dim=-1, index=idx_lo)\n        # Perturb the new samples.\n        u_mid = torch.linspace(0., 1., num_samples, device=t.device)\n        t_mid = torch.lerp(t_mid, torch.gather(t, dim=-1, index=idx_hi), u_mid)\n        t_new = torch.cat([t_new[..., :1], t_mid, t_new[..., -1:]], dim=-1)\n    # Jitter samples in time.\n    if single_jitter:\n        jitter = torch.rand(t.shape[:-1], device=t.device)\n        jitter = (2 * jitter - 1) * (torch.gather(t, dim=-1, index=idx_hi) - torch.gather(t, dim=-1, index=idx_lo))\n        t_new = t_new + jitter[..., None]\n    else:\n        jitter = torch.rand(t_new.shape, device=t."}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Match the shapes of `t` and `w` and add a new dimension to `t` if necessary.\n    t, w = matchup_channels(t, w)\n\n    # Compute the PDF and CDF for each weight vector.\n    pdf = w / torch.sum(w, dim=-1, keepdim=True)\n    cdf = integrate_weights(w)\n\n    # Compute the inverse CDF.\n    u = torch.linspace(0. + 1e-5, 1. - 1e-5, num_samples, device=t.device)\n    if perturb:\n        # Apply perturbation to the sampling process to avoid sample clustering at bin boundaries.\n        u += torch.rand(list(cdf.shape[:-1]) + [num_samples], device=t.device) / num_samples\n        u = u.clip(0., 1.)\n    else:\n        # Generate uniform samples.\n        u = torch.linspace(0. + 1e-5, 1. - 1e-5, num_samples, device=t.device)\n\n    # Invert the CDF to get the samples.\n    t_new = invert_cdf(u, t, w)\n\n    # Apply jitter to the samples.\n    if perturb:\n        mids = .5 * (t[..., 1:] + t[..., :-1])\n        if single_jitter:\n            # Apply the same jitter to every sample along each dimension.\n            samp = perturb_and_importance_sample(mids, t_new, u, t, pdf)\n        else:\n            # Apply independent jitter to each sample.\n            samp = perturb_and_importance_sample(mids, t_new, u, t, pdf)\n    else:\n        samp = t_new\n\n    return samp"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Get the PDF and CDF for the weights.\n    pdf = w / torch.sum(w, dim=-1, keepdim=True)\n    cdf = torch.cumsum(pdf, dim=-1)\n    cdf = torch.cat([torch.zeros_like(cdf[..., :1]), cdf], dim=-1)\n\n    # Take uniform samples.\n    if perturb:\n        # Don't use randomized -- the [0, 1) interval is divided into [0, 1-eps) and [1-eps, 1]. The CDF now\n        # has a jump of size epsilon at 1-eps.\n        # This technique is useful when we want to make the distinction between \"a != 0\" and \"a == 0\" in\n        # the piecewise constant PDF.\n        u = torch.linspace(0., 1. - 1e-5, num_samples, device=t.device)\n        u = u + torch.zeros_like(cdf)[..., :1]  # [num_samples, num_bins]\n        u = torch.rand(list(cdf.shape[:-1]) + [num_samples], device=t.device) / num_samples\n    else:\n        # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n        eps = 1e-5\n        u_max = (torch.tensor(1., device=t.device) - eps)\n        u = torch.linspace(0., u_max, num_samples, device=t.device)\n        u = u + torch.zeros_like(cdf)[..., :1]  # [num_samples, num_bins]\n        u = torch.rand(list(cdf.shape[:-1]) + [num_samples], device=t.device) * u_max\n\n    # Identify the location in the CDF that corresponds to a random sample.\n    # The final `True` index in `mask` will"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Match the shapes of `t` and `w`.\n    t, w = matchup_channels(t, w)\n    # Compute the PDF and CDF for each weight vector.\n    pdf = w / torch.sum(w, dim=-1, keepdim=True)\n    cdf = integrate_weights(w)\n\n    # Take mid-points of all intervals; we'll use these as inverse samples.\n    mid_points = 0.5 * (t[..., :-1] + t[..., 1:])\n\n    # Draw uniform samples.\n    if perturb:\n        # Get intervals according to inverse CDF.\n        # Interpolate the intervals according to the samples.\n        # Fencepost problem: sample uniformly on the interval, then take point on the left.\n        u = torch.linspace(0.0, 1.0, num_samples, device=t.device)\n        if not single_jitter:\n            u += (torch.rand(list(cdf.shape[:-1]) + [num_samples], device=t.device) - 0.5) / num_samples\n        u = u.clip(0.0, 1.0 - 1e-6)\n        t_new = invert_cdf(u, t, w)\n    else:\n        # Take the evenly-spaced samples from the mid-points (inverse of the CDF).\n        t_new = torch.linspace(0.0, 1.0, num_samples, device=t.device)\n        t_new = invert_cdf(t_new, t, w)\n\n    # Now draw samples from those bins according to the probability.\n    # Take uniform samples.\n    # inds = torch.searchsorted(cdf, u, side='right') - 1\n    inds = searchsorted(cdf, t_new)[0]\n    b = torch.gather(t, -1, inds[..., None])[..., 0]\n    inds_lo = torch.clip(inds - "}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the PDF and CDF for each weight vector.\n    pdf = w / torch.sum(w, dim=-1, keepdim=True)\n    cdf = integrate_weights(w)\n\n    # Take uniform samples.\n    if perturb:\n        # Match the shapes of the CDF and the samples to allow selecting along the\n        # CDF dimension.\n        cdf = cdf.unsqueeze(-2).expand(list(cdf.shape[:-1]) + [num_samples])\n        if single_jitter:\n            u = torch.linspace(0., 1., num_samples, device=cdf.device)\n            u = u.unsqueeze(-2).expand(list(cdf.shape[:-1]) + [num_samples])\n        else:\n            u = torch.rand(list(cdf.shape[:-1]) + [num_samples], device=cdf.device)\n\n        # Invert the CDF.\n        t_new = invert_cdf(u, t, w)\n        below = t_new - t[..., 0]\n        above = t[..., -1] - t_new\n        # Interpolate samples from the PDF.\n        # pytorch.org/docs/stable/notes/randomness.html#dont-use-torch-rand-or-numpy-random-rand\n        samp = torch.lerp(below, above, u)\n    else:\n        # Take midpoint samples.\n        samp = (t[..., :-1] + t[..., 1:]) / 2\n\n    return samp"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Match the shapes of t and w.\n    t, w = matchup_channels(t, w)\n\n    # Compute the CDF of the piecewise-constant PDF.\n    cw = integrate_weights(w)\n\n    # Generate uniform samples in [0, 1).\n    u = torch.linspace(0, 1, num_samples, device=t.device)\n    u = u[(...,) + (None,) * len(t.shape)]\n\n    # Invert the CDF to get sample positions.\n    t_new = invert_cdf(u, t, w)\n\n    # Perturb the samples to avoid sample clustering at bin boundaries.\n    if perturb:\n        # Compute the distance between consecutive bin endpoints.\n        midpoints = (t[..., 1:] + t[..., :-1]) / 2\n        delta = torch.cat([t[..., :1] - midpoints[..., :1],\n                           midpoints[..., 1:] - t[..., :-1],\n                           t[..., -1:] - midpoints[..., -1:]], dim=-1)\n\n        # Apply perturbation.\n        if single_jitter:\n            # Apply the same jitter to every sample along each dimension.\n            t_new += (u - u.detach()) * delta[..., None]\n        else:\n            # Apply independent jitter to each sample.\n            t_new += torch.rand(list(t.shape[:-1]) + [num_samples], device=t.device) * delta[..., None]\n\n    return t_new"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Match the shapes of the tensors to ensure they have the same number of dimensions.\n    t, w = matchup_channels(t, w)\n    # Generate uniform samples in [0, 1).\n    u = torch.rand(list(t.shape[:-1]) + [num_samples], device=t.device)\n    # Invert the CDF to get samples in the domain of the PDF.\n    t_new = invert_cdf(u, t, w)\n    # Perturb the samples to avoid sample clustering at bin boundaries.\n    if perturb:\n        # Compute the width of each bin.\n        widths = t[..., 1:] - t[..., :-1]\n        # Add a small epsilon to avoid division by zero.\n        widths = torch.cat([widths, torch.ones_like(widths[..., -1:]) * 1e-5], dim=-1)\n        # Compute the offset for each bin.\n        offset = torch.where(w > 0, torch.zeros_like(widths), torch.ones_like(widths))\n        offset = torch.cumsum(offset, dim=-1)\n        # Compute the offset for each sample.\n        if single_jitter:\n            jitter = torch.rand(list(t.shape[:-1]) + [1], device=t.device) * widths[..., None]\n        else:\n            jitter = torch.rand(list(t.shape[:-1]) + [num_samples], device=t.device) * widths[..., None]\n        # Apply the offset to the samples.\n        t_new = t_new + jitter - widths[..., None] * offset[..., None]\n    return t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    t, w = matchup_channels(t, w)\n\n    # Draw uniform samples.\n    u = torch.linspace(0. + 1e-5, 1. - 1e-5, num_samples, device=t.device)\n    if perturb:\n        # Perturb the samples to avoid numerical issues with `searchsorted`.\n        # See https://github.com/google/jax/issues/3050.\n        u = u + (torch.rand(num_samples, device=t.device) - 0.5) * (1. / num_samples)\n    else:\n        # Match the behavior of jax.random.uniform() by taking only the fractional part\n        # of the samples.\n        u = u % 1.\n    # Draw samples from the PDF.\n    t_new = invert_cdf(u, t, w)\n\n    # Perturb and apply padding.\n    if perturb:\n        # Avoid sample clustering at bin boundaries by applying padding.\n        u = u + (torch.rand(num_samples, device=t.device) - 0.5) * (1. / num_samples)\n        t_new = invert_cdf(u, t, w)\n\n    # Apply the same jitter to every sample along each dimension.\n    if single_jitter:\n        jittered_t_new = t_new + (torch.rand(t_new.shape, device=t.device) - 0.5) * (\n                1. / num_samples)\n    else:\n        jittered_t_new = t_new + torch.rand(t_new.shape, device=t.device) * (1. / num_samples)\n\n    return jittered_t_new\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Get pdf\n    pdf = w / torch.sum(w, -1, keepdim=True)\n    # Compute CDF\n    cdf = torch.cumsum(pdf, -1)\n    cdf = torch.cat([torch.zeros_like(cdf[..., :1]), cdf], -1)\n    # Take uniform samples\n    if perturb:\n        u = torch.linspace(0., 1., steps=num_samples)\n        u = u + (torch.rand(list(cdf.shape[:-1]) + [num_samples]) / num_samples)\n        u = u.clip(0., 1.)\n    else:\n        u = torch.linspace(0., 1., steps=num_samples)\n\n    # Invert CDF. This is the local inversion (Newton-Raphson) method from the\n    # original JAX codebase (and is likely to be faster than the global method\n    # used in jnp.interp()).\n    new_t = invert_cdf(u, t, w)\n\n    # Perturb and apply pixel center correction.\n    if perturb:\n        # Don't do anything if we don't have intervals to perturb.\n        if len(t) > 1:\n            mid = (t[..., 1:] + t[..., :-1]) / 2\n            # Get intervals between samples.\n            high = torch.cat([mid, mid[..., -1:]], dim=-1)\n            low = torch.cat([mid[..., :1], mid], dim=-1)\n            t_rand = torch.rand(t.shape)\n            if not single_jitter:\n                t_rand = torch.rand(new_t.shape)\n            new_t = low + (high - low) * t_rand\n    return new_t\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.importance_sampling", "completion": "    # Match the shape of `t` to the shape of `w`.\n    t, w = matchup_channels(t, w)\n\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n\n    # Get PDF and CDF only in the support of the bins.\n    cw = cw[..., :-1]\n    w = w[..., :-1]\n\n    # Compute the PDF and CDF for each weight vector.\n    pdf = w / cw[..., -1:]\n    cdf = cw / cw[..., -1:]\n\n    # Take uniform samples.\n    if perturb:\n        # Conceptually, if we just uniformly sample according to the inverse CDF\n        # provided by the weights alone, we would walk through the CDF and pick\n        # the coordinate according to the probability there. This is not the\n        # correct procedure when we have a non-uniformly spaced PDF. We need to\n        # walk *through* the PDF, and then we pick randomly within the small\n        # region under the PDF according to its value.\n\n        # So, first, we select a starting bin for each ray with some probability\n        # according to the weights.\n        # (Recall that bins and weights were both defined per-entry.)\n        # After selecting the bin, we then select a random point within that bin.\n        # We repeat this process for each ray.\n\n        # Draw uniform samples.\n        u = torch.rand(list(cdf.shape[:-1]) + [num_samples], device=w.device)  # [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Compute the dilated time steps\n    t_dilated = t + dilation\n\n    # Clip the dilated time steps within the specified domain\n    t_dilated = torch.clamp(t_dilated, min=domain[0], max=domain[1])\n\n    # Compute the weights for the dilated time steps\n    w_dilated = w * (t_dilated - t) / dilation\n\n    # Return the dilated and clipped time steps and the adjusted weights\n    return t_dilated, w_dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t_dilated = torch.cat([t[..., :1] - dilation, t[..., 1:] + dilation], dim=-1)\n    t_dilated = torch.clamp(t_dilated, domain[0], domain[1])\n    w_dilated = torch.maximum(w[..., :1], w[..., 1:])\n    return t_dilated, w_dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Compute the dilated time steps\n    t_dilated = t + dilation\n\n    # Clip the dilated time steps within the specified domain\n    t_dilated = torch.max(t_dilated, torch.as_tensor(domain[0], dtype=t.dtype, device=t.device))\n    t_dilated = torch.min(t_dilated, torch.as_tensor(domain[1], dtype=t.dtype, device=t.device))\n\n    # Compute the weights for the dilated time steps\n    w_dilated = w * (t_dilated - t[..., :-1]) / (t[..., 1:] - t[..., :-1])\n\n    return t_dilated, w_dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t_dilated = t * dilation\n    t_dilated = torch.cat([t_dilated[..., :1], t_dilated, t_dilated[..., -1:]], dim=-1)\n    t_dilated = torch.clamp(t_dilated, domain[0], domain[1])\n    w_dilated = w * (t_dilated[..., 1:] - t_dilated[..., :-1])\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Compute the dilated time steps\n    t_dilated = t + dilation\n\n    # Clip the dilated time steps to the specified domain\n    t_dilated = torch.clip(t_dilated, domain[0], domain[1])\n\n    # Compute the weights for the dilated time steps\n    w_dilated = w * (t_dilated - t[..., :-1]) / (t[..., 1:] - t[..., :-1])\n\n    # Ensure that the weights sum to 1\n    w_dilated = w_dilated / torch.sum(w_dilated, dim=-1, keepdim=True)\n\n    # Return the dilated and clipped time steps and the adjusted weights\n    return t_dilated, w_dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t = torch.cat([t[..., :1], t[..., 1:]], dim=-1)\n    w = torch.cat([w[..., :1], w[..., 1:]], dim=-1)\n    t_dilated = t[..., :-1] + dilation * (t[..., 1:] - t[..., :-1])\n    w_dilated = w[..., :-1] + dilation * (w[..., 1:] - w[..., :-1])\n    t_dilated = torch.cat([t_dilated, torch.full_like(t_dilated[..., :1], domain[1])], dim=-1)\n    w_dilated = torch.cat([w_dilated, torch.zeros_like(w_dilated[..., :1])], dim=-1)\n    t_dilated = torch.clamp(t_dilated, min=domain[0], max=domain[1])\n    return t_dilated, w_dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t0 = t[..., :-1]\n    t1 = t[..., 1:]\n    w0 = w[..., :-1]\n    w1 = w[..., 1:]\n    t_mid = (t0 + t1) / 2\n    w_max = torch.max(w0, w1)\n    t_max = torch.where(w0 > w1, t0, t1)\n    mask = (t_max > t0) & (t_max < t1)\n    w_max = torch.where(mask, w_max, torch.zeros_like(w_max))\n    t_max = torch.where(mask, t_max, torch.zeros_like(t_max))\n    t_new = torch.sort(torch.cat([t, t_max, t_mid], dim=-1), dim=-1)[0]\n    t_new = torch.clamp(t_new, domain[0], domain[1])\n    w_new = torch.where((t0 <= t_new) & (t_new <= t1), w_max, torch.zeros_like(w_max))\n    w_new = torch.cat([w_new, torch.zeros_like(w_new[..., :1])], dim=-1)\n    w_new = torch.cumsum(w_new, dim=-1) * dilation\n    return t_new, w_new"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the dilated time steps.\n    t_dilated = t[..., None, :] + dilation * (t[..., 1:] - t[..., :-1])[..., None]\n    # Clip the dilated time steps to the specified domain.\n    t_dilated = torch.cat([t_dilated[..., :1], t_dilated.clip(*domain), t_dilated[..., -1:]], dim=-1)\n    # Compute the weights corresponding to the dilated time steps.\n    w_dilated = (t[..., 1:] - t[..., :-1]) / (t_dilated[..., 1:] - t_dilated[..., :-1]).clip(1e-8)\n    w_dilated = w_dilated.clip(0, 1)\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t = torch.cat([t[..., :1], t, t[..., -1:]], dim=-1)\n    w = torch.cat([w[..., :1], w, w[..., -1:]], dim=-1)\n    t_dilated = torch.cat([t[..., :-1], t[..., 1:]], dim=-1)\n    w_dilated = torch.cat([w[..., :-1], w[..., 1:]], dim=-1)\n    t_dilated = t_dilated.clamp(*domain)\n    w_dilated = w_dilated.clamp(0, 1)\n    t_dilated = t_dilated.roll(1, dims=-1)\n    w_dilated = w_dilated.roll(1, dims=-1)\n    t_dilated = t_dilated.clamp(*domain)\n    w_dilated = w_dilated.clamp(0, 1)\n    t_dilated = t_dilated.roll(-1, dims=-1)\n    w_dilated = w_dilated.roll(-1, dims=-1)\n    t_dilated = t_dilated.clamp(*domain)\n    w_dilated = w_dilated.clamp(0, 1)\n    t_dilated = t_dilated.roll(1, dims=-1)\n    w_dilated = w_dilated.roll(1, dims=-1)\n    t_dilated = t_dilated.clamp(*domain)\n    w_dilated = w_dilated.clamp(0, 1)\n    t_dilated = t_dilated.roll(-1, dims=-1)\n    w_dilated = w_dilated.roll(-1, dims=-"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    # Dilate the time steps by the dilation parameter\n    t_dilated = t[..., None, :] + dilation\n    # Clip the dilated time steps to the specified domain\n    t_clipped = t_dilated.clip(*domain)\n    # Find the indices of the clipped time steps in the original time steps\n    idx = torch.searchsorted(t, t_clipped)\n    # Adjust the weights to match the dilated time steps\n    w_dilated = torch.gather(w, -1, idx.clip(1, w.shape[-1] - 1))\n    return t_clipped, w_dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Match the channels of t and w\n    t, w = matchup_channels(t, w)\n\n    # Compute the dilated time steps\n    t_dilated = t * dilation\n\n    # Clip the dilated time steps within the specified domain\n    t_dilated = torch.maximum(t_dilated, torch.as_tensor(domain[0], device=t.device, dtype=t.dtype))\n    t_dilated = torch.minimum(t_dilated, torch.as_tensor(domain[1], device=t.device, dtype=t.dtype))\n\n    # Compute the indices of the dilated time steps in the original time steps\n    indices = torch.searchsorted(t, t_dilated)\n\n    # Adjust the weights to match the dilated time steps\n    w_dilated = w.gather(dim=-1, index=indices)\n\n    return t_dilated, w_dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # Compute the dilated time steps by multiplying the original time steps with the dilation factor.\n    td = t * dilation\n\n    # Clip the dilated time steps within the specified domain.\n    td = torch.maximum(td, torch.as_tensor(domain[0], device=td.device, dtype=td.dtype))\n    td = torch.minimum(td, torch.as_tensor(domain[1], device=td.device, dtype=td.dtype))\n\n    # Compute the indices of the original time steps that correspond to the dilated time steps.\n    idx = torch.searchsorted(t, td)\n\n    # Compute the weights of the dilated time steps by taking the maximum weight among the original weights that correspond to the dilated time steps.\n    wd = torch.maximum.reduce(w[..., idx], axis=-1)\n\n    return td, wd\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the dilation factor for each time step.\n    dilation_factor = torch.arange(t.shape[-1], device=t.device) * dilation\n\n    # Compute the dilated time steps by adding the dilation factor to each time step.\n    t_dilated = t[..., :, None] + dilation_factor[None, None, :]\n\n    # Clip the dilated time steps within the specified domain.\n    t_dilated = torch.clip(t_dilated, domain[0], domain[1])\n\n    # Compute the weights for the dilated time steps by taking the maximum weight for each time step.\n    w_dilated = torch.max(w[..., :, None] * (t_dilated >= t[..., None, :]).float(), dim=-1).values\n\n    # Ensure that the weights sum to 1.\n    w_dilated /= torch.sum(w_dilated, dim=-1, keepdim=True)\n\n    return t_dilated, w_dilated"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    t_dilated = t[..., None, :] + dilation * torch.arange(\n        0, w.shape[-1], device=t.device, dtype=t.dtype\n    )[None, :, None]\n    w_dilated = torch.max(w[..., None, :], torch.zeros_like(w[..., None, :]))\n    t_dilated, w_dilated = t_dilated.reshape(-1, w_dilated.shape[-1]), w_dilated.reshape(-1, w_dilated.shape[-1])\n    t_dilated, w_dilated = t_dilated.min(dim=-1, keepdim=True)[0], w_dilated.max(dim=-1, keepdim=True)[0]\n    t_dilated, w_dilated = t_dilated.reshape(t.shape[:-1] + (t_dilated.shape[-1],)), w_dilated.reshape(w.shape[:-1] + (w_dilated.shape[-1],))\n    t_dilated, w_dilated = t_dilated.clip(*domain), w_dilated\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    # Compute the dilation of the time steps.\n    dilated_t = t[..., 1:] - t[..., :-1]\n    dilated_t = torch.cat([dilated_t[..., :1], dilated_t], dim=-1) * dilation\n\n    # Compute the clipped time steps.\n    clipped_t = torch.clamp(dilated_t, min=domain[0], max=domain[1])\n\n    # Compute the adjusted weights.\n    clipped_w = w * clipped_t / dilated_t\n\n    # Return the clipped time steps and the adjusted weights.\n    return clipped_t, clipped_w\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # t, w = matchup_channels(t, w)\n    # assert dilation > 0\n    # assert len(t.shape) == len(w.shape)\n    # assert t.shape[-1] == w.shape[-1] + 1\n    # assert t.ndim >= 1\n    # assert t.dtype == w.dtype\n\n    # # Compute the dilated time steps by multiplying the original time steps with the dilation factor.\n    # t_dilated = t[..., :-1] + dilation * (t[..., 1:] - t[..., :-1])\n\n    # # Clip the dilated time steps within the specified domain.\n    # t_dilated = torch.max(torch.min(t_dilated, domain[1]), domain[0])\n\n    # # Compute the weights for the dilated time steps by taking the maximum weight of the original weights.\n    # w_dilated = torch.max(w[..., :-1], w[..., 1:])\n\n    # return t_dilated, w_dilated\n\n    t, w = matchup_channels(t, w)\n    assert dilation > 0\n    assert len(t.shape) == len(w.shape)\n    assert t.shape[-1] == w.shape[-1] + 1\n    assert t.ndim >= 1\n    assert t.dtype == w.dtype\n\n    # Compute the dilated time steps by multiplying the original time steps with the dilation factor.\n    t_dilated = t[..., :-1] + dilation * (t[..., 1:] - t[..., :-1])\n\n    # Clip the dilated time steps within the specified domain.\n    t_dilated = torch.max(torch.min(t_dilated, domain[1]), domain[0])\n\n    # Compute the weights for the dilated time steps by taking the maximum weight of the original weights.\n    w_dilated = torch.max(w[...,"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    # Compute the dilated time steps.\n    t_dilated = t[..., 1:] + dilation\n    # Compute the weights for the dilated time steps.\n    w_dilated = w[..., 1:]\n    # Compute the weights for the original time steps.\n    w_orig = w[..., :-1]\n    # Combine the weights for the original and dilated time steps.\n    w_combined = torch.cat([w_orig, w_dilated], dim=-1)\n    # Combine the time steps for the original and dilated time steps.\n    t_combined = torch.cat([t, t_dilated], dim=-1)\n    # Clip the combined time steps to the specified domain.\n    t_combined = torch.maximum(t_combined, torch.as_tensor(domain[0], device=t.device))\n    t_combined = torch.minimum(t_combined, torch.as_tensor(domain[1], device=t.device))\n    # Compute the cumulative sum of the combined weights.\n    cw = integrate_weights(w_combined)\n    # Compute the indices of the time steps that are outside the specified domain.\n    indices = torch.logical_or(t_combined < domain[0], t_combined > domain[1])\n    # Set the weights for the time steps that are outside the specified domain to zero.\n    cw[..., indices] = 0\n    # Compute the inverse CDF of the combined weights.\n    t_new = invert_cdf(cw, t_combined, w_combined)\n    # Compute the weights for the time steps that are inside the specified domain.\n    w_new = weight_to_pdf(t_new, cw)\n    # Return the dilated and clipped time steps and the corresponding weights.\n    return t_new, w_new"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n    # prepare for size change\n    sh = *t.shape[:-1], t.shape[-1] - 1\n    t = t.reshape(-1, t.shape[-1])\n    w = w.reshape(-1, w.shape[-1])\n\n    # dilation\n    t_dil = torch.cat([t[..., :1], t[..., 1:] - t[..., :-1], t[..., -1:]], dim=-1)\n    t_dil = torch.clamp(t_dil * dilation, min=0)\n    t_dil = torch.cumsum(t_dil, dim=-1)\n\n    # clipping\n    t_dil = torch.cat([torch.zeros_like(t_dil[..., :1]), t_dil], dim=-1)\n    t_dil = torch.cat([t_dil, torch.full_like(t_dil[..., :1], domain[1])], dim=-1)\n    t_dil = torch.clamp(t_dil, min=domain[0], max=domain[1])\n\n    # prepare for size change\n    t_dil = t_dil.reshape(sh)\n\n    # compute weights\n    w_dil = torch.max(w, dim=-1, keepdim=True)[0]\n    w_dil = torch.where(t_dil[..., :-1] == t_dil[..., 1:], w_dil, w)\n    w_dil = torch.where(t_dil[..., :-1] == t_dil[..., :-2], w_dil, w_dil.new_zeros(w_dil.shape))\n\n    return t_dil, w_dil"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    t, w = matchup_channels(t, w)\n\n    # Weights are assumed to sum to 1.\n    assert torch.allclose(torch.sum(w, dim=-1), torch.tensor(1, dtype=w.dtype, device=w.device))\n\n    # Compute the dilation of the time steps.\n    t_dilated = t + dilation\n\n    # Clip the dilated time steps to the specified domain.\n    t_dilated = torch.maximum(t_dilated, torch.tensor(domain[0], dtype=t.dtype, device=t.device))\n    t_dilated = torch.minimum(t_dilated, torch.tensor(domain[1], dtype=t.dtype, device=t.device))\n\n    # Compute the weights for the dilated time steps.\n    w_dilated = torch.maximum(t_dilated[..., 1:] - t_dilated[..., :-1], torch.zeros_like(t_dilated[..., :-1]))\n    w_dilated = w_dilated / (torch.sum(w_dilated, dim=-1, keepdim=True) + 1e-8)\n\n    return t_dilated, w_dilated\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.max_dilate", "completion": "    # t, w = matchup_channels(t, w)\n    t_dilated = torch.cat([t[..., :1] - dilation, t[..., 1:] + dilation], dim=-1)\n    t_dilated = torch.clamp(t_dilated, domain[0], domain[1])\n\n    # Find the indices of the dilated time steps that are outside the domain.\n    outside_domain = (t_dilated[..., :-1] < domain[0]) | (t_dilated[..., 1:] > domain[1])\n\n    # If there are no dilated time steps outside the domain, return the original time steps and weights.\n    if not torch.any(outside_domain):\n        return t, w\n\n    # Create a mask for the dilated time steps that are outside the domain.\n    mask = torch.cat([outside_domain, torch.zeros_like(outside_domain[..., :1])], dim=-1)\n\n    # Create a mask for the dilated time steps that are inside the domain.\n    mask = ~mask\n\n    # Create a mask for the weights corresponding to the dilated time steps that are inside the domain.\n    w_mask = torch.cat([torch.zeros_like(w[..., :1]), w], dim=-1)\n    w_mask = w_mask * mask\n\n    # Create a mask for the weights corresponding to the dilated time steps that are outside the domain.\n    w_outside_domain = torch.cat([w, torch.zeros_like(w[..., :1])], dim=-1)\n    w_outside_domain = w_outside_domain * outside_domain\n\n    # Find the indices of the dilated time steps that are inside the domain.\n    inside_domain = ~outside_domain\n\n    # Find the indices of the dilated time steps that are outside the domain and their neighbors inside the domain.\n    outside_neighbors = torch.cat([torch.zeros_like(inside_domain"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    t, y = matchup_channels(t, y)\n    if t.shape[-1] != y.shape[-1] + 1:\n        t = torch.cat([t, torch.ones_like(t[..., -1:])], dim=-1)\n    tq = tq[..., None, :]\n    y = torch.where(tq >= t[..., :, None], y[..., None, :], outside_value)\n    y = torch.max(y, dim=-1)[0]\n    return y"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Compute the step function values at the query times.\n    yq = torch.where(\n        (tq[..., None, :] >= t[..., None, :-1]) & (tq[..., None, :] < t[..., None, 1:]),\n        y[..., None, :],\n        outside_value,\n    )\n\n    # Interpolate the step function values at the query times.\n    yq = torch.where(\n        (tq[..., None, :] >= t[..., None, :-1]) & (tq[..., None, :] < t[..., None, 1:]),\n        yq + (yq - y[..., None, :-1]) * (tq[..., None, :] - t[..., None, :-1]) / (t[..., None, 1:] - t[..., None, :-1]),\n        yq,\n    )\n\n    return yq"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    t, y = matchup_channels(t, y)\n    tq = tq.reshape([-1, 1])\n    t, y = t.reshape([1, -1]), y.reshape([1, -1])\n    tq = tq.clip(t[..., 0], t[..., -1])\n    i = torch.sum(torch.ge(tq, t), dim=-1) - 1\n    i = i.clip(0, y.shape[-1] - 1)\n    y = torch.gather(y, -1, i[..., None])[..., 0]\n    y = torch.where(tq == t[..., 0], outside_value, y)\n    return y"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices of the time values that are just to the left of each query time.\n    indices = torch.searchsorted(t, tq, side='left')\n\n    # Find the values of the step function at the query times.\n    yq = torch.where(\n        (indices > 0) & (indices < t.shape[-1]),\n        torch.gather(y, -1, indices),\n        outside_value,\n    )\n\n    # Interpolate the values of the step function at the query times.\n    yq = torch.where(\n        (indices > 0) & (indices < t.shape[-1]),\n        (yq + (tq - t[..., indices - 1]) * (y[..., indices] - yq) /\n         (t[..., indices] - t[..., indices - 1])),\n        yq,\n    )\n\n    return yq"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Check that tq is a tensor\n    if not isinstance(tq, torch.Tensor):\n        raise ValueError(\"tq must be a tensor\")\n\n    # Check that t and y are tensors\n    if not isinstance(t, torch.Tensor) or not isinstance(y, torch.Tensor):\n        raise ValueError(\"t and y must be tensors\")\n\n    # Check that tq, t, and y have the same number of dimensions\n    if tq.ndim != t.ndim or tq.ndim != y.ndim:\n        raise ValueError(\"tq, t, and y must have the same number of dimensions\")\n\n    # Check that tq, t, and y have the same shape\n    if tq.shape != t.shape or tq.shape != y.shape:\n        raise ValueError(\"tq, t, and y must have the same shape\")\n\n    # Check that tq, t, and y have at least one dimension\n    if tq.ndim < 1 or t.ndim < 1 or y.ndim < 1:\n        raise ValueError(\"tq, t, and y must have at least one dimension\")\n\n    # Check that tq, t, and y have the same first dimension\n    if tq.shape[0] != t.shape[0] or tq.shape[0] != y.shape[0]:\n        raise ValueError(\"tq, t, and y must have the same first dimension\")\n\n    # Check that tq is sorted\n    if not torch.all(tq[..., :-1] <= tq[..., 1:]):\n        raise ValueError(\"tq must be sorted\")\n\n    # Check that t is sorted\n    if not torch.all(t[..., :-1] <= t[..., 1:]):\n        raise ValueError(\"t must be sorted\")\n\n    # Check that tq is within the range of t\n    if not torch.all(tq >= t[..., 0, None]) or not torch.all(tq <= t[...,"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Check if tq is a single value or a tensor\n    if isinstance(tq, float) or isinstance(tq, int):\n        tq = torch.tensor(tq)\n\n    # Check if tq is a single value or a tensor\n    if isinstance(t, float) or isinstance(t, int):\n        t = torch.tensor(t)\n\n    # Check if y is a single value or a tensor\n    if isinstance(y, float) or isinstance(y, int):\n        y = torch.tensor(y)\n\n    # Check if tq is a single value or a tensor\n    if isinstance(outside_value, float) or isinstance(outside_value, int):\n        outside_value = torch.tensor(outside_value)\n\n    # Check if tq, t, and y have the same shape\n    if tq.shape != t.shape or tq.shape != y.shape:\n        raise ValueError(\"tq, t, and y must have the same shape\")\n\n    # Check if t is sorted\n    if not torch.all(t[..., :-1] <= t[..., 1:]):\n        raise ValueError(\"t must be sorted in ascending order\")\n\n    # Check if tq is within the range of t\n    if not torch.all((tq >= t[..., 0]) & (tq <= t[..., -1])):\n        raise ValueError(\"tq must be within the range of t\")\n\n    # Check if tq is a single value or a tensor\n    if isinstance(tq, float) or isinstance(tq, int):\n        tq = torch.tensor(tq)\n\n    # Check if tq is a single value or a tensor\n    if isinstance(t, float) or isinstance(t, int):\n        t = torch.tensor(t)\n\n    # Check if y is a single value or a tensor\n    if isinstance(y, float) or isinstance(y, int):\n        y = torch.tensor(y)\n\n    #"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # tq.shape = [B, P, I]\n    # t.shape = [B, P, I+1]\n    # y.shape = [B, P, I]\n\n    # Find the index of the last interval that ends before each query time.\n    idx = torch.searchsorted(t, tq, side='right') - 1\n\n    # Compute the fraction of the interval that each query time falls within.\n    t0 = t[..., idx]\n    t1 = t[..., idx + 1]\n    alpha = (tq - t0) / (t1 - t0)\n\n    # Interpolate the values of the step function at the query times.\n    y0 = y[..., idx]\n    y1 = y[..., idx + 1]\n    yq = y0 + alpha * (y1 - y0)\n\n    # Set the values of the step function at query times that exactly match a step change time to the outside value.\n    yq = torch.where(tq == t1, outside_value, yq)\n\n    return yq"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Compute the indices of the first time value that is greater than each query time\n    indices = torch.sum(torch.gt(tq[..., None], t[..., :, None]), dim=-1) - 1\n\n    # Compute the indices of the last time value that is less than or equal to each query time\n    indices_lo = torch.max(torch.where(tq[..., None] <= t[..., :, None], indices[..., None], -torch.ones_like(indices[..., None])), dim=-2)[0]\n\n    # Compute the indices of the first time value that is greater than each query time\n    indices_hi = torch.min(torch.where(tq[..., None] > t[..., :, None], indices[..., None], torch.ones_like(indices[..., None]) * t.shape[-1]), dim=-2)[0]\n\n    # Compute the interpolation weights for each query time\n    weights_lo = (tq - t[..., indices_lo]) / (t[..., indices_lo + 1] - t[..., indices_lo] + 1e-8)\n    weights_hi = 1 - weights_lo\n\n    # Compute the interpolated values for each query time\n    yq = weights_lo * y[..., indices_lo] + weights_hi * y[..., indices_hi]\n\n    # Set the values of the step function at query times that exactly match a step change time to the outside value\n    yq = torch.where(tq[..., None] == t[..., :, None], outside_value, yq)\n\n    return yq"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Add a final step at the end of the step function.\n    t = torch.cat([t, t[-1:]], dim=-1)\n    y = torch.cat([y, y[-1:]], dim=-1)\n\n    # Find the index of the last step change before each query time.\n    indices = torch.searchsorted(t, tq, side='right') - 1\n\n    # Compute the fractional distance between the query time and the step change times.\n    fraction = (tq - t[indices]) / (t[indices + 1] - t[indices])\n\n    # Interpolate between the step values using linear interpolation.\n    yq = torch.where(fraction < 1, y[indices] + fraction * (y[indices + 1] - y[indices]), y[indices + 1])\n\n    # Set the values to the outside value for query times that exactly match a step change time.\n    yq = torch.where(fraction == 0, outside_value, yq)\n\n    return yq"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    tq, t, y = matchup_channels(tq, t, y)\n\n    # Find the index of the interval where each query time falls.\n    idx = torch.searchsorted(t, tq, side='left')\n\n    # Handle cases where the query time is exactly equal to a step change time.\n    idx = torch.where(tq == t[..., :-1], idx - 1, idx)\n\n    # Compute the interpolated values of the step function at the query times.\n    yq = torch.where(\n        idx < t.shape[-1] - 1,\n        torch.lerp(y[..., idx], y[..., idx + 1],\n                   (tq - t[..., idx]) / (t[..., idx + 1] - t[..., idx])),\n        outside_value)\n\n    return yq"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Ensure that the query times are sorted.\n    tq = torch.sort(tq)[0]\n\n    # Ensure that the step function is sorted.\n    t, y = torch.sort(torch.stack([t, y]), dim=-1)\n\n    # Find the indices of the query times that are exactly equal to a step change time.\n    idx = torch.searchsorted(t, tq)\n    idx = torch.where(t[..., idx] == tq, idx, torch.maximum(idx - 1, 0))\n\n    # If a query time matches a step change time, return the outside value.\n    y_outside = torch.where(t[..., idx] == tq, outside_value, y[..., idx])\n\n    # If a query time is between two step change times, interpolate the value.\n    y_interpolated = torch.where(\n        t[..., idx] < tq,\n        (tq - t[..., idx]) * (y[..., idx + 1] - y[..., idx]) /\n        (t[..., idx + 1] - t[..., idx]),\n        y_outside,\n    )\n\n    return y_interpolated"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Find the indices of the time steps where the query time falls between two step function times.\n    indices = torch.searchsorted(t, tq, side='right') - 1\n    indices = torch.clamp(indices, 0, y.shape[-1] - 1)\n\n    # If the query time exactly matches a time step, return the outside value.\n    # Otherwise, interpolate between the values of the step function at the two adjacent time steps.\n    t0, t1 = t[indices], t[indices + 1]\n    y0, y1 = y[indices], y[indices + 1]\n    outside_mask = (tq == t0) | (tq == t1)\n    outside_value = torch.full_like(tq, outside_value)\n    yq = torch.where(outside_mask, outside_value, (tq - t0) / (t1 - t0) * (y1 - y0) + y0)\n\n    return yq"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # tq: [..., num_query_times]\n    # t: [..., num_steps]\n    # y: [..., num_steps]\n\n    # Convert the query times to the internal representation.\n    tq = tq[..., None]\n    tq = tq.clip(t[..., :1], t[..., -1:])\n\n    # Find the indices of the steps that are just before the query times.\n    indices = torch.sum(tq > t[..., :, None], dim=-1) - 1\n    indices = indices.clip(0, t.shape[-1] - 2)\n\n    # Compute the values of the step function at the query times.\n    values = torch.where(tq == t[..., indices], y[..., indices], y[..., indices + 1])\n\n    # Set the values of the step function at query times that exactly match a step change time to the outside value.\n    values = torch.where(tq == t[..., indices], outside_value, values)\n\n    return values"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # tq: [..., num_query]\n    # t: [..., num_steps + 1]\n    # y: [..., num_steps]\n    # outside_value: scalar\n    # return: [..., num_query]\n    # assert tq.shape[-1] == t.shape[-1] - 1\n    # assert t.shape[-1] == y.shape[-1] + 1\n\n    # Find the indices of the step function changes that occur before each query time.\n    indices = torch.sum(tq[..., :, None] < t[..., None, :], dim=-1) - 1\n    indices = torch.clip(indices, min=0, max=t.shape[-1] - 2)\n\n    # Compute the interpolated values of the step function at the query times.\n    yq = torch.where(\n        tq[..., :, None] == t[..., None, :],\n        y[..., None, :],\n        torch.where(\n            tq[..., :, None] < t[..., None, :],\n            y[..., None, :],\n            y[..., None, :],\n        ),\n    )\n    yq = torch.gather(yq, -1, indices[..., None])[..., 0]\n\n    # Set the values of the step function at query times that exactly match a step change time to the outside value.\n    yq = torch.where(tq[..., :, None] == t[..., None, :], outside_value, yq)\n\n    return yq"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Shape checking\n    assert t.shape == y.shape, \"t and y must have the same shape.\"\n\n    # Get the indices of the step function changes\n    indices = torch.searchsorted(t, tq)\n\n    # Check if any query times exactly match a step change time\n    is_exact = (t[indices] == tq).to(torch.float32)\n\n    # Compute the interpolated values\n    yq = torch.where(\n        indices == 0,\n        y[0],\n        torch.where(\n            indices == t.shape[-1],\n            y[-1],\n            (1 - (tq - t[indices - 1]) / (t[indices] - t[indices - 1])) * y[indices - 1] +\n            (tq - t[indices - 1]) / (t[indices] - t[indices - 1]) * y[indices],\n        ),\n    )\n\n    # Set the interpolated values to the outside value for exact matches\n    yq = torch.where(is_exact, outside_value, yq)\n\n    return yq\n\n"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # tq: [..., num_query_times]\n    # t: [..., num_steps + 1]\n    # y: [..., num_steps + 1]\n    # outside_value: [..., num_query_times]\n\n    # If the query time is exactly equal to a step change time, return the outside value.\n    outside_mask = torch.logical_and(\n        torch.logical_and(\n            tq[..., None, :] >= t[..., :-1], tq[..., None, :] <= t[..., 1:]),\n        tq[..., None, :] != t[..., :-1])\n    outside_value = torch.where(outside_mask, outside_value, 0.)\n\n    # If the query time is between two step change times, interpolate the value.\n    t_lo = torch.max(tq[..., None, :], t[..., :-1])\n    t_hi = torch.min(tq[..., None, :], t[..., 1:])\n    w = (t_hi - t_lo) / (t[..., 1:] - t[..., :-1])\n    y_lo = y[..., :-1]\n    y_hi = y[..., 1:]\n    y_interp = w * y_lo + (1. - w) * y_hi\n    inside_value = torch.where(t_lo < t_hi, y_interp, 0.)\n\n    # Combine the outside and inside values.\n    return outside_value + inside_value"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    t, y = matchup_channels(t, y)\n    # assert t.ndim == y.ndim + 1\n    # assert t.shape[-1] == y.shape[-1] + 1\n\n    # if tq.shape[-1] == 1:\n    #     tq = tq.expand(-1, t.shape[-1])\n\n    # Find the indices of the step function changes that are just to the left of the query times.\n    idx = torch.searchsorted(t, tq, side='right') - 1\n    idx = idx.clip(0, t.shape[-1] - 1)\n\n    # If the query time exactly matches a step change time, return the outside value.\n    # Otherwise, interpolate the value at the query time based on the step function.\n    yq = torch.where(t[..., idx] == tq, outside_value,\n                     torch.lerp(y[..., idx], y[..., idx + 1],\n                                (tq - t[..., idx]) / (t[..., idx + 1] - t[..., idx] + 1e-8)))\n    return yq"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # tq: [..., Tq]\n    # t: [..., T + 1], where T is the number of step changes\n    # y: [..., T + 1]\n    # outside_value: [..., 1]\n    # Output: [..., Tq]\n\n    # Compute the step function values at the query times.\n    tq_shape = tq.shape[:-1]\n    t_shape = t.shape[:-1]\n    y_shape = y.shape[:-1]\n    assert tq_shape == t_shape == y_shape\n    assert tq.shape[-1] > 0\n    assert t.shape[-1] >= 2\n    assert y.shape[-1] == t.shape[-1]\n\n    # Find the indices of the step function changes that are closest to the query times.\n    indices = torch.searchsorted(t, tq, side='right') - 1\n    indices = indices.clip(0, t.shape[-1] - 2)\n\n    # Compute the interpolation weights for each query time.\n    t0 = t.gather(-1, indices)\n    t1 = t.gather(-1, indices + 1)\n    alpha = (tq - t0) / (t1 - t0)\n\n    # Interpolate the step function values at the query times.\n    y0 = y.gather(-1, indices)\n    y1 = y.gather(-1, indices + 1)\n    yq = (1 - alpha) * y0 + alpha * y1\n\n    # Set the values of the step function at query times that exactly match a step change time to the outside value.\n    yq = torch.where((tq == t0) | (tq == t1), outside_value, yq)\n\n    return yq"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    # Add a value at the end of the step function to catch cases where the query time is after the last step.\n    t = torch.cat([t, t[..., -1:]], dim=-1)\n    y = torch.cat([y, y[..., -1:]], dim=-1)\n\n    # Find the index of the step function at or before each query time.\n    indices = torch.searchsorted(t, tq, side='right') - 1\n    indices = torch.clamp(indices, 0, t.shape[-1] - 2)\n\n    # If the query time matches a step change time, return the outside value.\n    matches = (tq == t[..., indices])\n    if torch.any(matches):\n        yq = torch.where(matches, outside_value, y[..., indices])\n    else:\n        yq = y[..., indices]\n\n    # If the query time is within the interval between two step function values, interpolate between the two values.\n    t0 = t[..., indices]\n    t1 = t[..., indices + 1]\n    y0 = y[..., indices]\n    y1 = y[..., indices + 1]\n    yq = torch.where(tq < t0, y0, yq)\n    yq = torch.where(tq > t1, y1, yq)\n    yq = torch.where((tq >= t0) & (tq <= t1), (tq - t0) / (t1 - t0) * (y1 - y0) + y0, yq)\n\n    return yq"}
{"namespace": "easyvolcap.utils.prop_utils.query", "completion": "    tq, t, y = matchup_channels(tq, t, y)\n    # Compute the step function values at the query times.\n    # The step function is defined by the values in 'y' at the times in 't'.\n    # The query times are 'tq'.\n    # If a query time matches a step change time, the function returns an outside value.\n    # Otherwise, it interpolates the value at the query time based on the step function.\n    # The outside value is specified by the 'outside_value' argument.\n    # The function returns a tensor containing the interpolated or outside values of the step function at the query times.\n    # The shape of the output tensor is the same as the shape of the 'tq' input tensor.\n\n    # Find the indices of the step changes that are immediately before each query time.\n    indices = torch.searchsorted(t, tq, side='right')\n    # Clamp the indices to the valid range of the 't' tensor.\n    indices = torch.clamp(indices, 1, t.shape[-1] - 1)\n    # Compute the time differences between the query times and the step changes.\n    t_diff = tq - t[..., indices - 1]\n    # Compute the weights for interpolating between the step changes.\n    weights = torch.where(t_diff > 0, t_diff / (t[..., indices] - t[..., indices - 1]), 0)\n    # Compute the interpolated values of the step function at the query times.\n    yq = y[..., indices - 1] * (1 - weights) + y[..., indices] * weights\n    # Set the values of the step function at query times that exactly match a step change time to the outside value.\n    yq = torch.where(t_diff == 0, outside_value, yq)\n    return yq"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # Compute the weights for the current training fraction.\n    w_train = torch.sigmoid(w * anneal_slope)\n\n    # Compute the weights for the next training fraction.\n    w_next = torch.sigmoid((w + (1 - w_train)) * anneal_slope)\n\n    # Compute the weights for the next training fraction.\n    w_next = torch.sigmoid((w + (1 - w_train)) * anneal_slope)\n\n    # Compute the weights for the next training fraction.\n    w_next = torch.sigmoid((w + (1 - w_train)) * anneal_slope)\n\n    # Compute the weights for the next training fraction.\n    w_next = torch.sigmoid((w + (1 - w_train)) * anneal_slope)\n\n    # Compute the weights for the next training fraction.\n    w_next = torch.sigmoid((w + (1 - w_train)) * anneal_slope)\n\n    # Compute the weights for the next training fraction.\n    w_next = torch.sigmoid((w + (1 - w_train)) * anneal_slope)\n\n    # Compute the weights for the next training fraction.\n    w_next = torch.sigmoid((w + (1 - w_train)) * anneal_slope)\n\n    # Compute the weights for the next training fraction.\n    w_next = torch.sigmoid((w + (1 - w_train)) * anneal_slope)\n\n    # Compute the weights for the next training fraction.\n    w_next = torch.sigmoid((w + (1 - w_train)) * anneal_slope)\n\n    # Compute the weights for the next training fraction.\n    w_next = torch.sigmoid((w + (1 - w_train)) * anneal_slope)\n\n    # Compute the"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    t_diff = t[..., 1:] - t[..., :-1]\n    # Set the weight adjustment to zero if the adjacent intervals have zero distance.\n    w_adj = torch.where(t_diff == 0, 0, torch.exp(anneal_slope * (train_frac - t[..., :-1])) * t_diff)\n    # Prevent NaN values by using a softmax operation on the adjusted weights.\n    w_adj = torch.softmax(w_adj, dim=-1) * w\n    # Normalize the weights to sum to 1.\n    w_adj /= torch.sum(w_adj, dim=-1, keepdim=True).clip(eps)\n    return w_adj"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # Compute the weight adjustment based on the training fraction and anneal slope.\n    weight_adjustment = (1 - torch.exp(-train_frac * anneal_slope))\n\n    # Compute the distance between adjacent intervals.\n    dist = (t[..., 1:] - t[..., :-1])\n\n    # Handle cases where adjacent intervals have zero distance.\n    dist = torch.where(dist == 0, torch.zeros_like(dist), dist)\n\n    # Compute the adjusted weights.\n    adjusted_weights = w * torch.exp(-weight_adjustment * dist)\n\n    # Ensure stability in the computation by handling cases where adjacent intervals have zero distance.\n    adjusted_weights = torch.where(dist == 0, torch.zeros_like(adjusted_weights), adjusted_weights)\n\n    # Prevent NaN values by using a softmax operation.\n    adjusted_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # compute the distance between adjacent intervals\n    dist = t[..., 1:] - t[..., :-1]\n\n    # compute the annealing effect based on the training fraction\n    anneal_effect = torch.sigmoid(train_frac * anneal_slope)\n\n    # compute the adjusted weights using the annealing effect\n    w_adj = w * (1 - anneal_effect) + anneal_effect * torch.exp(-dist * anneal_slope)\n\n    # handle cases where adjacent intervals have zero distance\n    w_adj = torch.where(dist == 0, torch.zeros_like(w_adj), w_adj)\n\n    # prevent NaN values by using a softmax operation on the adjusted weights\n    w_adj = torch.softmax(w_adj, dim=-1)\n\n    # normalize the weights to ensure they sum to 1\n    w_adj = w_adj / (torch.sum(w_adj, dim=-1, keepdim=True) + eps)\n\n    return w_adj"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # compute the fraction of the training that has been completed\n    t_frac = t[..., 1:] / t[..., -1:]\n\n    # compute the annealing effect using Schlick's bias function\n    bias = 1.0 - torch.exp(-(t_frac - train_frac) * anneal_slope)\n\n    # compute the adjusted weights\n    w_adj = w * bias\n\n    # handle cases where adjacent intervals have zero distance\n    w_adj = torch.where(torch.isclose(t[..., 1:] - t[..., :-1], torch.zeros_like(t[..., 1:]), atol=eps), torch.zeros_like(w_adj), w_adj)\n\n    # prevent NaN values by using a softmax operation on the adjusted weights\n    w_adj = torch.nn.functional.softmax(w_adj, dim=-1)\n\n    return w_adj"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    t_diff = t[..., 1:] - t[..., :-1]\n    t_diff = torch.where(t_diff > 0, t_diff, torch.ones_like(t_diff) * eps)\n    t_diff = t_diff[..., None, :]\n    t_diff = torch.cat([t_diff, t_diff[..., -2:-1]], dim=-1)\n    t_diff = t_diff.clip(min=eps)\n    t_diff = t_diff[..., :-1]\n    w_adj = w * torch.exp(-t_diff * anneal_slope * (1 - train_frac))\n    w_adj = torch.where(w_adj > 0, w_adj, torch.zeros_like(w_adj))\n    w_adj = w_adj / torch.sum(w_adj, dim=-1, keepdim=True)\n    return w_adj"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # t.shape[-1] = w.shape[-1] + 1\n    # compute the distance between adjacent intervals\n    dt = t[..., 1:] - t[..., :-1]\n    # handle cases where adjacent intervals have zero distance\n    dt = dt.clip(eps)\n    # compute the annealing effect based on the training fraction and anneal slope\n    anneal = torch.sigmoid(torch.log(train_frac) * anneal_slope)\n    # compute the adjusted weights\n    w_adjusted = w * (1 - anneal) + anneal * (dt / dt.sum(dim=-1, keepdim=True))\n    # handle cases where adjacent intervals have zero distance\n    w_adjusted = w_adjusted.where(dt > 0, 0)\n    # ensure stability in the computation by using a softmax operation\n    w_adjusted = torch.softmax(w_adjusted, dim=-1)\n    return w_adjusted"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # Get the time differences between adjacent intervals\n    dt = t[..., 1:] - t[..., :-1]\n\n    # Calculate the bias using Schlick's bias function\n    bias = torch.exp(-dt * anneal_slope * train_frac)\n\n    # Calculate the annealed weights\n    w_anneal = w[..., :-1] * bias\n\n    # Handle cases where adjacent intervals have zero distance\n    w_anneal = torch.where(dt == 0, 0, w_anneal)\n\n    # Prevent NaN values by using a softmax operation on the adjusted weights\n    w_anneal = torch.softmax(w_anneal, dim=-1)\n\n    return w_anneal"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # compute the fraction of training completed\n    t_d = t[..., 1:] - t[..., :-1]\n    t_d = t_d.clip(eps)\n\n    # compute the annealing effect\n    anneal_effect = torch.sigmoid(anneal_slope * (train_frac - t_d))\n\n    # compute the adjusted weights\n    w_adjusted = w[..., :-1] * anneal_effect\n\n    # handle cases where adjacent intervals have zero distance\n    w_adjusted = torch.where(t_d == 0, torch.zeros_like(w_adjusted), w_adjusted)\n\n    # prevent NaN values by using a softmax operation on the adjusted weights\n    w_adjusted = torch.nn.functional.softmax(w_adjusted, dim=-1)\n\n    return w_adjusted"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n\n    # Compute the distance between adjacent intervals in t.\n    dist = t[..., 1:] - t[..., :-1]\n\n    # Compute the annealing effect based on the training fraction and anneal slope.\n    anneal_effect = torch.sigmoid(train_frac * anneal_slope)\n\n    # Compute the adjusted weights based on the annealing effect and the distance between intervals.\n    adjusted_weights = w * (dist + eps) * anneal_effect\n\n    # Handle cases where adjacent intervals have zero distance.\n    adjusted_weights = torch.where(dist == 0, 0, adjusted_weights)\n\n    # Apply softmax to the adjusted weights to ensure stability in the computation.\n    adjusted_weights = torch.nn.functional.softmax(adjusted_weights, dim=-1)\n\n    # Return the adjusted weights tensor.\n    return adjusted_weights"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # Compute the time differences between adjacent intervals.\n    dt = t[..., 1:] - t[..., :-1]\n\n    # Compute the annealing effect based on the training fraction and anneal slope.\n    anneal_effect = torch.exp(anneal_slope * (train_frac - dt))\n\n    # Compute the adjusted weights by multiplying the original weights with the annealing effect.\n    w_adj = w[..., :-1] * anneal_effect\n\n    # Handle cases where adjacent intervals have zero distance.\n    w_adj = torch.where(dt == 0, torch.zeros_like(w_adj), w_adj)\n\n    # Compute the sum of the adjusted weights.\n    w_sum = torch.sum(w_adj, dim=-1, keepdim=True)\n\n    # Compute the adjusted weights by dividing the adjusted weights by the sum.\n    w_adj = w_adj / w_sum.clip(eps)\n\n    # Compute the softmax of the adjusted weights.\n    w_adj = torch.softmax(w_adj, dim=-1)\n\n    # Return the adjusted weights.\n    return w_adj"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # compute the distance between adjacent intervals\n    dist = t[..., 1:] - t[..., :-1]\n    # handle cases where adjacent intervals have zero distance\n    dist = dist.clip(eps)\n    # compute the bias using Schlick's bias function\n    bias = torch.exp(-(dist[..., None, :] * anneal_slope * train_frac))\n    # compute the adjusted weights\n    w_adj = torch.where(train_frac > t[..., None, :], w[..., None, :] * bias, w[..., None, :])\n    # handle cases where adjacent intervals have zero distance\n    w_adj = torch.where(dist[..., None, :] == 0, 0, w_adj)\n    # normalize the adjusted weights\n    w_adj = w_adj / torch.sum(w_adj, dim=-1, keepdim=True).clip(eps)\n    return w_adj"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # t: [..., num_bins + 1], w: [..., num_bins]\n    # t: [B, P, I + 1], w: [B, P, I]\n\n    # Compute the distance between adjacent intervals.\n    # t_diff: [..., num_bins]\n    t_diff = t[..., 1:] - t[..., :-1]\n\n    # Compute the annealing effect using Schlick's bias function.\n    # anneal_effect: [..., num_bins]\n    anneal_effect = (1 / (1 + torch.exp(-(t_diff - train_frac) * anneal_slope)) - 1 / (1 + torch.exp(-1 * anneal_slope))) / (\n                1 / (1 + torch.exp(-1 * anneal_slope)) - 1 / (1 + torch.exp(-1 * anneal_slope)))\n\n    # Compute the adjusted weights.\n    # w_adj: [..., num_bins]\n    w_adj = w * (1 - anneal_effect)\n\n    # Set the weights of adjacent intervals with zero distance to zero.\n    # w_adj: [..., num_bins]\n    w_adj = torch.where(t_diff == 0, 0, w_adj)\n\n    # Normalize the weights.\n    # w_adj: [..., num_bins]\n    w_adj = w_adj / (torch.sum(w_adj, dim=-1, keepdim=True) + eps)\n\n    return w_adj"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    # t.shape[-1] = w.shape[-1] + 1\n    # handle case where adjacent intervals have zero distance\n    t_diff = t[..., 1:] - t[..., :-1]\n    t_diff = torch.where(t_diff == 0, torch.ones_like(t_diff) * eps, t_diff)\n    # compute annealing effect\n    anneal_effect = torch.sigmoid(train_frac * anneal_slope)\n    anneal_effect = torch.where(anneal_effect == 0, torch.ones_like(anneal_effect) * eps, anneal_effect)\n    anneal_effect = torch.log(anneal_effect)\n    anneal_effect = anneal_effect / torch.max(t_diff)\n    # adjust weights\n    w_adjusted = torch.exp(anneal_effect * t_diff) * w\n    # handle case where weights are zero\n    w_adjusted = torch.where(w_adjusted == 0, torch.ones_like(w_adjusted) * eps, w_adjusted)\n    # normalize weights\n    w_adjusted = w_adjusted / torch.sum(w_adjusted, dim=-1, keepdim=True).clip(eps)\n    return t, w_adjusted"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    w_diff = t[..., 1:] - t[..., :-1]\n    w_diff_zero = torch.where(w_diff == 0, 1, w_diff)\n    w_diff_zero = w_diff_zero.clip(eps)\n\n    # compute anneal weights\n    anneal_w = torch.sigmoid((train_frac - t[..., :-1]) * anneal_slope)\n\n    # compute weights\n    w_new = w[..., :-1] * anneal_w / w_diff_zero\n    w_new = torch.where(w_diff == 0, 0, w_new)\n    w_new = torch.where(torch.isnan(w_new), 0, w_new)\n\n    # normalize weights\n    w_new = w_new / torch.sum(w_new, dim=-1, keepdim=True).clip(eps)\n\n    return w_new"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # accepts t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n\n    # Compute the PDF and CDF for each weight vector.\n    cw = integrate_weights(w)\n    # Compute the annealed weights.\n    t_new = t[..., 1:-1]  # remove first and last bin\n    w_new = w[..., 1:-1]\n    w_new = w_new * (1 - torch.exp(-train_frac * anneal_slope * cw[..., 1:-1]))\n    w_new = w_new / (torch.sum(w_new, dim=-1, keepdim=True) + eps)\n    w_new = torch.where(w_new < 0, 0, w_new)\n    w_new = w_new / (torch.sum(w_new, dim=-1, keepdim=True) + eps)\n    w_new = torch.cat([w_new[..., :1], w_new, w_new[..., -1:]], dim=-1)\n    return t_new, w_new"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n\n    # compute the distance between adjacent intervals\n    t_dist = t[..., 1:] - t[..., :-1]\n    # set the distance between adjacent intervals to zero if they are zero\n    t_dist = torch.where(t_dist == 0, 0, t_dist)\n\n    # compute the bias factor using Schlick's bias function\n    bias_factor = torch.exp(torch.log(1.0 - anneal_slope / t_dist) * train_frac)\n    # apply the bias factor to the weights\n    w = w * bias_factor\n\n    # set the weights of adjacent intervals to zero if they are zero\n    w = torch.where(t_dist == 0, 0, w)\n\n    # normalize the weights to ensure stability in the computation\n    w = w / (torch.sum(w, dim=-1, keepdim=True) + eps)\n\n    return t, w"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n    # w = w.clip(eps)\n    # t = t.clip(eps)\n\n    # compute the distance between adjacent intervals\n    dist = t[..., 1:] - t[..., :-1]\n\n    # handle the case where adjacent intervals have zero distance\n    # set their weight to zero\n    dist = dist.clip(min=eps)\n\n    # compute the annealing effect based on the training fraction\n    # and anneal slope using Schlick's bias function\n    bias = 1 - torch.exp(-(1 - train_frac) * anneal_slope)\n\n    # compute the adjusted weights using the annealing effect\n    # and the original weights\n    w_adj = w * bias\n\n    # handle NaN values by using a softmax operation\n    # on the adjusted weights\n    w_adj = torch.softmax(w_adj, dim=-1)\n\n    return w_adj"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    t, w = matchup_channels(t, w)\n    t_diff = t[..., 1:] - t[..., :-1]\n    w_diff = w[..., 1:] - w[..., :-1]\n    t_diff = torch.cat([t_diff, torch.ones_like(t_diff[..., -1:]) * 1e10], dim=-1)\n    w_diff = torch.cat([w_diff, torch.zeros_like(w_diff[..., -1:])], dim=-1)\n    t_diff = t_diff.clip(min=eps)\n    w_diff = w_diff / t_diff\n    w_diff = torch.where(t_diff > 1e10, torch.zeros_like(w_diff), w_diff)\n    w_diff = torch.where(torch.isnan(w_diff), torch.zeros_like(w_diff), w_diff)\n\n    # Compute the bias factor based on the training fraction and anneal slope.\n    bias = torch.exp(-anneal_slope * (train_frac - 1))\n\n    # Compute the adjusted weights using the bias factor.\n    w_adjusted = w * (1 + bias * w_diff)\n\n    # Normalize the adjusted weights to ensure they sum to 1.\n    w_adjusted = w_adjusted / torch.sum(w_adjusted, dim=-1, keepdim=True).clip(eps)\n\n    return w_adjusted"}
{"namespace": "easyvolcap.utils.prop_utils.anneal_weights", "completion": "    # t.shape[-1] = w.shape[-1] + 1\n    t, w = matchup_channels(t, w)\n    # Compute the annealing weights.\n    anneal_w = torch.sigmoid(\n        anneal_slope * (train_frac - torch.linspace(0.0, 1.0, w.shape[-1], device=w.device, dtype=w.dtype)))\n    anneal_w = anneal_w[..., None]\n\n    # Compute the adjusted weights.\n    # Pad each weight array by 0 on each side to get [0, 0, w[0], w[1], ..., w[-1], 0, 0].\n    w_pad = torch.cat([torch.zeros_like(w[..., :1]), w, torch.zeros_like(w[..., :1])], dim=-1)\n    w_adj = torch.max(w_pad[..., 1:-1] - anneal_w, 0) + torch.max(w_pad[..., 2:] - anneal_w, 0)\n    w_adj = w_adj / torch.sum(w_adj, dim=-1, keepdim=True).clip(eps)\n\n    return t, w_adj"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    elif isinstance(batch, list):\n        if ignore_list:\n            return batch\n        else:\n            return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) if k != \"meta\" else v for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    elif isinstance(batch, list):\n        if ignore_list:\n            return batch\n        else:\n            return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device, ignore_list) for key, value in batch.items() if key != \"meta\"}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, tuple):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, list):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != 'meta'}\n    elif isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, tuple) or isinstance(batch, list):\n        if ignore_list:\n            return batch\n        return [to_cuda(b, device=device) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device=device) if k != \"meta\" else v for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    else:\n        return batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    elif isinstance(batch, tuple):\n        return tuple([to_cuda(b, device, ignore_list) for b in batch])\n    elif isinstance(batch, list):\n        if ignore_list:\n            return [to_cuda(b, device, ignore_list) for b in batch]\n        else:\n            return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(x, device, ignore_list) for x in batch]\n    elif isinstance(batch, dict):\n        if ignore_list:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != 'meta'}\n        else:\n            return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != 'meta'}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    elif isinstance(batch, tuple) and not ignore_list:\n        return tuple(to_cuda(t, device) for t in batch)\n    elif isinstance(batch, list) and not ignore_list:\n        return [to_cuda(t, device) for t in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device) if k != \"meta\" else v for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    elif isinstance(batch, list):\n        if ignore_list:\n            return batch\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        if 'meta' in batch:\n            return batch\n        return {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        if batch.device != device:\n            return batch.to(device)\n        else:\n            return batch\n    elif isinstance(batch, list):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) if k != \"meta\" else v for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, tuple):\n        batch = tuple(to_cuda(t, device, ignore_list) for t in batch)\n    elif isinstance(batch, list):\n        if ignore_list:\n            batch = [to_cuda(t, device, ignore_list) for t in batch]\n        else:\n            batch = [to_cuda(t, device, ignore_list) for t in batch]\n    elif isinstance(batch, dict):\n        batch = {k: to_cuda(v, device, ignore_list) for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.to(device, non_blocking=True)\n    else:\n        pass\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, tuple):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, list):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) if k != \"meta\" else v for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    elif isinstance(batch, np.ndarray):\n        return torch.from_numpy(batch).to(device, non_blocking=True)\n    elif isinstance(batch, str):\n        return batch\n    elif isinstance(batch, bytes):\n        return batch\n    elif isinstance(batch, int):\n        return batch\n    elif isinstance(batch, float):\n        return batch\n    elif isinstance(batch, bool):\n        return batch\n    elif isinstance(batch, np.bool_):\n        return bool(batch)\n    elif isinstance(batch, np.int64):\n        return int(batch)\n    elif isinstance(batch, np.float64):\n        return float(batch)\n    elif isinstance(batch, np.float32):\n        return float(batch)\n    elif isinstance(batch, np.int32):\n        return int(batch)\n    elif isinstance(batch, np.int16):\n        return int(batch)\n    elif isinstance(batch, np.int8):\n        return int(batch)\n    elif isinstance(batch, np.uint8):\n        return int(batch)\n    elif isinstance(batch, np.uint16):\n        return int(batch)\n    elif isinstance(batch, np.uint32):\n        return int(batch)\n    elif isinstance(batch, np.uint64):\n        return int(batch)\n    elif isinstance(batch, np.float16):\n        return float(batch"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.cuda(device)\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, list):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    elif isinstance(batch, list):\n        if ignore_list:\n            return batch\n        else:\n            return [to_cuda(b, device) for b in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(b, device) for b in batch)\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device) for k, v in batch.items() if k != 'meta'}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(b, device) for b in batch)\n    elif isinstance(batch, list):\n        if ignore_list:\n            return [b for b in batch]\n        else:\n            return [to_cuda(b, device) for b in batch]\n    elif isinstance(batch, dict):\n        if \"meta\" in batch:\n            return batch\n        else:\n            return {k: to_cuda(v, device) for k, v in batch.items()}\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device)\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) if k != \"meta\" else v for k, v in batch.items()}\n    elif isinstance(batch, (tuple, list)):\n        return [to_cuda(v, device, ignore_list) for v in batch]\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device, ignore_list) for key, value in batch.items() if key != \"meta\"}\n    elif isinstance(batch, list):\n        if ignore_list:\n            return [to_cuda(value, device, ignore_list) for value in batch]\n        else:\n            return [to_cuda(value, device, ignore_list) for value in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(value, device, ignore_list) for value in batch)\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    elif isinstance(batch, list):\n        if ignore_list:\n            return batch\n        else:\n            return [to_cuda(item, device) for item in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(item, device) for item in batch)\n    elif isinstance(batch, dict):\n        return {key: to_cuda(value, device) if key != \"meta\" else value for key, value in batch.items()}\n    else:\n        raise NotImplementedError(f\"Unsupported data type: {type(batch)}\")\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, tuple) or isinstance(batch, list):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) if k != \"meta\" else v for k, v in batch.items()}\n    elif isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    else:\n        return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.to_cuda", "completion": "    if isinstance(batch, torch.Tensor):\n        return batch.to(device, non_blocking=True)\n    elif isinstance(batch, list):\n        return [to_cuda(b, device, ignore_list) for b in batch]\n    elif isinstance(batch, tuple):\n        return tuple(to_cuda(b, device, ignore_list) for b in batch)\n    elif isinstance(batch, dict):\n        return {k: to_cuda(v, device, ignore_list) for k, v in batch.items() if k != \"meta\"}\n    elif isinstance(batch, np.ndarray):\n        return torch.from_numpy(batch).to(device, non_blocking=True)\n    elif isinstance(batch, str):\n        return batch\n    elif isinstance(batch, BytesIO):\n        return batch\n    elif isinstance(batch, bytes):\n        return batch\n    elif isinstance(batch, Image.Image):\n        return batch\n    elif isinstance(batch, bytes):\n        return batch\n    elif isinstance(batch, int):\n        return batch\n    elif isinstance(batch, float):\n        return batch\n    elif isinstance(batch, bool):\n        return batch\n    elif isinstance(batch, np.bool_):\n        return batch\n    elif isinstance(batch, np.ndarray):\n        return batch\n    elif isinstance(batch, np.int64):\n        return batch\n    elif isinstance(batch, np.float32):\n        return batch\n    else:\n        raise NotImplementedError(f\"Unrecognized type: {type(batch)}\")\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # index will first be augmented to match the values' dimentionality at the back\n    # take care of batch dimension of, and acts like a linear indexing in the target dimention\n    # we assume that the values's second to last dimension is the dimension to be indexed on\n    f = multi_indexing(f, v.shape, dim)\n    f = f.reshape(*v.shape[:dim], -1, 3)\n    return v.gather(dim, f)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim < v.ndim:\n        f = f.unsqueeze(0).expand(v.shape[:-2] + (-1, -1))\n    # gather the vertices corresponding to each face\n    f_v = multi_gather(v, f, dim)\n    # compute the normals of the faces\n    normals = torch.cross(f_v[:, :, 1] - f_v[:, :, 0], f_v[:, :, 2] - f_v[:, :, 0], dim=-1)\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    return normals.view(*f.shape, -1)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim < v.ndim:\n        f = f.unsqueeze(0).expand(*v.shape[:f.ndim], *f.shape)\n\n    # gather the vertices corresponding to the faces\n    v_f = multi_gather(v, f, dim)\n\n    # compute the normals of the faces\n    n = torch.cross(v_f[..., 1, :] - v_f[..., 0, :], v_f[..., 2, :] - v_f[..., 0, :])\n    n = n / (n.norm(dim=-1, keepdim=True) + 1e-8)\n\n    # reshape the result to maintain the structure of the original faces tensor with additional dimensions for batch processing\n    n = n.view(*f.shape[:-1], *n.shape[1:])\n\n    return n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim == 2:\n        f = f.unsqueeze(0)\n        f = f.expand(v.shape[0], *f.shape[1:])\n\n    # gather the vertices corresponding to the faces\n    v_f = multi_gather(v, f, dim=dim)\n\n    # compute the normals of the faces\n    n = torch.cross(v_f[:, :, 1] - v_f[:, :, 0], v_f[:, :, 2] - v_f[:, :, 0], dim=-1)\n    n = n / (n.norm(dim=-1, keepdim=True) + 1e-8)\n\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    return n.view(*f.shape, 3)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimension of f to match the batch dimension of v\n    if f.ndim == v.ndim - 1:\n        f = f.unsqueeze(0).expand(v.shape[0], *f.shape)\n\n    # compute the triangles by gathering the vertices based on the faces indices\n    tri = multi_gather(v, f, dim)\n\n    # reshape the result to maintain the original faces tensor structure\n    return tri.reshape(*f.shape, *tri.shape[1:])"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimension of faces to match the vertices\n    if f.ndim > v.ndim:\n        f = f[(slice(None),) * (f.ndim - v.ndim) + (slice(None),)]\n    # gather vertices\n    v = multi_gather(v, f, dim)\n    # reshape\n    return v.view(*f.shape, *v.shape[v.ndim - 1:])"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor if necessary\n    if f.ndim < v.ndim:\n        f = f.unsqueeze(0).expand(v.shape[:-2] + (-1, -1))\n\n    # reshape the faces tensor to match the batch dimension of the vertices tensor\n    f = f.reshape(-1, *f.shape[-2:])\n\n    # gather the vertices for each face\n    v_f = multi_gather(v, f, dim)\n\n    # compute the face normals\n    n = torch.cross(v_f[..., 1, :] - v_f[..., 0, :], v_f[..., 2, :] - v_f[..., 0, :])\n    n = n / (n.norm(dim=-1, keepdim=True) + 1e-8)\n\n    # reshape the result to match the original faces tensor structure with additional dimensions for batch processing\n    n = n.reshape(*f.shape[:-2], *n.shape[1:])\n\n    return n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim < v.ndim:\n        f = f.unsqueeze(0).expand(v.shape[0], *f.shape)\n    # gather the vertices corresponding to the faces\n    v0, v1, v2 = multi_gather(v, f, dim=dim).unbind(-1)\n    # compute the face normals\n    n = torch.cross(v1 - v0, v2 - v0, dim=-1)\n    # normalize the normals\n    n = n / torch.norm(n, dim=-1, keepdim=True)\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    return n.reshape(*f.shape, *n.shape[1:])"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim < v.ndim:\n        f = f.unsqueeze(0).expand(v.shape[:-2] + f.shape)\n    # gather the vertices for each face\n    f_v = multi_gather(v, f, dim)\n    # compute the normals of the faces\n    normals = torch.cross(f_v[:, :, 1] - f_v[:, :, 0], f_v[:, :, 2] - f_v[:, :, 0])\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    normals = normals.view(v.shape[:-2] + f.shape[:-2] + f.shape[-2:])\n    return normals\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim > v.ndim: f = f.squeeze(0)\n    elif f.ndim < v.ndim: f = f.unsqueeze(0).expand(*v.shape[:-2], *f.shape[-2:])\n    # gather the vertices for each face\n    v0 = multi_gather(v, f[:, :, 0], dim)\n    v1 = multi_gather(v, f[:, :, 1], dim)\n    v2 = multi_gather(v, f[:, :, 2], dim)\n    # compute the face normals\n    normals = torch.cross(v1 - v0, v2 - v0, dim=-1)\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    normals = normals.view(*f.shape, 3)\n    return normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim < v.ndim:\n        f = f.unsqueeze(0)\n    elif f.ndim > v.ndim:\n        f = f.reshape(f.shape[:v.ndim] + (-1, 3))\n\n    # gather the vertices for each face\n    f_v = multi_gather(v, f, dim)\n\n    # compute the face normals\n    normals = torch.cross(f_v[..., 1, :] - f_v[..., 0, :], f_v[..., 2, :] - f_v[..., 0, :], dim=-1)\n    normals = normals / (normals.norm(dim=-1, keepdim=True) + 1e-8)\n\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    normals = normals.reshape(f.shape[:-1] + (3,))\n\n    return normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimension of faces tensor to match the batch dimension of vertices tensor\n    if f.ndim == v.ndim - 1:\n        f = f.unsqueeze(0).expand(v.shape[0], *f.shape)\n\n    # gather the vertices for each face\n    v1 = multi_gather(v, f, dim)\n\n    # compute the normals of the faces\n    normals = torch.cross(v1[:, :, 1] - v1[:, :, 0], v1[:, :, 2] - v1[:, :, 0])\n\n    # reshape the result to maintain the structure of the original faces tensor\n    normals = normals.reshape(*f.shape, 3)\n\n    return normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    if f.ndim == v.ndim: f = f.unsqueeze(0)  # add batch dimension\n    if f.shape[0] != v.shape[0]: f = f.expand(v.shape[0], *f.shape[1:])  # expand batch dimension\n    v = v.unsqueeze(1)  # add triangle dimension\n    f = f.unsqueeze(-1)  # add vertex dimension\n    tri = multi_gather(v, f, dim)  # gather triangles\n    tri = tri.view(*f.shape[:-1], 3, v.shape[-1])  # reshape to original faces structure\n    return tri"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimension of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim < v.ndim:\n        f = f.unsqueeze(0).expand(v.shape[0], *f.shape)\n\n    # reshape the faces tensor to match the batch dimension of the vertices tensor\n    shape = list(f.shape)\n    shape[dim] = -1\n    f = f.reshape(*shape)\n\n    # gather the vertices corresponding to the faces\n    v = multi_gather(v, f, dim)\n\n    # compute the normals of the faces\n    n = torch.cross(v[:, :, 1] - v[:, :, 0], v[:, :, 2] - v[:, :, 0], dim=-1)\n    n = n / (n.norm(dim=-1, keepdim=True) + 1e-12)\n\n    # reshape the result to match the original faces tensor structure with additional dimensions for batch processing\n    shape = list(f.shape)\n    shape[dim] = 3\n    return n.reshape(*shape)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim > v.ndim:\n        f = f.unsqueeze(0).expand(v.shape[:-2] + (-1, -1))\n    elif f.ndim < v.ndim:\n        f = f.unsqueeze(-2).expand(v.shape[:-2] + (-1, -1))\n\n    # reshape the faces tensor to maintain the original structure with additional dimensions for batch processing\n    f = f.reshape(*f.shape[:-2], -1, 3)\n\n    # gather the vertices using the faces tensor and compute the normals\n    v_gathered = multi_gather(v, f, dim)\n    normals = torch.cross(v_gathered[:, :, 1] - v_gathered[:, :, 0], v_gathered[:, :, 2] - v_gathered[:, :, 0], dim=-1)\n    normals = normals / (normals.norm(dim=-1, keepdim=True) + 1e-8)\n    return normals"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim < v.ndim:\n        f = f.unsqueeze(0).expand(v.shape[:-2] + f.shape)\n\n    # compute the faces normals\n    triangles = multi_gather(v, f, dim)\n\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    return triangles.view(*f.shape[:-1], 3, 3)\n\n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim > v.ndim:\n        f = f.view(*v.shape[:f.ndim - v.ndim], *f.shape)\n\n    # reshape the faces tensor to match the batch dimension of the vertices tensor\n    f = f.expand(*v.shape[:f.ndim - 2], *f.shape)\n\n    # gather the vertices corresponding to the faces\n    v = multi_gather(v, f, dim=dim)\n\n    # compute the faces normals\n    v0, v1, v2 = v[..., 0, :], v[..., 1, :], v[..., 2, :]\n    n = torch.cross(v1 - v0, v2 - v0, dim=-1)\n    n = n / (n.norm(dim=-1, keepdim=True) + 1e-8)\n\n    # reshape the result to maintain the structure of the original faces tensor with additional dimensions for batch processing\n    n = n.view(*f.shape[:-1], *n.shape[f.ndim - 1:])\n\n    return n"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor if necessary\n    if f.ndim > v.ndim:\n        f = f.squeeze(-1)\n    elif f.ndim < v.ndim:\n        f = f.unsqueeze(-1)\n    # gather the vertices using the faces indices\n    v = multi_gather(v, f, dim)\n    # compute the face normals by taking the cross product of two edges of the triangle\n    normals = torch.cross(v[:, :, 1] - v[:, :, 0], v[:, :, 2] - v[:, :, 0], dim=-1)\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    return normals.reshape(*f.shape, -1)"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    # adjust the dimensions of the faces tensor to match the batch dimension of the vertices tensor\n    if f.ndim == v.ndim - 1:\n        f = f.unsqueeze(0)\n    elif f.ndim == v.ndim:\n        f = f.unsqueeze(-1)\n    else:\n        raise ValueError(\"The dimensions of the faces tensor do not match the batch dimension of the vertices tensor.\")\n\n    # reshape the faces tensor to match the original structure with additional dimensions for batch processing\n    f = f.view(*f.shape[:-1], 3, -1)\n\n    # gather the vertices to form triangles\n    triangles = multi_gather(v, f, dim)\n\n    # reshape the result to maintain the original faces tensor structure with additional dimensions for batch processing\n    triangles = triangles.view(*f.shape[:-1], 3, -1, triangles.shape[-1])\n\n    return triangles"}
{"namespace": "easyvolcap.utils.chunk_utils.multi_gather_tris", "completion": "    if f.ndim == v.ndim:\n        f = f.unsqueeze(0)\n    elif f.ndim != v.ndim + 1:\n        raise RuntimeError(f'Unsupported face dimension: {f.ndim}')\n\n    # adjust the dimension of faces to match the batch dimension of vertices\n    v_sh = v.shape\n    f_sh = f.shape\n    v_sh = v_sh[:-2]\n    f_sh = f_sh[:-2] + (1,) * (len(v_sh) - 1) + f_sh[-2:]\n    f = f.expand(*f_sh)\n\n    # reshape the faces tensor to maintain the original structure with additional dimensions for batch processing\n    f_sh = f.shape\n    f = f.reshape(*f_sh[:-2], -1, 3)\n\n    # gather the vertices using the faces tensor\n    v = v.unsqueeze(-2).expand(*f_sh[:-2], -1, -1, -1)\n    f = f.unsqueeze(-1).expand(*f_sh[:-2], -1, -1, v.shape[-1])\n    v = v.gather(dim=dim, index=f)\n\n    # reshape the vertices tensor to maintain the original structure\n    v = v.reshape(*f_sh[:-2], -1, v.shape[-1])\n    return v"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):  # numpy and others\n        batch = batch[None]\n    else:  # others, keep as is\n        pass\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, 0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = batch[np.newaxis]\n    else:\n        batch = torch.as_tensor(batch)[np.newaxis]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, axis=0)\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch[None]\n    elif isinstance(batch, np.ndarray):\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, 0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = batch[None, ...]\n    else:\n        batch = torch.as_tensor(batch)[None, ...]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, torch.Tensor):\n        batch = batch.unsqueeze(0)\n    elif isinstance(batch, np.ndarray):\n        batch = np.expand_dims(batch, 0)\n    else:\n        batch = torch.as_tensor(batch).unsqueeze(0)\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.data_utils.add_batch", "completion": "    if isinstance(batch, (tuple, list)):\n        batch = [add_batch(b) for b in batch]\n    elif isinstance(batch, dict):\n        batch = dotdict({k: add_batch(v) for k, v in batch.items()})\n    elif isinstance(batch, (torch.Tensor, np.ndarray)):  # numpy and others\n        batch = batch[None]\n    else:\n        batch = torch.as_tensor(batch)[None]\n    return batch\n\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.origin, batch.world_up, batch.movement_speed, batch.movement_force, batch.drag_coeff_mult, batch.constant_drag, batch.mass, batch.moment_of_inertia, batch.movement_torque, batch.angular_friction, batch.constant_torque = self.origin, self.world_up, self.movement_speed, self.movement_force, self.drag_coeff_mult, self.constant_drag, self.mass, self.moment_of_inertia, self.movement_torque, self.angular_friction, self.constant_torque\n        batch.min_interval, batch.pause_physics = self.min_interval, self.pause_physics\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta.origin, batch.meta.world_up, batch.meta.movement_speed, batch.meta.movement_force, batch.meta.drag_coeff_mult, batch.meta.constant_drag, batch.meta.mass, batch.meta.moment_of_inertia, batch.meta.movement_torque, batch.meta.angular_friction, batch.meta.constant_torque = self.origin, self.world_up, self."}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta = dotdict(batch)\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Add a nested 'meta' dictionary with the same content\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Add the GUI related elements to the batch\n        batch.origin = self.origin\n        batch.world_up = self.world_up\n        batch.movement_speed = self.movement_speed\n        batch.movement_force = self.movement_force\n        batch.drag_coeff_mult = self.drag_coeff_mult\n        batch.constant_drag = self.constant_drag\n        batch.mass = self.mass\n        batch.moment_of_inertia = self.moment_of_inertia\n        batch.movement_torque = self.movement_torque\n        batch.angular_friction = self.angular_friction\n        batch.constant_torque = self.constant_torque\n        batch.min_interval = self.min_interval\n        batch.pause_physics = self.pause_physics\n\n        # Convert all the parameters to tensors\n        batch.H = torch.as_tensor(batch.H, dtype=torch.int32)\n        batch.W = torch.as_tensor(batch.W, dtype=torch.int32)\n        batch.K = torch.as_tensor(batch.K, dtype=torch.float32)\n        batch.R = torch.as_tensor(batch.R, dtype=torch.float32)\n        batch.T = torch.as_tensor(batch.T, dtype=torch.float32)\n        batch.n = torch.as_tensor(batch.n, dtype=torch.float32)\n        batch.f = torch.as_tensor(batch.f, dtype=torch.float32)\n       "}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = \\\n            self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = \\\n            self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta = dotdict(batch)\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Add meta information\n        meta = dotdict()\n        meta.H, meta.W, meta.K, meta.R, meta.T, meta.n, meta.f, meta.t, meta.v, meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta = meta\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Convert the camera parameters and GUI related elements into tensors\n        H, W, K, R, T, n, f, t, v, bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        H, W, n, f, t, v = torch.tensor(H), torch.tensor(W), torch.tensor(n), torch.tensor(f), torch.tensor(t), torch.tensor(v)\n        K, R, T, bounds = torch.as_tensor(K), torch.as_tensor(R), torch.as_tensor(T), torch.as_tensor(bounds)\n\n        # Organize the parameters into a structured dictionary format\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = H, W, K, R, T, n, f, t, v, bounds\n\n        # Create a nested 'meta' dictionary with the same content\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = H, W, K, R, T, n, f, t, v, bounds\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Store the camera parameters in the batch\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta = dotdict(batch)\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta = dotdict(batch)\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        # Create a structured dictionary with a direct mapping of parameters\n        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Create a nested 'meta' dictionary with the same content\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n\n        # Convert all tensor elements to tensors\n        for k, v in batch.items():\n            batch[k] = torch.as_tensor(v)\n\n        return batch\n"}
{"namespace": "easyvolcap.utils.viewer_utils.Camera.to_batch", "completion": "        batch = dotdict()\n        batch.H, batch.W, batch.K, batch.R, batch.T, batch.n, batch.f, batch.t, batch.v, batch.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        batch.meta = dotdict()\n        batch.meta.H, batch.meta.W, batch.meta.K, batch.meta.R, batch.meta.T, batch.meta.n, batch.meta.f, batch.meta.t, batch.meta.v, batch.meta.bounds = self.H, self.W, self.K, self.R, self.T, self.n, self.f, self.t, self.v, self.bounds\n        return batch\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_dict = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent_dict)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_working_agent() or agent.is_prime_agent():\n            return\n\n        serialized_agent = AgentSerializer.serialize(agent)\n        self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_working_agent() or agent.is_prime_agent():\n            return\n\n        agent_dict = AgentSerializer.serialize(agent)\n        self.persistence.save_agent(agent_dict)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_working_agent() or agent.is_prime_agent():\n            return\n\n        agent_dict = AgentSerializer.serialize(agent)\n        self.persistence.save_agent(agent_dict)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serializer = AgentSerializer()\n            agent_dict = serializer.serialize(agent)\n            self.persistence.save_agent(agent_dict)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serialized_agent = AgentSerializer.serialize_agent(agent)\n            self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serializer = AgentSerializer(agent)\n            agent_dict = serializer.serialize()\n            self.persistence.save_agent(agent_dict)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_working_agent() or agent.is_prime_agent():\n            return\n\n        serialized_agent = AgentSerializer.serialize_agent(agent)\n        self.persistence.save_agent(serialized_agent)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_state = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent_state)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_working_agent() or agent.is_prime_agent():\n            return\n\n        serialized_agent = AgentSerializer.serialize(agent)\n        self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_working_agent() or agent.is_prime_agent():\n            return\n        agent_state = AgentSerializer.serialize_agent(agent)\n        self.persistence.save_agent(agent_state)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            agent_dict = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_working_agent() or agent.is_prime_agent():\n            return\n\n        agent_dict = AgentSerializer.serialize(agent)\n        self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            serialized_agent = AgentSerializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_working_agent():\n            return\n\n        if agent.is_prime_agent():\n            return\n\n        agent_dict = AgentSerializer.serialize(agent)\n        self.persistence.save_agent(agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if not agent.is_working_agent() or agent.is_prime_agent():\n            return\n\n        agent_dict = AgentSerializer.serialize(agent)\n        self.persistence.save_agent(agent.id, agent_dict)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent() and not agent.is_prime_agent():\n            serializer = AgentSerializer()\n            serialized_agent = serializer.serialize(agent)\n            self.persistence.save_agent(serialized_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.save_agent", "completion": "        if agent.is_working_agent and not agent.is_prime_agent:\n            serializer = AgentSerializer(agent)\n            state = serializer.serialize()\n            self.persistence.save_agent(agent.id, state)\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float('inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float('inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float('inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float('inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float('inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            highest_similarity = -float('inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n\n                if similarity > highest_similarity:\n                    highest_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, highest_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, -np.inf\n\n            similarities = [cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0] for agent in self.agents]\n            max_index = np.argmax(similarities)\n            return self.agents[max_index], similarities[max_index]\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float('inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            return None, -float('inf')"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, -float('inf')\n\n            max_similarity = -float('inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float('inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -np.inf\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float('inf')\n            closest_agent = None\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            if not self.agents:\n                return None, -float('inf')\n\n            max_similarity = -float('inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n"}
{"namespace": "agent_similarity.AgentSimilarity.find_closest_agent", "completion": "        try:\n            max_similarity = -float('inf')\n            closest_agent = None\n\n            for agent in self.agents:\n                if agent.purpose_embedding is None:\n                    agent.purpose_embedding = self.get_embedding(agent.purpose)\n\n                similarity = cosine_similarity([purpose_embedding], [agent.purpose_embedding])[0][0]\n\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    closest_agent = agent\n\n            return closest_agent, max_similarity\n        except Exception as e:\n            logger.exception(f\"Error finding closest agent: {e}\")\n            raise ValueError(f\"Error finding closest agent: {e}\")\n\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence=self.agent_persistence,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            unspecified=True\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True,\n            openai_api=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True,\n            stop_on_model_output=True,\n            stop_on_action=True,\n            verbose=True,\n            openai_api_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence=self.agent_persistence,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True,\n            openai_api_wrapper=self.openai_wrapper,\n            agent_persistence_manager=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            is_unspecified=True,\n            openai_wrapper=self.openai_wrapper,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            name=PRIME_NAME,\n            prompt=PRIME_PROMPT,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence=self.agent_persistence,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True,\n            openai_wrapper=self.openai_wrapper,\n            agent_persistence=self.agent_persistence\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            is_prime=True,\n            unspecified=True,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.create_prime_agent", "completion": "        prime_agent = MicroAgent(\n            prompt=PRIME_PROMPT,\n            name=PRIME_NAME,\n            weight=PRIME_AGENT_WEIGHT,\n            prime=True,\n            unspecified=True,\n            stop_agent=False,\n            stop_on_model_output=False,\n            stop_on_output_length=False,\n        )\n        self.agents.append(prime_agent)\n"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(serialized_agent, agent_lifecycle, openai_wrapper)\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None\n\n    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: A list of deserialized agent instances.\n        \"\"\"\n        serialized_agents = self.persistence.load_all_agents()\n        return [\n            AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite(db_filename=\"agents.db\", table_name=\"agents\")\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        else:\n            return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None\n\n    \"\"\"\n    Loads the prime agent from the database. If the prime agent is found, it is deserialized and returned; otherwise, None is returned.\n\n    Input-Output Arguments\n    :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n    :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n    :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n    :return: An instance of the deserialized prime agent if found, otherwise None.\n    \"\"\"\n\n    @memoize_to_sqlite\n    def load_prime_agent(self, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_prime_agent()\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None\n\n    def get_agent_purposes(self):\n        \"\"\"\n        Retrieves the purposes of all agents stored in the persistence.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :return: A list of strings representing the purposes of all agents stored in the persistence.\n        \"\"\"\n        return self.persistence.get_agent_purposes()"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    @memoize_to_sqlite(persistence_method=\"load_agent\")\n    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent:\n            return AgentSerializer.deserialize(\n                serialized_agent,\n                agent_lifecycle=agent_lifecycle,\n                openai_wrapper=openai_wrapper,\n            )\n        return None"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_agent", "completion": "    def load_agent(self, purpose, agent_lifecycle, openai_wrapper):\n        serialized_agent = self.persistence.load_agent(purpose)\n        if serialized_agent is not None:\n            return AgentSerializer.deserialize(\n                serialized_agent, agent_lifecycle, openai_wrapper\n            )\n        return None\n\n    @memoize_to_sqlite\n    def get_agent_by_purpose(self, purpose):\n        \"\"\"\n        Loads an agent with a specified purpose from the database. If an agent with the given purpose is found, it is deserialized and returned; otherwise, None is returned.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str, The purpose of the agent to be loaded. It is used to identify the agent in the database.\n        :param agent_lifecycle: The lifecycle state of the agent. It is passed to the deserializer to properly initialize the agent.\n        :param openai_wrapper: An instance or interface used for interacting with OpenAI services. It is passed to the deserializer for initializing the agent with OpenAI functionalities.\n        :return: An instance of the deserialized agent if found, otherwise None.\n        \"\"\"\n        return self.load_agent(purpose, None, None)"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": ""}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        agents = []\n        for purpose in self.persistence.fetch_all_agents():\n            agent = self.load_agent(purpose, agent_lifecycle, openai_wrapper)\n            if agent:\n                agents.append(agent)\n        return agents"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "    def load_all_agents(self, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads all agents from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A list of agents that have been successfully loaded from the database.\n        \"\"\"\n        serialized_agents = self.persistence.fetch_all_agents()\n        loaded_agents = []\n        for serialized_agent in serialized_agents:\n            loaded_agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            loaded_agents.append(loaded_agent)\n        return loaded_agents\n\n    def load_agents_by_purpose(self, purpose, agent_lifecycle, openai_wrapper):\n        \"\"\"\n        Loads agents with the specified purpose from the database and returns a list of these agents if they are successfully loaded. Each agent is loaded based on its purpose, utilizing the provided agent lifecycle and OpenAI wrapper for the loading process.\n\n        Input-Output Arguments\n        :param self: AgentPersistenceManager. An instance of the AgentPersistenceManager class.\n        :param purpose: str. The purpose or category of agents to be loaded from the database.\n        :param agent_lifecycle: The lifecycle manager for agents, used to manage the state and transitions of an agent throughout its lifecycle.\n        :param openai_wrapper: An interface or wrapper for OpenAI functionalities, used to interact with OpenAI services or models in the process of loading an agent.\n        :return: list. A"}
{"namespace": "agent_persistence_manager.AgentPersistenceManager.load_all_agents", "completion": "        serialized_agents = self.persistence.fetch_all_agents()\n        loaded_agents = []\n        for serialized_agent in serialized_agents:\n            agent = AgentSerializer.from_dict(serialized_agent, agent_lifecycle, openai_wrapper)\n            if agent:\n                loaded_agents.append(agent)\n        return loaded_agents\n\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error saving agent: %s\", e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error saving agent: %s\", e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error saving agent: %s\", e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error while saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error saving agent: %s\", e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error while saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error saving agent: %s\", e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error saving agent: %s\", e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.error(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error while saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error while saving agent: %s\", e)\n            raise\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent: {e}\")\n            raise\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error saving agent: %s\", e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(f\"Error saving agent: {e}\")\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error saving agent: %s\", e)\n            raise e\n"}
{"namespace": "agent_lifecycle.AgentLifecycle.save_agent", "completion": "        try:\n            self.agent_persistence.save_agent(agent)\n        except Exception as e:\n            logger.exception(\"Error saving agent: %s\", e)\n            raise e\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "microagent_manager.MicroAgentManager.get_agents", "completion": "        self.cleanup_agents()\n        return self.agent_lifecycle.agents\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = self.openai_wrapper.get_chat_completion(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT,\n                PROMPT_ENGINEERING_TEMPLATE,\n                EXAMPLES,\n                goal,\n                sample_input\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = self.openai_wrapper.get_chat_completion(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT,\n                PROMPT_ENGINEERING_TEMPLATE,\n                EXAMPLES,\n                goal,\n                sample_input\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = self.openai_wrapper.get_chat_completion(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT,\n                PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, sample_input=sample_input, examples=EXAMPLES),\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT + PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, sample_input=sample_input, examples=EXAMPLES)\n        try:\n            return self.openai_wrapper.get_chat_completion(prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT + PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, example_input=sample_input, examples=EXAMPLES)\n        try:\n            response = self.openai_wrapper.get_chat_completion(prompt)\n            return response\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = self.openai_wrapper.get_chat_completion(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT,\n                PROMPT_ENGINEERING_TEMPLATE,\n                goal,\n                sample_input,\n                EXAMPLES,\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = self.openai_wrapper.get_chat_completion(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT,\n                PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, example_input=sample_input, examples=EXAMPLES)\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_TEMPLATE.format(\n            goal=goal,\n            examples=EXAMPLES,\n            sample_input=sample_input\n        )\n\n        try:\n            response = self.openai_wrapper.get_chat_completion(prompt)\n            return response\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = self.openai_wrapper.get_chat_completion(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT, \n                PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, example=sample_input, examples=EXAMPLES)\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = self.openai_wrapper.get_chat_completion(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT,\n                PROMPT_ENGINEERING_TEMPLATE,\n                goal,\n                EXAMPLES,\n                sample_input,\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT + PROMPT_ENGINEERING_TEMPLATE.format(\n            examples=EXAMPLES,\n            goal=goal,\n            sample_input=sample_input\n        )\n\n        try:\n            return self.openai_wrapper.get_chat_completion(prompt)\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_TEMPLATE.format(\n            prime_prompt=PRIME_PROMPT,\n            prime_name=PRIME_NAME,\n            examples=EXAMPLES,\n            goal=goal,\n            sample_input=sample_input\n        )\n\n        try:\n            chat_completion = self.openai_wrapper.get_chat_completion(prompt)\n            return chat_completion\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = self.openai_wrapper.get_chat_completion(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT,\n                PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, sample_input=sample_input, examples=EXAMPLES),\n                max_tokens=1024,\n                temperature=0.7,\n                top_p=1,\n                frequency_penalty=0,\n                presence_penalty=0\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\""}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(goal=goal, sample_input=sample_input, examples=EXAMPLES)\n        try:\n            response = self.openai_wrapper.get_chat_completion(prompt)\n            return response\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = self.openai_wrapper.get_chat_completion(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT,\n                PROMPT_ENGINEERING_TEMPLATE,\n                EXAMPLES,\n                goal,\n                sample_input\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = self.openai_wrapper.get_chat_completion(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT,\n                PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, sample_input=sample_input, examples=EXAMPLES)\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT + PROMPT_ENGINEERING_TEMPLATE.format(\n                goal=goal,\n                sample_input=sample_input,\n                examples=EXAMPLES\n            )\n            response = self.openai_wrapper.get_chat_completion(prompt)\n            return response\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = f\"{PRIME_PROMPT}\\n\\n{PROMPT_ENGINEERING_SYSTEM_PROMPT}\\n\\n{PROMPT_ENGINEERING_TEMPLATE}\\n\\n{EXAMPLES}\\n\\nGoal: {goal}\\n\\nSample input: {sample_input}\\n\\nPrompt:\"\n        try:\n            response = self.openai_wrapper.get_chat_completion(prompt)\n            return response\n        except Exception as e:\n            logger.exception(f\"Error in generating prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        try:\n            prompt = self.openai_wrapper.get_chat_completion(\n                PROMPT_ENGINEERING_SYSTEM_PROMPT,\n                PROMPT_ENGINEERING_TEMPLATE.format(goal=goal, sample_input=sample_input, examples=EXAMPLES),\n            )\n            return prompt\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\"\n"}
{"namespace": "agent_lifecycle.AgentLifecycle._generate_llm_prompt", "completion": "        prompt = PROMPT_ENGINEERING_SYSTEM_PROMPT.format(\n            purpose=goal,\n            examples=EXAMPLES,\n            template=PROMPT_ENGINEERING_TEMPLATE\n        )\n\n        try:\n            response = self.openai_wrapper.get_chat_completion(prompt, sample_input)\n            return response\n        except Exception as e:\n            logger.exception(f\"Error in generating LLM prompt: {e}\")\n            return \"\"\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        # Serialize the agent dictionary into a JSON string\n        agent_json = json.dumps(agent_dict)\n\n        # Connect to the SQLite database\n        with sqlite3.connect(self.filename) as conn:\n            # Check if the agent already exists in the database\n            cursor = conn.execute(\"SELECT id FROM agents WHERE id = ?\", (agent_dict['id'],))\n            existing_agent = cursor.fetchone()\n\n            # If the agent exists, update its record\n            if existing_agent:\n                conn.execute(\"UPDATE agents SET purpose = ?, data = ? WHERE id = ?\", (agent_dict['purpose'], agent_json, agent_dict['id']))\n            # If the agent does not exist, insert a new record\n            else:\n                conn.execute(\"INSERT INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], agent_json))"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            data = json.dumps(agent_dict)\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], data))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            data = json.dumps(agent_dict)\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], data))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict['data'])))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\n                \"INSERT OR REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\",\n                (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict))\n            )\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict[\"id\"], agent_dict[\"purpose\"], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            agent_id = agent_dict[\"id\"]\n            agent_purpose = agent_dict[\"purpose\"]\n            agent_data = json.dumps(agent_dict)\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_id, agent_purpose, agent_data))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            data = json.dumps(agent_dict)\n            conn.execute(\"REPLACE INTO agents (id, purpose, data) VALUES (?, ?, ?)\", (agent_dict['id'], agent_dict['purpose'], data))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict['data'])))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            data = json.dumps(agent_dict)\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], data))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], json.dumps(agent_dict)))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.save_agent", "completion": "        # Serialize the agent_dict to JSON\n        agent_json = json.dumps(agent_dict)\n\n        # Insert or update the agent record in the database\n        with sqlite3.connect(self.filename) as conn:\n            conn.execute(\"\"\"\n                INSERT OR REPLACE INTO agents (id, purpose, data)\n                VALUES (?, ?, ?)\n            \"\"\", (agent_dict['id'], agent_dict['purpose'], agent_json))\n"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is not None:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is not None:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is not None:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is not None:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is not None:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is not None:\n                return json.loads(row[0])\n            return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.execute(\"SELECT data FROM agents WHERE id = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row is not None:\n                return json.loads(row[0])\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.fetch_agent", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT data FROM agents WHERE purpose = ?\", (purpose,))\n            row = cursor.fetchone()\n            if row:\n                agent_data = json.loads(row[0])\n                return agent_data\n            else:\n                return None"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": ""}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "sqlite_agent_persistence.SQLiteAgentPersistence.load_all_purposes", "completion": "        with sqlite3.connect(self.filename) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT purpose FROM agents\")\n            rows = cursor.fetchall()\n            return [row[0] for row in rows]"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        result = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        ).fetchone()\n\n        if result is not None:\n            return json.loads(result[0])\n\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is not None:\n            return json.loads(result[0])\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        row = cursor.fetchone()\n        if row is None:\n            return None\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is not None:\n            return json.loads(result[0])\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        row = cursor.fetchone()\n        if row is not None:\n            return json.loads(row[0])\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\",\n            (arg_hash,),\n        )\n        row = cursor.fetchone()\n        if row is None:\n            return None\n\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        result = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        ).fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        result = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        ).fetchone()\n        if result is not None:\n            return json.loads(result[0])\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        row = cursor.fetchone()\n        if row is not None:\n            return json.loads(row[0])\n\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        row = cursor.fetchone()\n        if row is None:\n            return None\n\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        row = cursor.fetchone()\n        if row is not None:\n            return json.loads(row[0])\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        result = cursor.fetchone()\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\n            \"SELECT result FROM cache WHERE hash = ?\", (arg_hash,)\n        )\n        row = cursor.fetchone()\n        if row is None:\n            return None\n        return json.loads(row[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is not None:\n            return json.loads(result[0])\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash=?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is not None:\n            return json.loads(result[0])\n        return None\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._fetch_from_cache", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"SELECT result FROM cache WHERE hash = ?\", (arg_hash,))\n        result = cursor.fetchone()\n        if result is None:\n            return None\n\n        return json.loads(result[0])\n"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": ""}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": ""}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": ""}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": ""}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": ""}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": ""}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        self.connection.execute(\n            \"INSERT INTO cache (hash, result) VALUES (?, ?)\",\n            (arg_hash, json.dumps(result)),\n        )\n        self.connection.commit()"}
{"namespace": "memoize.SQLiteMemoization._cache_result", "completion": "        cursor = self.connection.cursor()\n        cursor.execute(\"INSERT INTO cache VALUES (?, ?)\", (arg_hash, json.dumps(result)))\n        self.connection.commit()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                # Execute the command line process\n                execute_command_line_process(args, quiet_mode=True)\n    else:\n        # Execute the command line process\n        execute_command_line_process(args, quiet_mode=False)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file instead of displaying it in the terminal\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                # Execute the command line process\n                execute_command_line_process(args)\n    else:\n        # Execute the command line process\n        execute_command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                # Execute the command line process\n                execute_command_line_process(args, quiet_mode=True)\n    else:\n        # Execute the command line process\n        execute_command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file instead of displaying it in the terminal\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                # Execute the command line process\n                CommandLine().run()\n    else:\n        # Execute the command line process\n        CommandLine().run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters\n    CONFIG.update(vars(args))\n\n    # Redirect output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                execute_command_line_process(args)\n    else:\n        execute_command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    global CONFIG, ARGS\n    CONFIG.update(vars(args))\n    ARGS = args\n\n    if quiet_mode:\n        with open(os.devnull, \"w\") as devnull:\n            with redirect_stdout(devnull):\n                command_line = CommandLine(\n                    task=args.task,\n                    upload_files=args.upload_files,\n                    model=args.model,\n                    record_dir=args.record_dir,\n                    mode=args.mode,\n                    max_subtask_chain_length=args.max_subtask_chain_length,\n                    enable_ask_human_for_help=args.enable_ask_human_for_help,\n                    max_plan_refine_chain_length=args.max_plan_refine_chain_length,\n                    max_plan_tree_depth=args.max_plan_tree_depth,\n                    max_plan_tree_width=args.max_plan_tree_width,\n                    max_retry_times=args.max_retry_times\n                )\n                command_line.run()\n    else:\n        command_line = CommandLine(\n            task=args.task,\n            upload_files=args.upload_files,\n            model=args.model,\n            record_dir=args.record_dir,\n            mode=args.mode,\n            max_subtask_chain_length=args.max_subtask_chain_length,\n            enable_ask_human_for_help=args.enable_ask_human_for_help,\n            max_plan_refine_chain_length=args.max_plan_refine_chain_length,\n            max_plan_tree_depth=args.max_plan_tree_depth,\n            max_plan_tree_width=args.max_plan_tree_width,\n            max_retry_times=args.max_retry_times\n        )\n        command_line.run()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect the standard output to a file instead of displaying it in the terminal\n    if quiet_mode:\n        with open(os.devnull, \"w\") as devnull:\n            with redirect_stdout(devnull):\n                # Execute the command line process\n                CommandLine(deepcopy(ARGS)).run()\n    else:\n        # Execute the command line process\n        CommandLine(deepcopy(ARGS)).run()"}
{"namespace": "run.execute_command_line_process", "completion": "    global CONFIG, ARGS\n\n    ARGS = args\n    CONFIG.update(args)\n\n    if quiet_mode:\n        with open(os.devnull, \"w\") as devnull:\n            with redirect_stdout(devnull):\n                CommandLine(\n                    CommandLineParam(\n                        task=args.task,\n                        upload_files=args.upload_files,\n                        model=args.model,\n                        record_dir=args.record_dir,\n                        mode=args.mode,\n                        quiet=args.quiet,\n                        max_subtask_chain_length=args.max_subtask_chain_length,\n                        enable_ask_human_for_help=args.enable_ask_human_for_help,\n                        max_plan_refine_chain_length=args.max_plan_refine_chain_length,\n                        max_plan_tree_depth=args.max_plan_tree_depth,\n                        max_plan_tree_width=args.max_plan_tree_width,\n                        max_retry_times=args.max_retry_times,\n                        config_file=args.config_file,\n                    )\n                ).run()\n    else:\n        CommandLine(\n            CommandLineParam(\n                task=args.task,\n                upload_files=args.upload_files,\n                model=args.model,\n                record_dir=args.record_dir,\n                mode=args.mode,\n                quiet=args.quiet,\n                max_subtask_chain_length=args.max_subtask_chain_length,\n                enable_ask_human_for_help=args.enable_ask_human_for_help,\n                max_plan_refine_chain_length=args.max_plan_refine_chain_length,\n                max_plan_tree_depth=args.max_plan_tree_depth,\n                max_plan_tree_width=args.max_plan_tree_width,\n                max_retry_times=args.max_retry_times,\n                config_file=args.config_file,\n            )\n        ).run()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with provided arguments\n    CONFIG.update(vars(args))\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                # Execute the command line process\n                CommandLine.run()\n    else:\n        # Execute the command line process\n        CommandLine.run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with provided arguments\n    CONFIG.update(vars(args))\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                execute_command_line_process(args)\n    else:\n        execute_command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters\n    for arg_name, arg_value in vars(args).items():\n        if arg_value is not None:\n            CONFIG[arg_name] = arg_value\n\n    # Redirect output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                CommandLine(\n                    task=CONFIG.task,\n                    upload_files=CONFIG.upload_files,\n                    model=CONFIG.model,\n                    record_dir=CONFIG.record_dir,\n                    mode=CONFIG.mode,\n                    max_subtask_chain_length=CONFIG.max_subtask_chain_length,\n                    enable_ask_human_for_help=CONFIG.enable_ask_human_for_help,\n                    max_plan_refine_chain_length=CONFIG.max_plan_refine_chain_length,\n                    max_plan_tree_depth=CONFIG.max_plan_tree_depth,\n                    max_plan_tree_width=CONFIG.max_plan_tree_width,\n                    max_retry_times=CONFIG.max_retry_times,\n                    config_file=CONFIG.config_file\n                ).run()\n    else:\n        CommandLine(\n            task=CONFIG.task,\n            upload_files=CONFIG.upload_files,\n            model=CONFIG.model,\n            record_dir=CONFIG.record_dir,\n            mode=CONFIG.mode,\n            max_subtask_chain_length=CONFIG.max_subtask_chain_length,\n            enable_ask_human_for_help=CONFIG.enable_ask_human_for_help,\n            max_plan_refine_chain_length=CONFIG.max_plan_refine_chain_length,\n            max_plan_tree_depth=CONFIG.max_plan_tree_depth,\n            max_plan_tree_width=CONFIG.max_plan_tree_width,\n            max_retry_times=CONFIG.max_retry_times,\n            config_file=CONFIG.config_file\n        ).run()"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect standard output to a file instead of displaying it in the terminal\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                # Execute the command line process\n                CommandLine().execute()\n    else:\n        # Execute the command line process\n        CommandLine().execute()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with command line arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            if key in ARGS:\n                ARGS[key] = value\n            else:\n                raise ValueError(f\"Invalid command line argument: {key}\")\n\n    # Redirect output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.devnull, \"w\") as devnull:\n            with redirect_stdout(devnull):\n                # Execute command line process here\n                pass\n    else:\n        # Execute command line process here\n        pass"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with command line arguments\n    CONFIG.update_from_args(args)\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.path.join(CONFIG.record_dir, 'stdout.txt'), 'w') as f:\n            with redirect_stdout(f):\n                execute_command_line_process(args)\n    else:\n        execute_command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with provided arguments\n    for key, value in vars(args).items():\n        if value is not None:\n            CONFIG[key] = value\n\n    # If quiet mode is enabled, redirect standard output to a file\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                # Execute command line process\n                CommandLine.execute_command_line_process(args)\n    else:\n        # Execute command line process\n        CommandLine.execute_command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update(args)\n\n    # Redirect standard output to a file if quiet mode is enabled\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                # Execute the command line process\n                execute_command_line_process(args)\n    else:\n        # Execute the command line process\n        execute_command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    global CONFIG, ARGS\n\n    # Update global configuration parameters\n    CONFIG.update_config(args)\n    ARGS = args\n\n    if quiet_mode:\n        with open(os.devnull, \"w\") as devnull:\n            with redirect_stdout(devnull):\n                execute_command_line_process(args)\n    else:\n        execute_command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update the global configuration parameters with the provided arguments\n    CONFIG.update(vars(args))\n\n    # If quiet mode is enabled, redirect standard output to a file\n    if quiet_mode:\n        with open(os.devnull, 'w') as devnull:\n            with redirect_stdout(devnull):\n                # Execute the command line process\n                execute_command_line_process(args)\n    else:\n        # Execute the command line process\n        execute_command_line_process(args)\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    global CONFIG, ARGS\n\n    # Update global configuration with command line arguments\n    CONFIG.update_from_args(args)\n    ARGS = deepcopy(args)\n\n    if quiet_mode:\n        with open(os.devnull, \"w\") as devnull:\n            with redirect_stdout(devnull):\n                # Execute command line process\n                CommandLine.run()\n    else:\n        # Execute command line process\n        CommandLine.run()\n\n"}
{"namespace": "run.execute_command_line_process", "completion": "    # Update global configuration parameters with the provided arguments\n    CONFIG.update_params(args)\n\n    # If quiet mode is enabled, redirect standard output to a file\n    if quiet_mode:\n        with open(os.devnull, \"w\") as devnull:\n            with redirect_stdout(devnull):\n                CommandLine.execute_command_line_process()\n    else:\n        CommandLine.execute_command_line_process()\n\n"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": ""}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": ""}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": ""}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": ""}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": ""}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": ""}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": ""}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": ""}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": ""}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": ""}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": ""}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": ""}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": ""}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apicon"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apicon"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apicon"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apicon"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_apicon"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "XAgent.ai_functions.request.openai.chatcompletion_request", "completion": "        model_name = get_model_name(\n            kwargs.pop(\"model\", CONFIG.default_completion_kwargs[\"model\"])\n        )\n        logger.debug(\"chatcompletion: using \" + model_name)\n        chatcompletion_kwargs = get_apiconfig_by_model(model_name)\n        if \"azure_endpoint\" in chatcompletion_kwargs:\n            api_base = chatcompletion_kwargs.pop(\"azure_endpoint\", None)\n            chatcompletion_kwargs.update({\"api_base\": api_base})\n        chatcompletion_kwargs.update(kwargs)\n\n        try:\n            response = openai.ChatCompletion.create(**chatcompletion_kwargs)\n            response = json.loads(str(response))\n            if response[\"choices\"][0][\"finish_reason\"] == \"length\":\n                raise BadRequestError(\"maximum context length exceeded\", None)\n        except BadRequestError as e:\n            if \"maximum context length\" in e._message:\n                if model_name == \"gpt-4\":\n                    if \"gpt-4-32k\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-32k\"\n                    elif \"gpt-4-1106-preview\" in CONFIG.api_keys:\n                        model_name = \"gpt-4-1106-preview\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                elif model_name == \"gpt-3.5-turbo\":\n                    if \"gpt-3.5-turbo-1106\" in CONFIG.api_keys:\n                        model_name = \"gpt-3.5-turbo-1106\"\n                    else:\n                        model_name = \"gpt-3.5-turbo-16k\"\n                else:\n                    raise e\n                print(\"max context length reached, retrying with \" + model_name)\n                chatcompletion_kwargs = get_ap"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None:\n            self._create_client()\n        elif self._last_time is not None and time() - self._last_time > self._refetch_interval:\n            self._create_client()\n        self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if not self._client or (self._last_time and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (\n            self._last_time is not None and time() - self._last_time > self._refetch_interval\n        ):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if not self._client or (self._last_time and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if not self._client or (self._last_time and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None or (self._last_time is not None and time() - self._last_time > self._refetch_interval):\n            self._create_client()\n            self._last_time = time()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None:\n            self._create_client()\n        elif self._last_time is not None and time() - self._last_time > self._refetch_interval:\n            self._create_client()\n\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None:\n            self._create_client()\n        elif self._last_time is not None and time() - self._last_time > self._refetch_interval:\n            self._create_client()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if self._client is None:\n            self._create_client()\n        elif self._last_time is None or time() - self._last_time > self._refetch_interval:\n            self._create_client()\n        return self._client"}
{"namespace": "litdata.streaming.client.S3Client.client", "completion": "        if not self._client:\n            self._create_client()\n        elif self._last_time and time() - self._last_time > self._refetch_interval:\n            self._create_client()\n        return self._client"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should not be called from a DataLoader worker process.\"\n            )\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\n                \"The `state_dict` method should not be called from a DataLoader worker process. \"\n                \"It should be called from the main process or a worker process that is not used for loading data.\"\n            )\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\"The `state_dict` method should not be called from a DataLoader worker process.\")\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The state_dict method should not be called from a DataLoader worker process.\")\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        self._state_dict = state\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The state_dict method should not be called from a DataLoader worker process. \"\n                \"Please use the state_dict method of the StreamingDataLoader instead.\"\n            )\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should not be called from a DataLoader worker process. \"\n                \"It should be called from the main process or the process that is creating the DataLoader.\"\n            )\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should not be called from a DataLoader worker process. \"\n                \"Please call it from the main process or outside of a DataLoader worker process.\"\n            )\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should not be called from a DataLoader worker process. \"\n                \"Please call this method in the main process before starting the DataLoader.\"\n            )\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should only be called from the main process. \"\n                \"Please make sure that you are not calling it from a DataLoader worker process.\"\n            )\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\n                \"The state_dict method should not be called from within a DataLoader worker process. \"\n                \"It should be called from the main process or outside the DataLoader.\"\n            )\n\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader is not None else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should only be called from the main process, not from a DataLoader worker process.\"\n            )\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        self._state_dict = state\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should not be called from a DataLoader worker process. \"\n                \"Please call it from the main process.\"\n            )\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"`state_dict` should not be called from a DataLoader worker process.\")\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The state_dict method should not be called from a DataLoader worker process. \"\n                \"It should only be called from the main process or a process that is not using the StreamingDataset.\"\n            )\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise ValueError(\n                \"The `state_dict` method should only be called from the main process, not from a DataLoader worker process.\"\n            )\n\n        state = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return state\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should not be called from a DataLoader worker process. \"\n                \"It should be called from the main process or the parent process.\"\n            )\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"`state_dict` should only be called from the main process. \"\n                \"If you're using the StreamingDataset in a DataLoader, please use the `StreamingDataLoader` instead.\"\n            )\n\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The state_dict method should not be called from a DataLoader worker process. \"\n                \"It is intended to be used in the main process during training.\"\n            )\n\n        return {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The state_dict method should not be called from a DataLoader worker process.\"\n                \" Please use the state_dict method of the StreamingDataLoader class instead.\"\n            )\n\n        self._state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir_path\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n\n        return self._state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\n                \"The `state_dict` method should not be called from a DataLoader worker process. \"\n                \"Please call it from the main process or outside the DataLoader.\"\n            )\n\n        state_dict = {\n            \"num_samples_yielded\": num_samples_yielded,\n            \"num_workers\": num_workers,\n            \"batch_size\": batch_size,\n            \"current_epoch\": self.current_epoch,\n            \"input_dir\": self.input_dir.path,\n            \"input_dir_url\": self.input_dir.url,\n            \"item_loader_state\": self.item_loader.state_dict() if self.item_loader else None,\n            \"drop_last\": self.drop_last,\n            \"seed\": self.seed,\n            \"world_size\": self.distributed_env.world_size,\n            \"shuffle\": self.shuffle,\n        }\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self._validate_state_dict()\n\n        state: Dict[str, Any] = state_dict\n\n        self.current_epoch = state[\"current_epoch\"]\n        self.input_dir.path = state[\"input_dir_path\"]\n        self.input_dir.url = state[\"input_dir_url\"]\n        self.item_loader = BaseItemLoader.load_state_dict(state[\"item_loader\"]) if state[\"item_loader\"] else None\n        self.drop_last = state[\"drop_last\"]\n        self.seed = state[\"seed\"]\n        self.distributed_env = _DistributedEnv(state[\"world_size\"])\n        self.shuffle = state[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.seed = state_dict[\"seed\"]\n        self.drop_last = state_dict[\"drop_last\"]\n        self.distributed_env = _DistributedEnv(state_dict[\"world_size\"])\n        self.shuffle = state_dict[\"shuffle\"]\n\n        if state_dict[\"input_dir_path\"]:\n            self.input_dir.path = state_dict[\"input_dir_path\"]\n        if state_dict[\"input_dir_url\"]:\n            self.input_dir.url = state_dict[\"input_dir_url\"]\n\n        if state_dict[\"item_loader\"]:\n            self.item_loader = BaseItemLoader.load_state_dict(state_dict[\"item_loader\"])\n\n        self.cache = self._create_cache(worker_env=_WorkerEnv.detect())\n        self.shuffler = self._create_shuffler(self.cache)\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._validate_state_dict(state_dict)\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.input_dir.path = state_dict[\"input_dir_path\"]\n        self.input_dir.url = state_dict[\"input_dir_url\"]\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env = _DistributedEnv(world_size=state_dict[\"world_size\"])\n        self.shuffle = state_dict[\"shuffle\"]\n\n        if state_dict[\"item_loader\"] is not None:\n            self.item_loader = BaseItemLoader.load_state_dict(state_dict[\"item_loader\"])\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self.current_epoch = state_dict[\"current_epoch\"]\n\n        # Restore the input directory\n        self.input_dir = Dir(state_dict[\"input_dir_path\"], state_dict[\"input_dir_url\"])\n\n        # Restore the item loader\n        if state_dict[\"item_loader\"] is not None:\n            self.item_loader = BaseItemLoader.load_state_dict(state_dict[\"item_loader\"])\n        else:\n            self.item_loader = None\n\n        # Restore the drop_last\n        self.drop_last = state_dict[\"drop_last\"]\n\n        # Restore the seed\n        self.seed = state_dict[\"seed\"]\n\n        # Restore the distributed environment\n        self.distributed_env = _DistributedEnv(state_dict[\"world_size\"])\n\n        # Restore the shuffle\n        self.shuffle = state_dict[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.input_dir.path = state_dict[\"input_dir_path\"]\n        self.input_dir.url = state_dict[\"input_dir_url\"]\n        self.item_loader = state_dict[\"item_loader\"]\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env.world_size = state_dict[\"world_size\"]\n        self.shuffle = state_dict[\"shuffle\"]\n\n        self.worker_env = _WorkerEnv.detect()\n        self.cache = self._create_cache(worker_env=self.worker_env)\n        self.shuffler = self._create_shuffler(self.cache)\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        self.current_epoch = state_dict[\"current_epoch\"]\n        self.input_dir.path = state_dict[\"input_dir_path\"]\n        self.input_dir.url = state_dict[\"input_dir_url\"]\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env = _DistributedEnv(state_dict[\"world_size\"])\n        self.shuffle = state_dict[\"shuffle\"]\n\n        if self.item_loader is not None:\n            self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n\n        if self.shuffler is None:\n            self.cache = self._create_cache(worker_env=_WorkerEnv.detect())\n            self.shuffler = self._create_shuffler(self.cache)\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n        self.input_dir.path = state_dict[\"input_dir_path\"]\n        self.input_dir.url = state_dict[\"input_dir_url\"]\n        self.drop_last = state_dict[\"drop_last\"]\n        self.seed = state_dict[\"seed\"]\n        self.distributed_env.world_size = state_dict[\"world_size\"]\n        self.shuffle = state_dict[\"shuffle\"]\n        self.current_epoch = state_dict[\"current_epoch\"]\n\n        if self.item_loader:\n            self.item_loader.load_state_dict(state_dict[\"item_loader\"])\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        # Update the input_dir\n        self.input_dir = Dir(state_dict[\"input_dir_path\"], state_dict[\"input_dir_url\"])\n\n        # Update the item_loader\n        if state_dict[\"item_loader\"]:\n            self.item_loader = BaseItemLoader.load_state_dict(state_dict[\"item_loader\"])\n\n        # Update the drop_last\n        self.drop_last = state_dict[\"drop_last\"]\n\n        # Update the seed\n        self.seed = state_dict[\"seed\"]\n\n        # Update the distributed_env\n        self.distributed_env = _DistributedEnv(state_dict[\"world_size\"])\n\n        # Update the shuffle\n        self.shuffle = state_dict[\"shuffle\"]\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        self._state_dict = state_dict\n\n        # Validate the state dict\n        self._validate_state_dict()\n\n        # Load the state\n        state = state_dict\n        self.current_epoch = state[\"current_epoch\"]\n        self.input_dir.path = state[\"input_dir_path\"]\n        self.input_dir.url = state[\"input_dir_url\"]\n        self.item_loader = BaseItemLoader.from_state_dict(state[\"item_loader\"]) if state[\"item_loader\"] else None\n        self.drop_last = state[\"drop_last\"]\n        self.seed = state[\"seed\"]\n        self.distributed_env = _DistributedEnv(world_size=state[\"world_size\"])\n        self.shuffle = state[\"shuffle\"]\n\n        # Create the cache and shuffler\n        self.cache = self._create_cache(worker_env=_WorkerEnv.detect())\n        self.shuffler = self._create_shuffler(self.cache)\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset.load_state_dict", "completion": "        self._state_dict = state_dict\n\n"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict\n        assert self.worker_env\n        assert self.cache\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state dict has been created with shuffle={state['shuffle']} while the current state is shuffle={self.shuffle}\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The state dict has been created with num_workers={state['num_workers']} while the current state is num_workers={self.worker_env.world_size}\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state dict has been created with input_dir_path={state['input_dir_path']} while the current state is input_dir_path={self.input_dir.path}\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state dict has been created with input_dir_url={state['input_dir_url']} while the current state is input_dir_url={self.input_dir.url}\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(f\"The state dict has been created with seed={state['seed']} while the current state is seed={self.seed}\")\n\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                f\"The state dict has been created with item_loader={state['item_loader']} while the current state is item_loader={self.item_loader.state_dict()}\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The state dict has been created with drop_last={"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict is not None\n        state = self._state_dict\n\n        if self.worker_env is None:\n            self.worker_env = _WorkerEnv.detect()\n\n        if self.cache is None:\n            self.cache = self._create_cache(worker_env=self.worker_env)\n\n        if self.shuffler is None:\n            self.shuffler = self._create_shuffler(self.cache)\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle parameter of the state dictionary ({state['shuffle']}) does not match the current shuffle parameter ({self.shuffle}).\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The num_workers parameter of the state dictionary ({state['num_workers']}) does not match the current num_workers parameter ({self.worker_env.world_size}).\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input_dir_path parameter of the state dictionary ({state['input_dir_path']}) does not match the current input_dir_path parameter ({self.input_dir.path}).\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input_dir_url parameter of the state dictionary ({state['input_dir_url']}) does not match the current input_dir_url parameter ({self.input_dir.url}).\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed parameter of the state dictionary ({state['seed']}) does not match the current seed parameter ({self.seed}).\"\n            )\n\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                f\"The item"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict\n        assert self.worker_env\n        assert self.cache\n\n        state = self._state_dict\n\n        # Validate shuffle\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state_dict shuffle ({state['shuffle']}) does not match the current shuffle ({self.shuffle}).\"\n            )\n\n        # Validate num_workers\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The state_dict num_workers ({state['num_workers']}) does not match the current num_workers ({self.worker_env.world_size}).\"\n            )\n\n        # Validate input_dir_path\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state_dict input_dir_path ({state['input_dir_path']}) does not match the current input_dir_path ({self.input_dir.path}).\"\n            )\n\n        # Validate input_dir_url\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state_dict input_dir_url ({state['input_dir_url']}) does not match the current input_dir_url ({self.input_dir.url}).\"\n            )\n\n        # Validate seed\n        if state[\"seed\"] != self.seed:\n            raise ValueError(f\"The state_dict seed ({state['seed']}) does not match the current seed ({self.seed}).\")\n\n        # Validate item_loader state\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                f\"The state_dict item_loader ({state['item_loader']}) does not match the current item_loader ({self.item_loader.state_dict()}).\"\n            )\n\n        # Validate drop_last"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        # Check if the state dictionary is empty\n        if self._state_dict is None:\n            raise ValueError(\"The state dictionary is empty.\")\n\n        # Check if the state dictionary is valid\n        if not isinstance(self._state_dict, dict):\n            raise ValueError(\"The state dictionary is not a valid dictionary.\")\n\n        # Check if the state dictionary has the required keys\n        required_keys = [\n            \"num_samples_yielded\",\n            \"num_workers\",\n            \"batch_size\",\n            \"current_epoch\",\n            \"input_dir_path\",\n            \"input_dir_url\",\n            \"item_loader\",\n            \"drop_last\",\n            \"seed\",\n            \"world_size\",\n            \"shuffle\",\n        ]\n        if not all(key in self._state_dict for key in required_keys):\n            raise ValueError(\"The state dictionary is missing required keys.\")\n\n        # Check if the state dictionary has the same number of workers\n        if self._state_dict[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\"The state dictionary has a different number of workers.\")\n\n        # Check if the state dictionary has the same input directory path\n        if self._state_dict[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\"The state dictionary has a different input directory path.\")\n\n        # Check if the state dictionary has the same input directory URL\n        if self._state_dict[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\"The state dictionary has a different input directory URL.\")\n\n        # Check if the state dictionary has the same shuffle flag\n        if self._state_dict[\"shuffle\"] != self.shuffle:\n            raise ValueError(\"The state dictionary has a different shuffle flag.\")\n\n        # Check if the state dictionary has the same seed\n        if self._state_dict[\"seed\"] != self.seed:\n            raise ValueError(\"The state dictionary has a different seed.\")\n\n        # Check if the state dictionary has the same drop_last flag\n        if self"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict\n\n        if self.worker_env is None:\n            self.worker_env = _WorkerEnv.detect()\n        if self.cache is None:\n            self.cache = self._create_cache(worker_env=self.worker_env)\n        if self.shuffler is None:\n            self.shuffler = self._create_shuffler(self.cache)\n\n        state: Dict[str, Any] = self._state_dict\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The shuffle parameter of the state dictionary ({state['shuffle']}) does not match the current state ({self.shuffle}).\"\n            )\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The num_workers parameter of the state dictionary ({state['num_workers']}) does not match the current state ({self.worker_env.world_size}).\"\n            )\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The input_dir_path parameter of the state dictionary ({state['input_dir_path']}) does not match the current state ({self.input_dir.path}).\"\n            )\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The input_dir_url parameter of the state dictionary ({state['input_dir_url']}) does not match the current state ({self.input_dir.url}).\"\n            )\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The seed parameter of the state dictionary ({state['seed']}) does not match the current state ({self.seed}).\"\n            )\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                f\"The item_loader parameter of the state dictionary ({state['item_loader']}) does not match the"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict is not None\n        assert self.worker_env is not None\n        assert self.cache is not None\n\n        state: Dict[str, Any] = self._state_dict\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state dictionary has a different value for the shuffle parameter: {state['shuffle']}.\"\n                f\" The current state of the StreamingDataset instance has a value of {self.shuffle}.\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The state dictionary has a different value for the num_workers parameter: {state['num_workers']}.\"\n                f\" The current state of the StreamingDataset instance has a value of {self.worker_env.world_size}.\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state dictionary has a different value for the input_dir_path parameter: {state['input_dir_path']}.\"\n                f\" The current state of the StreamingDataset instance has a value of {self.input_dir.path}.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state dictionary has a different value for the input_dir_url parameter: {state['input_dir_url']}.\"\n                f\" The current state of the StreamingDataset instance has a value of {self.input_dir.url}.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The state dictionary has a different value for the seed parameter: {state['seed']}.\"\n                f\" The current state of the StreamingDataset instance has a value of {self.seed}.\"\n            )\n\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                f\"The state dictionary has"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict\n        assert self.worker_env\n        assert self.cache\n\n        state = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state_dict has been generated with shuffle={state['shuffle']} but the current state is with shuffle={self.shuffle}.\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The state_dict has been generated with num_workers={state['num_workers']} but the current state is with num_workers={self.worker_env.world_size}.\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state_dict has been generated with input_dir_path={state['input_dir_path']} but the current state is with input_dir_path={self.input_dir.path}.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state_dict has been generated with input_dir_url={state['input_dir_url']} but the current state is with input_dir_url={self.input_dir.url}.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The state_dict has been generated with seed={state['seed']} but the current state is with seed={self.seed}.\"\n            )\n\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                f\"The state_dict has been generated with item_loader={state['item_loader']} but the current state is with item_loader={self.item_loader.state_dict()}.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict\n        assert self.worker_env\n        assert self.cache\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                \"The state_dict shuffle is different from the current shuffle.\"\n                f\" Found {state['shuffle']} and {self.shuffle}.\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                \"The state_dict num_workers is different from the current num_workers.\"\n                f\" Found {state['num_workers']} and {self.worker_env.world_size}.\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                \"The state_dict input_dir_path is different from the current input_dir_path.\"\n                f\" Found {state['input_dir_path']} and {self.input_dir.path}.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                \"The state_dict input_dir_url is different from the current input_dir_url.\"\n                f\" Found {state['input_dir_url']} and {self.input_dir.url}.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                \"The state_dict seed is different from the current seed.\" f\" Found {state['seed']} and {self.seed}.\"\n            )\n\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                \"The state_dict item_loader is different from the current item_loader.\"\n                f\" Found {state['item_loader']} and {self.item_loader.state_dict()}.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                \""}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if self.worker_env is None:\n            self.worker_env = _WorkerEnv.detect()\n        if self.cache is None:\n            self.cache = self._create_cache(worker_env=self.worker_env)\n        if self.shuffler is None:\n            self.shuffler = self._create_shuffler(self.cache)\n\n        state = self._state_dict\n\n        # Check if the shuffle parameter matches\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle parameter in the state dictionary ({state['shuffle']}) does not match the current state ({self.shuffle}).\"\n            )\n\n        # Check if the num_workers parameter matches\n        if self.worker_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The num_workers parameter in the state dictionary ({state['world_size']}) does not match the current state ({self.worker_env.world_size}).\"\n            )\n\n        # Check if the input directory path and URL match\n        if self.input_dir.path != state[\"input_dir_path\"] or self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory path and URL in the state dictionary ({state['input_dir_path']}, {state['input_dir_url']}) do not match the current state ({self.input_dir.path}, {self.input_dir.url}).\"\n            )\n\n        # Check if the seed matches\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The seed in the state dictionary ({state['seed']}) does not match the current state ({self.seed}).\"\n            )\n\n        # Check if the item_loader state matches\n        if self.item_loader is not None and self.item_loader.state_dict() != state[\"item_loader\"]:\n            raise ValueError(\n                f\"The item_loader state in the state dictionary ("}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict\n\n        state: Dict[str, Any] = self._state_dict\n        if self.worker_env is None:\n            self.worker_env = _WorkerEnv.detect()\n        if self.cache is None:\n            self.cache = self._create_cache(worker_env=self.worker_env)\n        if self.shuffler is None:\n            self.shuffler = self._create_shuffler(self.cache)\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state dictionary has a different shuffle parameter than the current state. \"\n                f\"Current shuffle: {self.shuffle}, state shuffle: {state['shuffle']}\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The state dictionary has a different num_workers parameter than the current state. \"\n                f\"Current num_workers: {self.worker_env.world_size}, state num_workers: {state['num_workers']}\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state dictionary has a different input_dir_path parameter than the current state. \"\n                f\"Current input_dir_path: {self.input_dir.path}, state input_dir_path: {state['input_dir_path']}\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state dictionary has a different input_dir_url parameter than the current state. \"\n                f\"Current input_dir_url: {self.input_dir.url}, state input_dir_url: {state['input_dir_url']}\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The state dictionary has a different seed parameter than the current state. \"\n                f\"Current seed: {"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict\n        assert self.worker_env\n        assert self.cache\n\n        state: Dict[str, Any] = self._state_dict\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle parameter of the StreamingDataset instance is {self.shuffle}, \"\n                f\"but the state dictionary suggests {state['shuffle']}.\"\n            )\n\n        if self.worker_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The world_size of the StreamingDataset instance is {self.worker_env.world_size}, \"\n                f\"but the state dictionary suggests {state['world_size']}.\"\n            )\n\n        if self.cache._reader._input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input directory path of the StreamingDataset instance is {self.cache._reader._input_dir.path}, \"\n                f\"but the state dictionary suggests {state['input_dir_path']}.\"\n            )\n\n        if self.cache._reader._input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory URL of the StreamingDataset instance is {self.cache._reader._input_dir.url}, \"\n                f\"but the state dictionary suggests {state['input_dir_url']}.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The seed of the StreamingDataset instance is {self.seed}, \"\n                f\"but the state dictionary suggests {state['seed']}.\"\n            )\n\n        if self.item_loader is not None:\n            if self.item_loader.state_dict() != state[\"item_loader\"]:\n                raise ValueError(\n                    f\"The item_loader state of the StreamingDataset instance is {self.item_loader.state_dict()}, \"\n                    f\"but the state dictionary suggests {state['item_loader']}.\""}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict is not None\n        assert self.worker_env is not None\n        assert self.cache is not None\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state dictionary's `shuffle` is {state['shuffle']} while the StreamingDataset's is {self.shuffle}\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The state dictionary's `num_workers` is {state['num_workers']} while the StreamingDataset's is {self.worker_env.world_size}\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state dictionary's `input_dir_path` is {state['input_dir_path']} while the StreamingDataset's is {self.input_dir.path}\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state dictionary's `input_dir_url` is {state['input_dir_url']} while the StreamingDataset's is {self.input_dir.url}\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The state dictionary's `seed` is {state['seed']} while the StreamingDataset's is {self.seed}\"\n            )\n\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                f\"The state dictionary's `item_loader` is {state['item_loader']} while the StreamingDataset's is {self.item_loader.state_dict()}\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                f\"The"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict\n        assert self.worker_env\n        assert self.cache\n        assert self.shuffler\n\n        state: Dict[str, Any] = self._state_dict\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle parameter of the StreamingDataset is {self.shuffle} but the state dict \"\n                f\"is {state['shuffle']}. The shuffle parameter should be the same in both cases.\"\n            )\n\n        if self.worker_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The world_size of the StreamingDataset is {self.worker_env.world_size} but the state dict \"\n                f\"is {state['world_size']}. The world_size should be the same in both cases.\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input_dir.path of the StreamingDataset is {self.input_dir.path} but the state dict \"\n                f\"is {state['input_dir_path']}. The input_dir.path should be the same in both cases.\"\n            )\n\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input_dir.url of the StreamingDataset is {self.input_dir.url} but the state dict \"\n                f\"is {state['input_dir_url']}. The input_dir.url should be the same in both cases.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The seed of the StreamingDataset is {self.seed} but the state dict \"\n                f\"is {state['seed']}. The seed should be the same in both cases.\"\n            )\n\n        if self.item_loader is not None and self.item_loader.state_dict() != state[\"item_loader\"]:\n            raise ValueError(\n                f"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict\n        state = self._state_dict\n\n        # Validate the shuffle flag\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle flag in the state dictionary ({state['shuffle']}) does not match the current state ({self.shuffle}).\"\n            )\n\n        # Validate the number of workers\n        if self.worker_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The number of workers in the state dictionary ({state['world_size']}) does not match the current state ({self.worker_env.world_size}).\"\n            )\n\n        # Validate the input directory path and URL\n        if self.input_dir.path != state[\"input_dir_path\"] or self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input directory path or URL in the state dictionary ({state['input_dir_path']}, {state['input_dir_url']}) do not match the current state ({self.input_dir.path}, {self.input_dir.url}).\"\n            )\n\n        # Validate the seed\n        if self.seed != state[\"seed\"]:\n            raise ValueError(f\"The seed in the state dictionary ({state['seed']}) does not match the current state ({self.seed}).\")\n\n        # Validate the item_loader state\n        if self.item_loader and self.item_loader.state_dict() != state[\"item_loader\"]:\n            raise ValueError(\n                f\"The item_loader state in the state dictionary ({state['item_loader']}) does not match the current state ({self.item_loader.state_dict()}).\"\n            )\n\n        # Validate the drop_last flag\n        if self.drop_last != state[\"drop_last\"]:\n            raise ValueError(\n                f\"The drop_last flag in the state dictionary ({state['drop_last']}) does not match the current state ({self.drop_"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict\n\n        if self.worker_env is None:\n            self.worker_env = _WorkerEnv.detect()\n        if self.cache is None:\n            self.cache = self._create_cache(worker_env=self.worker_env)\n        if self.shuffler is None:\n            self.shuffler = self._create_shuffler(self.cache)\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                \"The state dictionary and the current state of the StreamingDataset instance have different values for the shuffle parameter.\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                \"The state dictionary and the current state of the StreamingDataset instance have different values for the seed parameter.\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                \"The state dictionary and the current state of the StreamingDataset instance have different values for the input directory path.\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                \"The state dictionary and the current state of the StreamingDataset instance have different values for the input directory URL.\"\n            )\n\n        if state[\"item_loader\"] != (self.item_loader.state_dict() if self.item_loader else None):\n            raise ValueError(\n                \"The state dictionary and the current state of the StreamingDataset instance have different values for the item_loader state.\"\n            )\n\n        if state[\"drop_last\"] != self.drop_last:\n            raise ValueError(\n                \"The state dictionary and the current state of the StreamingDataset instance have different values for the drop_last flag.\"\n            )\n\n        if state[\"world_size\"] != self.distributed_env.world_size:\n            raise ValueError(\n                \"The state dictionary and the current state of the StreamingDataset instance have different"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict\n        assert self.worker_env\n        assert self.cache\n        assert self.shuffler\n\n        state: Dict[str, Any] = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                f\"The state dict is inconsistent with the current state. \"\n                f\"The shuffle state is different. \"\n                f\"State dict: {state['shuffle']}, current state: {self.shuffle}\"\n            )\n\n        if state[\"num_workers\"] != self.worker_env.world_size:\n            raise ValueError(\n                f\"The state dict is inconsistent with the current state. \"\n                f\"The num_workers is different. \"\n                f\"State dict: {state['num_workers']}, current state: {self.worker_env.world_size}\"\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                f\"The state dict is inconsistent with the current state. \"\n                f\"The input_dir_path is different. \"\n                f\"State dict: {state['input_dir_path']}, current state: {self.input_dir.path}\"\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                f\"The state dict is inconsistent with the current state. \"\n                f\"The input_dir_url is different. \"\n                f\"State dict: {state['input_dir_url']}, current state: {self.input_dir.url}\"\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                f\"The state dict is inconsistent with the current state. \"\n                f\"The seed is different. \"\n                f\"State dict: {state['seed']}, current state: {self.seed}\"\n            )\n\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                f\"The state"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict is not None\n        state = self._state_dict\n        if self.worker_env is None:\n            self.worker_env = _WorkerEnv.detect()\n\n        if self.cache is None:\n            self.cache = self._create_cache(worker_env=self.worker_env)\n\n        if self.shuffler is None:\n            self.shuffler = self._create_shuffler(self.cache)\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The `shuffle` parameter is different. Found {self.shuffle} in the state dict and {state['shuffle']} in the current state.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The `seed` parameter is different. Found {self.seed} in the state dict and {state['seed']} in the current state.\"\n            )\n\n        if self.worker_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                f\"The `world_size` parameter is different. Found {self.worker_env.world_size} in the state dict and {state['world_size']} in the current state.\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The `input_dir.path` parameter is different. Found {self.input_dir.path} in the state dict and {state['input_dir_path']} in the current state.\"\n            )\n\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The `input_dir.url` parameter is different. Found {self.input_dir.url} in the state dict and {state['input_dir_url']} in the current state.\"\n            )\n\n        if self.item_loader and self.item_loader.state_dict() != state[\"item_loader\"]:\n            raise ValueError(\n                f\"The `"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        if _is_in_dataloader_worker():\n            raise RuntimeError(\"The method `load_state_dict` should only be called in the main process.\")\n\n        if self._state_dict is None:\n            raise RuntimeError(\"The state dictionary has not been set yet.\")\n\n        state: Dict[str, Any] = self._state_dict\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                f\"The shuffle parameter has changed from {state['shuffle']} to {self.shuffle}.\"\n                \" Please make sure that the shuffle parameter is the same across all processes.\"\n            )\n\n        if self.worker_env is None:\n            raise RuntimeError(\"The worker environment has not been set yet.\")\n\n        if self.worker_env.num_workers != state[\"num_workers\"]:\n            raise ValueError(\n                f\"The num_workers parameter has changed from {state['num_workers']} to {self.worker_env.num_workers}.\"\n                \" Please make sure that the num_workers parameter is the same across all processes.\"\n            )\n\n        if self.cache is None:\n            raise RuntimeError(\"The cache has not been set yet.\")\n\n        if self.cache.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                f\"The input_dir_path parameter has changed from {state['input_dir_path']} to {self.cache.input_dir.path}.\"\n                \" Please make sure that the input_dir_path parameter is the same across all processes.\"\n            )\n\n        if self.cache.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                f\"The input_dir_url parameter has changed from {state['input_dir_url']} to {self.cache.input_dir.url}.\"\n                \" Please make sure that the input_dir_url parameter is the same across all processes.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                f\"The"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict is not None\n\n        if self.worker_env is None:\n            self.worker_env = _WorkerEnv.detect()\n\n        if self.cache is None:\n            self.cache = self._create_cache(worker_env=self.worker_env)\n\n        if self.shuffler is None:\n            self.shuffler = self._create_shuffler(self.cache)\n\n        state = self._state_dict\n\n        if state[\"shuffle\"] != self.shuffle:\n            raise ValueError(\n                \"The state dict has been created with shuffle={} but the current state has shuffle={}.\"\n                \" The state dict should be re-created.\".format(state[\"shuffle\"], self.shuffle)\n            )\n\n        if state[\"seed\"] != self.seed:\n            raise ValueError(\n                \"The state dict has been created with seed={} but the current state has seed={}.\"\n                \" The state dict should be re-created.\".format(state[\"seed\"], self.seed)\n            )\n\n        if state[\"input_dir_path\"] != self.input_dir.path:\n            raise ValueError(\n                \"The state dict has been created with input_dir_path={} but the current state has input_dir_path={}.\"\n                \" The state dict should be re-created.\".format(state[\"input_dir_path\"], self.input_dir.path)\n            )\n\n        if state[\"input_dir_url\"] != self.input_dir.url:\n            raise ValueError(\n                \"The state dict has been created with input_dir_url={} but the current state has input_dir_url={}.\"\n                \" The state dict should be re-created.\".format(state[\"input_dir_url\"], self.input_dir.url)\n            )\n\n        if state[\"item_loader\"] != self.item_loader.state_dict():\n            raise ValueError(\n                \"The state dict has been created with item_loader={} but the current state has item_loader={}.\"\n                \" The state dict should"}
{"namespace": "litdata.streaming.dataset.StreamingDataset._validate_state_dict", "completion": "        assert self._state_dict\n\n        state: Dict[str, Any] = self._state_dict\n\n        if self.shuffle != state[\"shuffle\"]:\n            raise ValueError(\n                \"The state dict has been loaded, but the shuffle parameter has changed.\"\n                \" HINT: If you want to keep the same shuffle parameter, you should set the `shuffle` parameter to `False`.\"\n            )\n\n        if self.worker_env.world_size != state[\"world_size\"]:\n            raise ValueError(\n                \"The state dict has been loaded, but the number of workers has changed.\"\n                \" HINT: If you want to keep the same number of workers, you should set the `num_workers` parameter to `None`.\"\n            )\n\n        if self.input_dir.path != state[\"input_dir_path\"]:\n            raise ValueError(\n                \"The state dict has been loaded, but the input directory path has changed.\"\n                \" HINT: If you want to keep the same input directory path, you should set the `input_dir` parameter to `None`.\"\n            )\n\n        if self.input_dir.url != state[\"input_dir_url\"]:\n            raise ValueError(\n                \"The state dict has been loaded, but the input directory URL has changed.\"\n                \" HINT: If you want to keep the same input directory URL, you should set the `input_dir` parameter to `None`.\"\n            )\n\n        if self.seed != state[\"seed\"]:\n            raise ValueError(\n                \"The state dict has been loaded, but the seed has changed.\"\n                \" HINT: If you want to keep the same seed, you should set the `seed` parameter to `None`.\"\n            )\n\n        if self.item_loader is not None and self.item_loader.state_dict() != state[\"item_loader\"]:\n            raise ValueError(\n                \"The state dict has been loaded, but the item_loader has changed.\"\n                \" HINT: If you want to keep the same item_loader, you should set the `item_loader` parameter to `None`.\""}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    # If the input directory is None, use an empty string for hashing\n    input_dir = input_dir or \"\"\n\n    # Generate a unique directory name based on the input directory\n    cache_dir_name = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # If certain environment variables are not set, create the cache directory in a default location\n    if not os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\") and not os.getenv(\"DATA_OPTIMIZER_CACHE_URL\"):\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n\n    # If the environment variables are set, create the cache directory in a specified location\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), cache_dir_name)\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n\n    # If the environment variables are set, create the cache directory in a specified location\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_URL\"):\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_URL\"), cache_dir_name)\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n\n    # If the environment variables are not set and the default location cannot be created, return None\n    return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest())\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir, exist_ok=True)\n        except Exception:\n            return None\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        return None\n\n    cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n    if not cache_dir:\n        cache_dir = _DEFAULT_CACHE_DIR\n\n    cache_dir = os.path.join(cache_dir, hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest())\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception:\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n    cache_dir_name = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), cache_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n    except Exception:\n        return None\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name based on the input directory\n    unique_dir_name = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Check if the environment variables are set\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), unique_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, unique_dir_name)\n\n    # Create the cache directory if it doesn't exist\n    os.makedirs(cache_dir, exist_ok=True)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name based on the input directory\n    directory_name = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # If certain environment variables are not set, create the cache directory in a default location\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\") is None and os.getenv(\"DATA_OPTIMIZER_CACHE_URL\") is None:\n        cache_path = os.path.join(_DEFAULT_CACHE_DIR, directory_name)\n        os.makedirs(cache_path, exist_ok=True)\n        return cache_path\n\n    # If the environment variables are set, create the cache directory in a specified location\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\") is not None:\n        cache_path = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), directory_name)\n        os.makedirs(cache_path, exist_ok=True)\n        return cache_path\n\n    # If the environment variables are set, create the cache directory in a specified location\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_URL\") is not None:\n        cache_path = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_URL\"), directory_name)\n        os.makedirs(cache_path, exist_ok=True)\n        return cache_path\n\n    return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        return None\n\n    cache_dir = os.environ.get(\"DATA_OPTIMIZER_CACHE_DIR\")\n    if not cache_dir:\n        cache_dir = _DEFAULT_CACHE_DIR\n\n    cache_dir = os.path.join(cache_dir, hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest())\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.warn(f\"Unable to create cache directory: {cache_dir}. Error: {e}\")\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name based on the input directory\n    cache_dir_name = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # If certain environment variables are not set, create the cache directory in a default location\n    if not os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\") and not os.getenv(\"DATA_OPTIMIZER_CACHE_URL\"):\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n\n    # If the environment variables are set, create the cache directory in a specified location\n    cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\", \"\")\n    cache_url = os.getenv(\"DATA_OPTIMIZER_CACHE_URL\", \"\")\n    cache_path = os.path.join(cache_dir, cache_dir_name)\n\n    # Create the cache directory if it doesn't exist\n    if not os.path.exists(cache_path):\n        os.makedirs(cache_path, exist_ok=True)\n\n    return cache_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    # If the input directory is None, use an empty string for hashing\n    input_dir = input_dir or \"\"\n\n    # Hash the input directory to create a unique directory name\n    hash_object = hashlib.sha256(input_dir.encode())\n    cache_dir_name = hash_object.hexdigest()\n\n    # Determine the cache directory based on environment variables\n    if os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), cache_dir_name)\n    else:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n\n    # Create the cache directory if it doesn't exist\n    if not os.path.exists(cache_dir):\n        try:\n            os.makedirs(cache_dir)\n        except Exception as e:\n            logger.error(f\"Error creating cache directory: {e}\")\n            return None\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n    cache_dir_name = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n    cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n    if not os.path.exists(cache_dir_path):\n        os.makedirs(cache_dir_path, exist_ok=True)\n    return cache_dir_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        return None\n\n    # Generate a unique directory name by hashing the input directory\n    cache_dir_name = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # If certain environment variables are not set, create the cache directory in a default location\n    if not os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n    else:\n        # Otherwise, create it in a specified location\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), cache_dir_name)\n\n    # Create the cache directory if it doesn't exist\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir, exist_ok=True)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name based on the input directory\n    cache_dir_name = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Attempt to create the cache directory in the specified location\n    cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n    try:\n        os.makedirs(cache_dir_path, exist_ok=True)\n        return cache_dir_path\n    except Exception as e:\n        logger.warning(f\"Failed to create cache directory in the specified location: {e}\")\n\n    # Attempt to create the cache directory in the default location\n    try:\n        os.makedirs(_DEFAULT_CACHE_DIR, exist_ok=True)\n        cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n        os.makedirs(cache_dir_path, exist_ok=True)\n        return cache_dir_path\n    except Exception as e:\n        logger.warning(f\"Failed to create cache directory in the default location: {e}\")\n\n    # If the cache directory cannot be created in either the specified or default location, return None\n    return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        return None\n\n    # Generate a unique directory name based on the input directory\n    cache_dir_name = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Check if the cache directory already exists\n    cache_dir_path = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n    if os.path.exists(cache_dir_path):\n        return cache_dir_path\n\n    # If the cache directory does not exist, create it\n    os.makedirs(cache_dir_path, exist_ok=True)\n\n    return cache_dir_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    # Hash the input directory to create a unique directory name\n    hashed_dir = hashlib.sha256(input_dir.encode()).hexdigest()\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashed_dir)\n\n    # Check if the cache directory already exists\n    if os.path.exists(cache_dir):\n        return cache_dir\n\n    # If the cache directory doesn't exist, create it\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.error(f\"Failed to create cache directory: {e}\")\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if input_dir is None:\n        input_dir = \"\"\n\n    # Create a unique directory name based on the input directory\n    directory_name = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Get the cache directory location from the environment variables, if set\n    cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\", _DEFAULT_CACHE_DIR)\n\n    # Create the cache directory if it does not exist\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir, exist_ok=True)\n\n    # Create the unique cache directory path\n    cache_path = os.path.join(cache_dir, directory_name)\n\n    # Create the unique cache directory if it does not exist\n    if not os.path.exists(cache_path):\n        os.makedirs(cache_path, exist_ok=True)\n\n    return cache_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    # Hash the input directory to create a unique directory name\n    input_dir_hash = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, input_dir_hash)\n\n    # Check if the cache directory already exists\n    if os.path.exists(cache_dir):\n        return cache_dir\n\n    # Attempt to create the cache directory\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.warning(f\"Failed to create cache directory {cache_dir}: {e}\")\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        return None\n\n    cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n    if not cache_dir:\n        cache_dir = _DEFAULT_CACHE_DIR\n\n    cache_dir = os.path.expanduser(cache_dir)\n    cache_dir = os.path.expandvars(cache_dir)\n\n    # Hash the input directory to create a unique cache directory\n    hash_object = hashlib.sha256(input_dir.encode())\n    unique_dir_name = hash_object.hexdigest()\n\n    # Create the cache directory if it doesn't exist\n    cache_path = os.path.join(cache_dir, unique_dir_name)\n    if not os.path.exists(cache_path):\n        os.makedirs(cache_path, exist_ok=True)\n\n    return cache_path\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        return None\n\n    cache_dir = os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\")\n    if not cache_dir:\n        cache_dir = os.path.join(_DEFAULT_CACHE_DIR, hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest())\n\n    try:\n        os.makedirs(cache_dir, exist_ok=True)\n        return cache_dir\n    except Exception as e:\n        logger.warning(f\"Failed to create cache directory: {e}\")\n        return None\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    # If the input directory is None, use an empty string for hashing.\n    if input_dir is None:\n        input_dir = \"\"\n\n    # Generate a unique directory name by hashing the input directory.\n    cache_dir_name = hashlib.sha256(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # If certain environment variables are not set, create the cache directory in a default location.\n    if not os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"):\n        if not os.getenv(\"DATA_OPTIMIZER_CACHE_DIR_PER_NODE\"):\n            cache_dir = os.path.join(_DEFAULT_CACHE_DIR, cache_dir_name)\n        else:\n            cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR_PER_NODE\"), cache_dir_name)\n    else:\n        cache_dir = os.path.join(os.getenv(\"DATA_OPTIMIZER_CACHE_DIR\"), cache_dir_name)\n\n    # Create the cache directory if it doesn't exist.\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.dataset._try_create_cache_dir", "completion": "    if not input_dir:\n        return None\n\n    # Generate a unique directory name by hashing the input directory\n    dir_name = hashlib.md5(input_dir.encode(\"utf-8\")).hexdigest()\n\n    # Create the cache directory in the default location\n    cache_dir = os.path.join(_DEFAULT_CACHE_DIR, dir_name)\n    os.makedirs(cache_dir, exist_ok=True)\n\n    return cache_dir\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": ""}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(f\"Invalid S3 URL: {remote_filepath}\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        os.makedirs(os.path.dirname(local_filepath), exist_ok=True)\n        lock_filepath = local_filepath + \".lock\"\n        with FileLock(lock_filepath, timeout=60 * 10):\n            if self._s5cmd_available:\n                cmd = f\"s5cmd --no-sign-request cp {remote_filepath} {local_filepath}\"\n                subprocess.run(cmd, shell=True, check=True)\n            else:\n                bucket = parsed_url.netloc\n                key = parsed_url.path.lstrip(\"/\")\n                self._client.download_file(bucket, key, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(f\"Invalid S3 URL: {remote_filepath}\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_path = f\"{local_filepath}.lock\"\n        with FileLock(lock_path, timeout=60):\n            if self._s5cmd_available:\n                cmd = f\"s5cmd cp {remote_filepath} {local_filepath}\"\n                subprocess.run(cmd, shell=True, check=True)\n            else:\n                bucket_name = parsed_remote_filepath.netloc\n                object_key = parsed_remote_filepath.path[1:]\n                self._client.download_file(bucket_name, object_key, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(f\"Invalid S3 URL: {remote_filepath}\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        os.makedirs(os.path.dirname(local_filepath), exist_ok=True)\n\n        lock_filepath = f\"{local_filepath}.lock\"\n        with FileLock(lock_filepath, timeout=10):\n            if self._s5cmd_available:\n                subprocess.run(\n                    f\"s5cmd --no-sign-request cp {remote_filepath} {local_filepath}\",\n                    shell=True,\n                    check=True,\n                )\n            else:\n                self._client.download_file(\n                    parsed_remote_filepath.netloc,\n                    parsed_remote_filepath.path[1:],\n                    local_filepath,\n                )\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(f\"Expected s3:// URL, got {remote_filepath}\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        os.makedirs(os.path.dirname(local_filepath), exist_ok=True)\n\n        lock_path = local_filepath + \".lock\"\n        with FileLock(lock_path, timeout=120):\n            if self._s5cmd_available:\n                cmd = f\"s5cmd --no-sign-request cp {remote_filepath} {local_filepath}\"\n                subprocess.check_call(cmd, shell=True)\n            else:\n                bucket = parsed_remote_filepath.netloc\n                key = parsed_remote_filepath.path.lstrip(\"/\")\n                self._client.download_file(bucket, key, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(f\"{remote_filepath} is not a valid S3 URL\")\n        if os.path.exists(local_filepath):\n            return\n\n        lock_path = local_filepath + \".lock\"\n        with FileLock(lock_path, timeout=60 * 60):\n            if self._s5cmd_available:\n                cmd = f\"s5cmd --no-sign-request cp {remote_filepath} {local_filepath}\"\n                subprocess.run(cmd, shell=True, check=True)\n            else:\n                bucket = parsed_remote_filepath.netloc\n                key = parsed_remote_filepath.path.lstrip(\"/\")\n                self._client.download_file(bucket, key, local_filepath)"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\"remote_filepath must be an S3 URL\")\n        if os.path.exists(local_filepath):\n            return\n\n        lock_path = local_filepath + \".lock\"\n        with FileLock(lock_path, timeout=10):\n            if self._s5cmd_available:\n                subprocess.check_call(\n                    f\"s5cmd --no-sign-request cp {remote_filepath} {local_filepath}\",\n                    shell=True,\n                )\n            else:\n                self._client.download_file(parsed_url.netloc, parsed_url.path.lstrip(\"/\"), local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(\n                f\"Expected remote_filepath to be an S3 URL, got {remote_filepath}\"\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_path = f\"{local_filepath}.lock\"\n        with FileLock(lock_path, timeout=10):\n            if self._s5cmd_available:\n                cmd = f\"s5cmd cp {remote_filepath} {local_filepath}\"\n                subprocess.run(cmd, shell=True, check=True)\n            else:\n                bucket = parsed_url.netloc\n                key = parsed_url.path.lstrip(\"/\")\n                self._client.download_file(bucket, key, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(f\"{remote_filepath} is not an S3 URL\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        os.makedirs(os.path.dirname(local_filepath), exist_ok=True)\n\n        lock_filepath = f\"{local_filepath}.lock\"\n        with FileLock(lock_filepath, timeout=60):\n            if self._s5cmd_available:\n                subprocess.run(\n                    [\"s5cmd\", \"cp\", remote_filepath, local_filepath],\n                    stdout=subprocess.DEVNULL,\n                    stderr=subprocess.DEVNULL,\n                )\n            else:\n                self._client.download_file(\n                    parsed_url.netloc, parsed_url.path[1:], local_filepath\n                )\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if parse.urlparse(remote_filepath).scheme != \"s3\":\n            raise ValueError(\"remote_filepath must be an S3 URL\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        os.makedirs(os.path.dirname(local_filepath), exist_ok=True)\n\n        lock_path = os.path.join(self._cache_dir, \".lock\")\n        with FileLock(lock_path, timeout=10):\n            if self._s5cmd_available:\n                cmd = f\"s5cmd --no-sign-request cp {remote_filepath} {local_filepath}\"\n                subprocess.run(cmd, shell=True, check=True)\n            else:\n                self._client.download_file(remote_filepath, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(\"Remote filepath must be an s3 URL\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        os.makedirs(os.path.dirname(local_filepath), exist_ok=True)\n\n        lock_filepath = f\"{local_filepath}.lock\"\n        with FileLock(lock_filepath, timeout=120):\n            if self._s5cmd_available:\n                subprocess.run(\n                    f\"s5cmd --no-sign-request cp {remote_filepath} {local_filepath}\",\n                    shell=True,\n                    check=True,\n                )\n            else:\n                self._client.download_file(\n                    parsed_remote_filepath.netloc,\n                    parsed_remote_filepath.path[1:],\n                    local_filepath,\n                )\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(f\"Invalid S3 URL: {remote_filepath}\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_filepath = f\"{local_filepath}.lock\"\n        lock = FileLock(lock_filepath, timeout=10)\n        try:\n            with lock.acquire(timeout=10):\n                if not os.path.exists(local_filepath):\n                    if self._s5cmd_available:\n                        subprocess.run(\n                            f\"s5cmd cp {remote_filepath} {local_filepath}\".split(),\n                            check=True,\n                        )\n                    else:\n                        self._client.download_file(\n                            parsed_remote_filepath.netloc,\n                            parsed_remote_filepath.path[1:],\n                            local_filepath,\n                        )\n        except Timeout:\n            pass\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(f\"Expected s3 scheme, got: {parsed_remote_filepath.scheme}\")\n        if os.path.exists(local_filepath):\n            return\n        os.makedirs(os.path.dirname(local_filepath), exist_ok=True)\n        lock_filepath = local_filepath + \".lock\"\n        with FileLock(lock_filepath, timeout=600) as lock:\n            try:\n                lock.acquire()\n                if self._s5cmd_available:\n                    subprocess.check_call([\"s5cmd\", \"cp\", remote_filepath, local_filepath])\n                else:\n                    self._client.download_file(parsed_remote_filepath.netloc, parsed_remote_filepath.path[1:], local_filepath)\n            except Timeout:\n                raise Timeout(f\"Failed to acquire lock for {local_filepath}\")\n            except subprocess.CalledProcessError as e:\n                raise RuntimeError(f\"Failed to download {remote_filepath} to {local_filepath}: {e}\")\n            finally:\n                lock.release()\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(\n                f\"Expected remote_filepath to be an S3 URL, got {remote_filepath}\"\n            )\n\n        if os.path.exists(local_filepath):\n            return\n\n        os.makedirs(os.path.dirname(local_filepath), exist_ok=True)\n\n        lock_filepath = f\"{local_filepath}.lock\"\n        with FileLock(lock_filepath, timeout=600) as lock:\n            try:\n                if self._s5cmd_available:\n                    subprocess.run(\n                        [\n                            \"s5cmd\",\n                            \"--no-sign-request\",\n                            \"cp\",\n                            remote_filepath,\n                            local_filepath,\n                        ],\n                        check=True,\n                    )\n                else:\n                    bucket_name = parsed_remote_filepath.netloc\n                    key = parsed_remote_filepath.path[1:]\n                    self._client.download_file(bucket_name, key, local_filepath)\n            except subprocess.CalledProcessError as e:\n                raise RuntimeError(f\"Failed to download {remote_filepath}\") from e\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(\"The remote file path must be an S3 URL\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        parsed_url = parse.urlparse(remote_filepath)\n        bucket = parsed_url.netloc\n        key = parsed_url.path.lstrip(\"/\")\n\n        lock_filepath = local_filepath + \".lock\"\n        with FileLock(lock_filepath, timeout=10):\n            if self._s5cmd_available:\n                subprocess.run(\n                    [\"s5cmd\", \"cp\", f\"s3://{bucket}/{key}\", local_filepath], check=True\n                )\n            else:\n                self._client.download_file(bucket, key, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        if not remote_filepath.startswith(\"s3://\"):\n            raise ValueError(f\"Invalid remote file path: {remote_filepath}\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        remote_url = parse.urlparse(remote_filepath)\n        remote_bucket = remote_url.netloc\n        remote_key = remote_url.path.lstrip(\"/\")\n\n        lock_filepath = os.path.join(self._cache_dir, \".lock\")\n        with FileLock(lock_filepath, timeout=120):\n            if self._s5cmd_available:\n                cmd = f\"s5cmd --no-sign-request cp s3://{remote_bucket}/{remote_key} {local_filepath}\"\n                subprocess.run(cmd, shell=True, check=True)\n            else:\n                self._client.download_file(remote_bucket, remote_key, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(f\"remote_filepath must be an S3 URL, got {remote_filepath}\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        # Download with s5cmd\n        if self._s5cmd_available:\n            cmd = f\"s5cmd --no-sign-request cp {remote_filepath} {local_filepath}\"\n            subprocess.run(cmd, shell=True, check=True)\n            return\n\n        # Download with boto3\n        bucket_name = parsed_remote_filepath.netloc\n        object_key = parsed_remote_filepath.path.lstrip(\"/\")\n        lock_filepath = os.path.join(self._cache_dir, f\".{object_key}.lock\")\n        with FileLock(lock_filepath, timeout=600):\n            self._client.download_file(bucket_name, object_key, local_filepath)\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(f\"Invalid S3 URL: {remote_filepath}\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        if self._s5cmd_available:\n            subprocess.run(\n                f\"s5cmd cp {remote_filepath} {local_filepath}\",\n                shell=True,\n                check=True,\n            )\n        else:\n            bucket = parsed_remote_filepath.netloc\n            key = parsed_remote_filepath.path[1:]\n            self._client.download_file(bucket, key, local_filepath)\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_url = parse.urlparse(remote_filepath)\n        if parsed_url.scheme != \"s3\":\n            raise ValueError(f\"Expected an S3 URL, got {remote_filepath}\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        lock_path = f\"{local_filepath}.lock\"\n        lock = FileLock(lock_path, timeout=120)\n        try:\n            with lock.acquire(timeout=120):\n                if self._s5cmd_available:\n                    cmd = f\"s5cmd --no-sign-request cp {remote_filepath} {local_filepath}\"\n                    subprocess.run(cmd, shell=True, check=True)\n                else:\n                    bucket = parsed_url.netloc\n                    key = parsed_url.path[1:]\n                    self._client.download_file(bucket, key, local_filepath)\n        except Timeout:\n            raise Timeout(\n                f\"Could not acquire lock on {lock_path} for {local_filepath}. Another process might be downloading this file.\"\n            )\n\n"}
{"namespace": "litdata.streaming.downloader.S3Downloader.download_file", "completion": "        parsed_remote_filepath = parse.urlparse(remote_filepath)\n\n        if parsed_remote_filepath.scheme != \"s3\":\n            raise ValueError(f\"Expected s3 scheme, got: {parsed_remote_filepath.scheme}\")\n\n        if os.path.exists(local_filepath):\n            return\n\n        if self._s5cmd_available:\n            lock_filename = os.path.join(self._cache_dir, \".lock\")\n            lock = FileLock(lock_filename, timeout=120)\n            try:\n                with lock.acquire(timeout=120):\n                    subprocess.check_output(\n                        f\"s5cmd cp {remote_filepath} {local_filepath}\", shell=True\n                    )\n            except Timeout:\n                print(\n                    \"Timeout while waiting for lock. Skipping download. \"\n                    f\"Lock file: {lock_filename}\"\n                )\n        else:\n            self._client.download_file(\n                parsed_remote_filepath.netloc,\n                parsed_remote_filepath.path[1:],\n                local_filepath,\n            )\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    if worker_env.world_size == 1:\n        return {0: chunks_replica}, {0: intervals_replica}\n\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that the chunks are evenly distributed among the workers\n    # We need to make sure that"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    if worker_env.world_size == 1:\n        for chunk_index, interval in zip(chunks_replica, intervals_replica):\n            workers_chunks[0].append(chunk_index)\n            workers_intervals[0].append(interval)\n    else:\n        for chunk_index, interval in zip(chunks_replica, intervals_replica):\n            worker_index = chunk_index % worker_env.world_size\n            workers_chunks[worker_index].append(chunk_index)\n            workers_intervals[worker_index].append(interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    assert len(chunks_replica) == len(intervals_replica)\n\n    if worker_env.world_size == 1:\n        return {0: chunks_replica}, {0: intervals_replica}\n\n    if num_workers == 1:\n        return {0: chunks_replica}, {0: intervals_replica}\n\n    # We use the same distribution strategy as PyTorch.\n    # https://github.com/pytorch/pytorch/blob/master/torch/utils/data/distributed.py#L122\n    # We use the same distribution strategy as PyTorch.\n    # https://github.com/pytorch/pytorch/blob/master/torch/utils/data/distributed.py#L122\n    # We use the same distribution strategy as PyTorch.\n    # https://github.com/pytorch/pytorch/blob/master/torch/utils/data/distributed.py#L122\n    # We use the same distribution strategy as PyTorch.\n    # https://github.com/pytorch/pytorch/blob/master/torch/utils/data/distributed.py#L122\n    # We use the same distribution strategy as PyTorch.\n    # https://github.com/pytorch/pytorch/blob/master/torch/utils/data/distributed.py#L122\n    # We use the same distribution strategy as PyTorch.\n    # https://github.com/pytorch/pytorch/blob/master/torch/utils/data/distributed.py#L122\n    # We use the same distribution strategy as PyTorch.\n    # https://github.com/pytorch/pytorch/blob/master/torch/utils/data/distributed.py#L122\n    # We use the same distribution strategy as PyTorch.\n    # https://github.com/pytorch/pytorch/blob/master/torch/utils/data/distributed.py#L122\n    # We use the"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Initialize empty lists for workers' chunks and intervals\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    # If the world size is 1, assign all chunks and intervals to the first worker\n    if worker_env.world_size == 1:\n        workers_chunks[0] = chunks_replica\n        workers_intervals[0] = intervals_replica\n    # If the world size is greater than 1, distribute chunks and intervals based on the worker index\n    else:\n        for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n            worker_index = i % worker_env.world_size\n            workers_chunks[worker_index].append(chunk_index)\n            workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Initialize dictionaries to store the chunks and intervals assigned to each worker\n    workers_chunks: Dict[int, List[int]] = {i: [] for i in range(num_workers)}\n    workers_intervals: Dict[int, List[Any]] = {i: [] for i in range(num_workers)}\n\n    # Calculate the number of chunks and intervals per worker\n    num_chunks_per_worker = len(chunks_replica) // num_workers\n    num_intervals_per_worker = len(intervals_replica) // num_workers\n\n    # Iterate over the number of workers\n    for i in range(num_workers):\n        # Calculate the start and end indices for the chunks and intervals for the current worker\n        start_chunk_index = i * num_chunks_per_worker\n        end_chunk_index = start_chunk_index + num_chunks_per_worker\n        start_interval_index = i * num_intervals_per_worker\n        end_interval_index = start_interval_index + num_intervals_per_worker\n\n        # Assign the chunks and intervals to the current worker based on the calculated indices\n        workers_chunks[i] = chunks_replica[start_chunk_index:end_chunk_index]\n        workers_intervals[i] = intervals_replica[start_interval_index:end_interval_index]\n\n    # Return the dictionaries containing the assigned chunks and intervals for each worker\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Initialize dictionaries to store the chunks and intervals assigned to each worker\n    workers_chunks = {i: [] for i in range(worker_env.world_size)}\n    workers_intervals = {i: [] for i in range(worker_env.world_size)}\n\n    # Calculate the number of chunks and intervals per worker\n    num_chunks_per_worker = len(chunks_replica) // num_workers\n    num_intervals_per_worker = len(intervals_replica) // num_workers\n\n    # Initialize variables to keep track of the current chunk and interval indices\n    chunk_index = 0\n    interval_index = 0\n\n    # Iterate over the workers and assign chunks and intervals to each worker\n    for worker_index in range(worker_env.world_size):\n        # Assign chunks and intervals to the current worker\n        for _ in range(num_chunks_per_worker):\n            workers_chunks[worker_index].append(chunks_replica[chunk_index])\n            workers_intervals[worker_index].append(intervals_replica[interval_index])\n            chunk_index += 1\n            interval_index += 1\n\n        # If there are remaining chunks and intervals, assign them to the current worker\n        if chunk_index < len(chunks_replica):\n            workers_chunks[worker_index].append(chunks_replica[chunk_index])\n            workers_intervals[worker_index].append(intervals_replica[interval_index])\n            chunk_index += 1\n            interval_index += 1\n\n    # Return the dictionaries of assigned chunks and intervals\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # The number of workers is the number of workers among which the chunks and intervals are to be distributed.\n    # The worker environment is an instance or object representing the worker environment, which includes details like world size that are used in the distribution logic.\n    # The chunks_replica is a list of chunk indices that need to be distributed among the workers.\n    # The intervals_replica is a list of intervals corresponding to each chunk in chunks_replica. Each interval represents the range or scope of the chunk it corresponds to.\n    # The function returns a tuple containing two dictionaries. The first dictionary maps worker indices to their assigned chunks, and the second dictionary maps worker indices to the intervals corresponding to their assigned chunks.\n\n    # The function starts by initializing two empty lists, workers_chunks and workers_intervals, to store the chunks and intervals assigned to each worker, respectively.\n    workers_chunks = []\n    workers_intervals = []\n\n    # The function then iterates over the range of worker indices, which is determined by the number of workers.\n    for i in range(num_workers):\n        # For each worker index, the function checks if the worker index is divisible by the total world size of the worker environment.\n        # If it is divisible, the function appends an empty list to workers_chunks and workers_intervals to represent the chunks and intervals assigned to this worker.\n        if i % worker_env.world_size == 0:\n            workers_chunks.append([])\n            workers_intervals.append([])\n\n        # The function then appends the chunk index and interval corresponding to the current worker index to the appropriate lists in workers_chunks and workers_intervals.\n        workers_chunks[-1].append(chunks_replica[i])\n        workers_intervals[-1].append(intervals_replica[i])\n\n    # Finally, the function returns the two dictionaries, workers_chunks and workers_intervals, as a tuple.\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    assert len(chunks_replica) == len(intervals_replica)\n\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_rank = i % num_workers\n        workers_chunks[worker_rank].append(chunk_index)\n        workers_intervals[worker_rank].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Calculate the number of chunks per worker\n    num_chunks_per_worker = len(chunks_replica) // num_workers\n\n    # Initialize lists to store the assigned chunks and intervals for each worker\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    # Iterate over the chunks and intervals\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        # Determine the worker index based on the current chunk index and the total number of workers\n        worker_index = i % num_workers\n\n        # Append the chunk index and interval to the corresponding worker's lists\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Initialize dictionaries to store the chunks and intervals assigned to each worker\n    workers_chunks = {i: [] for i in range(num_workers)}\n    workers_intervals = {i: [] for i in range(num_workers)}\n\n    # Determine the distribution strategy based on the worker index and the total world size\n    if worker_env.world_size % num_workers == 0:\n        # If the total world size is divisible by the number of workers, distribute chunks evenly\n        distribution_strategy = \"even\"\n    else:\n        # Otherwise, distribute chunks in a round-robin fashion\n        distribution_strategy = \"round-robin\"\n\n    # Assign chunks and intervals to workers based on the distribution strategy\n    if distribution_strategy == \"even\":\n        # Distribute chunks evenly among workers\n        for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n            worker_index = i % num_workers\n            workers_chunks[worker_index].append(chunk_index)\n            workers_intervals[worker_index].append(chunk_interval)\n    elif distribution_strategy == \"round-robin\":\n        # Distribute chunks in a round-robin fashion\n        for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n            worker_index = i % num_workers\n            workers_chunks[worker_index].append(chunk_index)\n            workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Initialize the output dictionaries\n    workers_chunks = {i: [] for i in range(num_workers)}\n    workers_intervals = {i: [] for i in range(num_workers)}\n\n    # Determine the distribution strategy based on the worker's index and world size\n    if worker_env.world_size == num_workers:\n        # If the number of workers equals the total world size, distribute chunks and intervals evenly\n        for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n            worker_index = i % num_workers\n            workers_chunks[worker_index].append(chunk_index)\n            workers_intervals[worker_index].append(chunk_interval)\n    else:\n        # If the number of workers is not equal to the total world size, distribute chunks and intervals based on the worker's index\n        for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n            worker_index = i % worker_env.world_size\n            workers_chunks[worker_index].append(chunk_index)\n            workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Initialize empty lists to store the assigned chunks and intervals for each worker\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    # Determine the distribution strategy based on the worker's index and the total world size\n    if worker_env.rank == 0:\n        # If the worker's rank is 0, use the \"round-robin\" strategy\n        strategy = \"round-robin\"\n    else:\n        # Otherwise, use the \"chunk-based\" strategy\n        strategy = \"chunk-based\"\n\n    if strategy == \"round-robin\":\n        # Distribute chunks and intervals using the round-robin strategy\n        for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n            # Assign the chunk and its interval to the corresponding worker based on round-robin\n            worker_index = i % num_workers\n            workers_chunks[worker_index].append(chunk_index)\n            workers_intervals[worker_index].append(chunk_interval)\n    else:\n        # Distribute chunks and intervals using the chunk-based strategy\n        for chunk_index, chunk_interval in zip(chunks_replica, intervals_replica):\n            # Assign the chunk and its interval to the corresponding worker based on the chunk index\n            worker_index = chunk_index % num_workers\n            workers_chunks[worker_index].append(chunk_index)\n            workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    # Distribute chunks and intervals among workers based on the distribution strategy\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % num_workers\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Initialize empty lists for worker chunks and intervals\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    # Iterate over the chunks and intervals\n    for chunk_index, interval in zip(chunks_replica, intervals_replica):\n        # Calculate the worker index based on the chunk index and the world size\n        worker_index = chunk_index % worker_env.world_size\n        # Append the chunk index and interval to the corresponding worker's lists\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(interval)\n\n    # Return the worker chunks and intervals as dictionaries\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Calculate the number of chunks per worker\n    num_chunks_per_worker = len(chunks_replica) // num_workers\n    num_chunks_per_worker = max(1, num_chunks_per_worker)\n\n    # Initialize dictionaries to store chunks and intervals for each worker\n    workers_chunks = {i: [] for i in range(num_workers)}\n    workers_intervals = {i: [] for i in range(num_workers)}\n\n    # Distribute chunks and intervals among workers based on the distribution strategy\n    for i in range(len(chunks_replica)):\n        worker_index = i % num_workers\n        chunk_index = chunks_replica[i]\n        interval = intervals_replica[i]\n\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Initialize empty lists for worker chunks and intervals\n    workers_chunks = []\n    workers_intervals = []\n\n    # Iterate over the number of workers\n    for i in range(num_workers):\n        # Append an empty list to workers_chunks for the current worker\n        workers_chunks.append([])\n        # Append an empty list to workers_intervals for the current worker\n        workers_intervals.append([])\n\n    # Iterate over the chunks and intervals\n    for chunk_index, interval in zip(chunks_replica, intervals_replica):\n        # Calculate the worker index based on the current chunk index and the world size in the worker environment\n        worker_index = chunk_index % worker_env.world_size\n        # Append the current chunk index to the list of chunks for the corresponding worker\n        workers_chunks[worker_index].append(chunk_index)\n        # Append the current interval to the list of intervals for the corresponding worker\n        workers_intervals[worker_index].append(interval)\n\n    # Return the workers_chunks and workers_intervals as a tuple\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Create empty lists to store the assigned chunks and intervals for each worker\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    # Determine the distribution strategy based on the world size in the worker environment\n    if worker_env.world_size == 1:\n        # If there is only one worker, assign all chunks and intervals to that worker\n        workers_chunks[0] = chunks_replica\n        workers_intervals[0] = intervals_replica\n    elif worker_env.world_size > 1:\n        # If there are multiple workers, distribute the chunks and intervals based on the worker index\n        for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n            worker_index = i % worker_env.world_size\n            workers_chunks[worker_index].append(chunk_index)\n            workers_intervals[worker_index].append(chunk_interval)\n\n    # Return the assigned chunks and intervals for each worker as dictionaries\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Initialize the dictionaries to store the chunks and intervals assigned to each worker\n    workers_chunks = {i: [] for i in range(num_workers)}\n    workers_intervals = {i: [] for i in range(num_workers)}\n\n    # Determine the distribution strategy based on the worker's index and the total world size\n    if worker_env.global_rank % worker_env.world_size == 0:\n        # If the worker's global rank is divisible by the world size, it is assigned the first chunk and interval\n        # This is done to ensure that each worker is assigned at least one chunk and interval\n        for i in range(num_workers):\n            workers_chunks[i].append(chunks_replica[0])\n            workers_intervals[i].append(intervals_replica[0])\n    else:\n        # If the worker's global rank is not divisible by the world size, it is assigned the last chunk and interval\n        # This is done to ensure that each worker is assigned at least one chunk and interval\n        for i in range(num_workers):\n            workers_chunks[i].append(chunks_replica[-1])\n            workers_intervals[i].append(intervals_replica[-1])\n\n    # Return the dictionaries containing the chunks and intervals assigned to each worker\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Create a dictionary to store the chunks assigned to each worker\n    workers_chunks = {i: [] for i in range(num_workers)}\n    workers_intervals = {i: [] for i in range(num_workers)}\n\n    # Distribute chunks and intervals based on the worker's index and the total world size\n    for i, (chunk_index, chunk_interval) in enumerate(zip(chunks_replica, intervals_replica)):\n        worker_index = i % num_workers\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(chunk_interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.dataset._associate_chunks_to_workers", "completion": "    # Initialize empty lists for workers' chunks and intervals\n    workers_chunks = [[] for _ in range(num_workers)]\n    workers_intervals = [[] for _ in range(num_workers)]\n\n    # Iterate over each chunk and its corresponding interval\n    for chunk_index, interval in zip(chunks_replica, intervals_replica):\n        # Calculate the worker index based on the chunk index and the total world size\n        worker_index = chunk_index % worker_env.world_size\n        # Append the chunk index and its interval to the corresponding worker's lists\n        workers_chunks[worker_index].append(chunk_index)\n        workers_intervals[worker_index].append(interval)\n\n    return workers_chunks, workers_intervals\n\n"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": ""}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": ""}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": ""}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[6:]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath[len(\"local:\") :]\n\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.downloader.LocalDownloaderWithCache.download_file", "completion": "        if remote_filepath.startswith(\"local:\"):\n            remote_filepath = remote_filepath.replace(\"local:\", \"\")\n        super().download_file(remote_filepath, local_filepath)"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        assert isinstance(item, Image), f\"Expected PIL Image, got {type(item)}\"\n        mode = item.mode\n        width, height = item.size\n        mode_length = len(mode)\n        raw_data = item.tobytes()\n        return (\n            width.to_bytes(4, byteorder=\"big\")\n            + height.to_bytes(4, byteorder=\"big\")\n            + mode_length.to_bytes(4, byteorder=\"big\")\n            + mode.encode(\"utf-8\")\n            + raw_data,\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image):\n            raise TypeError(f\"Expected Image, got {type(item)}\")\n\n        with io.BytesIO() as f:\n            item.save(f, format=\"PNG\")\n            f.seek(0)\n            data = f.read()\n\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        assert isinstance(item, Image), f\"Expected PIL Image, got {type(item)}\"\n\n        buffer = io.BytesIO()\n        item.save(buffer, format=\"PNG\")\n        buffer.seek(0)\n        data = buffer.read()\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        buffer = io.BytesIO()\n        item.save(buffer, format=\"PNG\")\n        image_bytes = buffer.getvalue()\n        return image_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=\"PNG\")\n            data = output.getvalue()\n\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as f:\n            item.save(f, format=\"PNG\")\n            f.seek(0)\n            return f.read(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not isinstance(item, Image):\n            raise TypeError(f\"Expected a PIL Image, got {type(item)}\")\n        mode = item.mode\n        width, height = item.size\n        raw_data = item.tobytes()\n        mode_length = len(mode)\n        return (\n            width.to_bytes(4, byteorder=\"big\")\n            + height.to_bytes(4, byteorder=\"big\")\n            + mode_length.to_bytes(4, byteorder=\"big\")\n            + mode.encode(\"utf-8\")\n            + raw_data,\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as f:\n            item.save(f, format=\"PNG\")\n            f.seek(0)\n            return f.read(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"The PIL module is required to use the PILSerializer. Please install PIL with `pip install Pillow`.\"\n            )\n\n        if not isinstance(item, Image):\n            raise TypeError(f\"Expected PIL Image, got {type(item)}\")\n\n        with io.BytesIO() as f:\n            item.save(f, format=\"PNG\")\n            data = f.getvalue()\n\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        assert isinstance(item, Image)\n        mode = item.mode\n        width, height = item.size\n        mode_length = len(mode)\n        data = bytearray(item.tobytes())\n        data[:0] = mode_length.to_bytes(4, \"big\")\n        data[:4] = width.to_bytes(4, \"big\")\n        data[:8] = height.to_bytes(4, \"big\")\n        data[8:8 + mode_length] = mode.encode(\"utf-8\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as stream:\n            item.save(stream, format=item.format)\n            data = stream.getvalue()\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        assert isinstance(item, Image)\n        mode = item.mode\n        width, height = item.size\n        mode_length = len(mode)\n        raw_data = item.tobytes()\n        return (\n            width.to_bytes(4, \"big\")\n            + height.to_bytes(4, \"big\")\n            + mode_length.to_bytes(4, \"big\")\n            + mode.encode(\"utf-8\")\n            + raw_data,\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as f:\n            item.save(f, format=\"PNG\")\n            data = f.getvalue()\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        assert isinstance(item, Image)\n        mode = item.mode\n        mode_length = len(mode)\n        mode_bytes = mode.encode(\"utf-8\")\n        data = item.tobytes()\n        return (\n            mode_length.to_bytes(1, \"big\")\n            + mode_bytes\n            + item.width.to_bytes(4, \"big\")\n            + item.height.to_bytes(4, \"big\")\n            + data,\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise ImportError(\"PIL is not installed. Please install it with `pip install pillow`.\")\n\n        if not isinstance(item, Image):\n            raise ValueError(\"item must be a PIL Image\")\n\n        # Serialize the image dimensions and mode\n        width, height = item.size\n        mode = item.mode\n        mode_length = len(mode)\n\n        # Serialize the image data\n        data = item.tobytes()\n\n        # Concatenate the serialized data into a single bytes object\n        serialized_data = (\n            width.to_bytes(4, byteorder=\"big\")\n            + height.to_bytes(4, byteorder=\"big\")\n            + mode_length.to_bytes(4, byteorder=\"big\")\n            + mode.encode(\"utf-8\")\n            + data\n        )\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        with io.BytesIO() as output:\n            item.save(output, format=\"png\")\n            return output.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        assert isinstance(item, Image), \"PILSerializer can only serialize PIL Image objects.\"\n\n        with io.BytesIO() as f:\n            item.save(f, format=\"PNG\")\n            f.seek(0)\n            data = f.read()\n\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        assert isinstance(item, Image)\n        mode = item.mode\n        w, h = item.size\n        mode_len = len(mode)\n        mode_bytes = mode.encode(\"utf-8\")\n        raw_data = item.tobytes()\n        return (\n            w.to_bytes(4, \"little\")\n            + h.to_bytes(4, \"little\")\n            + mode_len.to_bytes(4, \"little\")\n            + mode_bytes\n            + raw_data,\n            None,\n        )\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Serialize PIL Image\n        # Save the image dimensions\n        width, height = item.size\n        # Save the image mode\n        mode = item.mode\n        # Save the image raw pixel data\n        raw_data = item.tobytes()\n\n        # Serialize the image dimensions, mode, and raw pixel data\n        serialized_data = (\n            width.to_bytes(4, byteorder=\"big\")\n            + height.to_bytes(4, byteorder=\"big\")\n            + len(mode).to_bytes(4, byteorder=\"big\")\n            + mode.encode(\"utf-8\")\n            + raw_data\n        )\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.serialize", "completion": "        # Convert the image to RGB mode if it's not already in RGB\n        if item.mode != \"RGB\":\n            item = item.convert(\"RGB\")\n\n        # Get the image dimensions and mode\n        width, height = item.size\n        mode = item.mode\n\n        # Get the raw pixel data as a bytes object\n        raw_data = item.tobytes()\n\n        # Serialize the image data\n        serialized_data = (\n            width.to_bytes(4, byteorder=\"big\")\n            + height.to_bytes(4, byteorder=\"big\")\n            + len(mode).to_bytes(4, byteorder=\"big\")\n            + mode.encode(\"utf-8\")\n            + raw_data\n        )\n\n        return serialized_data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                item = item.convert(\"RGB\")\n        elif isinstance(item, PngImageFile):\n            item = item.convert(\"RGB\")\n        elif isinstance(item, GifImageFile):\n            item = item.convert(\"RGB\")\n        elif isinstance(item, Image):\n            item = item.convert(\"RGB\")\n        else:\n            raise TypeError(f\"Unsupported image type: {type(item)}\")\n\n        with io.BytesIO() as f:\n            item.save(f, format=\"JPEG\")\n            return f.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                return item.tobytes(), None\n        elif isinstance(item, Image):\n            return item.convert(\"RGB\").tobytes(), None\n        else:\n            raise TypeError(f\"Unsupported type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                return item.tobytes(), None\n        elif isinstance(item, Image):\n            return item.tobytes(\"jpeg\"), None\n        else:\n            raise TypeError(f\"Expected a JPEG image, got {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if hasattr(item, \"filename\"):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                return item.tobytes(), None\n        elif isinstance(item, Image.Image):\n            return item.convert(\"RGB\").tobytes(), None\n        else:\n            raise TypeError(f\"Unsupported image type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            filename = item.filename\n            if filename and os.path.exists(filename):\n                with open(filename, \"rb\") as f:\n                    return f.read(), None\n        return item.tobytes(\"jpeg\"), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n        elif isinstance(item, Image):\n            buf = io.BytesIO()\n            item.save(buf, format=\"JPEG\")\n            return buf.getvalue(), None\n        raise TypeError(f\"Unsupported item type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, Image):\n            if isinstance(item, JpegImageFile) and item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                with io.BytesIO() as f:\n                    item.save(f, format=\"JPEG\")\n                    return f.getvalue(), None\n        else:\n            raise TypeError(f\"Unsupported type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    data = f.read()\n                return data, None\n\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"Expected an instance of Image, but got {type(item)}\")\n\n        with io.BytesIO() as output:\n            item.save(output, format=\"JPEG\")\n            data = output.getvalue()\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    data = f.read()\n                return data, None\n\n        if isinstance(item, Image):\n            with io.BytesIO() as f:\n                item.save(f, format=\"JPEG\")\n                data = f.getvalue()\n            return data, None\n\n        raise TypeError(f\"Unsupported image type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                item = item.convert(\"RGB\")\n        elif isinstance(item, PngImageFile):\n            item = item.convert(\"RGB\")\n        elif isinstance(item, WebPImageFile):\n            item = item.convert(\"RGB\")\n        elif isinstance(item, GifImageFile):\n            item = item.convert(\"RGB\")\n        elif not isinstance(item, Image.Image):\n            raise TypeError(f\"Unsupported type: {type(item)}\")\n        with io.BytesIO() as f:\n            item.save(f, format=\"JPEG\")\n            return f.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                with io.BytesIO() as f:\n                    item.save(f, format=\"JPEG\")\n                    return f.getvalue(), None\n        elif isinstance(item, Image):\n            with io.BytesIO() as f:\n                item.save(f, format=\"JPEG\")\n                return f.getvalue(), None\n        else:\n            raise TypeError(f\"Cannot serialize {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename is not None and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                item = item.convert(\"RGB\")\n        elif isinstance(item, Image):\n            item = item.convert(\"RGB\")\n        else:\n            raise TypeError(f\"Expected PIL Image, got {type(item)}\")\n        with io.BytesIO() as buffer:\n            item.save(buffer, format=\"JPEG\")\n            return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if not _PIL_AVAILABLE:\n            raise TypeError(\"PIL is not installed\")\n        if isinstance(item, JpegImageFile):\n            filename = item.filename\n            if filename and os.path.exists(filename):\n                with open(filename, \"rb\") as f:\n                    return f.read(), None\n        if isinstance(item, Image.Image):\n            with io.BytesIO() as f:\n                item.save(f, format=\"JPEG\")\n                return f.getvalue(), None\n        raise TypeError(f\"Unsupported item type: {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, Image):\n            if isinstance(item, JpegImageFile):\n                filename = item.filename\n                if filename is not None and os.path.exists(filename):\n                    with open(filename, \"rb\") as f:\n                        return f.read(), None\n            return item.tobytes(\"jpeg\"), None\n        else:\n            raise TypeError(f\"{type(item)} is not supported by {self.__class__.__name__}\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                item = item.convert(\"RGB\")\n        elif isinstance(item, PngImageFile):\n            item = item.convert(\"RGB\")\n        elif isinstance(item, GifImageFile):\n            item = item.convert(\"RGB\")\n        elif isinstance(item, Image):\n            item = item.convert(\"RGB\")\n        else:\n            raise TypeError(f\"Expected a PIL Image, got {type(item)}\")\n\n        with io.BytesIO() as f:\n            item.save(f, format=\"JPEG\")\n            return f.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            filename = item.filename\n            if filename and os.path.exists(filename):\n                with open(filename, \"rb\") as f:\n                    return f.read(), None\n        if not isinstance(item, Image.Image):\n            raise TypeError(f\"{item.__class__.__name__} is not a supported image type.\")\n        with io.BytesIO() as f:\n            item.save(f, format=\"JPEG\")\n            return f.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                item = item.convert(\"RGB\")\n        elif isinstance(item, Image):\n            item = item.convert(\"RGB\")\n        else:\n            raise TypeError(f\"Expected a PIL image, got {type(item)}\")\n        with io.BytesIO() as f:\n            item.save(f, format=\"JPEG\")\n            return f.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            filename = item.filename\n            if filename is not None and os.path.exists(filename):\n                with open(filename, \"rb\") as f:\n                    return f.read(), None\n\n        if isinstance(item, (PngImageFile, GifImageFile, WebPImageFile)):\n            item = item.convert(\"RGB\")\n\n        with io.BytesIO() as f:\n            item.save(f, format=\"JPEG\")\n            return f.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if item.filename and os.path.exists(item.filename):\n                with open(item.filename, \"rb\") as f:\n                    data = f.read()\n                return data, None\n            else:\n                item = item.convert(\"RGB\")\n        elif isinstance(item, Image.Image):\n            item = item.convert(\"RGB\")\n        else:\n            raise TypeError(f\"Cannot serialize {type(item)}\")\n        buffer = io.BytesIO()\n        item.save(buffer, format=\"JPEG\")\n        return buffer.getvalue(), None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.serialize", "completion": "        if isinstance(item, JpegImageFile):\n            if hasattr(item, \"filename\"):\n                with open(item.filename, \"rb\") as f:\n                    return f.read(), None\n            else:\n                return item.tobytes(), None\n        elif isinstance(item, Image):\n            return item.convert(\"RGB\").tobytes(), None\n        else:\n            raise TypeError(f\"Expected a JPEG image, got {type(item)}\")\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_size = ints\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_size = ints\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_size = ints\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_size = ints\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_len = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        data = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), data)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_size = ints\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        ints = np.frombuffer(data[:12], np.uint32)\n        width, height, mode_len = ints\n        mode = data[12 : 12 + mode_len].decode(\"utf-8\")\n        raw = data[12 + mode_len :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.PILSerializer.deserialize", "completion": "        width, height, mode_size = np.frombuffer(data[:12], np.uint32)\n        mode = data[12 : 12 + mode_size].decode(\"utf-8\")\n        raw = data[12 + mode_size :]\n        return Image.frombytes(mode, (width, height), raw)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 0\n        dtype_indice = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        ndim = np.frombuffer(data[idx : idx + 4], np.uint32)[0]\n        idx += 4\n        shape = np.frombuffer(data[idx : idx + ndim * 4], np.uint32)\n        idx += ndim * 4\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        array = np.frombuffer(data[idx:], dtype=dtype).reshape(shape)\n        return torch.from_numpy(array)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        n_dims = np.frombuffer(data[4:8], np.uint32)[0]\n        dims = np.frombuffer(data[8 : 8 + n_dims * 4], np.uint32)\n        data = data[8 + n_dims * 4 :]\n        return torch.from_numpy(np.frombuffer(data, dtype=dtype).reshape(dims))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        shape_size = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + shape_size * 4\n        shape = np.frombuffer(data[idx2:idx3], np.uint32)\n        idx4 = idx3 + np.prod(shape) * dtype.itemsize\n        array = np.frombuffer(data[idx3:idx4], dtype=dtype)\n        array = array.reshape(shape)\n        return torch.from_numpy(array)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        num_dims = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = np.frombuffer(data[8 : 8 + num_dims * 4], np.uint32)\n        raw = data[8 + num_dims * 4 :]\n        return torch.frombuffer(raw, dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        n_dims = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = np.frombuffer(data[8 : 8 * (n_dims + 1)], np.uint32)\n        array = np.frombuffer(data[8 * (n_dims + 1) :], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        return torch.from_numpy(array.reshape(shape)).to(dtype=dtype)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        ndim = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx3 = idx2 + 4 * ndim\n        shape = np.frombuffer(data[idx2:idx3], np.uint32)\n        return torch.from_numpy(np.frombuffer(data[idx3:], dtype).reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        data = data[4:]\n        shape_size = np.frombuffer(data[:4], np.uint32)[0]\n        data = data[4:]\n        shape = []\n        for _ in range(shape_size):\n            shape.append(np.frombuffer(data[:4], np.uint32)[0])\n            data = data[4:]\n        array = np.frombuffer(data, dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        return torch.from_numpy(array.reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], dtype=np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_length = np.frombuffer(data[4:8], dtype=np.uint32)[0]\n        shape = np.frombuffer(data[8 : 8 + shape_length * 4], dtype=np.uint32)\n        array = np.frombuffer(data[8 + shape_length * 4 :], dtype=dtype)\n        return torch.from_numpy(array.reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], dtype=np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_length = np.frombuffer(data[4:8], dtype=np.uint32)[0]\n        shape = np.frombuffer(data[8 : 8 + shape_length * 4], dtype=np.uint32)\n        array = np.frombuffer(data[8 + shape_length * 4 :], dtype=dtype)\n        return torch.from_numpy(array.reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n\n        shape_len = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = np.frombuffer(data[8 : 8 + shape_len * 4], np.uint32)\n        data = data[8 + shape_len * 4 :]\n\n        return torch.tensor(np.frombuffer(data, dtype=dtype), dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        ndim = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        shape = []\n        for _ in range(ndim):\n            idx3 = idx2 + 4\n            shape.append(np.frombuffer(data[idx2:idx3], np.uint32)[0])\n            idx2 = idx3\n        idx4 = idx2 + np.prod(shape) * np.dtype(dtype).itemsize\n        array = np.frombuffer(data[idx2:idx4], dtype=dtype).reshape(shape)\n        return torch.from_numpy(array)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        data = data[4:]\n        ndims = np.frombuffer(data[:4], np.uint32)[0]\n        data = data[4:]\n        shape = np.frombuffer(data[: ndims * 4], np.uint32)\n        data = data[ndims * 4 :]\n        return torch.tensor(np.frombuffer(data, dtype=dtype), dtype=dtype).reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        # Extract the data type and shape information from the byte array\n        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        ndims = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = tuple(np.frombuffer(data[8 : 8 + ndims * 4], np.uint32))\n\n        # Extract the tensor data from the byte array\n        data_start = 8 + ndims * 4\n        tensor_data = np.frombuffer(data[data_start:], dtype=dtype)\n\n        # Reshape the tensor data to match the original shape\n        tensor_data = tensor_data.reshape(shape)\n\n        # Convert the tensor data to a PyTorch tensor\n        tensor = torch.from_numpy(tensor_data)\n\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        ndims = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = np.frombuffer(data[8 : 8 + ndims * 4], np.uint32)\n        data = data[8 + ndims * 4 :]\n        return torch.from_numpy(np.frombuffer(data, dtype=dtype).reshape(shape))  # pyright: ignore\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        num_dims = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = np.frombuffer(data[8 : 8 * (num_dims + 1)], np.uint32)\n        array = np.frombuffer(data[8 * (num_dims + 1) :], dtype=dtype, count=np.prod(shape))\n        array = array.reshape(shape)\n        return torch.from_numpy(array)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        idx = 4\n        dtype_indice = np.frombuffer(data[:idx], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        idx2 = idx + 4\n        n_dims = np.frombuffer(data[idx:idx2], np.uint32)[0]\n        idx = idx2\n        shape = []\n        for _ in range(n_dims):\n            idx2 = idx + 4\n            dim = np.frombuffer(data[idx:idx2], np.uint32)[0]\n            shape.append(dim)\n            idx = idx2\n        array = np.frombuffer(data[idx:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n        array = array.reshape(shape)\n        return torch.from_numpy(array)  # pyright: ignore\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        # TODO: Add support for quantized tensors\n        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        ndims = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = np.frombuffer(data[8 : 8 + 4 * ndims], np.uint32)\n        data = data[8 + 4 * ndims :]\n        return torch.from_numpy(np.frombuffer(data, dtype=dtype).reshape(shape))\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        # Extract the data type index and shape information from the byte array\n        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        ndim = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = np.frombuffer(data[8 : 8 + ndim * 4], np.uint32)\n        # Construct the tensor from the remaining bytes\n        tensor = torch.from_numpy(np.frombuffer(data[8 + ndim * 4 :], dtype=_TORCH_DTYPES_MAPPING[dtype_indice]))\n        # Reshape the tensor to the original shape\n        return tensor.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        dtype_indice, data = np.frombuffer(data[:4], dtype=np.uint32, count=1), data[4:]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice[0]]\n        ndim, data = np.frombuffer(data[:4], dtype=np.uint32, count=1), data[4:]\n        shape, data = np.frombuffer(data[: ndim[0] * 4], dtype=np.uint32, count=ndim[0]), data[ndim[0] * 4 :]\n        tensor = torch.from_numpy(np.frombuffer(data, dtype=_NUMPY_DTYPES_MAPPING[dtype])).view(shape)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.deserialize", "completion": "        # Extract the data type and shape information from the byte array\n        dtype_indice = np.frombuffer(data[:4], np.uint32)[0]\n        dtype = _TORCH_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32)[0]\n        shape = np.frombuffer(data[8 : 8 + shape_size * 4], np.uint32)\n\n        # Extract the tensor data from the byte array\n        offset = 8 + shape_size * 4\n        data = np.frombuffer(data[offset:], dtype=_NUMPY_DTYPES_MAPPING[dtype])\n\n        # Reshape the tensor data to the original shape and convert it to a PyTorch tensor\n        data = data.reshape(shape)\n        data = torch.from_numpy(data)\n\n        return data\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        ints = np.array([dtype, *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype_idx = self._dtype_to_indices[item.dtype]\n        shape_bytes = np.array(item.shape, dtype=np.int32).tobytes()\n        data_bytes = item.numpy().tobytes()\n        return dtype_idx.to_bytes(1, \"little\") + shape_bytes + data_bytes, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        ints = np.array([dtype, *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        ints = np.array([dtype, len(shape)], np.uint32)\n        for s in shape:\n            ints = np.append(ints, np.array([s], np.uint32))\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        ints = np.array([self._dtype_to_indices[dtype], *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {item}.\")\n        dtype = item.dtype\n        if dtype not in self._dtype_to_indices:\n            raise ValueError(f\"The provided dtype {dtype} is not supported.\")\n        dtype_index = self._dtype_to_indices[dtype]\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        ints = np.array([dtype_index, *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        ints = np.array([self._dtype_to_indices[dtype], *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        if dtype not in self._dtype_to_indices:\n            raise ValueError(f\"Unsupported dtype {dtype}\")\n        idx = self._dtype_to_indices[dtype]\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        ints = np.array([idx, *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, np.uint32)\n        raw = item.numpy().tobytes()\n        ints = np.array([dtype, len(shape)], np.uint32)\n        return ints.tobytes() + shape.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        idx = self._dtype_to_indices[dtype]\n        ints = np.array([idx, *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        ints = np.array([self._dtype_to_indices[dtype], *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        ints = np.array([self._dtype_to_indices[dtype], len(shape)], np.uint32)\n        for s in shape:\n            ints = np.append(ints, s)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, np.uint32)\n        raw = item.numpy().tobytes()\n        return shape.tobytes() + dtype.to_bytes(1, \"big\") + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        if dtype not in _TORCH_DTYPES_MAPPING:\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {dtype}.\")\n        shape = item.shape\n        raw = item.numpy()\n        ints = np.array([len(shape), _TORCH_DTYPES_MAPPING[dtype]], np.uint32)\n        return ints.tobytes() + raw.tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {item}.\")\n\n        dtype = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, np.int64)\n        raw = item.numpy().tobytes()\n        ints = np.array([dtype, len(shape)], np.uint32)\n        return ints.tobytes() + shape.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = item.dtype\n        shape = item.shape\n        raw = item.numpy()\n        ints = np.array([self._dtype_to_indices[dtype], *shape], np.uint32)\n        return ints.tobytes() + raw.tobytes(), None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        dtype = self._dtype_to_indices[item.dtype]\n        shape = np.array(item.shape, np.uint32)\n        raw = item.numpy().tobytes()\n        return shape.tobytes() + dtype.to_bytes(1, \"little\") + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {item}.\")\n        dtype = self._dtype_to_indices.get(item.dtype)\n        if dtype is None:\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {item}.\")\n        shape = np.array(item.shape, np.uint32)\n        raw = item.numpy().tobytes()\n        return dtype.to_bytes(1, \"little\") + shape.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # extract the dtype and shape of the tensor\n        dtype, shape = item.dtype, item.shape\n\n        # extract the raw data of the tensor\n        raw = item.numpy().tobytes()\n\n        # convert the dtype to an integer index\n        dtype_idx = self._dtype_to_indices[dtype]\n\n        # convert the shape to a numpy array of uint32\n        shape_array = np.array(shape, dtype=np.uint32)\n\n        # concatenate the dtype index, shape array, and raw data into a single bytes object\n        return shape_array.tobytes() + dtype_idx.to_bytes(1, \"big\") + raw, None\n"}
{"namespace": "litdata.streaming.serializers.TensorSerializer.serialize", "completion": "        # TODO: Add support for other types like int, float, etc.\n        if not isinstance(item, torch.Tensor):\n            raise TypeError(f\"The provided item should be of type {torch.Tensor}. Found {item}.\")\n\n        dtype = item.dtype\n        if dtype not in self._dtype_to_indices:\n            raise TypeError(f\"The provided dtype {dtype} is not supported. Supported dtypes are {self._dtype_to_indices.keys()}.\")\n\n        # TODO: Add support for more dtypes\n        dtype_idx = self._dtype_to_indices[dtype]\n        shape = item.shape\n        raw = item.numpy().tobytes()\n        ints = np.array([dtype_idx, *shape], np.uint32)\n        return ints.tobytes() + raw, None\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(data)\n            else:\n                return Image.open(io.BytesIO(data))\n        except RuntimeError:\n            if _TORCH_VISION_AVAILABLE:\n                return pil_to_tensor(Image.open(io.BytesIO(data)))\n            else:\n                return Image.open(io.BytesIO(data))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n        return pil_to_tensor(Image.open(io.BytesIO(data)))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(data)\n            else:\n                return Image.open(io.BytesIO(data))\n        except RuntimeError:\n            if _TORCH_VISION_AVAILABLE:\n                return pil_to_tensor(Image.open(io.BytesIO(data)))\n            else:\n                return Image.open(io.BytesIO(data))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        return Image.open(io.BytesIO(data))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(data)\n            else:\n                return Image.open(io.BytesIO(data))\n        except RuntimeError as e:\n            if \"JPEG\" in str(e):\n                if _TORCH_VISION_AVAILABLE:\n                    return pil_to_tensor(Image.open(io.BytesIO(data)))\n                else:\n                    return Image.open(io.BytesIO(data))\n            else:\n                raise e\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n        return pil_to_tensor(PILSerializer.deserialize(data))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        return PILSerializer().deserialize(data)\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n        return pil_to_tensor(Image.open(io.BytesIO(data)))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                image = decode_jpeg(data)\n                if _TORCH_AVAILABLE:\n                    image = pil_to_tensor(image)\n                return image\n        except RuntimeError:\n            pass\n\n        return Image.open(io.BytesIO(data))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(data)\n        except RuntimeError:\n            pass\n\n        if _PIL_AVAILABLE:\n            image = Image.open(io.BytesIO(data))\n            if _TORCH_VISION_AVAILABLE:\n                image = pil_to_tensor(image)\n            return image\n\n        raise TypeError(f\"The provided item should be of type {JpegImageFile}. Found {data}.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(data)\n        except RuntimeError:\n            pass\n\n        if _PIL_AVAILABLE:\n            return Image.open(io.BytesIO(data))\n\n        raise TypeError(f\"The provided item should be of type {JpegImageFile}. Found {data}.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                image = decode_jpeg(data)\n                if _TORCH_AVAILABLE:\n                    image = pil_to_tensor(image)\n                return image\n            except RuntimeError as e:\n                if \"Expected 1-dimensional data\" in str(e):\n                    return Image.open(io.BytesIO(data))\n        return Image.open(io.BytesIO(data))"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError as e:\n                if \"JPEG decoding failed\" in str(e):\n                    # fallback to PIL\n                    return pil_to_tensor(Image.open(io.BytesIO(data)))\n                raise e\n        else:\n            return Image.open(io.BytesIO(data))"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                pass\n\n        if _PIL_AVAILABLE:\n            return Image.open(io.BytesIO(data))\n\n        raise ImportError(\n            \"PIL is not installed. Install it with `pip install Pillow` to deserialize JPEG images.\"\n        )\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                # Try to decode the data as a JPEG image using torchvision\n                image = decode_jpeg(data)\n                if _TORCH_AVAILABLE:\n                    # Convert the decoded image to a PyTorch tensor if torch is available\n                    image = pil_to_tensor(image)\n                return image\n            except RuntimeError:\n                # If the decoding fails due to a runtime error, fall back to using PIL to deserialize the data\n                return Image.open(io.BytesIO(data))\n        else:\n            # If torchvision is not available, use PIL to deserialize the data\n            return Image.open(io.BytesIO(data))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(torch.from_numpy(np.frombuffer(data, dtype=np.uint8)))\n        except RuntimeError:\n            if _PIL_AVAILABLE:\n                return Image.open(io.BytesIO(data))\n\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(Image.open(io.BytesIO(data)))\n\n        raise TypeError(f\"The provided data should be of type bytes. Found {data}.\")\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                return decode_jpeg(data)\n            else:\n                return Image.open(io.BytesIO(data))\n        except RuntimeError:\n            if _TORCH_VISION_AVAILABLE:\n                return pil_to_tensor(Image.open(io.BytesIO(data)))\n            else:\n                return Image.open(io.BytesIO(data))\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        if _TORCH_VISION_AVAILABLE:\n            try:\n                return decode_jpeg(data)\n            except RuntimeError:\n                # if the data is actually a PNG with a JPEG extension, we fallback to using PIL\n                # to deserialize the data\n                pass\n\n        img = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            return pil_to_tensor(img)\n        return img\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                # try to decode as a JPEG\n                return decode_jpeg(data)\n        except RuntimeError:\n            # fall back to using PIL\n            pass\n\n        # use PIL to deserialize the data\n        image = Image.open(io.BytesIO(data))\n        if _TORCH_VISION_AVAILABLE:\n            # convert the PIL image to a PyTorch tensor\n            return pil_to_tensor(image)\n        else:\n            # return the PIL image\n            return image\n"}
{"namespace": "litdata.streaming.serializers.JPEGSerializer.deserialize", "completion": "        try:\n            if _TORCH_VISION_AVAILABLE:\n                # decode the data as a JPEG image using torchvision\n                decoded_jpeg = decode_jpeg(data)\n                if _TORCH_AVAILABLE:\n                    # convert the decoded JPEG image to a PyTorch tensor\n                    return pil_to_tensor(decoded_jpeg)\n                else:\n                    return decoded_jpeg\n        except RuntimeError as e:\n            if \"JPEG\" in str(e):\n                # if the decoding fails due to a runtime error, fall back to using PIL to deserialize the data\n                return Image.open(io.BytesIO(data))\n            else:\n                raise e\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        dtype_indice = self._dtype_to_indices[item.dtype]\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type is not defined. HINT: Use the `setup` method.\")\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        dtype_indice = self._dtype_to_indices[item.dtype]\n        return data, f\"no_header_tensor:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"NoHeaderTensorSerializer.setup() must be called before serializing.\")\n        if item.dtype != self._dtype:\n            raise ValueError(f\"Expected dtype {self._dtype}, found {item.dtype}\")\n        return item.numpy().tobytes(order=\"C\"), f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The dtype is not set. Please call the setup method.\")\n        if item.dtype != self._dtype:\n            raise ValueError(f\"The dtype of the tensor should be {self._dtype}. Found {item.dtype}.\")\n        return item.numpy().tobytes(order=\"C\"), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"You need to setup the serializer before using it.\")\n\n        data = [item.numpy().tobytes(order=\"C\")]\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"You need to call the setup method before serializing\")\n        if item.dtype != self._dtype:\n            raise ValueError(f\"Expected {self._dtype} but got {item.dtype}\")\n        return item.numpy().tobytes(order=\"C\"), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type is not defined. HINT: Set the data type in the `setup` method.\")\n        dtype_indice = self._dtype_to_indices[self._dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.numpy().tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The serializer has not been setup.\")\n        data = item.numpy().tobytes(order=\"C\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise RuntimeError(\"The data type of the tensor is not defined. HINT: Use the setup method to define it.\")\n        data = item.numpy().tobytes(order=\"C\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy().tobytes(order=\"C\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise RuntimeError(\"The data type is not defined. HINT: Set the data type with `serializer.setup(data_format)`.\")\n        data = item.numpy().tobytes(order=\"C\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type is not defined. HINT: Use the `setup` method to define the data type.\")\n        data = item.numpy().tobytes(order=\"C\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type is not defined. HINT: call the setup method.\")\n        if item.dtype != self._dtype:\n            raise ValueError(f\"The provided tensor should be of type {self._dtype}. Found {item.dtype}.\")\n        return item.numpy().tobytes(order=\"C\"), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        data = item.numpy()\n        return data.tobytes(), f\"no_header_tensor:{self._dtype_to_indices[self._dtype]}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        assert self._dtype is not None, \"Please call setup() before calling serialize()\"\n        data = item.numpy().tobytes(order=\"C\")\n        return data, None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.serialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type of the tensor is not defined. HINT: Setup the serializer with the data type.\")\n        return item.numpy().tobytes(order=\"C\"), None\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.from_numpy(np.frombuffer(data, dtype=self._dtype))\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.from_numpy(np.frombuffer(data, dtype=self._dtype))\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        assert self._dtype is not None\n        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type is not defined.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type must be set before deserializing the data.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        assert self._dtype is not None\n        return torch.from_numpy(np.frombuffer(data, dtype=self._dtype))\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"NoHeaderTensorSerializer must be setup with a data type before deserializing.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The NoHeaderTensorSerializer has not been setup.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"NoHeaderTensorSerializer has no dtype defined.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data type has not been set. HINT: Call setup() method.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\n                \"The data format is not defined. HINT: Set the data format using the `setup` method before calling the `deserialize` method.\"\n            )\n        tensor = torch.frombuffer(data, dtype=self._dtype)\n        return tensor\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data format isn't set. HINT: Call the setup method.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise RuntimeError(\n                \"The data type of the tensor is not defined. HINT: Use the setup method to define the data type.\"\n            )\n        return torch.from_numpy(np.frombuffer(data, self._dtype))\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\"The data format is not set. HINT: Use `NoHeaderTensorSerializer.setup(data_format)`.\")\n        return torch.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderTensorSerializer.deserialize", "completion": "        if self._dtype is None:\n            raise ValueError(\n                \"You need to setup the serializer with the data format. HINT: Use `.setup('no_header_tensor:{dtype_indice}')`.\"\n            )\n        return torch.from_numpy(np.frombuffer(data, dtype=self._dtype))\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return array.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return array.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return array.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return array.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return array.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return np.reshape(array, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        tensor = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if tensor.shape == shape:\n            return tensor\n        return np.reshape(tensor, shape)\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.deserialize", "completion": "        dtype_indice = np.frombuffer(data[0:4], np.uint32).item()\n        dtype = _NUMPY_DTYPES_MAPPING[dtype_indice]\n        shape_size = np.frombuffer(data[4:8], np.uint32).item()\n        shape = []\n        for shape_idx in range(shape_size):\n            shape.append(np.frombuffer(data[8 + 4 * shape_idx : 8 + 4 * (shape_idx + 1)], np.uint32).item())\n        array = np.frombuffer(data[8 + 4 * (shape_idx + 1) : len(data)], dtype=dtype)\n        shape = tuple(shape)\n        if array.shape == shape:\n            return array\n        return array.reshape(shape)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.deserialize", "completion": "        assert self._dtype\n        return np.frombuffer(data, dtype=self._dtype)\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NoHeaderNumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        return item.tobytes(order=\"C\"), f\"no_header_numpy:{dtype_indice}\"\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.serializers.NumpySerializer.serialize", "completion": "        dtype_indice = self._dtype_to_indices[item.dtype]\n        data = [np.uint32(dtype_indice).tobytes()]\n        data.append(np.uint32(len(item.shape)).tobytes())\n        for dim in item.shape:\n            data.append(np.uint32(dim).tobytes())\n        data.append(item.tobytes(order=\"C\"))\n        return b\"\".join(data), None\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"dataset\": self.dataset.state_dict(),\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, CombinedStreamingDataset):\n            state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {}\n        state_dict[\"dataset\"] = self.dataset.state_dict()\n        state_dict[\"current_epoch\"] = self.current_epoch\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state_dict[\"num_samples_yielded\"] = self._num_samples_yielded_combined\n        state_dict[\"latest_worker_idx\"] = self._latest_worker_idx\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state_dict = {\n            \"dataset\": self.dataset.state_dict(),\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n        if isinstance(self.dataset, StreamingDataset):\n            state_dict[\"dataset\"][\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state_dict[\"dataset\"][\"num_samples_yielded\"] = self._num_samples_yielded_combined\n        return state_dict\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_streaming,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n        else:\n            return {\n                \"dataset\": self.dataset.state_dict(),\n                \"current_epoch\": self.current_epoch,\n                \"num_samples_yielded\": self._num_samples_yielded_combined,\n                \"latest_worker_idx\": self._latest_worker_idx,\n            }\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"dataset\": self.dataset.state_dict(),\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming\n            if isinstance(self.dataset, StreamingDataset)\n            else self._num_samples_yielded_combined,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"][\"rng_state\"] = self.rng_state\n\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {}\n        state[\"dataset\"] = self.dataset.state_dict()\n        state[\"current_epoch\"] = self.current_epoch\n        state[\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        state[\"latest_worker_idx\"] = self._latest_worker_idx\n        return state\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.state_dict", "completion": "        state = {\n            \"dataset\": self.dataset.state_dict(),\n            \"current_epoch\": self.current_epoch,\n            \"num_samples_yielded\": self._num_samples_yielded_streaming,\n            \"latest_worker_idx\": self._latest_worker_idx,\n        }\n\n        if isinstance(self.dataset, StreamingDataset):\n            state[\"dataset\"][\"num_samples_yielded\"] = self._num_samples_yielded_streaming\n        else:\n            state[\"dataset\"][\"num_samples_yielded\"] = self._num_samples_yielded_combined\n\n        return state\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"The torchvision library is required to deserialize video data. Please install it with `pip install torchvision`.\")\n\n        with tempfile.NamedTemporaryFile() as f:\n            f.write(data)\n            f.flush()\n            return torchvision.io.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"The `av` library is required to deserialize video data. Please install it with `pip install av`.\"\n            )\n        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\n                \"The `torchvision` library is required to deserialize video data. Please install it with `pip install torchvision`.\"\n            )\n\n        with tempfile.NamedTemporaryFile() as f:\n            f.write(data)\n            f.flush()\n            return read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\n                \"The torchvision library is required to deserialize video data. Please install it with `pip install torchvision`.\"\n            )\n        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"The av library is required to deserialize video data. Please install it with `pip install av`.\"\n            )\n        with tempfile.NamedTemporaryFile() as f:\n            f.write(data)\n            f.flush()\n            return read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"The av library is required to deserialize videos. Install it with `pip install av`.\"\n            )\n        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\n                \"The torchvision library is required to deserialize videos. Install it with `pip install torchvision`.\"\n            )\n        with tempfile.TemporaryDirectory() as tmpdir:\n            filepath = os.path.join(tmpdir, \"video.mp4\")\n            with open(filepath, \"wb\") as f:\n                f.write(data)\n            return read_video(filepath)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"The av library is required to deserialize video data. Please install it with `pip install av`.\"\n            )\n        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\n                \"The torchvision library is required to deserialize video data. Please install it with `pip install torchvision`.\"\n            )\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n            return read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise RuntimeError(\n                \"The video serializer requires torchvision and av. Please install them with `pip install torchvision av`.\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as tmp:\n            tmp.write(data)\n            tmp.flush()\n            return read_video(tmp.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"To use the VideoSerializer, please install the `av` library.\")\n        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"To use the VideoSerializer, please install the `torchvision` library.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as f:\n            f.write(data)\n            f.flush()\n            return torchvision.io.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ValueError(\"The av library is not installed. HINT: pip install av\")\n        if not _TORCH_VISION_AVAILABLE:\n            raise ValueError(\"The torchvision library is not installed. HINT: pip install torchvision\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.flush()\n            return read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ValueError(\"The torchvision is not installed. HINT: pip install torchvision\")\n        if not _TORCH_VISION_AVAILABLE:\n            raise ValueError(\"The torchvision is not installed. HINT: pip install torchvision\")\n        with tempfile.NamedTemporaryFile() as f:\n            f.write(data)\n            f.flush()\n            return read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _TORCH_VISION_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"The torchvision library is required to deserialize video data. Install it with `pip install torchvision`.\"\n            )\n        if not _AV_AVAILABLE:\n            raise ModuleNotFoundError(\"The av library is required to deserialize video data. Install it with `pip install av`.\")\n\n        with tempfile.NamedTemporaryFile() as f:\n            f.write(data)\n            f.flush()\n            video, _, _ = torchvision.io.read_video(f.name)\n        return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"The torchvision library is required to deserialize videos. Install it with `pip install torchvision`.\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.seek(0)\n            return torchvision.io.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"The VideoSerializer requires the `av` package. Install it with `pip install av`.\"\n            )\n        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\n                \"The VideoSerializer requires the `torchvision` package. Install it with `pip install torchvision`.\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            f.seek(0)\n            return read_video(f.name)[0]\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"Torchvision is required to use the VideoSerializer. Install it by running `pip install torchvision`.\"\n            )\n        with tempfile.NamedTemporaryFile() as tmp:\n            tmp.write(data)\n            tmp.flush()\n            return torchvision.io.read_video(tmp.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"The torchvision library is required to deserialize video data. Please install it.\")\n        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"The av library is required to deserialize video data. Please install it.\")\n\n        with tempfile.NamedTemporaryFile() as tmp:\n            tmp.write(data)\n            tmp.seek(0)\n            video, _, _ = read_video(tmp.name)\n        return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"To use the video serializer, please install the av library: `pip install av`.\")\n        if not _TORCH_VISION_AVAILABLE:\n            raise ImportError(\"To use the video serializer, please install the torchvision library: `pip install torchvision`.\")\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as tmp:\n            tmp.write(data)\n            tmp.flush()\n            video, _, _ = read_video(tmp.name)\n        return video\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\"The `av` library is required to deserialize video files. Please install it with `pip install av`.\")\n\n        with tempfile.NamedTemporaryFile() as f:\n            f.write(data)\n            f.seek(0)\n            return torchvision.io.read_video(f.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ValueError(\"The torchvision library is required to deserialize video data.\")\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as tmp:\n            tmp.write(data)\n            tmp.flush()\n            return read_video(tmp.name)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ValueError(\n                \"The torchvision library is required to deserialize video data. HINT: Install it by running `pip install torchvision`.\"\n            )\n        with tempfile.NamedTemporaryFile(delete=False) as f:\n            f.write(data)\n            filename = f.name\n            try:\n                return read_video(filename, pts_unit=\"sec\")\n            finally:\n                os.remove(filename)\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ImportError(\n                \"The video serializer requires torchvision and av. Please install them with `pip install torchvision av`.\"\n            )\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            return read_video(f.name)[0]\n"}
{"namespace": "litdata.streaming.serializers.VideoSerializer.deserialize", "completion": "        if not _AV_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"The torchvision library is required to use the video serializer. \"\n                \"You can install it with `pip install torchvision`.\"\n            )\n        if not _TORCH_VISION_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"The torchvision library is required to use the video serializer. \"\n                \"You can install it with `pip install torchvision`.\"\n            )\n\n        with tempfile.NamedTemporaryFile(suffix=\".mp4\") as f:\n            f.write(data)\n            video, _, _ = read_video(f.name)\n            return video\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n        files = []\n        while self._should_write():\n            files.append(self.write_chunk())\n        self.write_chunks_index()\n        self._is_done = True\n        return files"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while self._should_write():\n            self.write_chunk()\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, chunk[\"filename\"]) for chunk in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write any remaining chunks\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the index file\n        self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the list of chunk file paths\n        return [os.path.join(self._cache_dir, chunk[\"filename\"]) for chunk in self._chunks_info]"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n        filepaths = []\n        while self._should_write():\n            filepaths.append(self.write_chunk())\n        self.write_chunks_index()\n        self._is_done = True\n        return filepaths\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while self._should_write():\n            self.write_chunk()\n        self.write_chunks_index()\n        self._is_done = True\n        return self._chunks_info\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n\n        # Write remaining chunks\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the index file\n        self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the list of file paths to the written chunks\n        return [os.path.join(self._cache_dir, chunk[\"filename\"]) for chunk in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # TODO: This function is misleading, it does not mark the writing process as complete, it marks it as done\n        # TODO: This function is not idempotent, it can be called multiple times\n        # TODO: This function is not thread-safe, it can be called multiple times\n        # TODO: This function is not deterministic, it can return different results each time it is called\n        # TODO: This function is not reentrant, it can be called multiple times\n        # TODO: This function is not deterministic, it can return different results each time it is called\n        # TODO: This function is not reentrant, it can be called multiple times\n        # TODO: This function is not deterministic, it can return different results each time it is called\n        # TODO: This function is not reentrant, it can be called multiple times\n        # TODO: This function is not deterministic, it can return different results each time it is called\n        # TODO: This function is not reentrant, it can be called multiple times\n        # TODO: This function is not deterministic, it can return different results each time it is called\n        # TODO: This function is not reentrant, it can be called multiple times\n        # TODO: This function is not deterministic, it can return different results each time it is called\n        # TODO: This function is not reentrant, it can be called multiple times\n        # TODO: This function is not deterministic, it can return different results each time it is called\n        # TODO: This function is not reentrant, it can be called multiple times\n        # TODO: This function is not deterministic, it can return different results each time it is called\n        # TODO: This function is not reentrant, it can be called multiple times\n        # TODO: This function is not deterministic, it can return different results each time it is called\n        # TODO: This function is not reentrant, it can be called multiple times\n        # TODO: This function is not deterministic, it can return different results each time it is called\n        # TODO: This function is not reentrant, it can be called multiple times\n        # TODO: This function is not deterministic, it can return different results each time it is called\n        #"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        while self._should_write():\n            self.write_chunk()\n\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, chunk[\"filename\"]) for chunk in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write any remaining chunks of data to files\n        while self._should_write():\n            self.write_chunk()\n\n        # Generate an index file for the written chunks\n        self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the list of file paths to the written chunks\n        return [os.path.join(self._cache_dir, chunk[\"filename\"]) for chunk in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while self._should_write():\n            self.write_chunk()\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, chunk[\"filename\"]) for chunk in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n        files = []\n        while self._should_write():\n            files.append(self.write_chunk())\n        self.write_chunks_index()\n        self._is_done = True\n        return files\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n        files = []\n        while self._should_write():\n            files.append(self.write_chunk())\n        self.write_chunks_index()\n        self._is_done = True\n        return files\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while self._should_write():\n            self.write_chunk()\n\n        filepath = self.write_chunks_index()\n        self._is_done = True\n        return [filepath]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while self._should_write():\n            self.write_chunk()\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, chunk[\"filename\"]) for chunk in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        while self._should_write():\n            self.write_chunk()\n        self.write_chunks_index()\n        self._is_done = True\n        return [os.path.join(self._cache_dir, chunk[\"filename\"]) for chunk in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write any remaining chunks of data to files\n        while self._should_write():\n            self.write_chunk()\n\n        # Generate an index file for the written chunks\n        self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        # Return the list of file paths to the written chunks\n        return [os.path.join(self._cache_dir, chunk[\"filename\"]) for chunk in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n        if self._should_write():\n            self.write_chunk()\n        self._is_done = True\n        return [self.write_chunks_index()]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self._is_done:\n            return []\n        files = []\n        while self._should_write():\n            files.append(self.write_chunk())\n        self.write_chunks_index()\n        self._is_done = True\n        return files\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        if self.filled:\n            return []\n\n        if self._should_write():\n            self.write_chunk()\n            self._min_index = None\n            self._max_index = None\n\n        # Write the last chunk\n        if self._serialized_items:\n            self.write_chunk(on_done=True)\n\n        # Write the index file\n        self.write_chunks_index()\n\n        # Mark the writing process as complete\n        self._is_done = True\n\n        return [os.path.join(self._cache_dir, chunk[\"filename\"]) for chunk in self._chunks_info]\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.done", "completion": "        # Write the remaining items\n        while self._should_write():\n            self.write_chunk()\n\n        # Write the chunks index\n        self.write_chunks_index()\n\n        # Mark the writing process as done\n        self._is_done = True\n\n        # Return the written chunks\n        return [os.path.join(self._cache_dir, chunk[\"filename\"]) for chunk in self._chunks_info]\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        self.restore = True\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._worker_idx_iter = iter(cycle([self._latest_worker_idx]))\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._worker_idx = cycle(list(range(self._latest_worker_idx, self.num_workers)))\n        self._worker_idx_iter = iter(self._worker_idx)\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self.restore = True\n        self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n        self._worker_idx_iter = iter(self._worker_idx)\n        for _ in range(self._latest_worker_idx):\n            next(self._worker_idx_iter)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.current_epoch = obj[\"current_epoch\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        self.restore = True\n        self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n        self._worker_idx_iter = iter(self._worker_idx)\n        for _ in range(self._latest_worker_idx):\n            next(self._worker_idx_iter)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._worker_idx = cycle(list(range(self._latest_worker_idx, self.num_workers)))\n        self._worker_idx_iter = iter(self._worker_idx)\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n        else:\n            raise RuntimeError(\"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\")\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n        self._worker_idx_iter = iter(self._worker_idx)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                self._num_samples_yielded_streaming,\n                self.num_workers,\n                self.batch_size,\n            )\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(\n                obj[\"dataset\"],\n                self.num_workers,\n                self.batch_size,\n                obj[\"num_samples_yielded\"],\n            )\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            assert self.batch_size\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n\n        if self.num_workers > 0:\n            self._worker_idx = cycle(list(range(self.num_workers)))\n            self._worker_idx_iter = iter(self._worker_idx)\n            for _ in range(self._latest_worker_idx):\n                next(self._worker_idx_iter)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self.restore = True\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\")\n\n        self._worker_idx = cycle(list(range(self._latest_worker_idx, self.num_workers)))\n        self._worker_idx_iter = iter(self._worker_idx)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        if isinstance(self.dataset, StreamingDataset):\n            assert self.batch_size\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self._worker_idx = cycle(list(range(self._latest_worker_idx, self.num_workers)))\n            self._worker_idx_iter = iter(self._worker_idx)\n        else:\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self.current_epoch = obj[\"current_epoch\"]\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.restore = True\n            self._worker_idx = cycle(list(range(self._latest_worker_idx, self.num_workers)))\n            self._worker_idx_iter = iter(self._worker_idx)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\")\n\n        if self.num_workers == 0:\n            self._worker_idx_iter = iter(self._worker_idx)\n        else:\n            self._worker_idx_iter = None\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\")\n\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._worker_idx = cycle(list(range(self._latest_worker_idx, self.num_workers)))\n        self._worker_idx_iter = iter(self._worker_idx)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self.restore = True\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self.dataset.load_state_dict(obj[\"dataset\"])\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n        else:\n            raise RuntimeError(\n                \"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\"\n                f\" Found {self.dataset}.\"\n            )\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        elif isinstance(self.dataset, CombinedStreamingDataset):\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            raise RuntimeError(\"The provided dataset should be either an instance of StreamingDataset or CombinedStreamingDataset.\")\n\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._worker_idx_iter = iter(cycle([self._latest_worker_idx]))\n\n        if isinstance(self.dataset, StreamingDataset):\n            self.dataset.set_epoch(self.current_epoch)\n        else:\n            self.dataset._set_use_streaming_dataloader(True)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self._latest_worker_idx = obj[\"latest_worker_idx\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n\n        if self._latest_worker_idx == 0:\n            self._worker_idx = cycle(list(range(self.num_workers if self.num_workers > 0 else 1)))\n            self._worker_idx_iter = iter(self._worker_idx)\n"}
{"namespace": "litdata.streaming.dataloader.StreamingDataLoader.load_state_dict", "completion": "        self.current_epoch = obj[\"current_epoch\"]\n        self.restore = True\n        self._latest_worker_idx = obj[\"latest_worker_idx\"]\n        self._worker_idx = cycle(list(range(self._latest_worker_idx, self.num_workers)))\n        self._worker_idx_iter = iter(self._worker_idx)\n\n        if isinstance(self.dataset, StreamingDataset):\n            self._num_samples_yielded_streaming = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n        else:\n            self._num_samples_yielded_combined = obj[\"num_samples_yielded\"]\n            self.dataset.load_state_dict(obj[\"dataset\"])\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                    __SAMPLES_KEY__: [\n                        dataset.state_dict(num_workers, batch_size, num_samples_yielded)\n                        for dataset, num_samples_yielded in zip(self._datasets, num_samples_yielded)\n                    ],\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                    __SAMPLES_KEY__: [\n                        dataset.state_dict(num_workers, batch_size, num_samples_yielded)\n                        for dataset, num_samples_yielded in zip(self._datasets, num_samples_yielded)\n                    ],\n                }\n        else:\n            return self._iterator.state_dict()\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                    __SAMPLES_KEY__: self._datasets,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n        else:\n            if num_samples_yielded is None:\n                return self._iterator.state_dict(num_workers, batch_size)\n            else:\n                return {\n                    __SAMPLES_KEY__: self._iterator.state_dict(num_workers, batch_size),\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                    __SAMPLES_KEY__: [\n                        dataset.state_dict(num_workers, batch_size, num_samples_yielded[i])\n                        for i, dataset in enumerate(self._datasets)\n                    ],\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            return {}\n\n        if num_samples_yielded is None:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n        state_dict = {\n            \"datasets\": [d.state_dict(num_workers, batch_size) for d in self._datasets],\n            \"seed\": self._seed,\n            \"weights\": self._weights,\n            \"num_samples_yielded\": num_samples_yielded,\n            \"current_epoch\": self._current_epoch,\n        }\n        return state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            return {\n                __SAMPLES_KEY__: num_samples_yielded,\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n            }\n\n        if self._iterator._num_samples_yielded is None:\n            return {}\n\n        return {\n            __SAMPLES_KEY__: self._iterator._num_samples_yielded,\n            __NUM_SAMPLES_YIELDED_KEY__: self._iterator._num_samples_yielded,\n        }\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                    __SAMPLES_KEY__: [d.state_dict(num_workers, batch_size, num_samples_yielded) for d in self._datasets],\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n\n        return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            return {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: [\n                    d.state_dict(num_workers, batch_size, num_samples_yielded) for d in self._datasets\n                ],\n            }\n\n        return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                    __SAMPLES_KEY__: [\n                        d.state_dict(num_workers, batch_size, num_samples_yielded=num_samples_yielded)\n                        for d in self._datasets\n                    ],\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            return {}\n\n        if self._iterator._state_dict is not None:\n            return self._iterator._state_dict\n\n        if num_samples_yielded is None:\n            return {}\n\n        self._num_samples_yielded = num_samples_yielded\n\n        # We need to create a new iterator to get the state_dict\n        self._iterator = _CombinedDatasetIterator(\n            self._datasets,\n            self._seed,\n            self._weights,\n            self._use_streaming_dataloader,\n            num_samples_yielded,\n        )\n        return self._iterator._state_dict\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                    __SAMPLES_KEY__: [d.state_dict(num_workers, batch_size, num_samples_yielded) for d in self._datasets],\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                    __SAMPLES_KEY__: [\n                        d.state_dict(num_workers, batch_size, num_samples_yielded) for d in self._datasets\n                    ],\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            return {}\n\n        if num_samples_yielded is not None:\n            return {\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                __SAMPLES_KEY__: self._iterator.state_dict(num_workers, batch_size),\n            }\n\n        return {\n            __NUM_SAMPLES_YIELDED_KEY__: self._iterator.num_samples_yielded,\n            __SAMPLES_KEY__: self._iterator.state_dict(num_workers, batch_size),\n        }\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            else:\n                return {\n                    __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n                }\n        else:\n            return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.state_dict", "completion": "        if self._iterator is None:\n            if num_samples_yielded is None:\n                return {}\n            return {\n                __SAMPLES_KEY__: num_samples_yielded,\n                __NUM_SAMPLES_YIELDED_KEY__: num_samples_yielded,\n            }\n        return self._iterator.state_dict(num_workers, batch_size, num_samples_yielded)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._check_datasets(self._datasets)\n        worker_env = _WorkerEnv.detect()\n\n        num_samples_yielded = None\n\n        if self._num_samples_yielded is not None and worker_env.rank in self._num_samples_yielded:\n            num_samples_yielded = self._num_samples_yielded[worker_env.rank]\n\n        self._iterator = _CombinedDatasetIterator(\n            self._datasets,\n            self._seed,\n            self._weights,\n            self._use_streaming_dataloader,\n            num_samples_yielded,\n        )\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        # Update the state of each dataset within the CombinedStreamingDataset\n        for i, dataset in enumerate(self._datasets):\n            dataset.load_state_dict(state_dict[f\"{__SAMPLES_KEY__}_{i}\"])\n\n        # Update the number of samples yielded by the streaming dataloader to avoid repeating samples\n        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict[__NUM_SAMPLES_YIELDED_KEY__])\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._iterator = _CombinedDatasetIterator(self._datasets, self._seed, self._weights, self._use_streaming_dataloader)\n        self._iterator.load_state_dict(state_dict)\n\n        if self._use_streaming_dataloader:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._num_samples_yielded = state_dict.pop(__NUM_SAMPLES_YIELDED_KEY__, None)\n        for dataset, samples in zip(self._datasets, state_dict.pop(__SAMPLES_KEY__, [])):\n            dataset.load_state_dict(samples)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._iterator = _CombinedDatasetIterator(self._datasets, self._seed, self._weights, self._use_streaming_dataloader)\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = _load_state_dict(self._datasets, state_dict)\n            return\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not state_dict:\n            return\n\n        # Update the state of each dataset within the CombinedStreamingDataset\n        for dataset_idx, dataset in enumerate(self._datasets):\n            dataset.load_state_dict(state_dict[__SAMPLES_KEY__][dataset_idx])\n\n        # Update the number of samples yielded by the streaming dataloader to avoid repeating samples\n        if self._iterator is not None:\n            self._iterator._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if state_dict:\n            if self._iterator is None:\n                self._iterator = _CombinedDatasetIterator.from_state_dict(state_dict)\n            else:\n                self._iterator.load_state_dict(state_dict)\n\n            # Update the number of samples yielded by the streaming dataloader to avoid repeating samples\n            self._num_samples_yielded = self._iterator._num_samples_yielded\n\n            for dataset in self._datasets:\n                dataset.load_state_dict(state_dict[dataset.name])\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not self._iterator:\n            self._iterator = _CombinedDatasetIterator(self._datasets, self._seed, self._weights)\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if len(state_dict) == 0:\n            return\n\n        for dataset, dataset_state in zip(self._datasets, state_dict[__SAMPLES_KEY__]):\n            dataset.load_state_dict(dataset_state)\n\n        if __NUM_SAMPLES_YIELDED_KEY__ in state_dict:\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if state_dict:\n            for dataset, state in zip(self._datasets, state_dict[__SAMPLES_KEY__]):\n                dataset.load_state_dict(state)\n\n            self._num_samples_yielded = state_dict[__NUM_SAMPLES_YIELDED_KEY__]\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not state_dict:\n            return\n\n        num_samples_yielded = state_dict.pop(__NUM_SAMPLES_YIELDED_KEY__, None)\n        self._num_samples_yielded = num_samples_yielded\n\n        for dataset_idx, dataset in enumerate(self._datasets):\n            dataset.load_state_dict(state_dict[__SAMPLES_KEY__][dataset_idx])\n\n        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not state_dict:\n            return\n\n        if self._iterator is None:\n            self._iterator = _CombinedDatasetIterator.load_state_dict(state_dict, self._datasets)\n            return\n\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if state_dict:\n            if self._iterator is not None:\n                self._iterator.load_state_dict(state_dict)\n            else:\n                for dataset, num_samples in zip(self._datasets, state_dict[__SAMPLES_KEY__]):\n                    dataset.load_state_dict(num_samples)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._iterator = _CombinedDatasetIterator(self._datasets, self._seed, self._weights, self._use_streaming_dataloader)\n        self._iterator.load_state_dict(state_dict)\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._check_datasets(self._datasets)\n\n        if self._iterator is None:\n            self._iterator = _CombinedDatasetIterator(self._datasets, self._seed, self._weights, self._use_streaming_dataloader)\n\n        self._iterator.load_state_dict(state_dict)\n\n        if self._use_streaming_dataloader:\n            self._num_samples_yielded = self._iterator.num_samples_yielded\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        # Update the state of each dataset within the CombinedStreamingDataset\n        for idx, dataset in enumerate(self._datasets):\n            dataset.load_state_dict(state_dict[f\"{idx}\"])\n\n        # Update the number of samples yielded by the streaming dataloader to avoid repeating samples\n        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        self._check_datasets(self._datasets)\n\n        if self._iterator is not None:\n            self._iterator.load_state_dict(state_dict)\n\n        for dataset in self._datasets:\n            dataset.load_state_dict(state_dict)\n\n        if state_dict:\n            self._num_samples_yielded = state_dict.get(__NUM_SAMPLES_YIELDED_KEY__)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if not self._iterator:\n            return\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.combined.CombinedStreamingDataset.load_state_dict", "completion": "        if self._iterator is None:\n            self._num_samples_yielded = state_dict.pop(__NUM_SAMPLES_YIELDED_KEY__, None)\n            self._iterator = _CombinedDatasetIterator(\n                self._datasets, self._seed, self._weights, self._use_streaming_dataloader, self._num_samples_yielded\n            )\n        self._iterator.load_state_dict(state_dict)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"s3a://\"):\n            return Dir(url=dir_path.replace(\"s3a://\", \"s3://\"))\n\n        if dir_path.startswith(\"s3n://\"):\n            return Dir(url=dir_path.replace(\"s3n://\", \"s3://\"))\n\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"s3a://\"):\n            return Dir(url=dir_path.replace(\"s3a://\", \"s3://\"))\n\n        if dir_path.startswith(\"s3n://\"):\n            return Dir(url=dir_path.replace(\"s3n://\", \"s3://\"))\n\n        if dir_path.startswith(\"gs://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"gcs://\"):\n            return Dir(url=dir_path.replace(\"gcs://\", \"gs://\"))\n\n        if dir_path.startswith(\"wasbs://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"wasbs://\"):\n            return Dir(url=dir_path.replace(\"wasbs://\", \"wasbs://\"))\n\n        if dir_path.startswith(\"wasbns://\"):\n            return Dir(url=dir_path.replace(\"wasbns://\", \"wasbs://\"))\n\n        if dir_path.startswith(\"wasb://\"):\n            return Dir(url=dir_path.replace(\"wasb://\", \"wasbs://\"))\n\n        if dir_path.startswith(\"wasbns://\"):\n            return Dir"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n    if dir_path.startswith(\"gs://\"):\n        return Dir(url=dir_path)\n    if dir_path.startswith(\"dbfs:/\"):\n        return Dir(url=dir_path)\n    if dir_path.startswith(\"wasbs://\"):\n        return Dir(url=dir_path)\n    if dir_path.startswith(\"abfss://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3a://\"):\n        return Dir(path=dir_path.replace(\"s3a://\", \"s3://\"))\n    if dir_path.startswith(\"gsa://\"):\n        return Dir(path=dir_path.replace(\"gsa://\", \"gs://\"))\n    if dir_path.startswith(\"dbfsa:/\"):\n        return Dir(path=dir_path.replace(\"dbfsa:/\", \"dbfs:/\"))\n    if dir_path.startswith(\"wasbsa:/\"):\n        return Dir(path=dir_path.replace(\"wasbsa:/\", \"wasbs://\"))\n    if dir_path.startswith(\"abfssa:/\"):\n        return Dir(path=dir_path.replace(\"abfssa:/\", \"abfss://\"))\n\n    if dir_path.startswith(\"s3n://\"):\n        return Dir(path=dir_path.replace(\"s3n://\", \"s3://\"))\n    if dir_path.startswith(\"gsn://\"):\n        return Dir(path=dir_path.replace(\"gsn://\", \"gs://\"))\n    if dir_path.startswith(\"dbfsn:/\"):\n        return Dir(path=dir_path.replace(\"dbfsn:/\", \"dbfs:/\"))\n    if dir_path.startswith(\""}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    if isinstance(dir_path, Dir):\n        return dir_path\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"gs://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"dbfs:/\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"dbfs://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"wasbs://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"wasbs://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"wasb://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"wasb://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"azure://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"azure://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"abfs://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"abfs://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"adl://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"adl://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"s3a://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"s3a://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"s3n://\"):\n            return"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"~\"):\n            dir_path = os.path.expanduser(dir_path)\n\n        if dir_path.startswith(\"lightning://\"):\n            return Dir(url=dir_path)\n\n        return Dir(path=dir_path)\n\n    raise ValueError(f\"Invalid dir_path: {dir_path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"gs://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"dbfs:\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"wasbs:\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"abfss:\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"azure:\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"s3a://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"s3n://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"s3n://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"s3a://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"s3n://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"s3a://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n\n        if dir_path.startswith(\"s3n://\"):\n            return Dir(url=dir_path)\n\n       "}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        # s3://bucket/path/to/dir\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"dbfs:/\"):\n        # dbfs:/path/to/dir\n        return Dir(path=dir_path.replace(\"dbfs:/\", \"/dbfs/\"))\n    elif dir_path.startswith(\"file:\"):\n        # file:/path/to/dir\n        return Dir(path=dir_path.replace(\"file:/\", \"/dbfs/\"))\n    elif dir_path.startswith(\"s3a://\"):\n        # s3a://bucket/path/to/dir\n        return Dir(url=dir_path.replace(\"s3a://\", \"s3://\"))\n    elif dir_path.startswith(\"s3n://\"):\n        # s3n://bucket/path/to/dir\n        return Dir(url=dir_path.replace(\"s3n://\", \"s3://\"))\n    elif dir_path.startswith(\"s3://\"):\n        # s3://bucket/path/to/dir\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"wasbs://\"):\n        # wasbs://container@storage_account.blob.core.windows.net/path/to/dir\n        return Dir(url=dir_path.replace(\"wasbs://\", \"wasb://\"))\n    elif dir_path.startswith(\"wasb://\"):\n        # wasb://container@storage_account.blob.core.windows.net/path/to/dir\n        return Dir(url=dir_path)\n    elif dir_path.startswith(\"wasbns://\"):\n        # wasbns://container@storage_account.blob.core.windows.net/path/to/dir\n        return Dir(url=dir_path.replace(\"wasbns://"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"gs://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"wasbs://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"hdfs://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"sftp://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"http://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"https://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"ssh://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"ftp://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3n://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3a://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3r://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3p://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3k://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3c://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3s://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    elif isinstance(dir_path, Dir):\n        return dir_path\n    elif isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"dbfs:/\"):\n            return Dir(path=dir_path)\n        elif dir_path.startswith(\"file://\"):\n            return Dir(path=dir_path.replace(\"file://\", \"\"))\n        elif dir_path.startswith(\"projects/\"):\n            return Dir(path=dir_path)\n        else:\n            return Dir(path=dir_path)\n    else:\n        raise ValueError(f\"Unsupported type for dir_path: {type(dir_path)}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    if isinstance(dir_path, Dir):\n        return dir_path\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"~\"):\n            return Dir(path=os.path.expanduser(dir_path))\n        elif dir_path.startswith(\"./\"):\n            return Dir(path=os.path.abspath(dir_path))\n        else:\n            return Dir(path=dir_path)\n    raise ValueError(f\"Invalid dir_path: {dir_path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    if isinstance(dir_path, Dir):\n        return dir_path\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"gs://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"dbfs:/\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"file://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"s3a://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"wasbs://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"wasbns://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"wasb://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"wasb-cfs://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"abfs://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"abfss://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"adl://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"adls://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"adl://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"adls://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"az://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"azure://\"):\n            return"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    elif isinstance(dir_path, Dir):\n        return dir_path\n    elif isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"gs://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"dbfs:/\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"sftp://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"hdfs://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"wasbs://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"abfss://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"adl://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"az://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"projects/\"):\n            return Dir(path=dir_path)\n        else:\n            return Dir(path=dir_path)\n    else:\n        raise ValueError(f\"Invalid directory path: {dir_path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    elif isinstance(dir_path, Dir):\n        return dir_path\n    elif isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"projects/\"):\n            return Dir(path=dir_path)\n        else:\n            return Dir(path=os.path.abspath(dir_path))\n    else:\n        raise ValueError(f\"Unknown type for dir_path: {type(dir_path)}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    elif isinstance(dir_path, Dir):\n        return dir_path\n    elif isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"~\"):\n            return Dir(path=os.path.expanduser(dir_path))\n        elif dir_path.startswith(\"./\"):\n            return Dir(path=os.path.abspath(dir_path))\n        elif dir_path.startswith(\"/\"):\n            return Dir(path=dir_path)\n        else:\n            return Dir(path=os.path.abspath(dir_path))\n    else:\n        raise ValueError(f\"Invalid dir_path: {dir_path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"gs://\"):\n            return Dir(url=dir_path)\n        if dir_path.startswith(\"dbfs:/\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"runs:/\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"file:\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"dbfs://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"runs://\"):\n            return Dir(path=dir_path)\n        if dir_path.startswith(\"file://\"):\n            return Dir(path=dir_path)\n        return Dir(path=dir_path)\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    raise ValueError(f\"Invalid dir_path: {dir_path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    elif isinstance(dir_path, Dir):\n        return dir_path\n    elif isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"dbfs:/\"):\n            return Dir(path=dir_path)\n        elif dir_path.startswith(\"dbfs://\"):\n            return Dir(path=dir_path.replace(\"dbfs://\", \"dbfs:/\"))\n        elif dir_path.startswith(\"file://\"):\n            return Dir(path=dir_path.replace(\"file://\", \"\"))\n        else:\n            return Dir(path=dir_path)\n    else:\n        raise ValueError(f\"Unknown dir_path type: {type(dir_path)}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    # Handle local paths\n    if os.path.exists(dir_path):\n        return Dir(path=dir_path)\n\n    # Handle S3 URLs\n    if dir_path.startswith(\"s3://\"):\n        parsed_url = parse.urlparse(dir_path)\n        return Dir(path=parsed_url.path.lstrip(\"/\"), url=dir_path)\n\n    # Handle project paths\n    if dir_path.startswith(\"~/\"):\n        return Dir(path=os.path.expanduser(dir_path))\n    elif dir_path.startswith(\"./\"):\n        return Dir(path=os.path.abspath(dir_path))\n    else:\n        return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"gs://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"dbfs:/\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"file:\"):\n        return Dir(path=dir_path.replace(\"file:\", \"\"))\n\n    if dir_path.startswith(\"projects/\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"/\"):\n        return Dir(path=dir_path)\n\n    if dir_path.startswith(\"dbfs://\"):\n        return Dir(path=dir_path.replace(\"dbfs://\", \"dbfs:/\"))\n\n    if dir_path.startswith(\"file://\"):\n        return Dir(path=dir_path.replace(\"file://\", \"file:\"))\n\n    if dir_path.startswith(\"gs://\"):\n        return Dir(url=dir_path)\n\n    if dir_path.startswith(\"s3://\"):\n        return Dir(url=dir_path)\n\n    return Dir(path=dir_path)\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    # If the dir_path is a string, it could be a local path, an S3 URL, or a specific project path.\n    if isinstance(dir_path, str):\n        # If the dir_path starts with \"s3://\", it's an S3 URL.\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n\n        # If the dir_path starts with \"projects/\", it's a specific project path.\n        if dir_path.startswith(\"projects/\"):\n            return Dir(path=dir_path)\n\n        # Otherwise, it's a local path.\n        return Dir(path=dir_path)\n\n    raise ValueError(f\"Invalid dir_path: {dir_path}\")\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"gs://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"https://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"lightning://\"):\n            return Dir(path=dir_path)\n        elif dir_path.startswith(\"dbfs://\"):\n            return Dir(path=dir_path)\n        else:\n            return Dir(path=dir_path)\n    else:\n        return dir_path\n\n"}
{"namespace": "litdata.streaming.resolver._resolve_dir", "completion": "    if dir_path is None:\n        return Dir()\n    if isinstance(dir_path, Dir):\n        return dir_path\n\n    if isinstance(dir_path, str):\n        if dir_path.startswith(\"s3://\"):\n            return Dir(url=dir_path)\n        elif dir_path.startswith(\"dbfs:/\"):\n            return Dir(path=dir_path)\n        elif dir_path.startswith(\"/\"):\n            return Dir(path=dir_path)\n        elif dir_path.startswith(\"dbfs:\"):\n            return Dir(path=dir_path)\n        elif dir_path.startswith(\"s3:\"):\n            return Dir(url=dir_path)\n        else:\n            return Dir(path=dir_path)\n    else:\n        raise ValueError(f\"Unknown dir_path type: {type(dir_path)}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"`output_dir` must be a S3 url, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be a S3 url, got: {output_dir}\")\n\n    if append:\n        raise NotImplementedError(\"`append` is not implemented yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"`overwrite` is not implemented yet.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ModuleNotFoundError(\n            \"`boto3` is required for this function. Please install it with `pip install boto3`.\"\n        )\n\n    bucket_name, key = parse.urlparse(output_dir.url).netloc, parse.urlparse(output_dir.url).path.lstrip(\"/\")\n    s3 = boto3.resource(\"s3\")\n\n    try:\n        s3.meta.client.head_bucket(Bucket=bucket_name)\n    except botocore.exceptions.ClientError as e:\n        # If a client error is thrown, then check that it was a 404 error.\n        # If it was a 404 error, then the bucket does not exist.\n        error_code = int(e.response[\"Error\"][\"Code\"])\n        if error_code == 404:\n            raise ValueError(f\"The bucket {bucket_name} does not exist.\")\n        raise\n\n    bucket = s3.Bucket(bucket_name)\n    objects = list(bucket.objects.filter(Prefix=key))\n    if len(objects) > 0:\n        raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(f\"`output_dir` must have a url, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 bucket, got: {output_dir}\")\n\n    if append:\n        raise NotImplementedError(\"`append` is not implemented yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"`overwrite` is not implemented yet.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"`boto3` is not installed. Please install it with `pip install boto3`.\")\n\n    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"`lightning_sdk` is not installed. Please install it with `pip install lightning-sdk`.\")\n\n    bucket_name, key = _parse_s3_url(output_dir.url)\n\n    s3 = boto3.resource(\"s3\")\n\n    try:\n        bucket = s3.Bucket(bucket_name)\n        bucket.load()\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            raise ValueError(f\"Bucket {bucket_name} does not exist.\")\n        else:\n            raise e\n\n    if key and bucket.objects.filter(Prefix=key):\n        raise ValueError(f\"Bucket {bucket_name} is not empty.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(\"`output_dir` must be an S3 directory.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 directory, got: {output_dir.url}\")\n\n    if append:\n        raise NotImplementedError(\"Appending to an S3 directory is not yet supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting an S3 directory is not yet supported.\")\n\n    if _BOTO3_AVAILABLE:\n        parsed_url = parse.urlparse(output_dir.url)\n        bucket_name = parsed_url.netloc\n        prefix = parsed_url.path.lstrip(\"/\")\n\n        s3 = boto3.resource(\"s3\")\n        bucket = s3.Bucket(bucket_name)\n\n        try:\n            bucket.meta.client.head_bucket(Bucket=bucket_name)\n        except botocore.exceptions.ClientError as e:\n            # If a client error is thrown, then check that it was a 404 error.\n            # If it was a 404 error, then the bucket does not exist.\n            error_code = int(e.response[\"Error\"][\"Code\"])\n            if error_code == 404:\n                raise ValueError(f\"Bucket {bucket_name} does not exist.\")\n            raise ValueError(f\"Error accessing bucket {bucket_name}: {e}\")\n\n        # Check if the bucket is empty\n        bucket_contents = bucket.objects.filter(Prefix=prefix)\n        if any(bucket_contents):\n            raise ValueError(f\"Bucket {bucket_name} is not empty.\")\n\n    else:\n        raise ValueError(\"`output_dir` must be an S3 directory.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"`output_dir` must be a `Dir` with a URL, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be a `Dir` with a URL starting with 's3://', got: {output_dir}\")\n\n    if append or overwrite:\n        raise NotImplementedError(\"`append` and `overwrite` are not implemented yet.\")\n\n    if _BOTO3_AVAILABLE:\n        parsed_url = parse.urlparse(output_dir.url)\n        bucket_name = parsed_url.netloc\n        prefix = parsed_url.path.lstrip(\"/\")\n\n        s3 = boto3.resource(\"s3\")\n        bucket = s3.Bucket(bucket_name)\n\n        for _ in bucket.objects.filter(Prefix=prefix):\n            raise ValueError(f\"The directory {output_dir} is not empty.\")\n    else:\n        raise NotImplementedError(\"`_assert_dir_is_empty` is not implemented yet.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"`output_dir` must be an S3 URL, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 URL, got: {output_dir}\")\n\n    if append:\n        raise NotImplementedError(\"`append` is not yet implemented.\")\n\n    if overwrite:\n        raise NotImplementedError(\"`overwrite` is not yet implemented.\")\n\n    if _BOTO3_AVAILABLE:\n        parsed_url = parse.urlparse(output_dir.url)\n        bucket_name = parsed_url.netloc\n        prefix = parsed_url.path.lstrip(\"/\")\n\n        s3 = boto3.resource(\"s3\")\n        bucket = s3.Bucket(bucket_name)\n        bucket_objects = list(bucket.objects.filter(Prefix=prefix))\n\n        if len(bucket_objects) > 0:\n            raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n    else:\n        raise ImportError(\"`boto3` is not installed. Please install `boto3` to use this function.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"`output_dir` must be an S3 URL, got: {output_dir.url}\")\n\n    if append:\n        raise NotImplementedError(\"Appending to S3 directories is not supported yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting S3 directories is not supported yet.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 URL, got: {output_dir.url}\")\n\n    if _BOTO3_AVAILABLE:\n        s3 = boto3.resource(\"s3\")\n        parsed_url = parse.urlparse(output_dir.url)\n        bucket_name = parsed_url.netloc\n        prefix = parsed_url.path.lstrip(\"/\")\n\n        bucket = s3.Bucket(bucket_name)\n        objects = list(bucket.objects.filter(Prefix=prefix))\n\n        if len(objects) > 0:\n            raise ValueError(f\"`output_dir` must be an empty S3 URL, got: {output_dir.url}\")\n\n    else:\n        raise ImportError(\"`boto3` is not installed. Please install it with `pip install boto3`.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must start with 's3://', got: {output_dir.url}\")\n\n    if not append and not overwrite:\n        if _BOTO3_AVAILABLE:\n            s3 = boto3.resource(\"s3\")\n            bucket_name, key = _parse_s3_url(output_dir.url)\n            bucket = s3.Bucket(bucket_name)\n            objects = list(bucket.objects.filter(Prefix=key))\n            if len(objects) > 0:\n                raise ValueError(f\"`output_dir` must be empty, got: {output_dir.url}\")\n        else:\n            raise ValueError(\n                \"`output_dir` must be empty, but boto3 is not available. \"\n                \"Install boto3 with `pip install boto3` and try again.\"\n            )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(f\"`output_dir` must have a URL, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 URL, got: {output_dir.url}\")\n\n    if append:\n        raise NotImplementedError(\"Appending to a directory is not yet supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting a directory is not yet supported.\")\n\n    bucket_name, key_prefix = parse_s3_url(output_dir.url)\n    s3 = boto3.resource(\"s3\")\n    bucket = s3.Bucket(bucket_name)\n\n    if key_prefix and bucket.objects.filter(Prefix=key_prefix):\n        raise ValueError(f\"The S3 directory {output_dir.url} is not empty.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url:\n        return\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must start with 's3://', got: {output_dir.url}\")\n\n    if append or overwrite:\n        raise ValueError(\"`append` and `overwrite` are not supported yet.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"`boto3` is required for S3 operations. Please install it with `pip install boto3`.\")\n\n    s3_resource = boto3.resource(\"s3\")\n    parsed_url = parse.urlparse(output_dir.url)\n    bucket_name = parsed_url.netloc\n    prefix = parsed_url.path[1:]\n\n    bucket = s3_resource.Bucket(bucket_name)\n    objects = list(bucket.objects.filter(Prefix=prefix))\n\n    if objects:\n        raise ValueError(f\"`output_dir` must be empty, but it contains {len(objects)} objects.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir` object, got: {output_dir}\")\n\n    if output_dir.url is not None and not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 bucket, got: {output_dir.url}\")\n\n    if append or overwrite:\n        raise NotImplementedError(\"Currently, appending or overwriting data is not supported.\")\n\n    if output_dir.url is not None:\n        if not _BOTO3_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"To use the `append` or `overwrite` arguments, you need to install the `boto3` package. \"\n                \"You can install it with `pip install boto3`.\"\n            )\n\n        parsed_url = parse.urlparse(output_dir.url)\n        bucket_name = parsed_url.netloc\n        prefix = parsed_url.path.lstrip(\"/\")\n\n        s3 = boto3.client(\"s3\")\n        try:\n            response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n            if \"Contents\" in response:\n                raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"NoSuchBucket\":\n                raise ValueError(f\"The bucket {bucket_name} does not exist.\")\n            raise\n\n    if output_dir.path is not None:\n        if os.path.exists(output_dir.path):\n            if os.path.isfile(output_dir.path):\n                raise ValueError(f\"The file {output_dir.path} already exists.\")\n            if os.path.isdir(output_dir.path) and os.listdir(output_dir.path):\n                raise ValueError(f\"The directory {output_dir."}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"`output_dir` must be an S3 directory, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 directory, got: {output_dir}\")\n\n    if append:\n        raise NotImplementedError(\"Appending to an S3 directory is not yet supported.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting an S3 directory is not yet supported.\")\n\n    if _BOTO3_AVAILABLE:\n        parsed_url = parse.urlparse(output_dir.url)\n        bucket_name = parsed_url.netloc\n        path = parsed_url.path[1:]\n        s3 = boto3.resource(\"s3\")\n        bucket = s3.Bucket(bucket_name)\n        objects = bucket.objects.filter(Prefix=path)\n        if any(obj.key for obj in objects):\n            raise ValueError(f\"The directory {output_dir} is not empty.\")\n\n    raise NotImplementedError(\"Checking if an S3 directory is empty is not yet supported.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(\"`output_dir` must be a `Dir` with a `url`, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be a `Dir` with a `url` starting with 's3://', got: {output_dir}\")\n\n    if append or overwrite:\n        raise NotImplementedError(\"`append` and `overwrite` are not yet implemented.\")\n\n    if _BOTO3_AVAILABLE:\n        parsed_url = parse.urlparse(output_dir.url)\n        bucket_name = parsed_url.netloc\n        key = parsed_url.path[1:]\n\n        s3 = boto3.resource(\"s3\")\n        bucket = s3.Bucket(bucket_name)\n        objects = list(bucket.objects.filter(Prefix=key))\n\n        if objects:\n            raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n\n    else:\n        raise NotImplementedError(\"S3 support is not available. Please install `boto3`.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"`output_dir` must be a `Dir` with an `url` attribute, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be a `Dir` with an `url` attribute starting with 's3://', got: {output_dir}\")\n\n    if append:\n        raise NotImplementedError(\"Appending to S3 directories is not supported yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwriting S3 directories is not supported yet.\")\n\n    parsed_url = parse.urlparse(output_dir.url)\n    bucket_name = parsed_url.netloc\n    path = parsed_url.path.lstrip(\"/\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"`boto3` is not installed. Please install it to use this function.\")\n\n    s3 = boto3.resource(\"s3\")\n    bucket = s3.Bucket(bucket_name)\n\n    try:\n        bucket.load()\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            raise ValueError(f\"Bucket {bucket_name} does not exist.\")\n        else:\n            raise\n\n    if path != \"\":\n        objects = bucket.objects.filter(Prefix=path)\n        if any(obj.key.endswith(\"/\") for obj in objects):\n            raise ValueError(f\"Bucket {bucket_name} already contains data.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"`output_dir` must have a url, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must have a url starting with 's3://', got: {output_dir.url}\")\n\n    if append:\n        raise NotImplementedError(\"Append mode is not implemented yet.\")\n\n    if overwrite:\n        raise NotImplementedError(\"Overwrite mode is not implemented yet.\")\n\n    s3_client = boto3.client(\"s3\")\n\n    parsed_url = parse.urlparse(output_dir.url)\n    bucket_name = parsed_url.netloc\n    prefix = parsed_url.path.lstrip(\"/\")\n\n    try:\n        s3_client.head_bucket(Bucket=bucket_name)\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            raise ValueError(f\"Bucket {bucket_name} does not exist.\")\n        else:\n            raise e\n\n    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n    if \"Contents\" in response:\n        raise ValueError(f\"Directory {output_dir.url} is not empty.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if output_dir.url is None:\n        if output_dir.path is None:\n            raise ValueError(f\"`output_dir` must be a `Dir` with either a `path` or a `url`, got: {output_dir}\")\n        if not append and not overwrite:\n            if os.path.exists(output_dir.path) and os.listdir(output_dir.path):\n                raise ValueError(f\"`output_dir` must be an empty directory, got: {output_dir}\")\n        return\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be a `Dir` with a `url` starting with 's3://', got: {output_dir}\")\n\n    if not append and not overwrite:\n        parsed_url = parse.urlparse(output_dir.url)\n        bucket_name = parsed_url.netloc\n        path = parsed_url.path.lstrip(\"/\")\n\n        if _BOTO3_AVAILABLE:\n            s3 = boto3.resource(\"s3\")\n            bucket = s3.Bucket(bucket_name)\n            bucket_objects = bucket.objects.filter(Prefix=path)\n            if any(bucket_objects):\n                raise ValueError(f\"`output_dir` must be an empty directory, got: {output_dir}\")\n        else:\n            raise ValueError(f\"`output_dir` must be an empty directory, got: {output_dir}\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The `output_dir` must be a `Dir` object.\")\n\n    if not output_dir.url:\n        raise ValueError(\"The `output_dir` must be an S3 bucket.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The `output_dir` must be an S3 bucket.\")\n\n    if append or overwrite:\n        raise NotImplementedError(\"Currently, appending or overwriting data in the directory is not supported.\")\n\n    bucket, key = parse.urlparse(output_dir.url).netloc, parse.urlparse(output_dir.url).path.lstrip(\"/\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"The `boto3` library is required for this function. Please install it using `pip install boto3`.\"\n        )\n\n    s3 = boto3.client(\"s3\")\n\n    try:\n        response = s3.list_objects_v2(Bucket=bucket, Prefix=key)\n        if response.get(\"KeyCount\") > 0:\n            raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NoSuchBucket\":\n            raise ValueError(f\"The bucket {bucket} does not exist.\")\n        elif e.response[\"Error\"][\"Code\"] == \"AccessDenied\":\n            raise ValueError(f\"You do not have access to the bucket {bucket}.\")\n        else:\n            raise ValueError(f\"An error occurred while checking the directory {output_dir.url}.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if output_dir.url is None:\n        raise ValueError(f\"`output_dir` must be a `Dir` with a url, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be a `Dir` with a url starting with 's3://', got: {output_dir}\")\n\n    if append or overwrite:\n        raise NotImplementedError(\"Currently, appending or overwriting data in the directory is not supported.\")\n\n    s3 = boto3.resource(\"s3\")\n    bucket_name, key = output_dir.url.replace(\"s3://\", \"\").split(\"/\", 1)\n    bucket = s3.Bucket(bucket_name)\n    exists = bucket.objects.filter(Prefix=key).limit(1).count() > 0\n    if exists:\n        raise ValueError(f\"The directory {output_dir} already contains data.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The `output_dir` must be an instance of the `Dir` class.\")\n\n    if not output_dir.url:\n        raise ValueError(\"The `output_dir` must be a URL.\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(\"The `output_dir` must be an S3 URL.\")\n\n    if append or overwrite:\n        raise NotImplementedError(\"Append and overwrite are not implemented yet.\")\n\n    if _BOTO3_AVAILABLE:\n        s3_client = boto3.client(\"s3\")\n        try:\n            s3_client.head_object(Bucket=parse.urlparse(output_dir.url).netloc, Key=output_dir.url.split(\"s3://\")[1])\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                return\n            else:\n                raise e\n\n        raise ValueError(f\"The directory {output_dir.url} is not empty.\")\n\n    raise ValueError(\"The `_assert_dir_is_empty` function is not implemented yet for non-S3 URLs.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url.startswith(\"s3://\"):\n        raise ValueError(f\"`output_dir` must be an S3 bucket, got: {output_dir.url}\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"`boto3` is required to use the `_assert_dir_is_empty` function. Install it with `pip install boto3`.\"\n        )\n\n    if append or overwrite:\n        raise NotImplementedError(\"`append` and `overwrite` are not implemented yet.\")\n\n    bucket_name, key = output_dir.url.split(\"://\")[1].split(\"/\", 1)\n    s3 = boto3.resource(\"s3\")\n\n    try:\n        bucket = s3.Bucket(bucket_name)\n        objects = list(bucket.objects.filter(Prefix=key))\n        if objects:\n            raise ValueError(f\"The S3 bucket {output_dir.url} already contains data. Please use `append` or `overwrite`.\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NoSuchBucket\":\n            raise ValueError(f\"The S3 bucket {output_dir.url} does not exist.\")\n        else:\n            raise e\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_is_empty", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"`output_dir` must be a `Dir`, got: {output_dir}\")\n\n    if not output_dir.url:\n        raise ValueError(\"`output_dir` must be an S3 path.\")\n\n    if output_dir.url.startswith(\"s3://\"):\n        url = parse.urlparse(output_dir.url)\n        bucket_name = url.netloc\n        prefix = url.path[1:]\n\n        if append or overwrite:\n            raise NotImplementedError(\"`append` and `overwrite` are not yet supported for S3 paths.\")\n\n        s3 = boto3.resource(\"s3\")\n\n        try:\n            bucket = s3.Bucket(bucket_name)\n            objects = list(bucket.objects.filter(Prefix=prefix))\n\n            if objects:\n                raise ValueError(\n                    f\"The bucket {bucket_name} already contains data. Please use `append` or `overwrite`.\"\n                )\n\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"NoSuchBucket\":\n                raise ValueError(f\"The bucket {bucket_name} does not exist.\")\n            else:\n                raise e\n\n    else:\n        raise ValueError(\"`output_dir` must be an S3 path.\")\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].endswith(\"index.json\"):\n                return\n\n        # We aren't alloweing to add more data\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # We aren't alloweing to add more data\n    raise RuntimeError(\n        f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n        \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n    )"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    try:\n        s3.get_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n            return\n        raise e\n\n    # Delete all objects\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\n            \"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]],\n        },\n    )"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].endswith(\"index.json\"):\n                return\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # Delete all objects in the bucket\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\n            \"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]],\n        },\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    try:\n        s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\")\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            # The object does not exist.\n            pass\n        else:\n            # Something else has gone wrong.\n            raise\n\n    # Delete all objects in the prefix\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\n            \"Objects\": [{\"Key\": obj[\"Key\"]} for obj"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # Check if the index.json file exists\n    index_file_key = obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\"\n    try:\n        s3.head_object(Bucket=obj.netloc, Key=index_file_key)\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            # Index file does not exist, delete all objects in the prefix\n            objects = s3.list_objects_v2(Bucket=obj.netloc, Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\")\n            if \"Contents\" in objects:\n                for obj in objects[\"Contents\"]:\n                    s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n            return\n        else:\n            raise e\n\n    # Index file exists, raise an"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n        for object in objects[\"Contents\"]:\n            if object[\"Key\"].endswith(\"index.json\"):\n                return\n\n    raise RuntimeError(\n        f\"The provided output_dir `{output_dir.path}` is an empty S3 bucket.\"\n        \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n    )"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] == 0:\n        return\n\n    if \"Contents\" not in objects:\n        return\n\n    for object in objects[\"Contents\"]:\n        if object[\"Key\"].endswith(\"index.json\"):\n            raise ValueError(\n                f\"The provided output_dir `{output_dir.path}` already contains an index file.\"\n                \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n            )\n\n    # Delete all objects in the bucket\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] == 0:\n        return\n\n    if \"Contents\" not in objects:\n        return\n\n    for object in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj.netloc, Key=object[\"Key\"])\n\n    # Delete all objects in the bucket\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] == 0:\n        return\n\n   "}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    try:\n        s3.get_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n            # The object does not exist, so we can continue\n            return\n        else:\n            # Something else has gone wrong.\n            raise e\n\n    # The object exists, so we need to delete all objects in the bucket\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\n            \"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + obj[\"Key\"]} for obj in objects[\"Contents\"]]\n        },\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # Check if the index file exists\n    try:\n        s3.get_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n            # The index file does not exist, so we can proceed\n            return\n        else:\n            # Some other error occurred, so we raise the exception\n            raise e\n\n    # If we reach this point, it means the index file exists\n    # We need to delete all objects within the specified prefix in the bucket\n    response = s3.list_objects_v2(Bucket=obj.netloc, Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\")\n    for obj in response[\"Contents\"]:\n        s3.delete_object(Bucket=obj.netloc, Key=obj[\"Key\"])\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    try:\n        s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"404\":\n            print(f\"The provided output_dir `{output_dir.path}` does not contain an index.json file.\")\n            return\n        else:\n            raise e\n\n    print(f\"The provided output_dir `{output_dir.path}` already contains an index.json file.\")\n\n    # Delete all objects within the specified prefix in the bucket\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\n            \"Objects\": [\n                {\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + obj[\"Key\"]}\n                for obj in s3.list_objects(Bucket=obj.netloc, Prefix"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].endswith(\"index.json\"):\n                raise RuntimeError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index file and datasets are meant to be immutable.\"\n                    \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n                )\n\n    if \"KeyCount\" in objects and objects[\"KeyCount\"] > 0:\n        print(\n            \"The provided output_dir already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n        print(\"Deleting all objects within the specified prefix...\")\n\n        # Delete all objects within the specified prefix\n        s3.delete_objects(\n            Bucket=obj.netloc,\n            Delete={\n                \"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]],\n                \"Quiet\": True,\n            },\n        )\n\n        # Wait for the objects to be deleted\n        while True:\n            objects = s3.list_objects_v2(\n                Bucket=obj.netloc,\n                Delimiter=\"/\",\n                Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    if \"Contents\" in objects:\n        for obj in objects[\"Contents\"]:\n            if obj[\"Key\"].endswith(\"index.json\"):\n                raise ValueError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index file. Please delete it first.\"\n                )\n\n    if \"CommonPrefixes\" in objects:\n        for obj in objects[\"CommonPrefixes\"]:\n            if obj[\"Prefix\"].endswith(\"index.json\"):\n                raise ValueError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index file. Please delete it first.\"\n                )\n\n    # If there is no index file, we delete all objects within the specified prefix in the bucket.\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if \"Contents"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    try:\n        s3.get_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/index.json\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n            raise RuntimeError(\n                f\"The provided output_dir `{output_dir.path}` doesn't contain an index file. Please create one before adding data.\"\n            )\n        raise e\n\n    # Delete all objects in the bucket\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\n            \"Objects\": [{\"Key\": obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\" + o[\"Key\"].split(\"/\")[-1]} for o in objects[\"Contents\"]],\n            \"Quiet\": True,\n        },\n    )"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    try:\n        s3.get_object(Bucket=obj.netloc, Key=f\"{obj.path.lstrip('/')}/index.json\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n            return\n\n    raise RuntimeError(\n        f\"The provided output_dir `{output_dir.path}` already contains an index file.\"\n        \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # We are looking for an index file\n    if any(key[\"Key\"].endswith(\"index.json\") for key in objects[\"Contents\"]):\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file. It's not possible to add more data to an existing dataset.\"\n        )\n\n    # We are deleting all objects within the prefix\n    for key in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj.netloc, Key=key[\"Key\"])\n\n    # We are deleting all objects within the prefix\n    for key in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj.netloc, Key=key[\"Key\"])"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] == 0:\n        return\n\n    if \"Contents\" in objects:\n        for object in objects[\"Contents\"]:\n            if object[\"Key\"].endswith(\"index.json\"):\n                raise RuntimeError(\n                    f\"The provided output_dir `{output_dir.path}` already contains an index file. \"\n                    \"HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n                )\n\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\n            \"Objects\": [{\"Key\": object[\"Key\"]} for object in objects[\"Contents\"]],\n        },\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    try:\n        s3.get_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\") + \"/index.json\")\n    except botocore.exceptions.ClientError as e:\n        if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n            return\n        else:\n            raise e\n\n    # We are deleting all objects in the folder\n    # TODO: Add support for `append` and `overwrite`.\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]]},\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index file. \"\n            \"HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # Delete all objects in the bucket\n    s3.delete_objects(\n        Bucket=obj.netloc,\n        Delete={\"Objects\": [{\"Key\": obj[\"Key\"]} for obj in objects[\"Contents\"]]},\n    )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    # We aren't alloweing to add more data\n    # TODO: Add support for `append` and `overwrite`.\n    if objects[\"KeyCount\"] > 0:\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains data and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n"}
{"namespace": "litdata.streaming.resolver._assert_dir_has_index_file", "completion": "    if not isinstance(output_dir, Dir):\n        raise ValueError(\"The provided output_dir isn't a Dir Object.\")\n\n    if output_dir.url is None:\n        return\n\n    obj = parse.urlparse(output_dir.url)\n\n    if obj.scheme != \"s3\":\n        raise ValueError(f\"The provided folder should start with s3://. Found {output_dir.path}.\")\n\n    s3 = boto3.client(\"s3\")\n\n    objects = s3.list_objects_v2(\n        Bucket=obj.netloc,\n        Delimiter=\"/\",\n        Prefix=obj.path.lstrip(\"/\").rstrip(\"/\") + \"/\",\n    )\n\n    if objects[\"KeyCount\"] == 0:\n        return\n\n    if any(obj[\"Key\"].endswith(\"index.json\") for obj in objects[\"Contents\"]):\n        raise RuntimeError(\n            f\"The provided output_dir `{output_dir.path}` already contains an index.json file and datasets are meant to be immutable.\"\n            \" HINT: Did you consider changing the `output_dir` with your own versioning as a suffix?\"\n        )\n\n    # Delete all objects in the bucket\n    for obj in objects[\"Contents\"]:\n        s3.delete_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\").rstrip(\"/\"))\n\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        if node_rank is None:\n            while not self.filled:\n                sleep(1)\n            return\n\n        if node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        if not self.filled:\n            while not self.filled:\n                sleep(1)\n\n        chunks_info: List[Dict[str, Any]] = []\n        for rank in range(num_workers):\n            with open(os.path.join(self._cache_dir, f\"{rank}.{_INDEX_FILENAME}\")) as f:\n                chunks_info.extend(json.load(f)[\"chunks\"])\n\n        config = self.get_config()\n        with open(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": chunks_info, \"config\": config}, out, sort_keys=True)\n\n        for rank in range(num_workers):\n            os.remove(os.path.join(self._cache_dir, f\"{rank}.{_INDEX_FILENAME}\"))"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        if node_rank is not None and node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        while True:\n            files = os.listdir(self._cache_dir)\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        chunks_info: List[Dict[str, Any]] = []\n        for index_file in index_files:\n            with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                chunks_info.extend(json.load(f)[\"chunks\"])\n\n        chunks_info = sorted(chunks_info, key=lambda x: x[\"chunk_index\"])\n\n        for i in range(len(chunks_info)):\n            chunks_info[i][\"chunk_index\"] = i\n\n        config = self.get_config()\n        with open(os.path.join(self._cache_dir, f\"{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": chunks_info, \"config\": config}, out, sort_keys=True)\n\n        for index_file in index_files:\n            os.remove(os.path.join(self._cache_dir, index_file))\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        if node_rank is not None and node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")):\n                sleep(0.1)\n            return\n\n        while True:\n            files = os.listdir(self._cache_dir)\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(0.1)\n\n        merged_index_file = os.path.join(self._cache_dir, f\"{_INDEX_FILENAME}\")\n        with open(merged_index_file, \"w\") as out:\n            chunks = []\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    chunks.extend(json.load(f)[\"chunks\"])\n            json.dump({\"chunks\": chunks}, out, sort_keys=True)\n\n        for index_file in index_files:\n            os.remove(os.path.join(self._cache_dir, index_file))\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            worker_env = _WorkerEnv.detect()\n            node_rank = worker_env.rank\n\n        if node_rank == 0:\n            # Wait for all parts to be available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(0.1)\n\n            # Merge the parts\n            chunks = []\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    chunks.extend(json.load(f)[\"chunks\"])\n\n            # Write down the index file\n            filepath = os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")\n            config = self.get_config()\n            with open(filepath, \"w\") as out:\n                json.dump({\"chunks\": chunks, \"config\": config}, out, sort_keys=True)\n        else:\n            # Wait until the merged index file is available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(0.1)"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n        if node_rank == 0:\n            # Wait until all parts are available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(1)\n\n            # Merge all parts\n            chunks_info = []\n            for file in index_files:\n                with open(os.path.join(self._cache_dir, file), \"r\") as f:\n                    chunks_info.extend(json.load(f)[\"chunks\"])\n\n            # Write down the index file\n            filepath = os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")\n            with open(filepath, \"w\") as out:\n                json.dump({\"chunks\": chunks_info, \"config\": self.get_config()}, out, sort_keys=True)\n\n        else:\n            # Wait until the merged index file is available\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == 1:\n                    break\n                sleep(1)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        if node_rank is not None and node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, \"0.index.json\")):\n                sleep(0.1)\n            return\n\n        while True:\n            files = os.listdir(self._cache_dir)\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(0.1)\n\n        index_files = sorted(index_files)\n        chunks: List[Dict[str, Any]] = []\n        for filepath in index_files:\n            with open(os.path.join(self._cache_dir, filepath)) as inp:\n                index = json.load(inp)\n                chunks.extend(index[\"chunks\"])\n\n        with open(os.path.join(self._cache_dir, \"0.index.json\"), \"w\") as out:\n            json.dump({\"chunks\": chunks}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self._distributed_env.world_size == 1:\n            return\n\n        if node_rank is None:\n            worker_env = _WorkerEnv.detect()\n            node_rank = worker_env.rank\n\n        while True:\n            files = os.listdir(self._cache_dir)\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        if node_rank == 0:\n            index_files = sorted(index_files)\n            merged_index_file = os.path.join(self._cache_dir, \"index.json\")\n            merged_index = {\"chunks\": []}\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    index = json.load(f)\n                    merged_index[\"chunks\"].extend(index[\"chunks\"])\n            with open(merged_index_file, \"w\") as f:\n                json.dump(merged_index, f, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        # Wait until all parts are available\n        while True:\n            if node_rank == 0:\n                index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n            else:\n                while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                    sleep(1)\n                break\n\n        # Only the master node merges the index files\n        if node_rank == 0:\n            # Read all index files\n            chunks_info = []\n            for i in range(num_workers):\n                with open(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\"), \"r\") as f:\n                    chunks_info.extend(json.load(f)[\"chunks\"])\n\n            # Write the merged index file\n            with open(os.path.join(self._cache_dir, f\"{_INDEX_FILENAME}\"), \"w\") as f:\n                json.dump({\"chunks\": chunks_info}, f)\n\n            # Remove the individual index files\n            for i in range(num_workers):\n                os.remove(os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\"))\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Check if the merge operation should be performed\n        if self._distributed_env.rank != 0:\n            # Wait until the merged index file is available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{self._distributed_env.rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Wait until all parts are available\n        while True:\n            files = os.listdir(self._cache_dir)\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        # Merge the index files\n        chunks_info: List[Dict[str, Any]] = []\n        for filename in index_files:\n            with open(os.path.join(self._cache_dir, filename), \"r\") as f:\n                index = json.load(f)\n            chunks_info.extend(index[\"chunks\"])\n\n        # Sort the chunks by filename\n        chunks_info.sort(key=lambda x: x[\"filename\"])\n\n        # Write the merged index file\n        with open(os.path.join(self._cache_dir, f\"{self._distributed_env.rank}.{_INDEX_FILENAME}\"), \"w\") as f:\n            json.dump({\"chunks\": chunks_info, \"config\": index[\"config\"]}, f, sort_keys=True)\n\n        # Remove the individual index files\n        for filename in index_files:\n            os.remove(os.path.join(self._cache_dir, filename))\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Determine the rank of the node if not provided\n        if node_rank is None:\n            node_rank = self.rank\n\n        # Wait until all parts of the index are available\n        while True:\n            files = os.listdir(self._cache_dir)\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        # If this is not the master node (rank 0), wait until the merged index file is available\n        if node_rank != 0:\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers + 1:\n                    break\n                sleep(1)\n\n        # If this is the master node (rank 0), proceed with the merging process\n        if node_rank == 0:\n            # Load the index parts from the individual files\n            index_parts = []\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    index_parts.append(json.load(f))\n\n            # Merge the index parts into a single unified index\n            merged_index = {}\n            for index_part in index_parts:\n                for key, value in index_part.items():\n                    if key not in merged_index:\n                        merged_index[key] = value\n                    else:\n                        merged_index[key] += value\n\n            # Write the merged index to a new file\n            with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as f:\n                json.dump(merged_index, f, sort_keys=True)\n\n            # Remove the individual index files\n            for index_file in index_files:\n                os.remove(os.path.join(self._cache_dir, index_file))"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait until all parts are available\n        while True:\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        # If the current node is not the master node (rank 0), wait until the merged index file is available\n        if node_rank is not None and node_rank != 0:\n            while True:\n                merged_index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(\"_merged.json\")]\n                if len(merged_index_files) > 0:\n                    break\n                sleep(1)\n\n        # Merge the index files\n        if node_rank is None or node_rank == 0:\n            merged_index = []\n            for index_file in index_files:\n                with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                    index = json.load(f)\n                    merged_index.extend(index[\"chunks\"])\n\n            # Sort the merged index by the chunk index\n            merged_index = sorted(merged_index, key=lambda x: x[\"chunk_index\"])\n\n            # Write the merged index to a file\n            with open(os.path.join(self._cache_dir, \"merged.json\"), \"w\") as f:\n                json.dump(merged_index, f)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait until all parts are available\n        while True:\n            files = os.listdir(self._cache_dir)\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(0.1)\n\n        # Only the master node (rank 0) is responsible for the merge\n        if node_rank is not None and node_rank != 0:\n            while True:\n                files = os.listdir(self._cache_dir)\n                merged_index_files = [f for f in files if f.endswith(f\"0.{_INDEX_FILENAME}\")]\n                if len(merged_index_files) == 1:\n                    break\n                sleep(0.1)\n            return\n\n        # Merge all the index files into a single one\n        index_files = [os.path.join(self._cache_dir, f) for f in index_files]\n        index_files = sorted(index_files)\n        merged_index_file = os.path.join(self._cache_dir, f\"0.{_INDEX_FILENAME}\")\n        with open(merged_index_file, \"w\") as out:\n            out.write(\"[\")\n            for i, index_file in enumerate(index_files):\n                with open(index_file, \"r\") as f:\n                    if i > 0:\n                        out.write(\",\")\n                    out.write(f.read())\n            out.write(\"]\")\n\n        # Remove all the individual index files\n        for index_file in index_files:\n            os.remove(index_file)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait until all index parts are available\n        while True:\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(0.1)\n\n        # Only the master node (rank 0) performs the merge operation\n        if node_rank is not None and node_rank != 0:\n            while True:\n                merged_index_file = os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")\n                if os.path.exists(merged_index_file):\n                    break\n                sleep(0.1)\n            return\n\n        # Merge all index parts into a single index file\n        chunks_info = []\n        for filepath in index_files:\n            with open(os.path.join(self._cache_dir, filepath), \"r\") as f:\n                index_data = json.load(f)\n                chunks_info.extend(index_data[\"chunks\"])\n\n        # Write the merged index file\n        config = self.get_config()\n        merged_index_file = os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")\n        with open(merged_index_file, \"w\") as out:\n            json.dump({\"chunks\": chunks_info, \"config\": config}, out, sort_keys=True)\n\n        # Remove individual index parts\n        for filepath in index_files:\n            os.remove(os.path.join(self._cache_dir, filepath))\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n\n        # Wait until all parts are available\n        while True:\n            files = os.listdir(self._cache_dir)\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        # If not master node, wait until merged index file is available\n        if node_rank != 0:\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == 1:\n                    break\n                sleep(1)\n\n        # Merge index files\n        index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n        index_files = sorted(index_files, key=lambda x: int(x.split(\".\")[0]))\n\n        # Load index files\n        chunks_info = []\n        for index_file in index_files:\n            with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                index = json.load(f)\n                chunks_info.extend(index[\"chunks\"])\n\n        # Write merged index file\n        with open(os.path.join(self._cache_dir, _INDEX_FILENAME), \"w\") as f:\n            json.dump({\"chunks\": chunks_info, \"config\": index[\"config\"]}, f, sort_keys=True)\n\n        # Delete individual index files\n        for index_file in index_files:\n            os.remove(os.path.join(self._cache_dir, index_file))\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if self._distributed_env.world_size == 1:\n            return\n\n        while not self.filled:\n            sleep(0.1)\n\n        if node_rank is None:\n            node_rank = self._distributed_env.global_rank\n\n        if node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{self._distributed_env.global_rank}.{_INDEX_FILENAME}\")):\n                sleep(0.1)\n            return\n\n        files = [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n\n        while len(files) < num_workers:\n            sleep(0.1)\n            files = [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n\n        chunks: List[Dict[str, Any]] = []\n        config: Optional[Dict[str, Any]] = None\n        for filepath in files:\n            with open(filepath, \"r\") as f:\n                data = json.load(f)\n            chunks.extend(data[\"chunks\"])\n            if config is None:\n                config = data[\"config\"]\n\n        chunks = sorted(chunks, key=lambda x: x[\"chunk_index\"])\n        with open(os.path.join(self._cache_dir, f\"{self._distributed_env.global_rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": chunks, \"config\": config}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = get_worker_rank()\n        if node_rank is None:\n            raise RuntimeError(\"Cannot determine node rank. Please provide a node rank or ensure the rank is set in the environment.\")\n\n        while True:\n            index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(1)\n\n        if node_rank != 0:\n            while True:\n                merged_index_file = os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")\n                if os.path.exists(merged_index_file):\n                    break\n                sleep(1)\n            return\n\n        # Merge the index files\n        chunks = []\n        for index_file in index_files:\n            with open(os.path.join(self._cache_dir, index_file), \"r\") as f:\n                chunks.extend(json.load(f)[\"chunks\"])\n\n        # Sort the chunks by their index\n        chunks = sorted(chunks, key=lambda x: x[\"chunk_index\"])\n\n        # Write the merged index file\n        merged_index_file = os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")\n        with open(merged_index_file, \"w\") as f:\n            json.dump({\"chunks\": chunks}, f, sort_keys=True)\n\n        # Remove the individual index files\n        for index_file in index_files:\n            os.remove(os.path.join(self._cache_dir, index_file))\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            worker_env = _WorkerEnv.detect()\n            node_rank = worker_env.rank\n\n        if node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Wait until all parts are available\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(1)\n\n        # Merge all parts\n        index_files = [os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\") for i in range(num_workers)]\n        merged_index = self._merge_index_files(index_files)\n\n        # Write merged index to file\n        with open(os.path.join(self._cache_dir, f\"{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump(merged_index, out, sort_keys=True)\n\n        # Remove individual index files\n        for filepath in index_files:\n            os.remove(filepath)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Check if the current node is the master node (rank 0)\n        if node_rank is None:\n            node_rank = self.rank\n        if node_rank != 0:\n            # If the current node is not the master node (rank != 0), wait until the merged index file is available\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\")):\n                sleep(1)\n            return\n\n        # Wait until all index parts are available\n        while True:\n            # Check if all index parts are available\n            index_parts = [\n                os.path.join(self._cache_dir, f\"{i}.{_INDEX_FILENAME}\") for i in range(num_workers)\n            ]\n            if all(os.path.exists(part) for part in index_parts):\n                break\n            sleep(1)\n\n        # Merge the index parts\n        merged_index_parts = []\n        for part in index_parts:\n            with open(part, \"r\") as f:\n                merged_index_parts.extend(json.load(f)[\"chunks\"])\n\n        # Write the merged index to a file\n        with open(os.path.join(self._cache_dir, f\"{node_rank}.{_INDEX_FILENAME}\"), \"w\") as out:\n            json.dump({\"chunks\": merged_index_parts, \"config\": self.get_config()}, out, sort_keys=True)\n\n        # Remove the individual index parts\n        for part in index_parts:\n            os.remove(part)\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        if node_rank is None:\n            node_rank = os.getenv(\"DATA_OPTIMIZER_NODE_RANK\", None)\n            if node_rank is not None:\n                node_rank = int(node_rank)\n\n        if node_rank is None:\n            node_rank = 0\n\n        if node_rank != 0:\n            while not os.path.exists(os.path.join(self._cache_dir, f\"{self.rank}.{_INDEX_FILENAME}\")):\n                sleep(0.01)\n            return\n\n        while len(os.listdir(self._cache_dir)) < num_workers:\n            sleep(0.01)\n\n        index_files = [os.path.join(self._cache_dir, f) for f in os.listdir(self._cache_dir) if f.endswith(_INDEX_FILENAME)]\n\n        chunks_info: List[Dict[str, Any]] = []\n        for index_file in index_files:\n            with open(index_file) as f:\n                index_data = json.load(f)\n            chunks_info.extend(index_data[\"chunks\"])\n\n        config = index_data[\"config\"]\n\n        self._data_format = config[\"data_format\"]\n        self._data_spec = treespec_dumps(config[\"data_spec\"]) if config[\"data_spec\"] else None\n\n        self._chunks_info = chunks_info\n        self.write_chunks_index()\n"}
{"namespace": "litdata.streaming.writer.BinaryWriter.merge", "completion": "        # Wait until all parts of the index are available\n        while True:\n            files = os.listdir(self._cache_dir)\n            index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n            if len(index_files) == num_workers:\n                break\n            sleep(0.1)\n\n        # Merge only if it's the master node (rank 0)\n        if node_rank is not None and node_rank != 0:\n            while True:\n                files = os.listdir(self._cache_dir)\n                index_files = [f for f in files if f.endswith(_INDEX_FILENAME)]\n                if len(index_files) == num_workers:\n                    break\n                sleep(0.1)\n\n        # Merge all the index files into a single index file\n        index_files = sorted(index_files)\n        chunks_info: List[Dict[str, Any]] = []\n        for index_file in index_files:\n            with open(os.path.join(self._cache_dir, index_file)) as f:\n                data = json.load(f)\n                chunks_info.extend(data[\"chunks\"])\n\n        # Write down the merged index file\n        filepath = os.path.join(self._cache_dir, _INDEX_FILENAME)\n        with open(filepath, \"w\") as out:\n            json.dump({\"chunks\": chunks_info}, out, sort_keys=True)\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is required to run this operator. Please install it with `pip install lightning`.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The boto3 library is required to run this operator. Please install it with `pip install boto3`.\")\n\n    if machine is None:\n        machine = Machine(\n            name=\"default\",\n            accelerators=\"auto\",\n            cpu_count=\"auto\",\n            memory=\"auto\",\n            disk_size=\"auto\",\n            image=\"lightning/base:latest\",\n            shared_memory_size=\"auto\",\n        )\n\n    if command is None:\n        command = \" \".join(\n            [\n                \"python\",\n                \"-m\",\n                \"lightning\",\n                \"run\",\n                \"app\",\n                f\"{os.getcwd()}\",\n                \"--cloud\",\n                \"--cluster-id\",\n                os.getenv(\"LIGHTNING_CLUSTER_ID\", \"\"),\n                \"--cluster-name\",\n                os.getenv(\"LIGHTNING_CLUSTER_NAME\", \"\"),\n                \"--cluster-region\",\n                os.getenv(\"LIGHTNING_CLUSTER_REGION\", \"\"),\n                \"--cluster-provider\",\n                os.getenv(\"LIGHTNING_CLUSTER_PROVIDER\", \"\"),\n                \"--cluster-status\",\n                os.getenv(\"LIGHTNING_CLUSTER_STATUS\", \"\"),\n                \"--cluster-type\",\n                os.getenv(\"LIGHTNING_CLUSTER_TYPE\", \"\"),\n                \"--cluster-availability\",\n                os.getenv(\"LIGHTNING_CLUSTER_AVAILABILITY\", \"\"),\n                \"--cluster-cost-savings\",\n                os.getenv(\"LIGHTNING_CLUSTER_COST_SAVINGS\", \"\"),\n                \"--cluster-scale\",\n                os.getenv(\"LIGHTNING_CL"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The `lightning_sdk` is required to execute the operator remotely. Please install the `lightning_sdk` package.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The `boto3` is required to execute the operator remotely. Please install the `boto3` package.\"\n        )\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    cloud_space_id = os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None)\n\n    if cluster_id is None:\n        raise RuntimeError(\"The `cluster_id` couldn't be found from the environement variables.\")\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    if cloud_space_id is None:\n        raise RuntimeError(\"The `cloud_space_id` couldn't be found from the environement variables.\")\n\n    client = LightningClient(max_tries=2)\n\n    # Get the current working directory\n    cwd = os.getcwd()\n\n    # Get the current environment variables\n    env_variables = os.environ.copy()\n\n    # Get the current command\n    command = command if command else \" \".join(sys.argv)\n\n    # Get the machine configuration\n    machine = machine if machine else Machine()\n\n    # Get the cloud space\n    cloud_space = client.cloud_space_service_get_cloud_space(\n        project_id=project_id,\n        cluster_id=cluster_id,\n        cloudspace_id=cloud_space_id,\n    )\n\n    # Get the cluster\n    cluster = client.cluster_service_get_cluster(project_id=project_"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The `lightning_sdk` package is required to execute this operator remotely.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The `boto3` package is required to execute this operator remotely.\")\n\n    if machine is None:\n        machine = Machine(\n            name=\"default\",\n            accelerators=\"auto\",\n            cpu_count=1,\n            memory=1000,\n            disk_size=1000,\n        )\n\n    if command is None:\n        command = f\"cd {os.getcwd()}; {sys.executable} -m lightning run data_prep --name {name}\"\n        for k, v in os.environ.items():\n            command += f\" --env {k}={v}\"\n\n    client = Studio(\n        api_key=os.getenv(\"LIGHTNING_CLOUD_API_KEY\", \"\"),\n        api_url=_get_lightning_cloud_url(),\n    )\n\n    job = client.create_job(\n        name=name,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n    )\n\n    print(f\"Job URL: {job.url}\")\n\n    while job.status.value != \"succeeded\":\n        sleep(1)\n        job.refresh()\n        if job.status.value in (\"failed\", \"stopped\"):\n            raise RuntimeError(f\"Job {name} failed with status {job.status.value}\")\n\n    print(f\"Job {name} succeeded\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The Lightning SDK is required to execute this operator remotely. \"\n            \"Please install the SDK by running `pip install lightning`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"The boto3 library is required to execute this operator remotely. \"\n            \"Please install the library by running `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine(\n            name=\"default\",\n            accelerators=\"auto\",\n            cpu_count=1,\n            memory=2000,\n            disk_size=1000,\n        )\n\n    if command is None:\n        command = f\"cd {os.getcwd()}; {sys.executable} -m lightning run data {name} --cloud\"\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    cloud_space_id = os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None)\n\n    if cluster_id is None:\n        raise RuntimeError(\"The `cluster_id` couldn't be found from the environement variables.\")\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    if cloud_space_id is None:\n        raise RuntimeError(\"The `cloud_space_id` couldn't be found from the environement variables.\")\n\n    client = LightningClient(max_tries=2)\n\n    # TODO: This should be a method in the SDK.\n    response = client.cloud_space_service_create_cloud_space_jobs(\n        project_id=project_id,\n        cluster_id=cluster_id,\n        cloud_space_id="}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise Exception(\"The Lightning SDK is not available in your environment.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise Exception(\"The boto3 SDK is not available in your environment.\")\n\n    if machine is None:\n        machine = Machine(num_nodes=num_nodes)\n\n    if command is None:\n        command = \" \".join(sys.argv)\n\n    # TODO: Add a check to see if the job already exists\n\n    # Create a job\n    job = Studio(\n        name=name,\n        machine=machine,\n        command=command,\n        env=os.environ,\n        working_dir=os.getcwd(),\n    )\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n\n    if cluster_id is None:\n        raise RuntimeError(\"The `cluster_id` couldn't be found from the environement variables.\")\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n\n    if cluster_id is None:\n        raise RuntimeError(\"The `cluster_id` couldn't be found from the environement variables.\")\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\n            \"The `lightning_sdk` package is required for the `_execute` function. Please install it with `pip install lightning-sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\n            \"The `boto3` package is required for the `_execute` function. Please install it with `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine(\n            name=\"default\",\n            accelerator=\"cpu\",\n            instance_size=\"large\",\n            num_cpus=num_nodes,\n            num_gpus=0,\n            num_memory_cpus=0,\n        )\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {' '.join([f'{k}={v}' for k, v in os.environ.items()])} && {sys.executable} -m {__name__}\"\n\n    studio = Studio(\n        name=name,\n        machine=machine,\n        command=command,\n        cloud_compute=\"default\",\n        cloud_build_config=None,\n        cloud_build_secret=None,\n        cloud_build_timeout=600,\n        cloud_build_idle_timeout=1800,\n        cloud_build_mount_cloudspace=True,\n        cloud_build_mount_dataset=True,\n        cloud_build_mount_workspace=True,\n        cloud_build_mount_ssh_keys=True,\n        cloud_build_mount_code=True,\n        cloud_build_mount_credentials=True,\n        cloud_build_mount_output=True,\n        cloud_build_mount_artifacts=True,\n        cloud_build_mount_ssh_keys_from=None,\n        cloud_build_mount_code_from=None,\n        cloud_build_mount_credentials_from=None,\n        cloud_build_mount_output_from=None,\n       "}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise Exception(\"The `lightning_sdk` package is required to run this operator.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise Exception(\"The `boto3` package is required to run this operator.\")\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    cloud_space_id = os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None)\n\n    if cluster_id is None:\n        raise RuntimeError(\"The `cluster_id` couldn't be found from the environement variables.\")\n\n    if project_id is None:\n        raise RuntimeError(\"The `project_id` couldn't be found from the environement variables.\")\n\n    if cloud_space_id is None:\n        raise RuntimeError(\"The `cloud_space_id` couldn't be found from the environement variables.\")\n\n    if machine is None:\n        machine = Machine(\n            machine_type=\"L\",\n            accelerators=\"V100\",\n            disk_size=100,\n            container_name=\"lightning\",\n            shared_memory_size=\"10G\",\n        )\n\n    if command is None:\n        command = \" \".join(\n            [\n                \"bash -c 'cd {0} && {1} {2}'\".format(\n                    os.getcwd(),\n                    sys.executable,\n                    \" \".join(sys.argv),\n                )\n            ]\n        )\n\n    # Create the job\n    job = Studio().create_job(\n        name=name,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n        cluster_id=cluster_id,\n        project_id=project_id,\n        cloud_space_id=cloud_space_id,\n    )\n\n   "}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The `lightning_sdk` is not installed. Please install it to use this function.\")\n\n    if machine is None:\n        machine = Machine(\n            name=\"data-preparation-machine\",\n            accelerators=\"auto\",\n            cpu_count=1,\n            gpu_count=1,\n            memory=\"10G\",\n            disk_size=\"10G\",\n            image=\"lightning/data-preparation-machine:latest\",\n        )\n\n    if command is None:\n        command = \" \".join(\n            [\n                \"cd\",\n                os.getcwd(),\n                \"&&\",\n                \"export\",\n                \">\",\n                \"env.txt\",\n                \"&&\",\n                \"python\",\n                \"-m\",\n                \"lightning_datasets\",\n                \"--name\",\n                name,\n                \"--num_nodes\",\n                str(num_nodes),\n            ]\n        )\n\n    print(\"Creating a data preparation machine job...\")\n    job = Studio().run(command=command, machine=machine)\n\n    print(f\"Job URL: {_get_lightning_cloud_url()}/{job.id}\")\n\n    while job.status.value != \"succeeded\" and job.status.value != \"failed\":\n        sleep(1)\n        job = Studio().get_job(job_id=job.id)\n\n    if job.status.value == \"succeeded\":\n        print(\"Job succeeded.\")\n    else:\n        raise RuntimeError(\"Job failed.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The lightning sdk is not available in this environment.\")\n\n    if machine is None:\n        machine = Machine(num_nodes=num_nodes)\n\n    if command is None:\n        command = \" \".join(sys.argv)\n        for key, value in os.environ.items():\n            command += f\" {key}={value}\"\n\n    # TODO: add support for other types of machines\n    if machine.accelerators is not None:\n        raise NotImplementedError(\"Accelerators are not supported yet.\")\n\n    if machine.instance_type is None:\n        raise ValueError(\"The machine instance type is not set.\")\n\n    if machine.disk_size is None:\n        raise ValueError(\"The disk size is not set.\")\n\n    if machine.image is None:\n        raise ValueError(\"The machine image is not set.\")\n\n    if machine.spot is None:\n        raise ValueError(\"The machine spot is not set.\")\n\n    if machine.cloud_compute is None:\n        raise ValueError(\"The machine cloud compute is not set.\")\n\n    if machine.cloud_compute.name is None:\n        raise ValueError(\"The machine cloud compute name is not set.\")\n\n    if machine.cloud_compute.region is None:\n        raise ValueError(\"The machine cloud compute region is not set.\")\n\n    if machine.cloud_compute.availability_zone is None:\n        raise ValueError(\"The machine cloud compute availability zone is not set.\")\n\n    if machine.cloud_compute.instance_type is None:\n        raise ValueError(\"The machine cloud compute instance type is not set.\")\n\n    if machine.cloud_compute.spot is None:\n        raise ValueError(\"The machine cloud compute spot is not set.\")\n\n    if machine.cloud_compute.image is None:\n        raise ValueError(\"The machine cloud compute image is not set.\")\n\n    if machine.cloud_compute.disk_size is None:\n        raise ValueError(\"The machine cloud compute disk size is not set.\")\n\n    if machine.cloud_compute.ssh_key is None"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The `lightning_sdk` package is required to use this function.\")\n\n    if machine is None:\n        machine = Machine()\n\n    if command is None:\n        command = \" \".join(\n            [\n                \"cd\",\n                os.getcwd(),\n                \"&&\",\n                \" \".join(\n                    [\n                        f\"{key}={value}\"\n                        for key, value in os.environ.items()\n                        if key not in [\"PYTHONPATH\", \"PATH\", \"LD_LIBRARY_PATH\"]\n                    ]\n                ),\n                \"&&\",\n                \"python\",\n                \"-m\",\n                \"lightning_datasets\",\n                \"run\",\n                \"--name\",\n                name,\n                \"--num_nodes\",\n                str(num_nodes),\n            ]\n        )\n\n    job = Studio().create_job(\n        name=name,\n        machine=machine,\n        command=command,\n        workdir=os.getcwd(),\n    )\n\n    print(f\"Job URL: {_get_lightning_cloud_url()}/{job.id}\")\n\n    job.wait(interval=10)\n\n    if job.status == \"failed\":\n        raise RuntimeError(f\"Job failed with exit code {job.exit_code}\")\n\n    if job.status != \"succeeded\":\n        raise RuntimeError(f\"Job failed with status {job.status}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The `lightning_sdk` is required to execute the operator remotely.\")\n\n    if machine is None:\n        machine = Machine(\n            name=\"Data Preparation\",\n            accelerators=\"auto\",\n            cpu_count=8,\n            memory=16,\n            disk_size=100,\n        )\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m pip install -r requirements.txt && {sys.executable} -m {__name__} --name={name}\"\n\n    job = Studio(\n        name=name,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n        cloud_compute=CloudCompute(\n            name=name,\n            region=\"us-east-1\",\n            gpu_type=\"NVIDIA Tesla V100\",\n            num_nodes=num_nodes,\n        ),\n    )\n\n    job.run()\n\n    print(f\"Job URL: {_get_lightning_cloud_url()}/{job.id}\")\n\n    while True:\n        sleep(1)\n        job.refresh()\n        if job.status == \"succeeded\":\n            break\n        if job.status == \"failed\":\n            raise RuntimeError(\"Job failed\")\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The lightning-sdk is required to execute this operator remotely.\")\n\n    if machine is None:\n        machine = Studio().machine(num_nodes=num_nodes)\n\n    if command is None:\n        command = \" \".join(sys.argv)\n        env = os.environ.copy()\n        env[\"PYTHONPATH\"] = \":\".join(sys.path)\n        command = \" \".join(f\"{k}={v}\" for k, v in env.items()) + \" \" + command\n\n    job = machine.run(\n        command,\n        name=name,\n        working_dir=os.getcwd(),\n        wait_for_running=True,\n    )\n\n    job_url = f\"{_get_lightning_cloud_url()}/{job.workspace}/jobs/{job.id}\"\n\n    print(f\"Job URL: {job_url}\")\n\n    while True:\n        job.reload()\n        if job.status.value == \"failed\":\n            raise RuntimeError(f\"Job {job.name} failed.\")\n        if job.status.value == \"succeeded\":\n            break\n        sleep(1)\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ImportError(\"You need to install the Lightning SDK to use this function.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise ImportError(\"You need to install boto3 to use this function.\")\n\n    if machine is None:\n        machine = Machine(\n            cpu=num_nodes,\n            gpu=0,\n            memory=10000,\n            disk=10000,\n        )\n\n    if command is None:\n        command = \" \".join(sys.argv)\n\n    if \"LIGHTNING_CLOUD_URL\" not in os.environ:\n        raise RuntimeError(\n            \"The environment variable `LIGHTNING_CLOUD_URL` is not set. This is required to use the `_execute` function.\"\n        )\n\n    studio = Studio(\n        name=name,\n        machine=machine,\n        command=command,\n        env=os.environ,\n        cloud_compute=CloudCompute(\"default\"),\n    )\n\n    print(f\"Job URL: {studio.url}\")\n\n    while True:\n        status = studio.status()\n        if status.state == \"failed\":\n            raise RuntimeError(f\"Job failed with status: {status.message}\")\n        if status.state == \"succeeded\":\n            return\n        sleep(1)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is required to execute the operator remotely.\")\n\n    if machine is None:\n        machine = Machine(\n            name=\"default\",\n            accelerators=\"auto\",\n            cpu_count=1,\n            memory_size=\"10G\",\n            disk_size=\"10G\",\n            image=\"lightning/base:latest\",\n            cloud_compute=\"default\",\n        )\n\n    if command is None:\n        command = f\"cd {os.getcwd()} && {sys.executable} -m lightning run data prepare {name} --cloud\"\n\n    for key, value in os.environ.items():\n        command += f\" --env {key}={value}\"\n\n    studio = Studio(\n        name=\"default\",\n        cloud_compute=\"default\",\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n        environment_variables={\n            \"LIGHTNING_CLOUD_URL\": _get_lightning_cloud_url(),\n            \"LIGHTNING_CLOUD_PROJECT_ID\": os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None),\n            \"LIGHTNING_CLOUD_CLUSTER_ID\": os.getenv(\"LIGHTNING_CLUSTER_ID\", None),\n            \"LIGHTNING_CLOUD_SPACE_ID\": os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None),\n        },\n    )\n\n    studio.run()\n\n    job_id = studio.job_id\n    job_url = f\"{_get_lightning_cloud_url()}/apps/{job_id}\"\n\n    print(f\"Job {job_id} started at {job_url}\")\n\n    client = LightningClient(max_tries=2)\n\n    while True:\n        job_status = client.job_service_get_job_status(job_id).status"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"You need to install the lightning-sdk package to use this function. Run `pip install lightning-sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\n            \"You need to install the boto3 package to use this function. Run `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine(num_nodes=num_nodes)\n\n    if command is None:\n        command = \" \".join(sys.argv)\n\n    command = f\"{command} --output_dir={_resolve_dir(os.getenv('LIGHTNING_DATA_CONNECTION_PATH')).url}\"\n\n    job = Studio(\n        name=name,\n        machine=machine,\n        command=command,\n        environment=os.environ,\n        cloud_compute=CloudCompute(\n            use_spot=True,\n            idle_timeout=60,\n            disk_size=100,\n            shutdown_timeout=1800,\n        ),\n    )\n\n    print(f\"Starting job: {job.name}\")\n    print(f\"Job URL: {_get_lightning_cloud_url()}/{job.cloudspace_id}/jobs/{job.id}\")\n\n    while True:\n        job.reload()\n        if job.status.value == \"FAILED\":\n            raise RuntimeError(f\"Job {job.name} failed.\")\n        if job.status.value == \"SUCCEEDED\":\n            break\n        sleep(1)"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\n            \"The Lightning SDK is not available. Please install the SDK to use this function. `pip install lightning`.\"\n        )\n\n    if machine is None:\n        machine = Machine(\n            name=name,\n            cloud_compute=LightningClient().compute_service_get_default_compute(),\n            machine_type=\"default\",\n            resource_type=\"cpu\",\n            idle_timeout=600,\n            shutdown_timeout=600,\n            num_cpus=num_nodes,\n            num_gpus=0,\n            num_hdd_gb=0,\n            num_ssd_gb=0,\n        )\n\n    if command is None:\n        command = f\"\"\"\n        cd {os.getcwd()}\n        {os.getenv(\"VIRTUAL_ENV\", \"\")}/bin/python -m pip install -r requirements.txt\n        {os.getenv(\"VIRTUAL_ENV\", \"\")}/bin/python -m {sys.argv[0]}\n        \"\"\"\n        command = \" \".join(command.split())\n\n    job = Studio().create_data_prep_job(\n        name=name,\n        machine=machine,\n        command=command,\n        env=dict(os.environ),\n    )\n\n    print(f\"Job URL: {_get_lightning_cloud_url()}/{job.id}\")\n\n    while True:\n        job = Studio().get_job(job.id)\n        if job.status.value == \"succeeded\":\n            break\n        elif job.status.value in [\"failed\", \"stopped\"]:\n            raise RuntimeError(f\"Job {job.id} failed with status {job.status.value}.\")\n        else:\n            sleep(1)\n\n    print(f\"Job {job.id} succeeded.\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"To use the `_execute` function, please install `lightning_sdk`.\")\n\n    if machine is None:\n        machine = Machine(\n            name=\"default\",\n            accelerators=\"auto\",\n            cpu_count=num_nodes,\n            disk_size=100,\n            disk_type=\"SSD\",\n            image=\"lightning/pytorch:latest\",\n            instance_type=\"g4dn.xlarge\",\n            is_spot=False,\n            region=\"us-east-1\",\n            shutdown_timeout=600,\n            ssh_enabled=False,\n        )\n\n    if command is None:\n        command = \" \".join(\n            [\n                \"python\",\n                \"-m\",\n                \"lightning_datasets\",\n                \"--workdir\",\n                os.getcwd(),\n                \"--name\",\n                name,\n                \"--num_nodes\",\n                str(num_nodes),\n            ]\n            + [f\"--env {k}={v}\" for k, v in os.environ.items()]\n        )\n\n    # TODO: Add support for `append` and `overwrite`.\n    job = Studio(\n        name=name,\n        machine=machine,\n        command=command,\n        cloud_compute=\"default\",\n        cloud_logging=False,\n        cloud_storage=\"default\",\n    ).run(\n        wait=False,\n        show_logs=False,\n        show_status=False,\n    )\n\n    while True:\n        sleep(1)\n        job.refresh()\n        if job.status == \"succeeded\":\n            break\n        if job.status == \"failed\":\n            raise RuntimeError(f\"Job {name} failed.\")\n\n    print(f\"Job {name} started at {_get_lightning_cloud_url()}/{job.id}\")"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The Lightning SDK is not available. Please install it with `pip install lightning`.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The boto3 SDK is not available. Please install it with `pip install boto3`.\")\n\n    if machine is None:\n        machine = Machine(\n            machine_type=\"GPU\",\n            accelerators=\"V100\",\n            num_cpus=1,\n            num_gpus=1,\n            memory=10,\n            disk_size=10,\n        )\n\n    if command is None:\n        command = \" \".join(\n            [\n                f\"cd {os.getcwd()}\",\n                \"&&\",\n                \" \".join(sys.argv),\n                \"&&\",\n                \" \".join([f\"export {k}={v}\" for k, v in os.environ.items()]),\n            ]\n        )\n\n    if os.getenv(\"LIGHTNING_CLOUD_URL\", \"\") == \"https://lightning.ai\":\n        # TODO: This is a temporary workaround for local development.\n        #       We should find a better way to handle this.\n        os.environ[\"LIGHTNING_CLOUD_URL\"] = _get_lightning_cloud_url()\n\n    studio = Studio(\n        name=name,\n        machine=machine,\n        command=command,\n        num_nodes=num_nodes,\n        parallel=True,\n        auto_connect=False,\n    )\n\n    print(f\"Job URL: {studio.url}\")\n\n    while True:\n        job_status = studio.status\n        if job_status == \"failed\":\n            raise RuntimeError(\"The job failed. Please check the logs for more information.\")\n        if job_status == \"succeeded\":\n            break\n        sleep(1)\n\n"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise ModuleNotFoundError(\n            \"To use this function, you need to install the `lightning_sdk` package. Run `pip install lightning_sdk`.\"\n        )\n\n    if not _BOTO3_AVAILABLE:\n        raise ModuleNotFoundError(\n            \"To use this function, you need to install the `boto3` package. Run `pip install boto3`.\"\n        )\n\n    if machine is None:\n        machine = Machine(\n            name=\"data-prep\",\n            accelerator=\"CPU\",\n            accelerator_count=1,\n            cpu_count=4,\n            memory=16,\n            disk_size=100,\n            image=\"lightning/data-prep\",\n        )\n\n    if command is None:\n        command = \" \".join(\n            [\n                \"python\",\n                \"-m\",\n                \"lightning\",\n                \"run\",\n                \"app\",\n                os.path.join(os.getcwd(), sys.argv[0]),\n                \"--cloud\",\n                \"--cloud_compute\",\n                machine.name,\n                \"--env\",\n                \" \".join([f\"{k}={v}\" for k, v in os.environ.items()]),\n            ]\n        )\n\n    if num_nodes <= 0:\n        raise ValueError(\"num_nodes must be greater than 0.\")\n\n    studio = Studio(\n        name=name,\n        cloud_compute=machine,\n        command=command,\n        parallel=True,\n        num_nodes=num_nodes,\n        secrets=[],\n    )\n\n    # Get the ids from env variables\n    cluster_id = os.getenv(\"LIGHTNING_CLUSTER_ID\", None)\n    project_id = os.getenv(\"LIGHTNING_CLOUD_PROJECT_ID\", None)\n    cloud_space_id = os.getenv(\"LIGHTNING_CLOUD_SPACE_ID\", None)\n\n    if cluster_id is None"}
{"namespace": "litdata.streaming.resolver._execute", "completion": "    if not _LIGHTNING_SDK_AVAILABLE:\n        raise RuntimeError(\"The `lightning_sdk` package is required for this function. Please install it with `pip install lightning_sdk`.\")\n\n    if not _BOTO3_AVAILABLE:\n        raise RuntimeError(\"The `boto3` package is required for this function. Please install it with `pip install boto3`.\")\n\n    if machine is None:\n        machine = Machine(\n            name=\"default\",\n            accelerators=\"auto\",\n            cpu_count=num_nodes,\n            disk_size=100,\n            disk_type=\"SSD\",\n            image=\"lightning/pytorch:latest\",\n            instance_type=\"t4\",\n            is_spot=False,\n            memory=10000,\n            region=\"us-east-1\",\n            role=\"arn:aws:iam::052331787853:role/LightningByHash\",\n            shutdown_timeout_in_minutes=60,\n            start_timeout_in_minutes=60,\n            tags=[],\n        )\n\n    if command is None:\n        command = \" \".join(\n            [\n                \"python\",\n                \"-m\",\n                \"lightning\",\n                \"run\",\n                \"operator\",\n                f\"--name={name}\",\n                f\"--cloud_compute={machine.name}\",\n                f\"--cluster_id={os.getenv('LIGHTNING_CLUSTER_ID', '')}\",\n                f\"--project_id={os.getenv('LIGHTNING_CLOUD_PROJECT_ID', '')}\",\n                f\"--cloudspace_id={os.getenv('LIGHTNING_CLOUD_SPACE_ID', '')}\",\n                f\"--work_dir={os.getcwd()}\",\n                f\"--env={os.environ}\",\n            ]\n        )\n\n    # TODO: Remove this once the Studio API is available in the SDK.\n    # TODO: Add support"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.delete", "completion": "        for chunk_index in chunk_indexes:\n            self._to_delete_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is None:\n            try:\n                self._config = ChunksConfig.load(\n                    self._cache_dir,\n                    self._serializers,\n                    self._remote_input_dir,\n                    self._item_loader,\n                    self._distributed_env,\n                    self._rank,\n                )\n            except FileNotFoundError:\n                return None\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is None:\n            # Try to load the index files\n            try:\n                self._config = ChunksConfig.from_cache_dir(\n                    self._cache_dir,\n                    serializers=self._serializers,\n                    remote_input_dir=self._remote_input_dir,\n                    item_loader=self._item_loader,\n                )\n                return self._config\n            except FileNotFoundError:\n                return None\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is None:\n            self._config = ChunksConfig.from_cache_dir(\n                self._cache_dir,\n                self._serializers,\n                self._remote_input_dir,\n                self._item_loader,\n            )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Check if the chunks configuration file exists\n        if self._config is None:\n            self._config = ChunksConfig.from_cache_dir(\n                self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                item_loader=self._item_loader,\n            )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the config containing the index\n        if self._config is None:\n            try:\n                self._config = ChunksConfig.from_cache_dir(\n                    self._cache_dir,\n                    serializers=self._serializers,\n                    remote_input_dir=self._remote_input_dir,\n                    item_loader=self._item_loader,\n                )\n            except FileNotFoundError:\n                return None\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is None:\n            try:\n                self._config = ChunksConfig.from_cache_dir(\n                    cache_dir=self._cache_dir,\n                    serializers=self._serializers,\n                    remote_input_dir=self._remote_input_dir,\n                    item_loader=self._item_loader,\n                )\n            except FileNotFoundError:\n                return None\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        if not os.path.exists(self._cache_dir):\n            return None\n\n        # Load the config\n        self._config = ChunksConfig.from_cache_dir(\n            cache_dir=self._cache_dir,\n            serializers=self._serializers,\n            remote_input_dir=self._remote_input_dir,\n            item_loader=self._item_loader,\n            compression=self._compression,\n        )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Load the index files\n        index_files = [f for f in os.listdir(self._cache_dir) if f.endswith(\".index\")]\n\n        # If no index files are found, return None\n        if not index_files:\n            return None\n\n        # Sort the index files by their modification time\n        index_files.sort(key=lambda x: os.path.getmtime(os.path.join(self._cache_dir, x)))\n\n        # Load the latest index file\n        latest_index_file = index_files[-1]\n        self._config = ChunksConfig.load(\n            self._cache_dir,\n            latest_index_file,\n            self._serializers,\n            self._remote_input_dir,\n            self._compression,\n            self._item_loader,\n        )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Check if the config is already loaded\n        if self._config is not None:\n            return self._config\n\n        # Check if the index files are available\n        index_filepath = os.path.join(self._cache_dir, \"index.json\")\n        if not os.path.exists(index_filepath):\n            return None\n\n        # Load the config\n        self._config = ChunksConfig.from_index_file(\n            index_filepath=index_filepath,\n            cache_dir=self._cache_dir,\n            serializers=self._serializers,\n            remote_input_dir=self._remote_input_dir,\n            item_loader=self._item_loader,\n        )\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        self._rank = self._distributed_env.rank\n        if self._rank is None:\n            return None\n\n        if self._config is not None:\n            return self._config\n\n        # Load the config containing the index\n        config_path = os.path.join(self._cache_dir, f\"{self._rank}.json\")\n        if os.path.exists(config_path):\n            self._config = ChunksConfig.load(config_path, self._serializers)\n            self._config._cache_dir = self._cache_dir\n            self._config._remote_input_dir = self._remote_input_dir\n            self._config._compression = self._compression\n            self._config._item_loader = self._item_loader\n            return self._config\n\n        return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        # Try to load the index files\n        if self._remote_input_dir is None:\n            self._config = ChunksConfig.from_local(\n                cache_dir=self._cache_dir, serializers=self._serializers, item_loader=self._item_loader\n            )\n        else:\n            self._config = ChunksConfig.from_remote(\n                cache_dir=self._cache_dir,\n                remote_input_dir=self._remote_input_dir,\n                serializers=self._serializers,\n                item_loader=self._item_loader,\n            )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Check if the index file exists\n        if not os.path.exists(self._cache_dir):\n            return None\n\n        # Load the index file\n        index_filepath = os.path.join(self._cache_dir, \"index.json\")\n        if not os.path.exists(index_filepath):\n            return None\n\n        # Load the config from the index file\n        config = ChunksConfig.from_json(index_filepath, self._serializers, self._item_loader)\n\n        # Update the instance's configuration\n        self._config = config\n        return config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is None:\n            # Load the config containing the index\n            try:\n                self._config = ChunksConfig.from_cache_dir(\n                    cache_dir=self._cache_dir,\n                    serializers=self._serializers,\n                    remote_input_dir=self._remote_input_dir,\n                    item_loader=self._item_loader,\n                    compression=self._compression,\n                )\n            except FileNotFoundError:\n                pass\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Check if the configuration has already been loaded\n        if self._config is not None:\n            return self._config\n\n        # Attempt to load the configuration from the index files\n        try:\n            self._config = ChunksConfig.from_index_files(\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                item_loader=self._item_loader,\n            )\n        except FileNotFoundError:\n            return None\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        # Load the index files\n        intervals = self._get_intervals()\n\n        if intervals is None:\n            return None\n\n        # Create the chunks config\n        self._config = ChunksConfig(\n            cache_dir=self._cache_dir,\n            intervals=intervals,\n            serializers=self._serializers,\n            remote_input_dir=self._remote_input_dir,\n            compression=self._compression,\n            item_loader=self._item_loader,\n        )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        if self._config is not None:\n            return self._config\n\n        if self._remote_input_dir is None:\n            return None\n\n        if not os.path.exists(self._cache_dir):\n            os.makedirs(self._cache_dir, exist_ok=True)\n\n        try:\n            self._config = ChunksConfig.from_remote_input_dir(\n                self._remote_input_dir,\n                self._cache_dir,\n                self._serializers,\n                self._item_loader,\n                self._compression,\n            )\n            return self._config\n        except FileNotFoundError:\n            return None\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Check if the configuration is already loaded\n        if self._config is not None:\n            return self._config\n\n        # Check if the index files are available\n        if self._remote_input_dir is None:\n            return None\n\n        # Attempt to load the configuration\n        try:\n            self._config = ChunksConfig.from_remote(\n                self._remote_input_dir, self._cache_dir, self._serializers, self._item_loader\n            )\n        except Exception:\n            return None\n\n        # Update the instance's configuration\n        self._config.set_cache_dir(self._cache_dir)\n        self._config.set_remote_input_dir(self._remote_input_dir)\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Check if the cache directory exists\n        if not os.path.exists(self._cache_dir):\n            return None\n\n        # Attempt to load the chunks configuration\n        self._config = ChunksConfig.load(\n            self._cache_dir,\n            serializers=self._serializers,\n            remote_input_dir=self._remote_input_dir,\n            item_loader=self._item_loader,\n            compression=self._compression,\n        )\n\n        # Return the loaded configuration\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Check whether the index files are available\n        if self._config is None:\n            index_filepath = os.path.join(self._cache_dir, \"index.json\")\n            if not os.path.exists(index_filepath):\n                return None\n\n            # Load the index files\n            self._config = ChunksConfig.from_index_file(\n                index_filepath=index_filepath,\n                cache_dir=self._cache_dir,\n                serializers=self._serializers,\n                remote_input_dir=self._remote_input_dir,\n                item_loader=self._item_loader,\n            )\n\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader._try_load_config", "completion": "        # Check if the index files exist\n        if not os.path.exists(self._cache_dir):\n            return None\n\n        # Load the index files\n        self._config = ChunksConfig.from_index_files(\n            cache_dir=self._cache_dir,\n            remote_input_dir=self._remote_input_dir,\n            serializers=self._serializers,\n            item_loader=self._item_loader,\n        )\n\n        # Update the intervals attribute\n        self._intervals = self._config.intervals\n\n        # Return the loaded configuration\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.PrepareChunksThread.download", "completion": "        for chunk_index in chunk_indexes:\n            self._to_download_queue.put(chunk_index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The configuration should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.config", "completion": "        if self._config is None:\n            raise RuntimeError(\"The config should be defined before accessing it.\")\n        return self._config\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be an instance of ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check whether the prepare thread is running\n        assert self._prepare_thread is not None, \"The prepare thread should be running.\"\n\n        # Download the chunk if it's not available\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        if chunk_index != self._last_chunk_index:\n            self._prepare_thread.download([chunk_index])\n            self._last_chunk_index = chunk_index\n\n        # Load the item from the chunk\n        return self._config.read(index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index should be an instance of ChunkedIndex. Got {type(index)}.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Load the chunk\n        chunk_filepath, _, _ = self._config[index]\n        self._item_loader.load_chunk(index.chunk_index, chunk_filepath)\n\n        # Prefetch the next chunk\n        if self._prepare_thread is not None:\n            self._prepare_thread.download([index.chunk_index + 1])\n\n        # Get the item from the chunk\n        item = self._item_loader.get_item(index.chunk_index, index.index)\n\n        # Delete the chunk if necessary\n        if self._prepare_thread is not None:\n            if self._last_chunk_index != index.chunk_index:\n                self._prepare_thread.delete([self._last_chunk_index])\n                self._last_chunk_index = index.chunk_index\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index should be an instance of ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Download the chunk if it's not available locally\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        if self._prepare_thread is not None:\n            self._prepare_thread.download([chunk_index])\n\n        # Load the chunk if it's not available in memory\n        if chunk_index != self._last_chunk_index:\n            self._item_loader.load_chunk(chunk_index, self._config)\n            self._last_chunk_index = chunk_index\n\n        # Load the item from the chunk\n        item = self._item_loader.load_item(chunk_index, index.index, self._config)\n\n        # Prefetch the next chunk if it's not already available\n        if self._prepare_thread is not None:\n            self._prepare_thread.download([chunk_index + 1])\n\n        # Delete the chunk once it's fully consumed\n        if self._prepare_thread is not None:\n            self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be an instance of ChunkedIndex but got {type(index)}.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Download the chunk if it isn't available\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread should be defined.\")\n\n        # Download the chunk if it isn't available\n        self._prepare_thread.download([chunk_index])\n\n        # Load the chunk from the cache\n        chunk_filepath, _, _ = self._config[ChunkedIndex(index=-1, chunk_index=chunk_index)]\n        item = self._item_loader.load_item_from_chunk(chunk_index, chunk_filepath, index.index)\n\n        # Delete the chunk if it is fully consumed\n        if self._last_chunk_index is not None and chunk_index == self._last_chunk_index:\n            self._prepare_thread.delete([chunk_index])\n\n        self._last_chunk_index = chunk_index\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be an instance of ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Load the chunk if needed\n        self._config.load_chunk_from_index(index.chunk_index)\n\n        # Initialize the prepare thread if needed\n        if self._prepare_thread is None:\n            self._prepare_thread = PrepareChunksThread(\n                self._config,\n                self._item_loader,\n                self._distributed_env,\n                self._max_cache_size,\n            )\n            self._prepare_thread.start()\n\n        # Make sure the prepare thread is alive\n        assert self._prepare_thread is not None\n\n        # Download the next chunk if needed\n        if self._last_chunk_index is None or self._last_chunk_index != index.chunk_index:\n            self._prepare_thread.download([index.chunk_index])\n            self._last_chunk_index = index.chunk_index\n\n        # Read the item\n        item = self._config.read_item_from_index(index)\n\n        # Delete the chunk if needed\n        if self._prepare_thread.has_exited:\n            self._prepare_thread.delete([index.chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be an instance of ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Ensure the chunk is available either locally or in memory\n        self._config.download_chunk_from_index(index.chunk_index)\n\n        # Initiate the download if the chunk is not available locally\n        if self._prepare_thread is not None:\n            self._prepare_thread.download([index.chunk_index])\n\n        # Prefetch the next chunk if possible\n        if self._last_chunk_index is not None and self._last_chunk_index != index.chunk_index:\n            self._prefetch_next_chunk(index.chunk_index)\n\n        # Load the item from the chunk\n        item = self._config.load_item(index)\n\n        # Handle the lifecycle of the chunk\n        self._handle_chunk_lifecycle(index.chunk_index)\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be of type `ChunkedIndex`, got `{type(index)}` instead.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Download the chunk if it's not available\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        if chunk_index != self._last_chunk_index:\n            self._last_chunk_index = chunk_index\n            self._download_chunk(chunk_index)\n\n        # Load the item from the chunk\n        item = self._load_item(index)\n\n        # Delete the chunk if it's fully consumed\n        if self._prepare_thread is not None:\n            self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index should be an instance of `ChunkedIndex`. Got `{type(index)}`.\")\n\n        if self._config is None:\n            self._try_load_config()\n\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread isn't defined.\")\n\n        # Check if the chunk is available\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        if chunk_index != self._last_chunk_index:\n            self._prepare_thread.delete([self._last_chunk_index])\n            self._last_chunk_index = chunk_index\n            self._prepare_thread.download([chunk_index])\n\n        # Ensure the chunk is available\n        self._prepare_thread.download([chunk_index])\n\n        # Load the chunk\n        chunk_filepath, _, _ = self._config[chunk_index]\n        item = self._item_loader.load_item_from_chunk(index, chunk_filepath)\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be an instance of ChunkedIndex. Got {type(index)} instead.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Get the chunk filepath from the chunk index\n        chunk_filepath, _, _ = self._config[chunk_index]\n\n        # Check if the chunk is available\n        if not self._item_loader.is_chunk_available(chunk_index, chunk_filepath):\n            if self._prepare_thread is None:\n                raise Exception(\"The prepare thread should be defined.\")\n\n            # Download the chunk\n            self._prepare_thread.download([chunk_index])\n\n            # Wait for the chunk to be downloaded\n            self._wait_for_chunk(chunk_index)\n\n        # Load the chunk\n        chunk = self._item_loader.load_chunk(chunk_index, chunk_filepath)\n\n        # Get the item from the chunk\n        item = self._item_loader.get_item(chunk, index.chunk_index)\n\n        # Check if the chunk is fully consumed\n        if self._item_loader.is_chunk_consumed(chunk_index):\n            # Delete the chunk\n            if self._prepare_thread is None:\n                raise Exception(\"The prepare thread should be defined.\")\n\n            self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index should be an instance of {ChunkedIndex}.\")\n\n        if self._config is None:\n            self._try_load_config()\n            if self._config is None:\n                raise Exception(\"The reader index isn't defined.\")\n\n        # Load the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Check whether the chunk is already loaded\n        if self._item_loader.is_chunk_loaded(chunk_index):\n            return self._item_loader.read(chunk_index, index.index)\n\n        # Check whether the chunk is already available locally\n        if self._config.is_chunk_available(chunk_index):\n            self._item_loader.load_chunk(chunk_index, self._config._get_chunk_filepath(chunk_index))\n            return self._item_loader.read(chunk_index, index.index)\n\n        # Check whether the chunk is already available in memory\n        if self._item_loader.is_chunk_in_memory(chunk_index):\n            return self._item_loader.read(chunk_index, index.index)\n\n        # Download the chunk if it's not available locally\n        if self._prepare_thread is None:\n            raise Exception(\"The prepare thread should be defined.\")\n\n        self._prepare_thread.download([chunk_index])\n        return self._item_loader.read(chunk_index, index.index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be a ChunkedIndex.\")\n\n        if self._config is None:\n            self._try_load_config()\n\n        # Load the config containing the index\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Make sure the chunk is available\n        self._ensure_chunk_available(chunk_index)\n\n        # Load the chunk\n        chunk_filepath, _, _ = self._config[index]\n        item = self._item_loader.load_item(chunk_index, chunk_filepath, index.item_index)\n\n        # Delete the chunk if it's the last one\n        if chunk_index == self._last_chunk_index:\n            self._delete_chunk(chunk_index)\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be an instance of {ChunkedIndex.__name__}.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index\n        chunk_index = self._config._get_chunk_index_from_index(index.index)\n\n        # Check if the chunk is already available\n        if self._prepare_thread is not None:\n            if not self._prepare_thread._has_exited:\n                self._prepare_thread.download([chunk_index])\n\n        # Check if the chunk is already available\n        if not self._is_chunk_available(chunk_index):\n            # Initiate the download of the chunk\n            self._config.download_chunk_from_index(chunk_index)\n\n            # Preload item if possible to gain some time but only\n            # if this is one of the pre-downloaded chunk\n            if self._prepare_thread is not None and self._prepare_thread._pre_download_counter > 0:\n                self._prepare_thread._pre_load_chunk(chunk_index)\n\n        # Load the chunk\n        chunk_filepath, _, _ = self._config[chunk_index]\n        item = self._item_loader.load_chunk(chunk_index, chunk_filepath, index)\n\n        # Delete the chunk if it's the last one\n        if chunk_index == self._last_chunk_index:\n            self._last_chunk_index = None\n            if self._prepare_thread is not None:\n                self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be a ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Download the chunk if needed\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        if chunk_index != self._last_chunk_index:\n            self._last_chunk_index = chunk_index\n            self._prepare_thread.download([chunk_index])\n\n        assert self._prepare_thread is not None\n\n        # Wait for the chunk to be available\n        self._prepare_thread.stop()\n        self._prepare_thread.join()\n\n        # Read the item\n        chunk_filepath, _, _ = self._config[index]\n        item = self._item_loader.load_item(chunk_filepath, index)\n\n        # Delete the chunk\n        self._prepare_thread.delete([chunk_index])\n        self._prepare_thread.stop()\n        self._prepare_thread.join()\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be an instance of `ChunkedIndex`. Received: {type(index)}\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Load the chunk if it isn't available\n        self._load_chunk(chunk_index)\n\n        # Load the item from the chunk\n        item = self._load_item_from_chunk(chunk_index, index.index)\n\n        # Delete the chunk if it is fully consumed\n        if self._prepare_thread is not None:\n            if self._config._is_chunk_fully_consumed(chunk_index):\n                self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be of type {ChunkedIndex}\")\n\n        if self._config is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Make sure the chunk is available locally or in memory\n        self._prepare_thread.download([chunk_index])\n\n        # Download the chunk if it isn't available\n        self._config.download_chunk_from_index(chunk_index)\n\n        # Load the item from the chunk\n        item = self._config.load_item_from_index(index)\n\n        # Delete the chunk if it is fully consumed\n        if index.index == self._config.num_samples - 1:\n            self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The index should be an instance of ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # If the chunk is not available locally, download it\n        if not self._config.is_chunk_available(chunk_index):\n            self._config.download_chunk_from_index(chunk_index)\n\n        # Load the chunk\n        chunk_filepath, _, _ = self._config[chunk_index]\n        item = self._item_loader.load_item_from_chunk(index, chunk_filepath)\n\n        # Prefetch the next chunk\n        if self._prepare_thread is not None:\n            self._prepare_thread.download([chunk_index + 1])\n\n        # Delete the current chunk if it is fully consumed\n        if self._prepare_thread is not None:\n            if self._last_chunk_index is not None and self._last_chunk_index != chunk_index:\n                self._prepare_thread.delete([self._last_chunk_index])\n\n            self._last_chunk_index = chunk_index\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index should be an instance of `ChunkedIndex`. Got `{index}`.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # If the chunk is not available, download it\n        if not self._config.is_chunk_available(chunk_index):\n            self._prepare_thread.download([chunk_index])\n\n        # If the chunk is available, load it\n        if self._config.is_chunk_available(chunk_index):\n            chunk_filepath, _, _ = self._config[chunk_index]\n            item = self._item_loader.load_chunk(chunk_index, chunk_filepath, index)\n\n            # If the chunk is fully consumed, delete it\n            if self._config.is_chunk_fully_consumed(chunk_index):\n                self._prepare_thread.delete([chunk_index])\n\n            return item\n\n        # If the chunk is not available, raise an error\n        raise ValueError(f\"The chunk index `{chunk_index}` is not available.\")\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The index should be an instance of `ChunkedIndex`. Received `{index}`.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Check whether the chunk is available in the cache\n        if not self._config.chunk_is_available(chunk_index):\n            # The chunk is not available, we need to download it\n            self._download_chunk(chunk_index)\n\n        # Get the chunk filepath\n        chunk_filepath, _, _ = self._config[chunk_index]\n\n        # Read the item\n        item = self._item_loader.read_item_from_chunk(chunk_filepath, index.chunk_index)\n\n        # Prefetch the next chunk\n        self._prefetch_next_chunk(chunk_index)\n\n        # Delete the chunk if it is fully processed\n        if self._prepare_thread is not None:\n            self._prepare_thread.delete([chunk_index])\n\n        return item\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        if not isinstance(index, ChunkedIndex):\n            raise ValueError(f\"The provided index `{index}` should be an instance of ChunkedIndex.\")\n\n        chunk_index = self._get_chunk_index_from_index(index.index)\n        if chunk_index != self._last_chunk_index:\n            self._last_chunk_index = chunk_index\n            self._prepare_thread.download([chunk_index])  # type: ignore\n\n        # Ensure that the prepare thread is running\n        assert self._prepare_thread is not None, \"The prepare thread should be defined.\"\n\n        # Load the chunk from the cache\n        chunk_filepath, _, _ = self.config[index]\n        self._prepare_thread.delete([chunk_index])  # type: ignore\n        return self._item_loader.load_chunk(chunk_index, chunk_filepath, index.index)\n"}
{"namespace": "litdata.streaming.reader.BinaryReader.read", "completion": "        # Check the index\n        if not isinstance(index, ChunkedIndex):\n            raise ValueError(\"The provided index should be an instance of ChunkedIndex.\")\n\n        # Load the config containing the index\n        if self._config is None and self._try_load_config() is None:\n            raise Exception(\"The reader index isn't defined.\")\n\n        # Check whether the prepare thread is running\n        assert self._prepare_thread is not None, \"The prepare thread should be running.\"\n\n        # Get the chunk index from the index\n        chunk_index = self._get_chunk_index_from_index(index.index)\n\n        # Check whether the chunk is already loaded\n        if chunk_index == self._last_chunk_index:\n            return self._item_loader.get_item(index.chunk_index)\n\n        # Load the chunk\n        self._config.load_chunk_from_index(chunk_index)\n\n        # Delete the chunk if the reader is not the first one\n        if self.rank != 0:\n            self._prepare_thread.delete([chunk_index])\n\n        # Update the last chunk index\n        self._last_chunk_index = chunk_index\n\n        # Get the item\n        return self._item_loader.get_item(index.chunk_index)\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": ""}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": ""}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    else:\n        return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n\n    return _ImmutableDistributedMap().set_and_get(key, obj)"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n    return _ImmutableDistributedMap().set_and_get(key, obj)"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if _is_distributed_environment():\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n    else:\n        return _ImmutableDistributedMap().set_and_get(key, obj)"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_STATE_URL\"):\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n    return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    # Check if the application is running in an environment with an external URL (indicating a distributed setting)\n    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        # Create an immutable distributed map\n        dm = _ImmutableDistributedMap()\n        # Use the immutable distributed map to share the object\n        return dm.set_and_get(key, obj)\n    # If not in such an environment, return the object as is\n    return obj"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\"):\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is not None:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n    return obj\n\n"}
{"namespace": "litdata.utilities.broadcast.broadcast_object", "completion": "    if os.getenv(\"LIGHTNING_APP_EXTERNAL_URL\") is None:\n        return obj\n    else:\n        return _ImmutableDistributedMap().set_and_get(key, obj)\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Set the seed for the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunk indexes for each rank within the node\n    for rank in range(distributed_env.world_size):\n        np.random.shuffle(chunks_per_ranks[rank])\n\n    # Flatten the chunk indexes for all nodes\n    shuffled_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Create a random number generator with the provided seed and the current epoch\n    rng = np.random.default_rng(seed + current_epoch)\n\n    # Flatten the list of chunk indexes assigned to each rank\n    chunks_per_ranks = [chunk for sublist in chunks_per_ranks for chunk in sublist]\n\n    # Shuffle the chunk indexes using the random number generator\n    rng.shuffle(chunks_per_ranks)\n\n    # Return the shuffled chunk indexes\n    return chunks_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Initialize the random number generator with the seed and current epoch\n    rng = np.random.default_rng(seed + current_epoch)\n\n    # Create a list of shuffled chunk indexes for each node\n    shuffled_chunks = [\n        rng.permutation(chunks_per_ranks[i]) for i in range(distributed_env.num_nodes)\n    ]\n\n    # Flatten the list of shuffled chunk indexes\n    shuffled_chunks = [chunk for sublist in shuffled_chunks for chunk in sublist]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Initialize the random number generator with the provided seed and the current epoch\n    rng = np.random.default_rng(seed + current_epoch)\n\n    # Shuffle the chunk indexes for each rank\n    shuffled_chunks_per_ranks = [\n        rng.permutation(chunks_per_rank).tolist()\n        for chunks_per_rank in chunks_per_ranks\n    ]\n\n    # Flatten the shuffled chunk indexes\n    shuffled_chunks = [\n        chunk\n        for chunks_per_rank in shuffled_chunks_per_ranks\n        for chunk in chunks_per_rank\n    ]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Set the random seed for the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunks per rank\n    shuffled_chunks_per_ranks = [\n        np.random.permutation(chunks).tolist() for chunks in chunks_per_ranks\n    ]\n\n    # Flatten the shuffled chunks per rank\n    shuffled_chunks = [\n        chunk for chunks in shuffled_chunks_per_ranks for chunk in chunks\n    ]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Generate a random seed based on the provided seed and the current epoch\n    random_seed = seed + current_epoch\n\n    # Initialize an empty list to store the shuffled chunk indexes\n    shuffled_chunks = []\n\n    # Iterate over the chunks assigned to each node\n    for node_chunks in chunks_per_ranks:\n        # Shuffle the chunk indexes for the current node using the random seed\n        np.random.seed(random_seed)\n        np.random.shuffle(node_chunks)\n        # Append the shuffled chunk indexes to the list\n        shuffled_chunks.extend(node_chunks)\n\n    # Return the flattened list of shuffled chunk indexes\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Generate a unique seed for each node based on the provided seed and the current epoch\n    node_seed = seed + current_epoch\n\n    # Shuffle the chunk indexes for each rank within the current node\n    for rank in range(distributed_env.world_size):\n        np.random.seed(node_seed + rank)\n        np.random.shuffle(chunks_per_ranks[rank])\n\n    # Flatten the chunk indexes across all nodes\n    shuffled_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Set the seed based on the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Shuffle the chunks of data assigned to each node\n    for node_idx in range(distributed_env.world_size):\n        np.random.shuffle(chunks_per_ranks[node_idx])\n\n    # Flatten the shuffled chunk indexes across all nodes\n    shuffled_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Get the number of nodes and the world size from the distributed environment\n    num_nodes = distributed_env.num_nodes\n    world_size = distributed_env.world_size\n\n    # Initialize an empty list to store the shuffled chunk indexes\n    shuffled_chunks = []\n\n    # Iterate over each node\n    for node_idx in range(num_nodes):\n        # Determine the rank of the current node\n        rank = node_idx * world_size\n\n        # Get the chunk indexes assigned to the current node\n        chunks = chunks_per_ranks[node_idx]\n\n        # Calculate the seed for the current node based on the provided seed and the current epoch\n        node_seed = seed + current_epoch + rank\n\n        # Shuffle the chunk indexes using the node seed\n        np.random.seed(node_seed)\n        np.random.shuffle(chunks)\n\n        # Append the shuffled chunk indexes to the shuffled_chunks list\n        shuffled_chunks.extend(chunks)\n\n    # Return the flattened list of shuffled chunk indexes\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Set the seed for the current epoch\n    np.random.seed(seed + current_epoch)\n\n    # Flatten the chunks_per_ranks list\n    flattened_chunks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Shuffle the flattened chunks\n    np.random.shuffle(flattened_chunks)\n\n    # Split the shuffled chunks into chunks_per_ranks_shuffled\n    chunks_per_ranks_shuffled = np.array_split(\n        flattened_chunks, distributed_env.num_nodes\n    )\n\n    # Convert chunks_per_ranks_shuffled to a list of lists\n    chunks_per_ranks_shuffled = [list(chunks) for chunks in chunks_per_ranks_shuffled]\n\n    # Return the shuffled chunks\n    return chunks_per_ranks_shuffled\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Initialize the random number generator with the provided seed and current epoch\n    rng = np.random.default_rng(seed + current_epoch)\n\n    # Flatten the chunk indexes assigned to each rank\n    chunks_per_ranks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Shuffle the chunk indexes using the random number generator\n    chunks_per_ranks = rng.permutation(chunks_per_ranks)\n\n    # Split the shuffled chunk indexes into chunks based on the number of nodes\n    chunks_per_ranks = np.array_split(chunks_per_ranks, distributed_env.world_size)\n\n    # Convert the chunk indexes back to a flattened list\n    chunks_per_ranks = [chunk.tolist() for chunk in chunks_per_ranks]\n\n    # Return the shuffled chunk indexes\n    return chunks_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Initialize the random number generator with the seed and the current epoch\n    rng = np.random.default_rng(seed=seed + current_epoch)\n\n    # Initialize an empty list to store the shuffled chunk indexes\n    shuffled_chunks = []\n\n    # Iterate through each rank in the distributed environment\n    for rank in range(distributed_env.world_size):\n\n        # Get the chunk indexes assigned to the current rank\n        chunks = chunks_per_ranks[rank]\n\n        # Shuffle the chunk indexes using the random number generator\n        rng.shuffle(chunks)\n\n        # Append the shuffled chunk indexes to the shuffled_chunks list\n        shuffled_chunks.append(chunks)\n\n    # Flatten the shuffled_chunks list into a single list\n    shuffled_chunks = [chunk for chunks in shuffled_chunks for chunk in chunks]\n\n    # Return the flattened list of shuffled chunk indexes\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    if distributed_env.world_size == 1:\n        return chunks_per_ranks[0]\n\n    # Get the number of chunks per node\n    chunks_per_node = len(chunks_per_ranks[0])\n\n    # Generate a random seed based on the provided seed and current epoch\n    random_seed = seed + current_epoch\n\n    # Create a list of shuffled chunk indexes for each node\n    shuffled_chunks = [\n        np.random.default_rng(random_seed + node_id).permutation(chunks_per_node)\n        for node_id in range(distributed_env.world_size)\n    ]\n\n    # Flatten the shuffled chunk indexes across all nodes\n    shuffled_chunks = [\n        chunk for node_chunks in shuffled_chunks for chunk in node_chunks\n    ]\n\n    return shuffled_chunks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Initialize the random number generator with the seed and current epoch\n    rng = np.random.default_rng(seed=seed + current_epoch)\n\n    # Create a list to store the shuffled chunk indexes for each node\n    shuffled_chunk_indexes = []\n\n    # Iterate over each node\n    for node_index in range(distributed_env.world_size):\n        # Shuffle the chunk indexes for the current node using the random number generator\n        shuffled_chunk_indexes.append(rng.permutation(chunks_per_ranks[node_index]))\n\n    # Flatten the list of shuffled chunk indexes and return it\n    return [index for sublist in shuffled_chunk_indexes for index in sublist]\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Create a random number generator using the provided seed and the current epoch\n    rng = np.random.default_rng(seed + current_epoch)\n\n    # Shuffle the chunk indexes for each rank within the current node\n    chunks_per_ranks_shuffled = [rng.permutation(chunks).tolist() for chunks in chunks_per_ranks]\n\n    # Flatten the shuffled chunk indexes across all nodes\n    chunks_shuffled = [chunk for chunks in chunks_per_ranks_shuffled for chunk in chunks]\n\n    return chunks_shuffled\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Determine the number of chunks per node\n    chunks_per_node = len(chunks_per_ranks[0])\n\n    # Determine the number of nodes\n    num_nodes = distributed_env.world_size\n\n    # Generate a random seed based on the provided seed and current epoch\n    random_seed = seed + current_epoch\n\n    # Create a list of chunk indexes for each node\n    chunk_indexes = [\n        [\n            (node_id * chunks_per_node) + chunk_id\n            for chunk_id in range(chunks_per_node)\n        ]\n        for node_id in range(num_nodes)\n    ]\n\n    # Flatten the list of chunk indexes\n    flattened_chunk_indexes = [\n        chunk_id for sublist in chunk_indexes for chunk_id in sublist\n    ]\n\n    # Shuffle the chunk indexes using the random seed\n    np.random.seed(random_seed)\n    np.random.shuffle(flattened_chunk_indexes)\n\n    return flattened_chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Generate a seed based on the provided seed and the current epoch\n    seed += current_epoch\n\n    # Determine the number of chunks per node\n    chunks_per_node = distributed_env.chunks_per_node\n\n    # Flatten the list of chunk indexes assigned to each rank\n    chunks_per_ranks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    # Shuffle the chunk indexes within each node\n    np.random.seed(seed)\n    np.random.shuffle(chunks_per_ranks)\n\n    # Split the shuffled chunk indexes into chunks of size chunks_per_node\n    chunks_per_ranks = [\n        chunks_per_ranks[i : i + chunks_per_node]\n        for i in range(0, len(chunks_per_ranks), chunks_per_node)\n    ]\n\n    # Flatten the list of shuffled chunk indexes across all nodes\n    chunks_per_ranks = [chunk for chunks in chunks_per_ranks for chunk in chunks]\n\n    return chunks_per_ranks\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Determine the number of chunks per rank\n    chunks_per_rank = len(chunks_per_ranks[0])\n\n    # Determine the number of chunks per node\n    chunks_per_node = distributed_env.world_size * chunks_per_rank\n\n    # Determine the number of nodes\n    num_nodes = distributed_env.world_size\n\n    # Generate a list of chunk indexes\n    chunk_indexes = list(range(chunks_per_node))\n\n    # Shuffle the chunk indexes based on the provided seed and the current epoch\n    np.random.seed(seed + current_epoch)\n    np.random.shuffle(chunk_indexes)\n\n    # Reshape the shuffled chunk indexes into a 2D array with dimensions (num_nodes, chunks_per_node)\n    shuffled_chunk_indexes = np.array(chunk_indexes).reshape(num_nodes, chunks_per_node)\n\n    # Flatten the shuffled chunk indexes into a 1D list\n    flattened_shuffled_chunk_indexes = shuffled_chunk_indexes.flatten().tolist()\n\n    return flattened_shuffled_chunk_indexes\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Check if the current node is the master node\n    if distributed_env.rank == 0:\n        # Flatten the chunk indexes assigned to each rank\n        chunks_per_ranks = np.array(chunks_per_ranks).flatten()\n        # Create a random number generator with the specified seed and current epoch\n        rng = np.random.default_rng(seed=seed + current_epoch)\n        # Shuffle the chunk indexes using the random number generator\n        rng.shuffle(chunks_per_ranks)\n        # Reshape the shuffled chunk indexes back into a list of lists, with each sublist containing the chunk indexes for a specific rank\n        chunks_per_ranks = chunks_per_ranks.reshape(\n            distributed_env.world_size, -1\n        ).tolist()\n    # Broadcast the shuffled chunk indexes from the master node to all other nodes in the distributed environment\n    chunks_per_ranks = distributed_env.broadcast(chunks_per_ranks)\n    # Flatten the chunk indexes assigned to the current node\n    chunks_per_ranks = np.array(chunks_per_ranks[distributed_env.rank]).flatten()\n    # Return the shuffled chunk indexes as a list\n    return chunks_per_ranks.tolist()\n\n"}
{"namespace": "litdata.utilities.shuffle._intra_node_chunk_shuffle", "completion": "    # Determine the number of chunks per rank\n    chunks_per_rank = len(chunks_per_ranks[0])\n\n    # Determine the number of nodes in the distributed environment\n    num_nodes = distributed_env.num_nodes\n\n    # Determine the number of ranks per node\n    ranks_per_node = distributed_env.world_size // num_nodes\n\n    # Determine the number of chunks per node\n    chunks_per_node = chunks_per_rank * ranks_per_node\n\n    # Determine the number of nodes that will be used for this epoch\n    num_nodes_for_epoch = min(num_nodes, chunks_per_node)\n\n    # Determine the number of chunks per node for this epoch\n    chunks_per_node_for_epoch = chunks_per_node // num_nodes_for_epoch\n\n    # Determine the number of chunks that will be left over after distributing chunks evenly across nodes\n    num_chunks_left = chunks_per_node % num_nodes_for_epoch\n\n    # Create a list of chunk indexes for each node, with chunks distributed evenly across nodes\n    chunks_per_node_list = [\n        list(range(i, chunks_per_node, chunks_per_node_for_epoch))\n        for i in range(chunks_per_node_for_epoch)\n    ]\n\n    # Distribute the remaining chunks across the first nodes\n    for i in range(num_chunks_left):\n        chunks_per_node_list[i].append(chunks_per_node_for_epoch * num_nodes_for_epoch + i)\n\n    # Flatten the chunk indexes for each node into a single list\n    chunks_per_node_list = [\n        chunk for node_chunks in chunks_per_node_list for chunk in node_chunks\n    ]\n\n    # Shuffle the chunk indexes for the current epoch using the provided seed\n    np.random.seed((seed + current_epoch) % (2"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    first_path = indexed_paths[0]\n    second_path = indexed_paths[1] if len(indexed_paths) > 1 else None\n\n    if second_path is not None:\n        if os.path.dirname(first_path) != os.path.dirname(second_path):\n            raise ValueError(\"Inconsistent file paths found in the inputs.\")\n\n    input_dir = os.path.dirname(first_path)\n\n    if _IS_IN_STUDIO:\n        return input_dir\n\n    return _resolve_dir(input_dir)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\"Too many inputs\")\n\n    input_dir = os.path.dirname(indexed_paths[0])\n\n    return input_dir"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            f\"Expected at most one indexed path, found {len(indexed_paths)}: {indexed_paths}\"\n        )\n\n    input_dir = os.path.dirname(list(indexed_paths.values())[0])\n\n    if input_dir == \"\":\n        return None\n\n    if _IS_IN_STUDIO:\n        return input_dir\n\n    return os.path.abspath(input_dir)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    first_path = indexed_paths[0]\n    second_path = indexed_paths[1] if 1 in indexed_paths else None\n\n    if not first_path:\n        return None\n\n    if not second_path:\n        return _resolve_dir(first_path)\n\n    if not os.path.exists(first_path):\n        raise ValueError(f\"Path {first_path} does not exist.\")\n\n    if not os.path.exists(second_path):\n        raise ValueError(f\"Path {second_path} does not exist.\")\n\n    first_dir = os.path.dirname(first_path)\n    second_dir = os.path.dirname(second_path)\n\n    if first_dir != second_dir:\n        raise ValueError(f\"Paths {first_path} and {second_path} do not share the same directory.\")\n\n    return _resolve_dir(first_dir)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) == 0:\n        return None\n\n    indexed_paths = _get_indexed_paths(inputs[0])\n\n    if len(inputs) > 1:\n        indexed_paths_2 = _get_indexed_paths(inputs[1])\n\n        if indexed_paths != indexed_paths_2:\n            raise ValueError(\"Inconsistent file paths in inputs.\")\n\n    if len(indexed_paths) == 0:\n        return None\n\n    index, path = next(iter(indexed_paths.items()))\n\n    if _IS_IN_STUDIO:\n        return os.path.abspath(path)\n\n    return os.path.abspath(path).split(f\"/{index}/\")[0]\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\"Inconsistent file paths found.\")\n\n    indexed_path = list(indexed_paths.values())[0]\n    input_dir = os.path.dirname(indexed_path)\n    if _IS_IN_STUDIO:\n        input_dir = os.path.join(os.environ[\"LIGHTNING_DATA_ROOT\"], input_dir)\n    else:\n        input_dir = os.path.join(os.getcwd(), input_dir)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            \"More than one file path found. Only one file path is allowed as input.\"\n        )\n\n    indexed_path = next(iter(indexed_paths.values()))\n\n    if not os.path.exists(indexed_path):\n        raise ValueError(f\"File path {indexed_path} does not exist.\")\n\n    if _IS_IN_STUDIO:\n        return os.path.abspath(indexed_path)\n\n    return os.path.abspath(indexed_path)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Get the indexed paths from the first two elements of the input sequence\n    indexed_paths = _get_indexed_paths(inputs[:2])\n\n    # If no indexed paths are found, return None\n    if not indexed_paths:\n        return None\n\n    # Get the first indexed path\n    indexed_path = list(indexed_paths.values())[0]\n\n    # If the indexed path is a directory, check if it has an index file\n    if os.path.isdir(indexed_path):\n        _assert_dir_has_index_file(indexed_path)\n\n    # If the indexed path is a file, check if it is a directory\n    elif os.path.isfile(indexed_path):\n        if not os.path.isdir(os.path.dirname(indexed_path)):\n            raise ValueError(f\"File {indexed_path} is not in a directory.\")\n\n    # Get the absolute path of the input directory\n    input_dir = os.path.abspath(os.path.dirname(indexed_path))\n\n    # Check if the input directory is empty\n    _assert_dir_is_empty(input_dir)\n\n    # Return the input directory\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) < 2:\n        return None\n\n    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            \"Multiple file paths found in the input sequence. Please provide a single file path.\"\n        )\n\n    input_path = list(indexed_paths.values())[0]\n\n    if not os.path.exists(input_path):\n        raise ValueError(f\"Input path '{input_path}' does not exist.\")\n\n    if _IS_IN_STUDIO:\n        input_dir = os.path.dirname(input_path)\n    else:\n        input_dir = os.path.dirname(input_path)\n        input_dir = os.path.abspath(input_dir)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) == 0:\n        return None\n\n    indexed_paths = _get_indexed_paths(inputs[0])\n\n    if len(inputs) >= 2:\n        indexed_paths.update(_get_indexed_paths(inputs[1]))\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise RuntimeError(\n            f\"Expected only one file path in the first two inputs, but found {len(indexed_paths)}.\"\n        )\n\n    input_path = list(indexed_paths.values())[0]\n\n    if _IS_IN_STUDIO:\n        input_dir = os.path.dirname(input_path)\n        input_dir = _resolve_dir(input_dir)\n    else:\n        input_dir = os.path.dirname(input_path)\n        input_dir = _resolve_dir(input_dir)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            \"Only one input is allowed for streaming datasets. \"\n            \"Found multiple inputs: \" + str(indexed_paths.values())\n        )\n\n    input_path = next(iter(indexed_paths.values()))\n\n    if _IS_IN_STUDIO:\n        return os.path.abspath(input_path)\n\n    if not os.path.exists(input_path):\n        raise ValueError(\n            \"The input path does not exist. \"\n            f\"Please check the input path: {input_path}\"\n        )\n\n    if os.path.isfile(input_path):\n        input_dir = os.path.dirname(input_path)\n    else:\n        input_dir = input_path\n\n    return os.path.abspath(input_dir)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 2:\n        raise ValueError(\n            f\"Expected at most 2 indexed paths, but found {len(indexed_paths)}.\"\n        )\n\n    first_path = indexed_paths[0]\n    second_path = indexed_paths[1]\n\n    if os.path.isfile(first_path) and os.path.isdir(second_path):\n        first_path, second_path = second_path, first_path\n\n    if not os.path.isfile(first_path):\n        raise ValueError(f\"Expected a file path, but found {first_path}.\")\n\n    if not os.path.isdir(second_path):\n        raise ValueError(f\"Expected a directory path, but found {second_path}.\")\n\n    if _IS_IN_STUDIO:\n        return f\"{second_path}/\"\n\n    return f\"{second_path}/\"\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) == 0:\n        return None\n\n    if len(inputs) == 1:\n        path = inputs[0]\n    else:\n        path = inputs[0] if os.path.exists(inputs[0]) else inputs[1]\n\n    if not os.path.exists(path):\n        return None\n\n    if os.path.isdir(path):\n        path = os.path.join(path, \"index.json\")\n\n    path = os.path.abspath(path)\n    if not os.path.exists(path):\n        raise ValueError(f\"Path {path} does not exist.\")\n\n    if path.endswith(\".json\"):\n        path = os.path.dirname(path)\n\n    if path.endswith(\"/\"):\n        path = path[:-1]\n\n    if _IS_IN_STUDIO:\n        path = os.path.join(os.environ[\"LIGHTNING_DATA_DIR\"], path)\n\n    return path\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Check if the input sequence is empty\n    if not inputs:\n        return None\n\n    # Get the first two elements of the input sequence\n    first_two_elements = inputs[:2]\n\n    # Get the indexed paths from the first two elements\n    indexed_paths = _get_indexed_paths(first_two_elements)\n\n    # Check if there are no indexed paths\n    if not indexed_paths:\n        return None\n\n    # Get the first indexed path\n    first_indexed_path = list(indexed_paths.values())[0]\n\n    # Check if the first indexed path is a file\n    if os.path.isfile(first_indexed_path):\n        # Get the parent directory of the first indexed path\n        parent_dir = os.path.dirname(first_indexed_path)\n    else:\n        # Set the parent directory as the first indexed path\n        parent_dir = first_indexed_path\n\n    # Check if the parent directory is a valid file path\n    if not os.path.exists(parent_dir):\n        raise ValueError(f\"Invalid file path: {parent_dir}\")\n\n    # Get the absolute path of the parent directory\n    parent_dir = os.path.abspath(parent_dir)\n\n    # Check if the parent directory is a directory\n    if not os.path.isdir(parent_dir):\n        raise ValueError(f\"Invalid directory path: {parent_dir}\")\n\n    # Check if the parent directory is empty\n    if not os.listdir(parent_dir):\n        raise ValueError(f\"Directory is empty: {parent_dir}\")\n\n    # Check if the parent directory contains a file named \"index.json\"\n    index_file_path = os.path.join(parent_dir, \"index.json\")\n    if not os.path.exists(index_file_path):\n        raise ValueError(f\"Directory does not contain index.json file: {parent_dir}\")\n\n    # Check if the parent directory contains only one file\n    if len(os.listdir(parent_dir))"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) == 0:\n        return None\n\n    if len(inputs) == 1:\n        indexed_paths = _get_indexed_paths(inputs[0])\n    else:\n        indexed_paths = _get_indexed_paths(inputs[0])\n        indexed_paths.update(_get_indexed_paths(inputs[1]))\n\n    if len(indexed_paths) == 0:\n        return None\n\n    first_path = indexed_paths[0]\n    first_path_is_file = os.path.isfile(first_path)\n\n    if first_path_is_file:\n        first_path = os.path.dirname(first_path)\n\n    for index, path in indexed_paths.items():\n        if os.path.isfile(path):\n            path = os.path.dirname(path)\n\n        if first_path_is_file:\n            if os.path.dirname(path) != first_path:\n                raise ValueError(\n                    f\"Inconsistent file paths: {first_path} and {path} are not in the same directory.\"\n                )\n        else:\n            if path != first_path:\n                raise ValueError(\n                    f\"Inconsistent file paths: {first_path} and {path} are not the same directory.\"\n                )\n\n    if first_path_is_file:\n        first_path = os.path.dirname(first_path)\n\n    if _IS_IN_STUDIO:\n        return first_path\n\n    return os.path.abspath(first_path)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) == 0:\n        return None\n\n    if len(inputs) == 1:\n        if isinstance(inputs[0], str):\n            return os.path.abspath(inputs[0])\n        else:\n            return None\n\n    indexed_paths = _get_indexed_paths(inputs[0])\n\n    if len(indexed_paths) == 0:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\n            \"Multiple indexed paths found in the first element of the input sequence. \"\n            \"Please provide a single input sequence with a single indexed path.\"\n        )\n\n    indexed_path = indexed_paths[0]\n\n    if not os.path.exists(indexed_path):\n        raise FileNotFoundError(f\"The indexed path '{indexed_path}' does not exist.\")\n\n    if len(inputs) == 2:\n        if isinstance(inputs[1], str):\n            if os.path.abspath(inputs[1]) != os.path.abspath(indexed_path):\n                raise ValueError(\n                    \"The second element of the input sequence must be the same as the indexed path in the first element.\"\n                )\n        else:\n            raise ValueError(\n                \"The second element of the input sequence must be a string representing the indexed path.\"\n            )\n\n    input_dir = os.path.dirname(indexed_path)\n    input_dir = os.path.abspath(input_dir)\n\n    if not os.path.exists(input_dir):\n        raise FileNotFoundError(f\"The input directory '{input_dir}' does not exist.\")\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    if len(inputs) == 0:\n        return None\n\n    if len(inputs) == 1:\n        return _get_input_dir([inputs[0], None])\n\n    indexed_paths_1 = _get_indexed_paths(inputs[0])\n    indexed_paths_2 = _get_indexed_paths(inputs[1])\n\n    if len(indexed_paths_1) == 0 and len(indexed_paths_2) == 0:\n        return None\n\n    if len(indexed_paths_1) == 0:\n        indexed_paths_1 = indexed_paths_2\n\n    if len(indexed_paths_2) == 0:\n        indexed_paths_2 = indexed_paths_1\n\n    if indexed_paths_1 != indexed_paths_2:\n        raise ValueError(\"Inconsistent file paths provided in inputs.\")\n\n    indexed_paths = indexed_paths_1\n\n    for index, path in indexed_paths.items():\n        path = _resolve_dir(path)\n        indexed_paths[index] = path\n\n    input_dir = os.path.commonpath(list(indexed_paths.values()))\n\n    if _IS_IN_STUDIO:\n        input_dir = os.path.join(os.environ[\"LIGHTNING_DATA_ROOT\"], input_dir)\n    else:\n        input_dir = os.path.abspath(input_dir)\n\n    return input_dir\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Get the first two elements of the input sequence\n    first_two_elements = inputs[:2]\n\n    # Extract and resolve indexed paths from the first two elements\n    indexed_paths = _get_indexed_paths(first_two_elements)\n\n    # If no indexed paths are found, return None\n    if not indexed_paths:\n        return None\n\n    # Get the first indexed path\n    first_path = indexed_paths[0]\n\n    # Check if all indexed paths are consistent\n    for index, path in indexed_paths.items():\n        if path != first_path:\n            raise ValueError(\n                f\"Inconsistent file paths found: {path} and {first_path}. All indexed paths must be consistent.\"\n            )\n\n    # Get the absolute path to the input directory\n    input_dir = os.path.abspath(os.path.dirname(first_path))\n\n    # If the input directory is the same as the project root, return None\n    if input_dir == os.path.abspath(os.path.join(os.getcwd(), \"..\")):\n        return None\n\n    # Format the path to include the project root or a specified depth in the file system\n    if _IS_IN_STUDIO:\n        # If in Lightning Studio, return the input directory as is\n        return input_dir\n    else:\n        # If not in Lightning Studio, return the input directory with a specified depth in the file system\n        return os.path.join(\"..\", \"..\", \"..\", \"..\", \"..\", input_dir)\n\n"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    # Check if the inputs are a sequence of length 2\n    if not isinstance(inputs, Sequence) or len(inputs) != 2:\n        raise ValueError(\"Inputs must be a sequence of length 2\")\n\n    # Extract the first two elements of the inputs\n    input_1, input_2 = inputs[:2]\n\n    # Determine the input directory based on the first two elements\n    if isinstance(input_1, str) and os.path.exists(input_1):\n        # If the first element is a valid file path, use it as the input directory\n        input_dir = input_1\n    elif isinstance(input_2, str) and os.path.exists(input_2):\n        # If the second element is a valid file path, use it as the input directory\n        input_dir = input_2\n    else:\n        # If neither element is a valid file path, return None\n        return None\n\n    # Resolve the input directory to an absolute path\n    input_dir = os.path.abspath(input_dir)\n\n    # Check if the input directory is a file\n    if os.path.isfile(input_dir):\n        # If the input directory is a file, raise an error\n        raise ValueError(f\"Input directory {input_dir} is a file\")\n\n    # Check if the input directory is empty\n    if not os.listdir(input_dir):\n        # If the input directory is empty, raise an error\n        raise ValueError(f\"Input directory {input_dir} is empty\")\n\n    # Format the input directory to include the project root or a specified depth in the file system\n    if _IS_IN_STUDIO:\n        # If running in the Lightning App Studio, format the input directory to include the project root\n        input_dir = os.path.join(\"/lit\", input_dir)\n    else:\n        # If not running in the Lightning App Studio, format the input directory to include a specified depth in the file system\n        input_dir = os.path.join(os.path.dirname(input_dir), \"*\")\n\n    # Return"}
{"namespace": "litdata.processing.functions._get_input_dir", "completion": "    indexed_paths = _get_indexed_paths(inputs)\n\n    if not indexed_paths:\n        return None\n\n    if len(indexed_paths) > 1:\n        raise ValueError(\"Multiple file paths found in the inputs\")\n\n    indexed_path = next(iter(indexed_paths.values()))\n\n    if _IS_IN_STUDIO:\n        return os.path.dirname(indexed_path)\n\n    return os.path.dirname(indexed_path)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        yield\n        return\n\n    if enable:\n        Popen([\"sudo\", \"systemctl\", \"start\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)\n        yield\n        Popen([\"sudo\", \"systemctl\", \"stop\", \"systemd-resolved\"], stdout=DEVNULL, stderr=DEVNULL)\n    else:\n        yield"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        import lightning_app\n\n        if enable:\n            lightning_app.utilities.network.enable_dns_optimization()\n        try:\n            yield\n        finally:\n            if enable:\n                lightning_app.utilities.network.disable_dns_optimization()\n    else:\n        if enable:\n            Popen(\"sudo /etc/init.d/networking restart\", shell=True, stdout=DEVNULL, stderr=DEVNULL)\n        try:\n            yield\n        finally:\n            if enable:\n                Popen(\"sudo /etc/init.d/networking restart\", shell=True, stdout=DEVNULL, stderr=DEVNULL)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if enable:\n        if _IS_IN_STUDIO:\n            Popen([\"sudo\", \"lightning_cloud\", \"dns\", \"enable\"], stdout=DEVNULL, stderr=DEVNULL)\n        else:\n            Popen([\"sudo\", \"lightning\", \"dns\", \"enable\"], stdout=DEVNULL, stderr=DEVNULL)\n    try:\n        yield\n    finally:\n        if enable:\n            if _IS_IN_STUDIO:\n                Popen([\"sudo\", \"lightning_cloud\", \"dns\", \"disable\"], stdout=DEVNULL, stderr=DEVNULL)\n            else:\n                Popen([\"sudo\", \"lightning\", \"dns\", \"disable\"], stdout=DEVNULL, stderr=DEVNULL)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        if enable:\n            Popen(\"sudo netconfig update -d -a\", shell=True, stdout=DEVNULL, stderr=DEVNULL)\n        yield\n        Popen(\"sudo netconfig update -d -a\", shell=True, stdout=DEVNULL, stderr=DEVNULL)\n    else:\n        yield"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        yield\n        return\n\n    if enable:\n        # Enable DNS optimization\n        try:\n            Popen([\"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"127.0.0.1\"], stdout=DEVNULL, stderr=DEVNULL)\n        except Exception:\n            pass\n        try:\n            Popen([\"networksetup\", \"-setdnsservers\", \"Ethernet\", \"127.0.0.1\"], stdout=DEVNULL, stderr=DEVNULL)\n        except Exception:\n            pass\n\n    try:\n        yield\n    finally:\n        # Disable DNS optimization\n        try:\n            Popen([\"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"Empty\"], stdout=DEVNULL, stderr=DEVNULL)\n        except Exception:\n            pass\n        try:\n            Popen([\"networksetup\", \"-setdnsservers\", \"Ethernet\", \"Empty\"], stdout=DEVNULL, stderr=DEVNULL)\n        except Exception:\n            pass"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        yield\n        return\n\n    if enable:\n        Popen([\"sudo\", \"lightning\", \"optimize\", \"dns\", \"enable\"], stdout=DEVNULL)\n    else:\n        Popen([\"sudo\", \"lightning\", \"optimize\", \"dns\", \"disable\"], stdout=DEVNULL)\n    try:\n        yield\n    finally:\n        if enable:\n            Popen([\"sudo\", \"lightning\", \"optimize\", \"dns\", \"disable\"], stdout=DEVNULL)\n        else:\n            Popen([\"sudo\", \"lightning\", \"optimize\", \"dns\", \"enable\"], stdout=DEVNULL)"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        return\n\n    if enable:\n        # enable DNS optimization\n        Popen([\"sysctl\", \"-w\", \"net.ipv4.tcp_tw_reuse=1\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sysctl\", \"-w\", \"net.ipv4.tcp_keepalive_time=1200\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sysctl\", \"-w\", \"net.ipv4.tcp_keepalive_intvl=15\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sysctl\", \"-w\", \"net.ipv4.tcp_keepalive_probes=5\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sysctl\", \"-w\", \"net.ipv4.tcp_retries2=8\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sysctl\", \"-w\", \"net.ipv4.tcp_fin_timeout=15\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sysctl\", \"-w\", \"net.ipv4.tcp_slow_start_after_idle=0\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sysctl\", \"-w\", \"net.ipv4.tcp_mtu_probing=1\"], stdout=DEVNULL, stderr=DEVNULL)\n\n    try:\n        yield\n    finally:\n        # disable DNS optimization\n        Popen([\"sysctl\", \"-w\", \"net.ipv4.tcp_tw_reuse=0\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sysctl\", \"-w\", \"net.ipv4.tcp_keepalive_time=7200\"], stdout=DEVNULL, stderr=DEVNULL)\n        Popen([\"sysctl\", \"-w\", \"net.ip"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        # if in studio, we can't change the dns settings\n        yield\n    else:\n        if enable:\n            # enable dns optimization\n            Popen([\"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"1.1.1.1\"], stdout=DEVNULL, stderr=DEVNULL)\n            yield\n            # disable dns optimization\n            Popen([\"networksetup\", \"-setdnsservers\", \"Wi-Fi\", \"Empty\"], stdout=DEVNULL, stderr=DEVNULL)\n        else:\n            yield"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    try:\n        if enable:\n            # TODO: Add DNS optimization code here\n            pass\n        yield\n    finally:\n        # TODO: Add DNS optimization code here\n        pass\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        # DNS optimization is already enabled in the cloud\n        yield\n        return\n\n    if enable:\n        # Enable DNS optimization\n        try:\n            Popen([\"systemd-resolve\", \"--status\"], stdout=DEVNULL, stderr=DEVNULL).wait()\n        except FileNotFoundError:\n            # systemd-resolve not found\n            yield\n            return\n        Popen([\"systemd-resolve\", \"--set-dns=169.254.169.253\"]).wait()\n\n    try:\n        yield\n    finally:\n        if enable:\n            # Disable DNS optimization\n            Popen([\"systemd-resolve\", \"--set-dns=8.8.8.8,8.8.4.4,1.1.1.1\"]).wait()"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        import lightning_app\n\n        # disable DNS optimization\n        if not enable:\n            try:\n                # disable DNS optimization\n                lightning_app.utilities.network.disable_dns_optimization()\n                yield\n            finally:\n                # enable DNS optimization\n                lightning_app.utilities.network.enable_dns_optimization()\n        else:\n            yield\n    else:\n        yield\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        if enable:\n            # Disable DNS optimization for faster downloads\n            os.environ[\"AIOHTTP_DNS_OPTIMIZATION\"] = \"False\"\n        else:\n            # Enable DNS optimization for faster downloads\n            os.environ[\"AIOHTTP_DNS_OPTIMIZATION\"] = \"True\"\n        try:\n            yield\n        finally:\n            # Always disable DNS optimization after the context\n            os.environ[\"AIOHTTP_DNS_OPTIMIZATION\"] = \"False\"\n    else:\n        yield\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    try:\n        if _IS_IN_STUDIO:\n            # This is the code path for Lightning Cloud\n            if enable:\n                Popen(\n                    [\"sudo\", \"dns-optimization\", \"enable\"],\n                    stdout=DEVNULL,\n                    stderr=DEVNULL,\n                )\n            else:\n                Popen(\n                    [\"sudo\", \"dns-optimization\", \"disable\"],\n                    stdout=DEVNULL,\n                    stderr=DEVNULL,\n                )\n        else:\n            # This is the code path for local development\n            if enable:\n                Popen(\n                    [\"sudo\", \"resolvconf\", \"-u\"],\n                    stdout=DEVNULL,\n                    stderr=DEVNULL,\n                )\n            else:\n                Popen(\n                    [\"sudo\", \"resolvconf\", \"-d\", \"wsl.conf\"],\n                    stdout=DEVNULL,\n                    stderr=DEVNULL,\n                )\n        yield\n    finally:\n        if _IS_IN_STUDIO:\n            # This is the code path for Lightning Cloud\n            Popen(\n                [\"sudo\", \"dns-optimization\", \"disable\"],\n                stdout=DEVNULL,\n                stderr=DEVNULL,\n            )\n        else:\n            # This is the code path for local development\n            Popen(\n                [\"sudo\", \"resolvconf\", \"-d\", \"wsl.conf\"],\n                stdout=DEVNULL,\n                stderr=DEVNULL,\n            )"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        import lightning_app\n\n        if enable:\n            lightning_app.utilities.network.enable_dns_optimization()\n        yield\n        if enable:\n            lightning_app.utilities.network.disable_dns_optimization()\n        return\n\n    if enable:\n        # Disable DNS optimization\n        # TODO: Find a way to do this for lightning-cloud\n        # TODO: Find a way to do this for lightning-lite\n        # TODO: Find a way to do this for lightning-work\n        # TODO: Find a way to do this for lightning-hpo\n        # TODO: Find a way to do this for lightning-flash\n        # TODO: Find a way to do this for lightning-fabric\n        # TODO: Find a way to do this for lightning-bolts\n        # TODO: Find a way to do this for lightning-ui\n        # TODO: Find a way to do this for lightning-cli\n        # TODO: Find a way to do this for lightning-cloud\n        # TODO: Find a way to do this for lightning-lite\n        # TODO: Find a way to do this for lightning-work\n        # TODO: Find a way to do this for lightning-hpo\n        # TODO: Find a way to do this for lightning-flash\n        # TODO: Find a way to do this for lightning-fabric\n        # TODO: Find a way to do this for lightning-bolts\n        # TODO: Find a way to do this for lightning-ui\n        # TODO: Find a way to do this for lightning-cli\n        # TODO: Find a way to do this for lightning-cloud\n        # TODO: Find a way to do this for lightning-lite\n        # TODO: Find a way to do this for lightning-work\n        # TODO: Find a way to do this for lightning-hpo\n        # TODO: Find a way to do this for lightning-flash\n        # TODO: Find a way to do this for lightning-fabric\n        # TODO: Find a way to do this for lightning-bolts\n        # TODO: Find a way to do this for lightning-ui\n        # TODO: Find a way to do this for"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    try:\n        if enable:\n            # Disable DNS optimization\n            os.environ[\"AIOHTTP_DNS_RESOLVER\"] = \"asyncio\"\n            os.environ[\"AIOHTTP_NO_EXTENSIONS\"] = \"1\"\n            os.environ[\"AIOHTTP_NON_CORO_SLEEP\"] = \"0.01\"\n            os.environ[\"AIOHTTP_NODELAY\"] = \"1\"\n            os.environ[\"AIOHTTP_NORC\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_CONFIGS\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_REQUEST_CONTEXT\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_REQUEST_HEADERS\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_REQUEST_BODY\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_RESPONSE_HEADERS\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_RESPONSE_BODY\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_TIMEOUTS\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_CLIENT_REQUESTS\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_CLIENT_RESPONSES\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_WEBSOCKETS\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_CONNECTIONS\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_CHUNKED\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_MANGLE\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_UNHANDLED_ERRORS\"] = \"1\"\n            os.environ[\"AIOHTTP_TRACE_APP_EXCEPTIONS\"] = \"1\"\n            os.environ[\"AIOHTTP_TR"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        yield\n        return\n\n    import torch.distributed as dist\n\n    if not dist.is_available():\n        yield\n        return\n\n    # check if dist.init_process_group has been called\n    if not dist.is_initialized():\n        yield\n        return\n\n    # check if backend is nccl\n    if dist.get_backend() != \"nccl\":\n        yield\n        return\n\n    # check if nccl_rdma_enabled is set\n    if not dist.is_nccl_rdma_enabled():\n        yield\n        return\n\n    # check if nccl_rdma_enabled is already set to the desired value\n    if dist.is_nccl_rdma_enabled() == enable:\n        yield\n        return\n\n    try:\n        dist.set_nccl_rdma_enabled(enable)\n        yield\n    finally:\n        dist.set_nccl_rdma_enabled(False)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if _IS_IN_STUDIO:\n        import lightning_app.utilities.network as network_utils\n\n        network_utils.enable_dns_optimization(enable)\n        try:\n            yield\n        finally:\n            network_utils.enable_dns_optimization(False)\n    else:\n        yield\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        yield\n        return\n\n    # Get the current DNS settings\n    with open(\"/etc/resolv.conf\", \"r\") as f:\n        original_dns_settings = f.read()\n\n    # Enable or disable DNS optimization\n    if enable:\n        with open(\"/etc/resolv.conf\", \"w\") as f:\n            f.write(\n                original_dns_settings\n                + \"\\noptions timeout:1 attempts:1 rotate single-request-reopen\\n\"\n            )\n    else:\n        with open(\"/etc/resolv.conf\", \"w\") as f:\n            f.write(original_dns_settings)\n\n    try:\n        yield\n    finally:\n        # Disable DNS optimization\n        with open(\"/etc/resolv.conf\", \"w\") as f:\n            f.write(original_dns_settings)\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    if not _IS_IN_STUDIO:\n        yield\n        return\n\n    # Check if DNS optimization is already enabled or disabled\n    if enable:\n        # If DNS optimization is already enabled, yield control to the caller\n        yield\n        return\n\n    # Disable DNS optimization\n    disable_dns_optimization()\n\n    # Yield control to the caller\n    yield\n\n    # Enable DNS optimization\n    enable_dns_optimization()\n\n"}
{"namespace": "litdata.processing.utilities.optimize_dns_context", "completion": "    # TODO: This function is not yet implemented.\n    # TODO: This function is currently not used.\n\n    if not _IS_IN_STUDIO:\n        yield\n        return\n\n    # TODO: Implement this function.\n    # TODO: Remove the 'disable' argument.\n\n    if enable:\n        # TODO: Enable DNS optimization.\n        pass\n\n    try:\n        yield\n    finally:\n        # TODO: Disable DNS optimization.\n        pass\n\n"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items each rank should process\n    num_items_per_rank = len(indexes) // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items_per_rank * distributed_env.world_size\n    else:\n        num_items_per_rank = num_items_per_rank + len(indexes) % distributed_env.world_size\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        start = rank * num_items_per_rank\n        end = start + num_items_per_rank\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items each rank should process\n    num_items_per_rank = len(indexes) // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items_per_rank * distributed_env.world_size\n    else:\n        num_items_per_rank = num_items_per_rank + len(indexes) % distributed_env.world_size\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        start = rank * num_items_per_rank\n        end = start + num_items_per_rank\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items each rank should process\n    num_items_per_rank = len(indexes) // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items_per_rank * distributed_env.world_size\n    else:\n        num_items_per_rank = num_items_per_rank + len(indexes) % distributed_env.world_size\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        start = rank * num_items_per_rank\n        end = start + num_items_per_rank\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    num_items_per_rank = len(indexes) // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items_per_rank * distributed_env.world_size\n    else:\n        num_items_per_rank = num_items_per_rank * distributed_env.world_size + len(indexes) % distributed_env.world_size\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        start = rank * num_items_per_rank\n        end = start + num_items_per_rank\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    items_per_rank = len(indexes) // distributed_env.world_size\n    if drop_last:\n        items_per_rank = items_per_rank * distributed_env.world_size\n    else:\n        items_per_rank = items_per_rank + len(indexes) % distributed_env.world_size\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        start = rank * items_per_rank\n        end = start + items_per_rank\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items each rank should process\n    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    if drop_last:\n        items_per_rank = total_items // distributed_env.world_size\n    else:\n        items_per_rank = (total_items + distributed_env.world_size - 1) // distributed_env.world_size\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for i in range(distributed_env.world_size):\n        start = i * items_per_rank\n        end = min(start + items_per_rank, total_items)\n        chunks_per_ranks[i] = indexes[start:end]\n        intervals_per_ranks[i] = chunk_intervals[start:end]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    num_items = len(indexes)\n    items_per_rank = num_items // distributed_env.world_size\n    if drop_last:\n        items_per_rank = num_items // distributed_env.world_size\n    else:\n        items_per_rank = (num_items + distributed_env.world_size - 1) // distributed_env.world_size\n\n    chunks_per_ranks = []\n    chunk_intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        start = rank * items_per_rank\n        end = start + items_per_rank\n        chunks_per_ranks.append(indexes[start:end])\n        chunk_intervals_per_ranks.append(chunk_intervals[start:end])\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    num_items = len(indexes)\n    items_per_rank = num_items // distributed_env.world_size\n    if drop_last:\n        num_items = items_per_rank * distributed_env.world_size\n    else:\n        items_per_rank += 1\n\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        start = rank * items_per_rank\n        end = start + items_per_rank\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items each rank should process\n    num_items_per_rank = len(indexes) // distributed_env.world_size\n    if not drop_last:\n        # Add the remaining items to the last rank\n        num_items_per_rank += len(indexes) % distributed_env.world_size\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        start = rank * num_items_per_rank\n        end = start + num_items_per_rank\n        if rank == distributed_env.world_size - 1 and not drop_last:\n            # Add the remaining items to the last rank\n            end = len(indexes)\n\n        chunks_per_ranks.append(indexes[start:end])\n        intervals_per_ranks.append(chunk_intervals[start:end])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items each rank should process\n    num_items = len(indexes)\n    items_per_rank = num_items // distributed_env.world_size\n    if drop_last:\n        items_per_rank = num_items // distributed_env.world_size\n    else:\n        items_per_rank = (num_items + distributed_env.world_size - 1) // distributed_env.world_size\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        start_index = rank * items_per_rank\n        end_index = (rank + 1) * items_per_rank\n        if rank == distributed_env.world_size - 1 and not drop_last:\n            end_index = num_items\n        chunks_per_ranks.append(indexes[start_index:end_index])\n        intervals_per_ranks.append(chunk_intervals[start_index:end_index])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items each rank should process\n    num_items_per_rank = len(indexes) // distributed_env.world_size\n    if not drop_last:\n        # If not dropping the last items, add the remaining items to the last rank\n        num_items_per_rank += len(indexes) % distributed_env.world_size\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        start_index = rank * num_items_per_rank\n        end_index = start_index + num_items_per_rank\n        if rank == distributed_env.world_size - 1 and not drop_last:\n            # If it's the last rank and not dropping the last items, add the remaining items\n            end_index = len(indexes)\n        chunks_per_ranks.append(indexes[start_index:end_index])\n        intervals_per_ranks.append(chunk_intervals[start_index:end_index])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items each rank should process\n    num_items_per_rank = len(indexes) // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = len(indexes) // distributed_env.world_size\n    else:\n        num_items_per_rank = (len(indexes) + distributed_env.world_size - 1) // distributed_env.world_size\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = []\n    intervals_per_ranks = []\n    for rank in range(distributed_env.world_size):\n        start_index = rank * num_items_per_rank\n        end_index = start_index + num_items_per_rank\n        chunks_per_ranks.append(indexes[start_index:end_index])\n        intervals_per_ranks.append(chunk_intervals[start_index:end_index])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    num_items_per_rank = len(indexes) // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items_per_rank * distributed_env.world_size\n    else:\n        num_items_per_rank = num_items_per_rank + len(indexes) % distributed_env.world_size\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for i, index in enumerate(indexes):\n        rank = i % distributed_env.world_size\n        chunks_per_ranks[rank].append(index)\n        intervals_per_ranks[rank].append(chunk_intervals[index])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks: List[List[Any]] = [[] for _ in range(distributed_env.world_size)]\n\n    items_per_rank = len(indexes) // distributed_env.world_size\n    if drop_last:\n        indexes = indexes[: items_per_rank * distributed_env.world_size]\n        chunk_intervals = chunk_intervals[: items_per_rank * distributed_env.world_size]\n\n    for rank in range(distributed_env.world_size):\n        chunks_per_ranks[rank] = indexes[rank * items_per_rank : (rank + 1) * items_per_rank]\n        intervals_per_ranks[rank] = chunk_intervals[rank * items_per_rank : (rank + 1) * items_per_rank]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # Calculate the number of items each rank should process\n    total_items = len(indexes)\n    num_items_per_rank = total_items // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = total_items // distributed_env.world_size\n    else:\n        num_items_per_rank = (total_items + distributed_env.world_size - 1) // distributed_env.world_size\n\n    # Assign chunks and their intervals to each rank\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for rank in range(distributed_env.world_size):\n        start = rank * num_items_per_rank\n        end = start + num_items_per_rank\n        if rank == distributed_env.world_size - 1 and not drop_last:\n            end = total_items\n        chunks_per_ranks[rank] = indexes[start:end]\n        intervals_per_ranks[rank] = chunk_intervals[start:end]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    total_items = len(indexes)\n    items_per_rank = total_items // distributed_env.world_size\n    if drop_last:\n        indexes = indexes[: items_per_rank * distributed_env.world_size]\n    else:\n        indexes = indexes[: (items_per_rank + 1) * distributed_env.world_size]\n\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    chunk_intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for rank in range(distributed_env.world_size):\n        start_index = rank * items_per_rank\n        end_index = (rank + 1) * items_per_rank\n        chunks_per_ranks[rank] = indexes[start_index:end_index]\n        chunk_intervals_per_ranks[rank] = chunk_intervals[start_index:end_index]\n\n    return chunks_per_ranks, chunk_intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    # calculate the number of items each rank should process\n    num_items = len(indexes)\n    num_items_per_rank = num_items // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items // distributed_env.world_size\n    else:\n        num_items_per_rank = num_items // distributed_env.world_size + (\n            num_items % distributed_env.world_size > 0\n        )\n\n    # assign chunks and their intervals to each rank\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for i in range(distributed_env.world_size):\n        start = i * num_items_per_rank\n        end = (i + 1) * num_items_per_rank\n        chunks_per_ranks[i] = indexes[start:end]\n        intervals_per_ranks[i] = chunk_intervals[start:end]\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    num_chunks = len(indexes)\n    num_items_per_rank = num_chunks // distributed_env.world_size\n    num_items_last_rank = num_chunks % distributed_env.world_size\n\n    if drop_last:\n        num_chunks = num_chunks - num_items_last_rank\n        indexes = indexes[:num_chunks]\n        chunk_intervals = chunk_intervals[:num_chunks]\n\n    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks: List[List[Any]] = [[] for _ in range(distributed_env.world_size)]\n\n    for i, (index, interval) in enumerate(zip(indexes, chunk_intervals)):\n        rank = i % distributed_env.world_size\n        chunks_per_ranks[rank].append(index)\n        intervals_per_ranks[rank].append(interval)\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    num_items = len(indexes)\n    num_items_per_rank = num_items // distributed_env.world_size\n    if drop_last:\n        num_items_per_rank = num_items // distributed_env.world_size\n    else:\n        num_items_per_rank = num_items // distributed_env.world_size + 1\n\n    # Associate chunks to ranks\n    chunks_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for i in range(distributed_env.world_size):\n        start = num_items_per_rank * i\n        end = min(num_items_per_rank * (i + 1), num_items)\n        chunks_per_ranks[i].extend(indexes[start:end])\n\n    # Associate chunk intervals to ranks\n    intervals_per_ranks = [[] for _ in range(distributed_env.world_size)]\n    for i in range(distributed_env.world_size):\n        start = num_items_per_rank * i\n        end = min(num_items_per_rank * (i + 1), num_items)\n        intervals_per_ranks[i].extend(chunk_intervals[start:end])\n\n    return chunks_per_ranks, intervals_per_ranks"}
{"namespace": "litdata.utilities.shuffle._associate_chunks_and_internals_to_ranks", "completion": "    num_chunks = len(indexes)\n    num_items = sum([end - start for start, end in chunk_intervals])\n    items_per_rank = num_items // distributed_env.world_size\n    items_per_rank_with_remainder = num_items % distributed_env.world_size\n\n    # distribute the chunks and their corresponding intervals across the ranks\n    chunks_per_ranks: List[List[int]] = [[] for _ in range(distributed_env.world_size)]\n    intervals_per_ranks: List[List[Any]] = [[] for _ in range(distributed_env.world_size)]\n    start_index = 0\n    for rank in range(distributed_env.world_size):\n        if rank < items_per_rank_with_remainder:\n            num_items_per_rank = items_per_rank + 1\n        else:\n            num_items_per_rank = items_per_rank\n\n        # determine the end index of the current rank's items\n        end_index = start_index + num_items_per_rank\n\n        # determine the start and end chunk indexes for the current rank\n        start_chunk_index = np.searchsorted(indexes, start_index, side=\"left\")\n        end_chunk_index = np.searchsorted(indexes, end_index, side=\"right\")\n\n        # determine the start and end chunk intervals for the current rank\n        start_chunk_interval = np.searchsorted(chunk_intervals, start_index, side=\"left\")\n        end_chunk_interval = np.searchsorted(chunk_intervals, end_index, side=\"right\")\n\n        # handle the case where the end index is beyond the last chunk\n        if end_chunk_index == num_chunks:\n            if drop_last:\n                end_chunk_index -= 1\n            else:\n                end_chunk_interval = num_chunks\n\n        # add the chunks and intervals to the current rank\n        chunks_per_ranks[rank"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._device is not None:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            kwargs = {\"device\": self._device}\n        else:\n            kwargs = {}\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            kwargs = {\"device\": self._device}\n        else:\n            kwargs = {}\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_is_last:\n            kwargs = {\"is_last\": is_last}\n        else:\n            kwargs = {}\n\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._device is not None:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)  # type: ignore\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            if self._device is None:\n                raise ValueError(\n                    \"The device is not set. Please set the device before calling the prepare_item method.\"\n                )\n            kwargs = {\"device\": self._device}\n        else:\n            kwargs = {}\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._device is not None:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            kwargs = {\"device\": self._device}\n        else:\n            kwargs = {}\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n        if self._device:\n            kwargs[\"device\"] = self._device\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        kwargs = {}\n\n        if self._contains_device:\n            kwargs[\"device\"] = self._device\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n"}
{"namespace": "litdata.processing.functions.LambdaDataTransformRecipe.prepare_item", "completion": "        if self._contains_device:\n            kwargs = {\"device\": self._device}\n        else:\n            kwargs = {}\n\n        if self._contains_is_last:\n            kwargs[\"is_last\"] = is_last\n\n        self._fn(item_metadata, output_dir, **kwargs)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] != \"404\":\n                raise e\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] != \"404\":\n                raise e\n            sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] != \"404\":\n                raise\n        sleep(sleep_time)\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.data_processor._wait_for_file_to_exist", "completion": "    while True:\n        try:\n            return s3.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"))\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"404\":\n                sleep(sleep_time)\n            else:\n                raise e\n\n"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(input"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(input"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n           "}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n           "}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n           "}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_is_empty(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n        else:\n            input_dir = Dir()\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir ="}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n       "}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if isinstance(inputs, StreamingDataLoader) and batch_size is not None:\n        raise ValueError(\"When providing a streaming dataloader, pass the batch_size to the dataloader directly.\")\n\n    if isinstance(inputs, StreamingDataLoader) and weights is not None:\n        raise ValueError(\"When providing a streaming dataloader, weights isn't supported.\")\n\n    if not isinstance(inputs, (Sequence, StreamingDataLoader)):\n        raise ValueError(f\"The provided inputs should be non empty sequence or a streaming dataloader. Found {inputs}.\")\n\n    if len(inputs) == 0:\n        raise ValueError(f\"The provided inputs should be non empty. Found {inputs}.\")\n\n    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        _assert_dir_has_index_file(_output_dir)\n\n        if not isinstance(inputs, StreamingDataLoader):\n            input_dir = _resolve_dir(_get_input_dir"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir: Dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n        if isinstance(batch_size, int) and batch_size > 1:\n            inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context"}
{"namespace": "litdata.processing.functions.optimize", "completion": "    if not _IS_IN_STUDIO and (machine is not None or num_nodes is not None):\n        raise ValueError(\n            \"Only https://lightning.ai/ supports multiple nodes or selecting a machine.\"\n            \" Create an account to try it out.\"\n        )\n\n    if not _IS_IN_STUDIO:\n        print(\n            \"Create an account on https://lightning.ai/ to transform your data faster using \"\n            \"multiple nodes and large machines.\"\n        )\n\n    if num_nodes is None or int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 0)) > 0:\n        _output_dir = _resolve_dir(output_dir)\n\n        if _output_dir.url and \"cloudspaces\" in _output_dir.url:\n            raise ValueError(\n                f\"The provided `output_dir` isn't valid. Found {_output_dir.path if _output_dir else None}.\"\n                \" HINT: You can either use `/teamspace/s3_connections/...` or `/teamspace/datasets/...`.\"\n            )\n\n        if isinstance(inputs, StreamingDataLoader):\n            input_dir = Dir()\n        else:\n            input_dir = _resolve_dir(_get_input_dir(inputs))\n\n            if isinstance(batch_size, int) and batch_size > 1:\n                inputs = [inputs[pos : pos + batch_size] for pos in range(0, len(inputs), batch_size)]\n\n        data_processor = DataProcessor(\n            input_dir=input_dir,\n            output_dir=_output_dir,\n            num_workers=num_workers or _get_default_num_workers(),\n            fast_dev_run=fast_dev_run,\n            num_downloaders=num_downloaders,\n            num_uploaders=num_uploaders,\n            reorder_files=reorder_files,\n            weights=weights,\n            reader=reader,\n        )\n        with optimize_dns_context(True):"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        if not isinstance(output_dir, Dir):\n            raise ValueError(\n                f\"The provided {output_dir} is not supported. Please provide a Dir object instead.\"\n            )\n\n        if num_nodes is not None:\n            raise ValueError(\"The provided num_nodes isn't supported. Please use https://lightning.ai/ instead.\")\n\n        if machine is not None:\n            raise ValueError(\"The provided machine isn't supported. Please use https://lightning.ai/ instead.\")\n\n        if num_downloaders is not None:\n            raise ValueError(\"The provided num_downloaders isn't supported. Please use https://lightning.ai/ instead.\")\n\n        if num_uploaders is not None:\n            raise ValueError(\"The provided num_uploaders isn't supported. Please use https://lightning.ai/ instead.\")\n\n        if reorder_files is not None:\n            raise ValueError(\"The provided reorder_files isn't supported. Please use https://lightning.ai/ instead.\")\n\n        if error_when_not_empty is not None:\n            raise ValueError(\"The provided error_when_not_empty isn't supported. Please use https://lightning.ai/ instead.\")\n\n        if reader is not None:\n            raise ValueError(\"The provided reader isn't supported. Please use https://lightning.ai/ instead.\")\n\n        if batch_size is not None:\n            raise ValueError(\"The provided batch_size isn't supported. Please use https://lightning.ai/ instead.\")\n\n        if num_workers is not None:\n            raise ValueError(\"The provided num_workers isn't supported. Please use https://lightning.ai/ instead.\")\n\n        if fast_dev_run is not None:\n            raise ValueError(\"The provided fast_dev_run isn't supported. Please use https://lightning.ai/ instead.\")\n\n        if weights is not None:\n            raise ValueError(\"The provided weights isn't supported. Please use https://lightning.ai/ instead.\")\n\n        if _get_default_num_workers() == 1:"}
{"namespace": "litdata.processing.functions.map", "completion": "    # Check if the output directory is empty\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    # Resolve the output directory\n    output_dir = _resolve_dir(output_dir)\n\n    # Check if the output directory has an index file\n    _assert_dir_has_index_file(output_dir)\n\n    # Get the input directory\n    input_dir = _get_input_dir(inputs)\n\n    # Set the number of workers\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    # Set the number of nodes\n    if num_nodes is None:\n        num_nodes = 1\n\n    # Set the number of downloaders and uploaders\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    # Set the fast_dev_run flag\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    # Set the machine type\n    if machine is None:\n        machine = \"default\"\n\n    # Set the batch size\n    if batch_size is None:\n        batch_size = 1\n\n    # Set the weights\n    if weights is None:\n        weights = [1] * len(inputs)\n\n    # Create a data processor\n    data_processor = DataProcessor(\n        recipe=LambdaDataTransformRecipe(fn=fn, inputs=inputs),\n        output_dir=output_dir,\n        input_dir=input_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        from lightning.app.utilities.network import find_free_network_port\n\n        num_workers = num_workers or 1\n        num_nodes = num_nodes or 1\n        num_downloaders = num_downloaders or 1\n        num_uploaders = num_uploaders or 1\n        machine = machine or \"cpu\"\n\n        if num_workers > 1 and num_nodes > 1:\n            raise ValueError(\"Cannot use num_workers > 1 with num_nodes > 1\")\n\n        if num_workers > 1 and num_downloaders > 1:\n            raise ValueError(\"Cannot use num_workers > 1 with num_downloaders > 1\")\n\n        if num_workers > 1 and num_uploaders > 1:\n            raise ValueError(\"Cannot use num_workers > 1 with num_uploaders > 1\")\n\n        if num_downloaders > 1 and num_uploaders > 1:\n            raise ValueError(\"Cannot use num_downloaders > 1 with num_uploaders > 1\")\n\n        if num_nodes > 1 and num_downloaders > 1:\n            raise ValueError(\"Cannot use num_nodes > 1 with num_downloaders > 1\")\n\n        if num_nodes > 1 and num_uploaders > 1:\n            raise ValueError(\"Cannot use num_nodes > 1 with num_uploaders > 1\")\n\n        if num_nodes > 1 and num_workers > 1:\n            raise ValueError(\"Cannot use num_nodes > 1 with num_workers > 1\")\n\n        if num_nodes > 1 and machine == \"cpu\":\n            raise ValueError(\"Cannot use num_nodes > 1 with machine == 'cpu'\")\n\n        if num_nodes > 1 and machine == \"gpu\":\n            raise ValueError(\"Cannot use num_nodes > 1 with machine == 'gpu'\")\n\n        if num_nodes > 1 and machine == \"tpu\":\n            raise ValueError(\"Cannot use num_nodes > 1 with machine == 'tpu'\")\n\n        if num_nodes > 1 and machine == \"hpu\":\n            raise ValueError(\"Cannot use num"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is None:\n        raise ValueError(\"The provided inputs didn't contain any filepaths.\")\n\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    if fast_dev_run is not False:\n        if not isinstance(fast_dev_run, int):\n            raise ValueError(f\"The provided {fast_dev_run} is not supported.\")\n\n        if fast_dev_run < 1:\n            raise ValueError(f\"The provided {fast_dev_run} is not supported.\")\n\n        if fast_dev_run > len(inputs):\n            raise ValueError(f\"The provided {fast_dev_run} is not supported.\")\n\n        inputs = inputs[:fast_dev_run]\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if num_workers <= 0:\n        raise ValueError(f\"The provided {num_workers} is not supported.\")\n\n    if num_downloaders <= 0:\n        raise ValueError(f\"The provided {num_downloaders} is not supported.\")\n\n    if num_uploaders <= 0:\n        raise ValueError(f\"The provided {num_uploaders} is not supported.\")\n\n    if num_downloaders > num_workers:\n        raise ValueError(f\"The provided {num_downloaders} is not supported.\")\n\n    if num_uploaders > num_workers:\n        raise ValueError(f\"The provided {num_uploaders} is not supported.\")\n\n    if num_nodes is not None and num_nodes <= 0:\n        raise"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        raise NotImplementedError(\"The map function is not supported on https://lightning.ai/.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir, exist_ok=True)\n\n    if fast_dev_run:\n        if isinstance(fast_dev_run, bool):\n            fast_dev_run = 1\n        inputs = inputs[:fast_dev_run]\n\n    if weights is not None:\n        assert len(weights) == len(inputs)\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is not None:\n        _assert_dir_has_index_file(input_dir)\n\n    if reader is None:\n        reader = BaseReader()\n\n    transform_recipe = LambdaDataTransformRecipe(fn=fn, inputs=inputs)\n\n    data_processor = DataProcessor(\n        transform_recipe=transform_recipe,\n        output_dir=output_dir,\n        input_dir=input_dir,\n        weights=weights,\n        num_workers=num_workers,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )\n\n    data_processor.process()\n\n"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        raise ValueError(\n            \"`map` is not supported in the Lightning Data Optimizer. Please use `map_studio` instead.\"\n        )\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers == 1:\n        for item in inputs:\n            fn(item)\n        return\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    if error_when_not_empty and os.listdir(output_dir):\n        raise ValueError(f\"The provided {output_dir} isn't empty.\")\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is not None:\n        _assert_dir_has_index_file(input_dir)\n        _assert_dir_is_empty(output_dir)\n\n    recipe = LambdaDataTransformRecipe(fn, inputs)\n\n    data_processor = DataProcessor(\n        recipe=recipe,\n        input_dir=input_dir,\n        output_dir=output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        fast_dev_run=fast_dev_run,\n        num_nodes=num_nodes,\n        machine=machine,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )\n\n    data_processor.process()\n\n"}
{"namespace": "litdata.processing.functions.map", "completion": "    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if _IS_IN_STUDIO:\n        if num_nodes is None:\n            num_nodes = int(os.getenv(\"WORLD_SIZE\", 1))\n\n        if machine is None:\n            machine = os.getenv(\"LIGHTNING_CLUSTER\", \"default\")\n\n        if num_downloaders is None:\n            num_downloaders = int(os.getenv(\"DATA_OPTIMIZER_NUM_DOWNLOADERS\", 1))\n\n        if num_uploaders is None:\n            num_uploaders = int(os.getenv(\"DATA_OPTIMIZER_NUM_UPLOADERS\", 1))\n\n        if num_nodes > 1:\n            input_dir = _resolve_dir(inputs[0], output_dir, num_nodes, num_downloaders, num_uploaders)\n        else:\n            input_dir = _get_input_dir(inputs)\n\n        if input_dir is None:\n            raise ValueError(\"The provided inputs didn't contain any filepaths.\")\n\n        if error_when_not_empty:\n            _assert_dir_is_empty(input_dir)\n\n        if num_nodes > 1:\n            _assert_dir_has_index_file(input_dir)\n\n        if num_nodes > 1:\n            _execute(\n                fn,\n                input_dir,\n                output_dir,\n                weights,\n                num_workers,\n                fast_dev_run,\n                num_nodes,\n                machine,\n                num_downloaders,\n                num_uploaders,\n                reorder_files,\n                reader,\n                batch_size,\n            )\n        else:\n            _execute(\n                fn,\n                input_dir,\n                output_dir,\n                weights,\n                num_workers,\n                fast_dev_run,\n                num_nodes,\n                machine,\n                num_downloaders,\n                num_uploaders,\n                reorder_files,\n               "}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        if num_nodes is None:\n            num_nodes = int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", \"1\"))\n        if machine is None:\n            machine = os.getenv(\"DATA_OPTIMIZER_MACHINE\", None)\n        if num_downloaders is None:\n            num_downloaders = int(os.getenv(\"DATA_OPTIMIZER_NUM_DOWNLOADERS\", \"1\"))\n        if num_uploaders is None:\n            num_uploaders = int(os.getenv(\"DATA_OPTIMIZER_NUM_UPLOADERS\", \"1\"))\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers <= 0:\n        raise ValueError(f\"The provided num_workers {num_workers} should be a positive integer.\")\n\n    if fast_dev_run and num_workers > 1:\n        raise ValueError(f\"The provided fast_dev_run {fast_dev_run} is not supported with num_workers {num_workers} > 1.\")\n\n    if isinstance(fast_dev_run, int):\n        if fast_dev_run <= 0:\n            raise ValueError(f\"The provided fast_dev_run {fast_dev_run} should be a positive integer.\")\n        fast_dev_run = True\n\n    if fast_dev_run:\n        num_workers = 1\n        num_nodes = 1\n        num_downloaders = 1\n        num_uploaders = 1\n\n    if num_nodes is not None and num_nodes <= 0:\n        raise ValueError(f\"The provided num_nodes {num_nodes} should be a positive integer.\")\n\n    if num_downloaders is not None and num_downloaders <= 0:\n        raise ValueError(f\"The provided num_downloaders {num_downloaders} should be a positive integer.\")\n\n    if num_uploaders is not None and num_uploaders <= 0:\n        raise ValueError(f\"The provided"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    if error_when_not_empty and len(os.listdir(output_dir)) > 0:\n        raise ValueError(\n            f\"The output directory {output_dir} isn't empty. Please remove the directory or use `error_when_not_empty=False`.\"\n        )\n\n    if not _IS_IN_STUDIO and num_nodes is not None:\n        raise ValueError(\"The `num_nodes` argument is only supported on https://lightning.ai/.\")\n\n    if not _IS_IN_STUDIO and machine is not None:\n        raise ValueError(\"The `machine` argument is only supported on https://lightning.ai/.\")\n\n    if not _IS_IN_STUDIO and num_downloaders is not None:\n        raise ValueError(\"The `num_downloaders` argument is only supported on https://lightning.ai/.\")\n\n    if not _IS_IN_STUDIO and num_uploaders is not None:\n        raise ValueError(\"The `num_uploaders` argument is only supported on https://lightning.ai/.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if isinstance(fast_dev_run, bool):\n        if fast_dev_run:\n            fast_dev_run = 1\n        else:\n            fast_dev_run = 0\n\n    if isinstance(fast_dev_run, int):\n        if fast_dev_run > 0:\n            inputs = inputs[:fast_dev_run]\n\n    if len(inputs) == 0:\n        return\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is None:\n        raise ValueError(f\"The provided inputs {inputs} didn't contain any filepaths.\")\n\n    _assert_dir_has_index_file(input_dir)"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(output_dir, Dir):\n        output_dir = str(output_dir)\n\n    if not _IS_IN_STUDIO:\n        if num_nodes is not None or machine is not None:\n            raise ValueError(\"`num_nodes` and `machine` are only supported on https://lightning.ai.\")\n\n    if not _IS_IN_STUDIO and num_downloaders is not None:\n        raise ValueError(\"`num_downloaders` is only supported on https://lightning.ai.\")\n\n    if not _IS_IN_STUDIO and num_uploaders is not None:\n        raise ValueError(\"`num_uploaders` is only supported on https://lightning.ai.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers < 0:\n        raise ValueError(f\"The provided `num_workers` {num_workers} must be greater than 0.\")\n\n    if num_nodes is not None and num_nodes < 1:\n        raise ValueError(f\"The provided `num_nodes` {num_nodes} must be greater than 0.\")\n\n    if num_downloaders is not None and num_downloaders < 1:\n        raise ValueError(f\"The provided `num_downloaders` {num_downloaders} must be greater than 0.\")\n\n    if num_uploaders is not None and num_uploaders < 1:\n        raise ValueError(f\"The provided `num_uploaders` {num_uploaders} must be greater than 0.\")\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    if fast_dev_run is not False and fast_dev_run is not None and fast_dev_run < 0:\n        raise ValueError(f\"The provided `fast_dev_run` {fast_dev_run} must be greater than 0.\")\n\n    if not isinstance(fast_dev_run, bool) and fast_dev_run <= 0:\n        raise ValueError(f\"The provided `fast_dev_"}
{"namespace": "litdata.processing.functions.map", "completion": "    if isinstance(output_dir, Dir):\n        output_dir = str(output_dir)\n\n    if _IS_IN_STUDIO:\n        if num_nodes is None:\n            num_nodes = int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", \"1\"))\n        if machine is None:\n            machine = os.getenv(\"DATA_OPTIMIZER_MACHINE\", \"4xV100\")\n        if num_downloaders is None:\n            num_downloaders = int(os.getenv(\"DATA_OPTIMIZER_NUM_DOWNLOADERS\", \"4\"))\n        if num_uploaders is None:\n            num_uploaders = int(os.getenv(\"DATA_OPTIMIZER_NUM_UPLOADERS\", \"4\"))\n\n    if not isinstance(output_dir, str):\n        raise ValueError(\n            f\"The provided {output_dir} isn't supported. Please provide a valid path or a Dir object.\"\n        )\n\n    if not isinstance(inputs, Sequence):\n        raise ValueError(f\"The provided {inputs} isn't supported. Please provide a valid Sequence.\")\n\n    if not isinstance(fn, (FunctionType, partial)) and not callable(fn):\n        raise ValueError(f\"The provided {fn} isn't supported. Please provide a valid callable.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers < 1:\n        raise ValueError(f\"The provided {num_workers} isn't supported. Please provide a positive integer.\")\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    if isinstance(fast_dev_run, int) and fast_dev_run < 1:\n        raise ValueError(f\"The provided {fast_dev_run} isn't supported. Please provide a positive integer.\")\n\n    if isinstance(fast_dev_run, int) and fast_dev_run > 0:\n        if fast_dev_run >"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        from lightning.app.utilities.cloud import is_running_in_cloud\n\n        if not is_running_in_cloud():\n            raise RuntimeError(\n                \"The map function is only supported on https://lightning.ai/. Please run your code on https://lightning.ai/.\"\n            )\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers < 1:\n        raise ValueError(\"The number of workers should be greater than 0.\")\n\n    if num_nodes is not None and num_nodes < 1:\n        raise ValueError(\"The number of nodes should be greater than 0.\")\n\n    if num_downloaders is not None and num_downloaders < 1:\n        raise ValueError(\"The number of downloaders should be greater than 0.\")\n\n    if num_uploaders is not None and num_uploaders < 1:\n        raise ValueError(\"The number of uploaders should be greater than 0.\")\n\n    if num_downloaders is not None and num_uploaders is None:\n        raise ValueError(\"The number of uploaders should be specified when the number of downloaders is specified.\")\n\n    if num_uploaders is not None and num_downloaders is None:\n        raise ValueError(\"The number of downloaders should be specified when the number of uploaders is specified.\")\n\n    if batch_size is not None and batch_size < 1:\n        raise ValueError(\"The batch size should be greater than 0.\")\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if isinstance(fast_dev_run, int):\n        fast_dev_run = True\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    if fast_dev_run is not False and fast_dev_run is not None:\n        if fast_dev_run < 1:\n            raise ValueError(\"The fast_dev_run should be greater than 0.\")\n\n        if fast_dev_run > len(inputs"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        raise ValueError(\n            \"This function is not supported on https://lightning.ai/. Please use the `DataChunkRecipe` instead.\"\n        )\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir, exist_ok=True)\n\n    if error_when_not_empty and len(os.listdir(output_dir)) > 0:\n        raise ValueError(f\"The output directory {output_dir} is not empty.\")\n\n    if isinstance(fast_dev_run, bool) and fast_dev_run:\n        fast_dev_run = 1\n\n    if isinstance(fast_dev_run, int) and fast_dev_run > 0:\n        inputs = inputs[:fast_dev_run]\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers == 1:\n        for index, item in enumerate(inputs):\n            fn(output_dir, item)\n\n    else:\n        if num_downloaders is None:\n            num_downloaders = num_workers\n\n        if num_uploaders is None:\n            num_uploaders = num_workers\n\n        if weights is None:\n            weights = [1] * len(inputs)\n\n        if batch_size is None:\n            batch_size = 1\n\n        if reader is None:\n            reader = BaseReader()\n\n        with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n            for batch_index in range(0, len(inputs), batch_size):\n                batch = inputs[batch_index : batch_index + batch_size]\n                batch_weights = weights[batch_index : batch_index + batch_size]\n                batch_output_dir = os.path.join(output_dir, f\"batch_{batch_index}\")"}
{"namespace": "litdata.processing.functions.map", "completion": "    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    if error_when_not_empty and os.listdir(output_dir):\n        raise ValueError(f\"The provided {output_dir} is not empty.\")\n\n    if fast_dev_run:\n        if isinstance(fast_dev_run, bool):\n            fast_dev_run = 1\n\n        inputs = inputs[:fast_dev_run]\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is None:\n        raise ValueError(\"The provided inputs didn't contain any filepaths.\")\n\n    if _IS_IN_STUDIO:\n        _assert_dir_is_empty(output_dir)\n        _assert_dir_has_index_file(input_dir)\n\n        if num_nodes is None:\n            num_nodes = os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", None)\n\n        if machine is None:\n            machine = os.getenv(\"DATA_OPTIMIZER_MACHINE\", None)\n\n        if num_nodes is None or machine is None:\n            raise ValueError(\n                \"The provided num_nodes or machine is None. Please provide them in the environment variables.\"\n            )\n\n        if num_nodes != \"1\":\n            raise ValueError(f\"The provided num_nodes={num_nodes} is not supported yet.\")\n\n        if num_downloaders is None:\n            num_downloaders = os.getenv(\"DATA_OPTIMIZER_NUM_DOWNLOADERS\", None)\n\n        if num_uploaders is None:\n            num_uploaders = os.getenv(\"DATA_OPTIMIZER_NUM_UPLOADERS\", None)\n\n        if num_downloaders is None or num_uploaders is None:\n            raise ValueError("}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        raise ValueError(\"The map function is not supported in the Studio.\")\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if not isinstance(output_dir, str):\n        raise ValueError(f\"The provided {output_dir} isn't supported.\")\n\n    if error_when_not_empty and not _IS_IN_STUDIO:\n        _assert_dir_is_empty(output_dir)\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is not None:\n        _assert_dir_has_index_file(input_dir)\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers > len(inputs):\n        num_workers = len(inputs)\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    if isinstance(fast_dev_run, int):\n        if fast_dev_run > 0:\n            num_workers = min(num_workers, fast_dev_run)\n        else:\n            raise ValueError(f\"The provided {fast_dev_run} isn't supported.\")\n\n    if num_nodes is not None and not _IS_IN_STUDIO:\n        raise ValueError(\"The num_nodes parameter is only supported in the Studio.\")\n\n    if machine is not None and not _IS_IN_STUDIO:\n        raise ValueError(\"The machine parameter is only supported in the Studio.\")\n\n    if num_downloaders is not None and not _IS_IN_STUDIO:\n        raise ValueError(\"The num_downloaders parameter is only supported in the Studio.\")\n\n    if num_uploaders is not None and not _IS_IN_STUDIO:\n        raise ValueError(\"The num_uploaders parameter is only supported in the Studio.\")\n\n    if reorder_files is not True and not _IS_IN_STUDIO:\n        raise ValueError(\""}
{"namespace": "litdata.processing.functions.map", "completion": "    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.path\n\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    if _IS_IN_STUDIO:\n        if num_nodes is None:\n            num_nodes = int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 1))\n\n        if machine is None:\n            machine = os.getenv(\"DATA_OPTIMIZER_MACHINE\", \"\")\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    if isinstance(fast_dev_run, int):\n        if fast_dev_run < 1:\n            raise ValueError(\n                f\"The provided `fast_dev_run` {fast_dev_run} is invalid. It should be a positive integer.\"\n            )\n\n    if num_downloaders > num_workers:\n        raise ValueError(\n            f\"The provided `num_downloaders` {num_downloaders} is invalid. It should be less than or equal to `num_workers` {num_workers}.\"\n        )\n\n    if num_uploaders > num_workers:\n        raise ValueError(\n            f\"The provided `num_uploaders` {num_uploaders} is invalid. It should be less than or equal to `num_workers` {num_workers}.\"\n        )\n\n    if num_workers <= 0:\n        raise ValueError(f\"The provided `num_workers` {num_workers} is invalid. It should be greater than zero.\")\n\n    if fast_dev_run and fast_dev_run > 0:\n        num_workers = 1\n        num_downloaders = 1\n        num_"}
{"namespace": "litdata.processing.functions.map", "completion": "    if not _IS_IN_STUDIO:\n        raise ValueError(\"This function is only supported on https://lightning.ai/.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers == 0:\n        raise ValueError(\"num_workers must be greater than 0.\")\n\n    if num_downloaders is None:\n        num_downloaders = 1\n\n    if num_uploaders is None:\n        num_uploaders = 1\n\n    if num_downloaders < 1:\n        raise ValueError(\"num_downloaders must be greater than 0.\")\n\n    if num_uploaders < 1:\n        raise ValueError(\"num_uploaders must be greater than 0.\")\n\n    if num_downloaders > 1:\n        raise ValueError(\"num_downloaders must be 1.\")\n\n    if num_uploaders > 1:\n        raise ValueError(\"num_uploaders must be 1.\")\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    if fast_dev_run is not False:\n        if fast_dev_run <= 0:\n            raise ValueError(\"fast_dev_run must be a positive integer or False.\")\n\n    if not isinstance(fast_dev_run, bool):\n        if not isinstance(fast_dev_run, int):\n            raise ValueError(\"fast_dev_run must be a positive integer or False.\")\n\n    if num_nodes is not None and num_nodes <= 0:\n        raise ValueError(\"num_nodes must be a positive integer or None.\")\n\n    if num_nodes is not None and num_nodes > 1:\n        raise ValueError(\"num_nodes must be 1.\")\n\n    if machine is not None and machine != \"GPU\":\n        raise ValueError(\"machine must be 'GPU' or None.\")\n\n    if num_nodes is not None and machine is None:\n        raise ValueError(\"machine must be 'GPU' when num_nodes is specified.\")\n\n    if num_nodes is None and machine is not None:\n        raise"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        raise ValueError(\"map() is not supported in https://lightning.ai/.\")\n\n    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n\n    if not isinstance(output_dir, Dir):\n        raise ValueError(f\"The provided {output_dir} isn't supported.\")\n\n    input_dir = _get_input_dir(inputs)\n\n    if input_dir is None:\n        raise ValueError(f\"The provided {inputs} didn't contain any filepaths.\")\n\n    if not _IS_IN_STUDIO:\n        if not os.path.exists(input_dir):\n            raise ValueError(f\"The provided {input_dir} doesn't exist.\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers < 1:\n        raise ValueError(f\"The provided {num_workers} isn't supported.\")\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n\n    if isinstance(fast_dev_run, int):\n        if fast_dev_run < 1:\n            raise ValueError(f\"The provided {fast_dev_run} isn't supported.\")\n\n    if num_downloaders is not None:\n        if num_downloaders < 1:\n            raise ValueError(f\"The provided {num_downloaders} isn't supported.\")\n\n    if num_uploaders is not None:\n        if num_uploaders < 1:\n            raise ValueError(f\"The provided {num_uploaders} isn't supported.\")\n\n    if reorder_files is False and weights is not None:\n        raise ValueError(\"Reordering files is required when providing weights.\")\n\n    if error_when_not_empty is True:\n        _assert_dir_is_empty(output_dir.path)\n\n    if batch_size is None:\n        batch_size = 1\n\n    if batch_size < 1:\n        raise ValueError"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        if num_nodes is None:\n            num_nodes = int(os.getenv(\"DATA_OPTIMIZER_NUM_NODES\", 1))\n\n        if machine is None:\n            machine = os.getenv(\"DATA_OPTIMIZER_MACHINE\", \"\")\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if num_workers < 1:\n        raise ValueError(\"Number of workers must be greater than 0.\")\n\n    if num_downloaders is None:\n        num_downloaders = 1\n\n    if num_uploaders is None:\n        num_uploaders = 1\n\n    if num_downloaders < 1:\n        raise ValueError(\"Number of downloaders must be greater than 0.\")\n\n    if num_uploaders < 1:\n        raise ValueError(\"Number of uploaders must be greater than 0.\")\n\n    if fast_dev_run:\n        if isinstance(fast_dev_run, bool):\n            fast_dev_run = 1\n        inputs = inputs[:fast_dev_run]\n\n    if len(inputs) == 0:\n        raise ValueError(\"No inputs provided.\")\n\n    if not isinstance(output_dir, Dir):\n        output_dir = Dir(output_dir)\n\n    if error_when_not_empty and output_dir.exists():\n        _assert_dir_is_empty(output_dir)\n\n    if isinstance(output_dir, Dir):\n        output_dir.mkdir(parents=True, exist_ok=True)\n\n    input_dir = _get_input_dir(inputs)\n    if input_dir is not None:\n        _assert_dir_has_index_file(input_dir)\n\n    if weights is None:\n        weights = [1] * len(inputs)\n\n    if len(inputs) != len(weights):\n        raise ValueError(\"Inputs and weights must have the same length.\")\n\n    recipe = LambdaDataTransformRecipe(fn=fn,"}
{"namespace": "litdata.processing.functions.map", "completion": "    if _IS_IN_STUDIO:\n        if num_nodes is not None:\n            raise ValueError(\"num_nodes is not supported in Studio.\")\n        if machine is not None:\n            raise ValueError(\"machine is not supported in Studio.\")\n\n    if isinstance(output_dir, Dir):\n        output_dir = output_dir.resolve()\n\n    if fast_dev_run is True:\n        fast_dev_run = 1\n    elif fast_dev_run is False:\n        fast_dev_run = None\n\n    if num_workers is None:\n        num_workers = _get_default_num_workers()\n\n    if batch_size is None:\n        batch_size = num_workers\n\n    if num_downloaders is None:\n        num_downloaders = num_workers\n\n    if num_uploaders is None:\n        num_uploaders = num_workers\n\n    if error_when_not_empty:\n        _assert_dir_is_empty(output_dir)\n\n    if fast_dev_run:\n        inputs = inputs[:fast_dev_run]\n\n    if weights is None:\n        weights = [1 for _ in inputs]\n\n    if reader is None:\n        reader = BaseReader()\n\n    if not _IS_IN_STUDIO:\n        input_dir = _get_input_dir(inputs)\n        if input_dir is not None:\n            _assert_dir_has_index_file(input_dir)\n\n    recipe = LambdaDataTransformRecipe(fn=fn, inputs=inputs)\n\n    processor = DataProcessor(\n        recipe=recipe,\n        output_dir=output_dir,\n        weights=weights,\n        num_workers=num_workers,\n        num_downloaders=num_downloaders,\n        num_uploaders=num_uploaders,\n        reorder_files=reorder_files,\n        reader=reader,\n        batch_size=batch_size,\n    )\n\n    if _IS_IN_STUDIO:\n        _execute(processor, num_nodes"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if input_dir.is_local:\n        return\n\n    s3 = S3Client(input_dir.url)\n\n    while True:\n        try:\n            task = queue_in.get(block=True, timeout=1)\n        except Empty:\n            continue\n\n        if task is None:\n            break\n\n        index, files = task\n\n        for file in files:\n            obj = parse.urlparse(file)\n            if not s3.exists(obj):\n                s3.download(obj, cache_dir)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if isinstance(input_dir, Dir):\n        input_dir = input_dir.path\n\n    while True:\n        try:\n            task_idx, files = queue_in.get(block=True, timeout=1)\n        except Empty:\n            continue\n\n        if task_idx is None:\n            break\n\n        for file in files:\n            output_file = os.path.join(cache_dir, file)\n            if not os.path.exists(output_file):\n                os.makedirs(os.path.dirname(output_file), exist_ok=True)\n                shutil.copy(os.path.join(input_dir, file), output_file)\n\n        queue_out.put(task_idx)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if _BOTO3_AVAILABLE:\n        s3 = S3Client(input_dir.scheme, input_dir.netloc)\n\n    while True:\n        try:\n            task = queue_in.get(block=True, timeout=1)\n            index = task[0]\n            files = task[1]\n\n            for file in files:\n                if not os.path.exists(os.path.join(cache_dir, file)):\n                    if _BOTO3_AVAILABLE:\n                        obj = parse.urlparse(os.path.join(input_dir.path, file))\n                        _wait_for_file_to_exist(s3, obj)\n                        s3.download_file(obj.path, os.path.join(cache_dir, file))\n                    else:\n                        shutil.copyfile(os.path.join(input_dir.path, file), os.path.join(cache_dir, file))\n\n            queue_out.put(index)\n        except Empty:\n            pass\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if input_dir.is_local:\n        raise ValueError(\"The input directory must be a remote directory.\")\n\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    s3 = S3Client(input_dir.s3_client_kwargs)\n    while True:\n        try:\n            task = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        if task is None:\n            break\n\n        index, files = task\n        for file in files:\n            obj = parse.urlparse(file)\n            local_file = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n            if not os.path.exists(local_file):\n                os.makedirs(os.path.dirname(local_file), exist_ok=True)\n                s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), local_file)\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if input_dir.scheme == \"s3\":\n        s3 = S3Client(input_dir.netloc)\n\n    while True:\n        try:\n            task = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        if task is None:\n            break\n\n        index, files = task\n\n        if input_dir.scheme == \"s3\":\n            for file in files:\n                obj = parse.urlparse(file)\n                if not os.path.exists(os.path.join(cache_dir, obj.path.lstrip(\"/\"))):\n                    _wait_for_file_to_exist(s3, obj)\n                    s3.download(file, os.path.join(cache_dir, obj.path.lstrip(\"/\")))\n        else:\n            for file in files:\n                if not os.path.exists(os.path.join(cache_dir, file.lstrip(\"/\"))):\n                    shutil.copy(os.path.join(input_dir.path, file), os.path.join(cache_dir, file.lstrip(\"/\")))\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if input_dir.scheme == \"s3\":\n        s3 = S3Client(input_dir.netloc)\n\n    while True:\n        try:\n            index, files = queue_in.get(timeout=0.1)\n        except Empty:\n            continue\n\n        for file in files:\n            path = os.path.join(cache_dir, file)\n            if not os.path.exists(path):\n                if input_dir.scheme == \"s3\":\n                    obj = parse.urlparse(file)\n                    _wait_for_file_to_exist(s3, obj)\n                    s3.client.download_file(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"), Filename=path)\n                else:\n                    os.makedirs(os.path.dirname(path), exist_ok=True)\n                    shutil.copyfile(os.path.join(input_dir.path, file), path)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if input_dir.is_local():\n        raise ValueError(\"input_dir must be a remote directory\")\n\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    s3 = S3Client(input_dir.scheme)\n    while True:\n        try:\n            task = queue_in.get(timeout=1)\n        except Empty:\n            continue\n        if task is None:\n            break\n        index, files = task\n        for file in files:\n            obj = parse.urlparse(file)\n            local_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n            if not os.path.exists(local_path):\n                _wait_for_file_to_exist(s3, obj)\n                s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), local_path)\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if _BOTO3_AVAILABLE:\n        s3 = S3Client()\n\n    while True:\n        try:\n            idx, files = queue_in.get(timeout=5)\n        except Empty:\n            return\n\n        if idx is None:\n            return\n\n        for f in files:\n            if not os.path.exists(os.path.join(cache_dir, f)):\n                if _BOTO3_AVAILABLE:\n                    obj = parse.urlparse(input_dir.url)\n                    s3.client.download_file(obj.netloc, obj.path.lstrip(\"/\"), os.path.join(cache_dir, f))\n                else:\n                    shutil.copyfile(os.path.join(input_dir.path, f), os.path.join(cache_dir, f))\n\n        queue_out.put(idx)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    s3 = S3Client(input_dir)\n    while True:\n        try:\n            task = queue_in.get(timeout=0.1)\n        except Empty:\n            continue\n\n        if task is None:\n            break\n\n        index, files = task\n\n        for file in files:\n            obj = parse.urlparse(file)\n            local_file = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n\n            if not os.path.exists(local_file):\n                os.makedirs(os.path.dirname(local_file), exist_ok=True)\n                s3.client.download_file(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"), Filename=local_file)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if input_dir.is_local:\n        local_path = input_dir.path\n    else:\n        local_path = _get_cache_data_dir()\n\n    if not os.path.exists(local_path):\n        os.makedirs(local_path)\n\n    if input_dir.is_local:\n        s3 = None\n    else:\n        s3 = S3Client(input_dir.path)\n\n    while True:\n        try:\n            task = queue_in.get(block=True, timeout=1)\n            index, files = task\n\n            for file in files:\n                if not os.path.exists(os.path.join(local_path, file)):\n                    if input_dir.is_local:\n                        shutil.copy(os.path.join(input_dir.path, file), os.path.join(local_path, file))\n                    else:\n                        obj = parse.urlparse(os.path.join(input_dir.path, file))\n                        _wait_for_file_to_exist(s3, obj)\n                        s3.client.download_file(obj.netloc, obj.path.lstrip(\"/\"), os.path.join(local_path, file))\n\n            queue_out.put(index)\n        except Empty:\n            pass\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if _BOTO3_AVAILABLE:\n        s3 = S3Client()\n        s3_obj = parse.urlparse(input_dir.url)\n        bucket = s3_obj.netloc\n        prefix = s3_obj.path.lstrip(\"/\")\n        s3_client = s3.client\n\n        while True:\n            try:\n                task = queue_in.get(timeout=1)\n            except Empty:\n                continue\n\n            if task is None:\n                break\n\n            index, files = task\n\n            for file in files:\n                file_path = os.path.join(cache_dir, file)\n                if not os.path.exists(file_path):\n                    file_obj = parse.urlparse(os.path.join(input_dir.url, file))\n                    _wait_for_file_to_exist(s3, file_obj)\n                    s3_client.download_file(bucket, os.path.join(prefix, file), file_path)\n\n            queue_out.put(index)\n\n    else:\n        while True:\n            try:\n                task = queue_in.get(timeout=1)\n            except Empty:\n                continue\n\n            if task is None:\n                break\n\n            index, files = task\n\n            for file in files:\n                file_path = os.path.join(cache_dir, file)\n                if not os.path.exists(file_path):\n                    file_url = os.path.join(input_dir.url, file)\n                    with requests.get(file_url, stream=True) as r:\n                        r.raise_for_status()\n                        with open(file_path, \"wb\") as f:\n                            for chunk in r.iter_content(chunk_size=8192):\n                                f.write(chunk)\n\n            queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if _BOTO3_AVAILABLE:\n        s3 = S3Client()\n\n    while True:\n        try:\n            task = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        if task is None:\n            break\n\n        index, files = task\n\n        for file in files:\n            file_path = os.path.join(cache_dir, file)\n            if not os.path.exists(file_path):\n                if _BOTO3_AVAILABLE:\n                    obj = parse.urlparse(file)\n                    _wait_for_file_to_exist(s3, obj)\n                    s3.client.download_file(obj.netloc, obj.path.lstrip(\"/\"), file_path)\n                else:\n                    input_dir.download(file, file_path)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if isinstance(input_dir, Dir):\n        input_dir = input_dir.path\n\n    while True:\n        try:\n            task_index, files = queue_in.get(block=True, timeout=1)\n        except Empty:\n            continue\n\n        for file in files:\n            if not os.path.exists(os.path.join(cache_dir, file)):\n                os.makedirs(os.path.dirname(os.path.join(cache_dir, file)), exist_ok=True)\n                shutil.copyfile(os.path.join(input_dir, file), os.path.join(cache_dir, file))\n\n        queue_out.put(task_index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if input_dir.protocol == \"s3\":\n        s3 = S3Client(input_dir.netloc)\n\n    while True:\n        try:\n            task = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        if task is None:\n            break\n\n        index, files = task\n\n        for file in files:\n            if input_dir.protocol == \"s3\":\n                obj = parse.urlparse(file)\n                s3.download_file(obj, cache_dir)\n            else:\n                file_path = Path(file)\n                file_path.parent.mkdir(parents=True, exist_ok=True)\n                shutil.copy(file, file_path)\n\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n\n    if _BOTO3_AVAILABLE:\n        s3 = S3Client()\n        obj = parse.urlparse(input_dir.url)\n\n    while True:\n        try:\n            task_index, files = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        if task_index is None:\n            break\n\n        for file in files:\n            file_path = os.path.join(cache_dir, file)\n            if not os.path.exists(file_path):\n                if _BOTO3_AVAILABLE:\n                    s3.client.download_file(obj.netloc, os.path.join(obj.path.lstrip(\"/\"), file), file_path)\n                else:\n                    shutil.copyfile(os.path.join(input_dir.path, file), file_path)\n\n        queue_out.put(task_index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if input_dir.is_s3:\n        s3 = S3Client(input_dir.netloc)\n    else:\n        s3 = None\n\n    while True:\n        try:\n            task_index, file_paths = queue_in.get(timeout=1)\n        except Empty:\n            continue\n\n        for file_path in file_paths:\n            local_file_path = os.path.join(cache_dir, file_path)\n            if os.path.exists(local_file_path):\n                continue\n\n            if input_dir.is_s3:\n                obj = parse.urlparse(input_dir.url + \"/\" + file_path)\n                _wait_for_file_to_exist(s3, obj)\n                s3.client.download_file(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"), Filename=local_file_path)\n            else:\n                os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n                shutil.copyfile(os.path.join(input_dir.path, file_path), local_file_path)\n\n        queue_out.put(task_index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    if input_dir.is_local:\n        raise ValueError(\n            \"The input directory must be a remote directory. Please use `_download_data_local` instead for local directories.\"\n        )\n\n    if _BOTO3_AVAILABLE:\n        s3 = S3Client(input_dir.path)\n    else:\n        raise ImportError(\"Please install boto3 to use the `_download_data_target` function.\")\n\n    while True:\n        try:\n            task = queue_in.get(timeout=1)\n        except Empty:\n            continue\n        index, files = task\n        for file in files:\n            obj = parse.urlparse(file)\n            obj_path = os.path.join(cache_dir, obj.path.lstrip(\"/\"))\n            if not os.path.exists(obj_path):\n                os.makedirs(os.path.dirname(obj_path), exist_ok=True)\n                s3.client.download_file(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\"), Filename=obj_path)\n                _wait_for_file_to_exist(s3, obj)\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # Create a client for the remote directory\n    client = _resolve_dir(input_dir)\n\n    # Continuously fetch download tasks from the input queue\n    while True:\n        # Get the next download task from the input queue\n        task = queue_in.get()\n\n        # If the task is None, it means the queue is empty and we can exit the loop\n        if task is None:\n            break\n\n        # Get the index and file paths from the task\n        index, files = task\n\n        # Check if the files are already downloaded\n        downloaded = True\n        for file in files:\n            if not os.path.exists(os.path.join(cache_dir, file)):\n                downloaded = False\n                break\n\n        # If the files are not downloaded, download them\n        if not downloaded:\n            for file in files:\n                client.download(file, os.path.join(cache_dir, file))\n\n        # Signal completion by putting the index into the output queue\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # TODO: This function is not yet used.\n    # TODO: It should be used to download files from a remote directory to a local cache directory.\n    # TODO: It should continuously fetch download tasks from an input queue, check if the files are already downloaded, download missing files, and then signal completion by putting the task index into an output queue.\n\n    # TODO: The input directory object is used to determine the source path or URL for the files.\n    # TODO: The cache directory is used as the destination for the downloaded files.\n    # TODO: The input queue is continuously fetched for download tasks, which include an index and a list of file paths to download.\n    # TODO: The function checks if the files are already downloaded, downloads missing files, and then signals completion by putting the task index into the output queue.\n\n    # TODO: The function should be used in conjunction with a DataProcessor or StreamingDataLoader to optimize reading of large datasets.\n    # TODO: It should be called by multiple worker processes to download files in parallel.\n    # TODO: The input and output queues are used to communicate between the worker processes and the main process.\n    # TODO: The function should be called by the main process to start the download process.\n\n    # TODO: The function should be used in conjunction with a DataProcessor or StreamingDataLoader to optimize reading of large datasets.\n    # TODO: It should be called by multiple worker processes to download files in parallel.\n    # TODO: The input and output queues are used to communicate between the worker processes and the main process.\n    # TODO: The function should be called by the main process to start the download process.\n\n    # TODO: The function should be used in conjunction with a DataProcessor or StreamingDataLoader to optimize reading of large datasets.\n    # TODO: It should be called by multiple worker processes to download files in parallel.\n    # TODO: The input and output queues are used to communicate between the worker processes and the main process.\n    # TODO: The function should be called by the main process to start the download process.\n\n    # TODO: The function should be used in conjunction with a DataProcessor or StreamingDataLoader to optimize reading of large datasets.\n    # TODO: It should be called by multiple worker processes to download"}
{"namespace": "litdata.processing.data_processor._download_data_target", "completion": "    # Initialize the cache object\n    cache = Cache(cache_dir)\n\n    # Initialize the S3 client\n    s3 = S3Client()\n\n    # Continuously fetch download tasks from the input queue\n    while True:\n        # Get the next task from the input queue\n        task = queue_in.get()\n\n        # If the task is None, it means the queue is empty and the function can stop\n        if task is None:\n            break\n\n        # Extract the index and file paths from the task\n        index, files = task\n\n        # Check if the files are already downloaded\n        for file in files:\n            # If the file is not already downloaded, download it\n            if not cache.exists(file):\n                # Resolve the file path to get the source path or URL\n                source = _resolve_dir(input_dir, file)\n\n                # If the source is a URL, parse it and download the file using S3\n                if source.scheme == \"s3\":\n                    obj = parse.urlparse(source.geturl())\n                    _wait_for_file_to_exist(s3, obj)\n                    s3.download_file(obj.netloc, obj.path.lstrip(\"/\"), cache.path(file))\n                # If the source is a local file path, copy it to the cache\n                elif source.scheme == \"file\":\n                    shutil.copyfile(source.path, cache.path(file))\n                # If the source is neither a URL nor a local file path, raise an error\n                else:\n                    raise ValueError(f\"Unsupported source: {source}\")\n\n        # Signal that the files for the current index are available by putting the index into the output queue\n        queue_out.put(index)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        paths = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if paths is None:\n            return\n\n        # 3. Iterate through the paths and upload them sequentially.\n        for path in paths:\n            if isinstance(path, tuple):\n                tmp_dir, path = path\n            else:\n                tmp_dir = None\n\n            if output_dir.path and not path.startswith(output_dir.path):\n                path = os.path.join(output_dir.path, path)\n\n            if output_dir.url and not path.startswith(output_dir.url):\n                path = os.path.join(output_dir.url, path)\n\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                if tmp_dir:\n                    tmp_path = os.path.join(tmp_dir, os.path.basename(path))\n                else:\n                    tmp_path = path.replace(output_dir.path, cache_dir)\n\n                s3.client.upload_file(tmp_path, obj.netloc, obj.path.lstrip(\"/\"))\n\n                if tmp_dir:\n                    os.remove(tmp_path)\n\n            elif os.path.isfile(path):\n                if not path.startswith(\"/teamspace/studios/this_studio\"):\n                    os.makedirs(os.path.dirname(path), exist_ok=True)\n                    shutil.copyfile(path, path)\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 4. Inform the worker the current files are available\n        remove_queue.put(paths)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmpdir, path = r\n\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)\n\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                dirpath = os.path.dirname(path)\n\n                os.makedirs(dirpath, exist_ok=True)\n\n                with open(path, \"wb\") as f:\n                    s3.client.download_fileobj(obj.netloc, obj.path.lstrip(\"/\"), f)\n\n            elif os.path.isfile(path):\n                os.makedirs(os.path.dirname(path), exist_ok=True)\n                shutil.copyfile(path, path)\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n            remove_queue.put(tmpdir)\n\n        else:\n            path = r\n\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)\n\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                dirpath = os.path.dirname(path)\n\n                os.makedirs(dirpath, exist_ok=True)\n\n                with open(path, \"wb\") as f:\n                    s3.client.download_fileobj(obj.netloc, obj.path.lstrip(\"/\"), f)\n\n            elif os.path.isfile(path):\n                os.makedirs(os.path.dirname(path), exist_ok=True)\n                shutil.copyfile(path, path)\n            else:\n                raise ValueError("}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmpdir, path = r\n        else:\n            tmpdir, path = None, r\n\n        # 4. Check whether the file is already uploaded\n        if output_dir.path and os.path.exists(path.replace(cache_dir, output_dir.path)):\n            remove_queue.put(path)\n            continue\n\n        if output_dir.url is not None or output_dir.path is not None:\n            if output_dir.url:\n                # 5. Wait for the removers to catch up when we are downloading data.\n                _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n            # 6. Upload the file\n            if output_dir.url:\n                obj = parse.urlparse(path.replace(cache_dir, output_dir.url))\n\n                if obj.scheme == \"s3\":\n                    with open(path, \"rb\") as f:\n                        s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n                elif obj.scheme == \"file\":\n                    dirpath = os.path.dirname(path.replace(cache_dir, output_dir.path))\n\n                    os.makedirs(dirpath, exist_ok=True)\n\n                    shutil.copyfile(path, path.replace(cache_dir, output_dir.path))\n\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n            elif os.path.isfile(path):\n                if not path.startswith(\"/teamspace/studios/this_studio\"):\n                    os.makedirs(os.path.dirname(path.replace(cache"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        paths = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if paths is None:\n            return\n\n        # 3. Iterate through the paths and upload them sequentially.\n        for path in paths:\n            if isinstance(path, tuple):\n                tmp_dir, path = path\n                path = os.path.join(tmp_dir, path)\n\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)\n\n            if output_dir.url is not None:\n                obj = parse.urlparse(path)\n\n                if obj.scheme == \"s3\":\n                    with open(path, \"rb\") as f:\n                        s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n                elif obj.scheme == \"file\":\n                    dirpath = os.path.dirname(path)\n\n                    if not dirpath.startswith(output_dir.path):\n                        dirpath = dirpath.replace(output_dir.path, \"\")\n\n                    os.makedirs(dirpath, exist_ok=True)\n                    shutil.copyfile(path, os.path.join(dirpath, os.path.basename(path)))\n\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n            elif output_dir.path is not None:\n                dirpath = os.path.dirname(path)\n\n                if not dirpath.startswith(output_dir.path):\n                    dirpath = dirpath.replace(output_dir.path, \"\")\n\n                os.makedirs(dirpath, exist_ok=True)\n                shutil.copyfile(path, os.path.join(dirpath, os.path.basename(path)))\n\n            # 4. Inform the worker the current files are available\n            remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            tmp_dir = None\n            path = r\n\n        # 4. Upload the file\n        if output_dir.url is not None:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                if tmp_dir is not None:\n                    path = os.path.join(tmp_dir, path)\n\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n\n            elif os.path.isfile(path):\n                if tmp_dir is not None:\n                    path = os.path.join(tmp_dir, path)\n\n                if not path.startswith(\"/teamspace/studios/this_studio\"):\n                    os.makedirs(os.path.dirname(path), exist_ok=True)\n                    shutil.copyfile(path, path)\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 5. Inform the worker the current files are available\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n            path = path.replace(cache_dir, output_dir.path) if output_dir.path else path\n            path = path.replace(cache_dir, output_dir.url) if output_dir.url else path\n        else:\n            path = r\n            path = path.replace(cache_dir, output_dir.path) if output_dir.path else path\n            path = path.replace(cache_dir, output_dir.url) if output_dir.url else path\n\n        # 4. Upload the file to the target directory\n        if output_dir.url:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                s3.client.upload_file(os.path.join(tmp_dir, os.path.basename(path)), obj.netloc, obj.path.lstrip(\"/\"))\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n        else:\n            os.makedirs(os.path.dirname(path), exist_ok=True)\n            shutil.move(tmp_dir, path)\n\n        # 5. Inform the worker the current files are available\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            return\n\n        # 3. Unpack the item\n        if isinstance(item, tuple):\n            tmp_dir, path = item\n        else:\n            tmp_dir, path = None, item\n\n        # 4. Check whether the file is already uploaded\n        if output_dir.path and os.path.exists(path.replace(cache_dir, output_dir.path)):\n            continue\n\n        # 5. Upload the file\n        if output_dir.path:\n            path = path.replace(cache_dir, output_dir.path)\n\n        if output_dir.url:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                dirpath = os.path.dirname(path)\n\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n                remove_queue.put(path)\n\n            elif obj.scheme == \"file\":\n                dirpath = os.path.dirname(path)\n\n                os.makedirs(dirpath, exist_ok=True)\n                shutil.copyfile(path, path)\n\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 6. Remove the temporary directory\n        if tmp_dir is not None:\n            shutil.rmtree(tmp_dir)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Tuple[int, List[str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        index, paths = r\n\n        # 4. Iterate through the paths and upload them sequentially.\n        for path in paths:\n            if output_dir.path and not path.startswith(output_dir.path):\n                path = os.path.join(output_dir.path, path)\n\n            if output_dir.url and not path.startswith(output_dir.url):\n                path = os.path.join(output_dir.url, path)\n\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n                # 5. Wait for the file to exist on the cloud\n                _wait_for_file_to_exist(s3, obj)\n\n            elif os.path.isdir(os.path.dirname(path)):\n                os.makedirs(os.path.dirname(path), exist_ok=True)\n                shutil.copyfile(path.replace(cache_dir, output_dir.path), path)\n\n        # 6. Inform the worker the current files are available\n        remove_queue.put(paths)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        paths = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if paths is None:\n            return\n\n        # 3. Iterate through the paths and delete them sequentially.\n        for path in paths:\n            if isinstance(path, tuple):\n                local_path, remote_path = path\n\n                if not remote_path.startswith(cache_dir):\n                    remote_path = os.path.join(cache_dir, remote_path)\n\n                if os.path.exists(local_path):\n                    if output_dir.url:\n                        obj = parse.urlparse(remote_path)\n                        s3.client.upload_file(local_path, obj.netloc, obj.path.lstrip(\"/\"))\n                        os.remove(local_path)\n                    else:\n                        os.makedirs(os.path.dirname(remote_path), exist_ok=True)\n                        shutil.copyfile(local_path, remote_path)\n                        os.remove(local_path)\n\n            else:\n                if not path.startswith(cache_dir):\n                    path = os.path.join(cache_dir, path)\n\n                if os.path.exists(path):\n                    if output_dir.url:\n                        obj = parse.urlparse(path)\n                        s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n                        os.remove(path)\n                    else:\n                        os.makedirs(os.path.dirname(path), exist_ok=True)\n                        shutil.copyfile(path, path)\n                        os.remove(path)\n\n            remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, paths = r\n        else:\n            temp_dir, paths = None, [r]\n\n        # 4. Iterate through the paths and upload them sequentially.\n        for path in paths:\n            if output_dir.path and not path.startswith(output_dir.path):\n                path = path.replace(cache_dir, output_dir.path)\n\n            if output_dir.url is not None or output_dir.path is not None:\n                if output_dir.url:\n                    obj = parse.urlparse(path)\n\n                    with open(path, \"rb\") as f:\n                        s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n                    if temp_dir is not None:\n                        os.remove(path)\n\n                elif os.path.isfile(path):\n                    if not path.startswith(\"/teamspace/studios/this_studio\"):\n                        os.makedirs(os.path.dirname(path), exist_ok=True)\n                        shutil.copyfile(path, path)\n\n                    if temp_dir is not None:\n                        os.remove(path)\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n            if temp_dir is not None:\n                remove_queue.put(path)\n\n        if temp_dir is not None:\n            remove_queue.put(None)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(item, tuple):\n            tmp_dir, path = item\n            path = os.path.join(tmp_dir, path)\n        else:\n            path = item\n\n        # 4. Upload the file to the target\n        if output_dir.path is not None:\n            path = path.replace(cache_dir, output_dir.path)\n\n        if output_dir.url is not None:\n            path = path.replace(cache_dir, output_dir.url)\n\n        obj = parse.urlparse(path)\n\n        if obj.scheme == \"s3\":\n            s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n        else:\n            os.makedirs(os.path.dirname(path), exist_ok=True)\n            shutil.move(path, path)\n\n        # 5. Inform the worker the current files are available\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            remove_queue.put(None)\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n            path = path.replace(cache_dir, output_dir.path)\n\n        else:\n            path = r.replace(cache_dir, output_dir.path)\n\n        # 4. Upload the file\n        if output_dir.url:\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        else:\n            dirpath = os.path.dirname(path)\n            os.makedirs(dirpath, exist_ok=True)\n            shutil.move(path, path)\n\n        # 5. Inform the worker the current files are available\n        remove_queue.put(r)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        paths = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if paths is None:\n            return\n\n        # 3. Iterate through the paths and upload them sequentially.\n        for path in paths:\n            if isinstance(path, tuple):\n                tmp_dir, path = path\n            else:\n                tmp_dir = None\n\n            if output_dir.path is not None:\n                path = path.replace(cache_dir, output_dir.path)\n\n            if output_dir.url is not None:\n                path = path.replace(cache_dir, output_dir.url)\n\n            obj = parse.urlparse(path)\n\n            if obj.scheme == \"s3\":\n                if tmp_dir is not None:\n                    for f in os.listdir(tmp_dir):\n                        s3.client.upload_file(os.path.join(tmp_dir, f), obj.netloc, obj.path.lstrip(\"/\"))\n\n                else:\n                    s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n\n            elif obj.scheme == \"file\":\n                if tmp_dir is not None:\n                    for f in os.listdir(tmp_dir):\n                        shutil.copyfile(os.path.join(tmp_dir, f), path)\n\n                else:\n                    shutil.copyfile(path, path)\n\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n            if tmp_dir is not None:\n                shutil.rmtree(tmp_dir)\n\n            remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Fetch from the queue\n        r: Optional[Union[str, Tuple[str, str]]] = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            tmp_dir, path = r\n        else:\n            tmp_dir, path = None, r\n\n        # 4. Check whether the file already exists\n        if output_dir.path and os.path.exists(path.replace(cache_dir, output_dir.path)):\n            continue\n\n        if output_dir.url is not None or output_dir.path is not None:\n            # 5. Wait for the removers to catch up when we are downloading data.\n            _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n            # 6. Upload the file to the target\n            if output_dir.url:\n                if output_dir.url.startswith(\"s3://\"):\n                    obj = parse.urlparse(path.replace(cache_dir, output_dir.url))\n                    s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n                else:\n                    raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n            elif output_dir.path:\n                dirpath = os.path.dirname(path.replace(cache_dir, output_dir.path))\n\n                if not os.path.exists(dirpath):\n                    os.makedirs(dirpath, exist_ok=True)\n\n                if tmp_dir:\n                    shutil.move(os.path.join(tmp_dir, os.path.basename(path)), path)\n                    shutil.rmtree(tmp_dir)\n                else:\n                    shutil.copyfile(path, path.replace(cache_dir, output_dir.path))\n\n            # 7"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    # Initialize the S3 client if the output directory is an S3 bucket\n    if output_dir.url and output_dir.url.startswith(\"s3://\"):\n        s3 = S3Client()\n\n    # Continuously process items from the upload queue until a termination signal is received\n    while True:\n        # Get the next item from the queue\n        item = upload_queue.get()\n\n        # If the item is None, it's a termination signal, so break out of the loop\n        if item is None:\n            break\n\n        # If the item is a tuple, it contains a temporary directory and a file path\n        if isinstance(item, tuple):\n            tmp_dir, file_path = item\n            # Construct the full path of the file to be uploaded\n            file_path = os.path.join(tmp_dir, file_path)\n        else:\n            # Otherwise, the item is a file path\n            file_path = item\n\n        # If the file path doesn't start with the cache directory, prepend the cache directory to it\n        if not file_path.startswith(cache_dir):\n            file_path = os.path.join(cache_dir, file_path)\n\n        # If the output directory is an S3 bucket, upload the file to it\n        if output_dir.url and output_dir.url.startswith(\"s3://\"):\n            # Construct the full S3 path for the file\n            s3_path = os.path.join(output_dir.url, os.path.relpath(file_path, cache_dir))\n            # Upload the file to S3\n            s3.upload_file(file_path, s3_path)\n        else:\n            # Otherwise, move the file to the output directory\n            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n            shutil.move(file_path, file_path.replace(cache_dir, output_dir.path))\n\n        # Send the file path to the remove queue for removal\n        remove_queue.put(file_path)"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        item = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if item is None:\n            return\n\n        # 3. Unpack\n        if isinstance(item, tuple):\n            tmp_dir, path = item\n        else:\n            tmp_dir, path = None, item\n\n        # 4. Check if the file exists\n        if not os.path.exists(path):\n            continue\n\n        # 5. Prepare the path\n        if tmp_dir is not None:\n            path = path.replace(tmp_dir, cache_dir)\n\n        if output_dir.path and not path.startswith(output_dir.path):\n            path = path.replace(cache_dir, output_dir.path)\n\n        # 6. Upload the file\n        if output_dir.url is not None or output_dir.path is not None:\n            obj = parse.urlparse(path)\n\n            if output_dir.url and output_dir.path:\n                path = path.replace(output_dir.path, output_dir.url)\n\n            if obj.scheme == \"s3\":\n                with open(path, \"rb\") as f:\n                    s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n            elif os.path.isfile(path):\n                os.makedirs(os.path.dirname(path), exist_ok=True)\n                shutil.copyfile(path, path)\n            else:\n                raise ValueError(f\"The provided {output_dir.url} isn't supported.\")\n\n        # 7. Inform the worker the current files are available\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        r = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if r is None:\n            return\n\n        # 3. Unpack\n        if isinstance(r, tuple):\n            temp_dir, path = r\n            path = os.path.join(temp_dir, path)\n\n        else:\n            path = r\n\n        # 4. Check whether the file exists\n        if not os.path.exists(path):\n            continue\n\n        # 5. Check whether the file is already uploaded\n        if output_dir.path and os.path.exists(path.replace(cache_dir, output_dir.path)):\n            continue\n\n        # 6. Upload the file\n        if output_dir.url:\n            # 6.1. Wait for the removers to catch up when we are uploading data.\n            _wait_for_disk_usage_higher_than_threshold(\"/\", 25)\n\n            obj = parse.urlparse(path.replace(cache_dir, output_dir.url))\n            s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n\n            # 6.2. Wait for the file to exist in the bucket\n            _wait_for_file_to_exist(s3, obj)\n\n        elif output_dir.path:\n            dirpath = os.path.dirname(path.replace(cache_dir, output_dir.path))\n            os.makedirs(dirpath, exist_ok=True)\n            shutil.copyfile(path, path.replace(cache_dir, output_dir.path))\n\n        # 7. Remove the file\n        remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    s3 = S3Client()\n\n    while True:\n        # 1. Collect paths\n        paths = upload_queue.get()\n\n        # 2. Terminate the process if we received a termination signal\n        if paths is None:\n            return\n\n        # 3. Iterate through the paths and delete them sequentially.\n        for path in paths:\n            if isinstance(path, tuple):\n                tmp_dir, path = path\n\n            if output_dir.path and not path.startswith(cache_dir):\n                path = path.replace(cache_dir, output_dir.path)\n\n            if output_dir.url is not None:\n                if output_dir.url.startswith(\"s3://\"):\n                    obj = parse.urlparse(path)\n\n                    if obj.scheme == \"s3\":\n                        path = path.replace(output_dir.url, \"\")\n\n                    s3.client.upload_file(tmp_dir, obj.netloc, obj.path.lstrip(\"/\"))\n\n                    # 4. Wait for the file to be available\n                    _wait_for_file_to_exist(s3, obj)\n\n                    # 5. Remove the temporary file\n                    os.remove(tmp_dir)\n\n                elif output_dir.url.startswith(\"file://\"):\n                    path = path.replace(cache_dir, output_dir.url)\n\n                    os.makedirs(os.path.dirname(path), exist_ok=True)\n\n                    shutil.move(tmp_dir, path)\n\n            # 6. Remove the file from the cache\n            remove_queue.put(path)\n\n"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    # 1. Initialize the S3 client if the output directory is an S3 bucket\n    s3 = S3Client() if output_dir.url and output_dir.url.startswith(\"s3://\") else None\n\n    # 2. Iterate through the upload queue\n    while True:\n        # 3. Fetch from the queue\n        item = upload_queue.get()\n\n        # 4. Terminate the process if we received a termination signal\n        if item is None:\n            remove_queue.put(None)\n            return\n\n        # 5. Unpack the item\n        if isinstance(item, tuple):\n            tmp_dir, path = item\n        else:\n            tmp_dir, path = None, item\n\n        # 6. Check whether the path is already uploaded\n        if output_dir.url and not path.startswith(output_dir.url):\n            path = os.path.join(output_dir.url, path)\n\n        if output_dir.url and output_dir.url.startswith(\"s3://\"):\n            obj = parse.urlparse(path)\n\n            if s3.client.head_object(Bucket=obj.netloc, Key=obj.path.lstrip(\"/\")):\n                remove_queue.put(path)\n                continue\n\n        # 7. Upload the file to the output directory\n        if tmp_dir is None:\n            local_path = path if path.startswith(cache_dir) else os.path.join(cache_dir, path)\n        else:\n            local_path = os.path.join(tmp_dir, path)\n\n        if output_dir.url and output_dir.url.startswith(\"s3://\"):\n            obj = parse.urlparse(path)\n\n            with open(local_path, \"rb\") as f:\n                s3.client.upload_fileobj(f, obj.netloc, obj.path.lstrip(\"/\"))\n\n            remove_queue.put(path)\n        elif os.path.isfile(local_path):\n            if not path.startswith"}
{"namespace": "litdata.processing.data_processor._upload_fn", "completion": "    # 1. Initialize the S3 client\n    s3 = S3Client()\n\n    # 2. Start an infinite loop to continuously process items from the upload queue\n    while True:\n        # 3. Fetch the next item from the upload queue\n        item = upload_queue.get()\n\n        # 4. If the item is None, it means the upload process has been terminated\n        if item is None:\n            return\n\n        # 5. If the item is a tuple, it represents a temporary directory and a file path\n        if isinstance(item, tuple):\n            temp_dir, path = item\n\n            # 6. If the file path doesn't start with the cache directory, prepend the cache directory\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)\n\n            # 7. If the temporary directory exists, move the file to the temporary directory\n            if os.path.exists(temp_dir):\n                shutil.move(path, temp_dir)\n\n            # 8. Remove the temporary directory\n            os.rmdir(temp_dir)\n\n            # 9. If the output directory is an S3 bucket, upload the file to the bucket\n            if output_dir.url is not None and output_dir.url.startswith(\"s3://\"):\n                obj = parse.urlparse(path)\n                s3.client.upload_file(path, obj.netloc, obj.path.lstrip(\"/\"))\n\n            # 10. Otherwise, move the file to the output directory\n            else:\n                os.makedirs(os.path.dirname(path), exist_ok=True)\n                shutil.move(path, path)\n\n        # 11. If the item is a file path, upload the file to the output directory\n        else:\n            path = item\n\n            # 12. If the file path doesn't start with the cache directory, prepend the cache directory\n            if not path.startswith(cache_dir):\n                path = os.path.join(cache_dir, path)"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    total_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    total_workers = total_nodes * num_workers\n\n    items_per_worker = len(user_items) // total_workers\n    extra_items = len(user_items) % total_workers\n\n    start = 0\n    result = []\n    for i in range(total_workers):\n        worker_items = items_per_worker + 1 if i < extra_items else items_per_worker\n        end = start + worker_items\n        result.append(user_items[start:end])\n        start = end\n\n    if len(result) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return result\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Print the distribution details for workers on the current node\n    for worker_id in worker_ids_this_node:\n        items = worker_items[worker_id]\n        weight = worker_weights[worker_id]\n\n        if file_size:\n            size = sum(os.path.getsize(item) for item in items) / 1024 / 1024\n            print(f\"Worker {worker_id} will process {len(items)} files ({size:.2f} MB)\")\n        else:\n            print(f\"Worker {worker_id} will process {weight} items\")\n\n    # Return a list of items for each worker, with the items shuffled\n    return [random.sample(worker_items[worker_id], len(worker_items[worker_id])) for worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Print the distribution details for workers on the current node\n    for i in worker_ids_this_node:\n        worker_items_this_node = worker_items[i]\n        worker_weights_this_node = worker_weights[i]\n        total_weight_this_node = sum(worker_weights_this_node)\n        if file_size:\n            total_size_this_node = sum(os.path.getsize(item) for item in worker_items_this_node) / 1024 / 1024\n            print(f\"Worker {i} has {len(worker_items_this_node)} items ({total_size_this_node:.2f} MB)\")\n        else:\n            print(f\"Worker {i} has {len(worker_items_this_node)} items ({total_weight_this_node} total weight)\")\n\n    # Return the list of items for each worker, shuffled randomly\n    return [random.sample(worker_items[i], len(worker_items[i])) for i in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    worker_items_this_node = [worker_items[i] for i in worker_ids_this_node]\n    worker_weights_this_node = [worker_weights[i] for i in worker_ids_this_node]\n\n    # Print the distribution details for workers on the current node\n    for i, (items, weight) in enumerate(zip(worker_items_this_node, worker_weights_this_node)):\n        if file_size:\n            size_mb = sum(os.path.getsize(item) for item in items) / 1024 / 1024\n            print(f\"Worker {i} (node {node_rank}): {len(items)} items ({size_mb:.2f} MB)\")\n        else:\n            print(f\"Worker {i} (node {node_rank}): {len(items)} items ({weight} total weight)\")\n\n    # Shuffle the items for each worker\n    worker_items_this_node_shuffled = [random.sample(items, len(items)) for items in worker_items_this_node]\n\n    return worker_items_this_node_shuffled\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    for i, (worker_id, worker_item, worker_weight) in enumerate(zip(worker_ids_this_node, worker_items, worker_weights)):\n        if file_size:\n            worker_size = sum(os.path.getsize(item) for item in worker_item) / (1024 * 1024)\n            print(f\"Worker {worker_id} will process {len(worker_item)} files ({worker_size:.2f} MB)\")\n        else:\n            print(f\"Worker {worker_id} will process {worker_weight} items\")\n\n    # Shuffle the items for each worker.\n    worker_items = [np.random.permutation(items).tolist() for items in worker_items]\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Print the distribution details for workers on the current node\n    print(f\"Node {node_rank}:\")\n    for i in worker_ids_this_node:\n        print(f\"Worker {i}: {len(worker_items[i])} items, total weight {sum(worker_weights[i])}\")\n\n    # Shuffle the items for each worker\n    for i in worker_ids_this_node:\n        random.shuffle(worker_items[i])\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Print the distribution details for workers on the current node\n    if file_size:\n        print(\n            f\"Distributing {len(user_items)} items to {num_workers} workers on node {node_rank} ({num_nodes} nodes total):\"\n        )\n        for worker_id in worker_ids_this_node:\n            worker_items_this_worker = [item for item, worker_id_ in zip(user_items, worker_ids) if worker_id_ == worker_id]\n            worker_weights_this_worker = [\n                weight for weight, worker_id_ in zip(weights, worker_ids) if worker_id_ == worker_id\n            ]\n            total_weight = sum(worker_weights_this_worker)\n            print(\n                f\"Worker {worker_id}: {len(worker_items_this_worker)} items ({total_weight / 1024 / 1024:.2f} MB)\"\n            )\n    else:\n        print(\n            f\"Distributing {len(user_items)} items to {num_workers} workers on node {node_rank} ({num_nodes} nodes total):\"\n        )\n        for worker_id in worker_ids_this_node:\n            worker_items_this_worker = [item for item, worker_id_ in zip(user_items, worker_ids) if worker_id_ == worker_id]\n            worker_weights_this_worker = [\n                weight for weight, worker_id_ in zip(weights, worker_ids) if worker_id_ == worker_id\n            ]\n            total_weight = sum(worker_weights_this_worker)\n            print(f\"Worker {worker_id}: {len(worker_items_this_worker)} items ({total_weight} total weight)\")\n\n    # Return the items assigned to each worker, shuffled randomly\n    return [\n        [item for item, worker_id in zip(user_items, worker_ids) if worker_id == worker_id_]\n        for worker_id_ in worker_"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    if file_size:\n        sizes = [os.path.getsize(item) / 1000 / 1000 for item in user_items]\n        print(f\"Node {node_rank}: {[round(size, 2) for size in sizes]} MB\")\n    else:\n        print(f\"Node {node_rank}: {weights}\")\n\n    # Return the items for each worker, shuffled randomly.\n    return [worker_items[i] for i in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Print the distribution details for workers on the current node\n    for worker_id in worker_ids_this_node:\n        worker_items_this_node = worker_items[worker_id]\n        worker_weights_this_node = worker_weights[worker_id]\n        total_weight_this_node = sum(worker_weights_this_node)\n        if file_size:\n            total_weight_this_node = sum(os.path.getsize(item) for item in worker_items_this_node) / 1024 / 1024\n        print(f\"Worker {worker_id} has {len(worker_items_this_node)} items with total weight {total_weight_this_node:.2f} MB.\")\n\n    # Return a list of items for each worker, with the items shuffled randomly\n    return [worker_items[worker_id] for worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Distribute items among workers based on weights\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n\n    # Get the worker IDs for the current node\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node\n    for worker_id in worker_ids_this_node:\n        worker_items_this_worker = worker_items[worker_id]\n        worker_weights_this_worker = worker_weights[worker_id]\n        if file_size:\n            worker_size_this_worker = sum(os.path.getsize(item) for item in worker_items_this_worker) / 1024 / 1024\n            print(f\"Worker {worker_id} has {len(worker_items_this_worker)} items with a total size of {worker_size_this_worker:.2f} MB.\")\n        else:\n            print(f\"Worker {worker_id} has {len(worker_items_this_worker)} items with a total weight of {worker_weights_this_worker}.\")\n\n    # Return the items assigned to each worker, shuffled randomly\n    return [random.sample(worker_items[worker_id], len(worker_items[worker_id])) for worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    total_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    total_workers = total_nodes * num_workers\n\n    items_per_worker = len(user_items) // total_workers\n    extra_items = len(user_items) % total_workers\n\n    start = 0\n    result = []\n    for i in range(total_workers):\n        worker_items = items_per_worker + 1 if i < extra_items else items_per_worker\n        end = start + worker_items\n        result.append(user_items[start:end])\n        start = end\n\n    if len(result) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return result\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    for worker_id in worker_ids_this_node:\n        worker_item_ids = [i for i, w in enumerate(worker_items) if w == worker_id]\n        worker_item_weights = [weights[i] for i in worker_item_ids]\n        worker_item_sizes = [os.path.getsize(user_items[i]) for i in worker_item_ids]\n        if file_size:\n            worker_item_sizes = [f\"{size / 1024 / 1024:.2f} MB\" for size in worker_item_sizes]\n        print(f\"Worker {worker_id} ({worker_item_weights}): {worker_item_sizes}\")\n\n    # Return the list of items for each worker, with the items shuffled.\n    return [\n        [user_items[i] for i in worker_item_ids]\n        for worker_item_ids in [\n            [i for i, w in enumerate(worker_items) if w == worker_id] for worker_id in worker_ids_this_node\n        ]\n    ]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Print the distribution details for workers on the current node\n    for i, worker_id in enumerate(worker_ids_this_node):\n        worker_weight = sum(worker_weights[i])\n        worker_items_this_worker = worker_items[i]\n        if file_size:\n            worker_size = sum(os.path.getsize(item) for item in worker_items_this_worker) / 1024 / 1024\n            print(f\"Worker {worker_id} has {len(worker_items_this_worker)} items, {worker_size:.2f} MB in total.\")\n        else:\n            print(f\"Worker {worker_id} has {len(worker_items_this_worker)} items, {worker_weight} total weight.\")\n\n    # Shuffle the items for each worker\n    result = []\n    for i in range(num_workers):\n        items_this_worker = worker_items[i]\n        random.shuffle(items_this_worker)\n        result.append(items_this_worker)\n\n    return result\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    for worker_id, worker_item, worker_weight in zip(worker_ids_this_node, worker_items, worker_weights):\n        if file_size:\n            print(\n                f\"Node {node_rank}: Worker {worker_id} is assigned {len(worker_item)} files with total size {sum(worker_weight) / 1000 / 1000:.2f} MB\"\n            )\n        else:\n            print(f\"Node {node_rank}: Worker {worker_id} is assigned {len(worker_item)} items with total weight {sum(worker_weight)}\")\n\n    # Return a list of items for each worker, with the items shuffled.\n    return [random.sample(worker_item, len(worker_item)) for worker_item in worker_items]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    print(f\"Node {node_rank}\")\n    for worker_id in worker_ids_this_node:\n        worker_item_indices = [i for i, w in enumerate(worker_items) if w == worker_id]\n        worker_item_weights = [weights[i] for i in worker_item_indices]\n        worker_item_sizes = [os.path.getsize(user_items[i]) for i in worker_item_indices]\n        worker_item_sizes_mb = [size / 1024 / 1024 for size in worker_item_sizes]\n        worker_total_weight = sum(worker_item_weights)\n        worker_total_size = sum(worker_item_sizes)\n        worker_total_size_mb = worker_total_size / 1024 / 1024\n        print(\n            f\"Worker {worker_id} has {len(worker_item_indices)} items, \"\n            f\"total weight {worker_total_weight} ({worker_total_size_mb:.2f} MB)\"\n        )\n        if file_size:\n            print(f\"Sizes: {worker_item_sizes_mb}\")\n\n    # Return the items for each worker, shuffled randomly.\n    return [\n        [user_items[i] for i in worker_"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if file_size:\n        worker_weights = [sum(w) / 1000 / 1000 for w in worker_weights]\n\n    # Print the distribution details for workers on the current node\n    for worker_id, worker_items in enumerate(worker_items):\n        if worker_id in worker_ids_this_node:\n            if file_size:\n                print(f\"Worker {worker_id} has {len(worker_items)} items with a total size of {worker_weights[worker_id]:.2f} MB\")\n            else:\n                print(f\"Worker {worker_id} has {len(worker_items)} items with a total weight of {worker_weights[worker_id]}\")\n\n    # Shuffle the items for each worker\n    for i in range(len(worker_items)):\n        random.shuffle(worker_items[i])\n\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    if _get_node_rank() == 0:\n        for worker_id in worker_ids_this_node:\n            worker_item_indices = [i for i, w in enumerate(worker_items) if w == worker_id]\n            worker_item_sizes = [weights[i] for i in worker_item_indices]\n            worker_item_sizes_str = [f\"{s / 1000 / 1000:.2f} MB\" for s in worker_item_sizes] if file_size else worker_item_sizes\n            worker_item_str = \", \".join(worker_item_sizes_str)\n            print(f\"Worker {worker_id} has {len(worker_item_indices)} items: {worker_item_str}\")\n\n    # Return the items for each worker, shuffled randomly.\n    return [\n        [user_items[i] for i in random.sample(worker_item_indices, len(worker_item_indices))]\n        for worker_id in worker_ids_this_node\n        for worker_item_indices in [[i for i, w in enumerate(worker_items) if w == worker_id]]\n    ]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Print the distribution details for workers on the current node\n    if file_size:\n        print(\n            f\"Distributing {len(user_items)} items to {len(worker_ids_this_node)} workers on node {node_rank} ({num_nodes} nodes total):\"\n        )\n        for i, (worker_id, worker_item, worker_weight) in enumerate(zip(worker_ids_this_node, worker_items, worker_weights)):\n            print(f\"Worker {worker_id}: {len(worker_item)} items ({sum(worker_weight) / 1000 / 1000:.2f} MB)\")\n    else:\n        print(\n            f\"Distributing {len(user_items)} items to {len(worker_ids_this_node)} workers on node {node_rank} ({num_nodes} nodes total):\"\n        )\n        for i, (worker_id, worker_item, worker_weight) in enumerate(zip(worker_ids_this_node, worker_items, worker_weights)):\n            print(f\"Worker {worker_id}: {len(worker_item)} items ({sum(worker_weight)} items)\")\n\n    # Return the list of items for each worker, shuffled randomly\n    return [list(items) for items in worker_items]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    # Associate the items to the workers based on number of nodes and node rank.\n    weights = [1] * len(user_items) if weights is None else weights\n    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    world_size = num_nodes * num_workers\n\n    worker_items, worker_weights = _pack_greedily(items=user_items, weights=weights, num_bins=world_size)\n    worker_ids_this_node = range(node_rank * num_workers, (node_rank + 1) * num_workers)\n\n    # Print the distribution details for workers on the current node.\n    for worker_id in worker_ids_this_node:\n        worker_item_indices = [i for i, w in enumerate(worker_weights) if w == worker_id]\n        worker_items_this_worker = [worker_items[i] for i in worker_item_indices]\n        worker_weights_this_worker = [worker_weights[i] for i in worker_item_indices]\n        total_weight_this_worker = sum(worker_weights_this_worker)\n        if file_size:\n            total_size_this_worker = sum(os.path.getsize(item) for item in worker_items_this_worker)\n            print(f\"Worker {worker_id} will process {len(worker_items_this_worker)} files, \"\n                  f\"with total size {total_size_this_worker / 1024 / 1024:.2f} MB.\")\n        else:\n            print(f\"Worker {worker_id} will process {len(worker_items_this_worker)} items, \"\n                  f\"with total weight {total_weight_this_worker}.\")\n\n    # Return a list of items for each worker, with the items shuffled.\n    return [worker_items_this_worker for worker_id, worker_items_this_worker in zip(worker_ids_this_node, worker_items)]"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_weighted", "completion": "    if file_size:\n        file_sizes = [os.path.getsize(item) / 1024 / 1024 for item in user_items]\n        total_size = sum(file_sizes)\n        print(f\"Total size of files: {total_size:.2f} MB\")\n\n    if weights is None:\n        weights = [1] * len(user_items)\n\n    total_weight = sum(weights)\n    print(f\"Total weight of items: {total_weight}\")\n\n    for i, worker_id in enumerate(worker_ids_this_node):\n        worker_weight = sum(weights[j] for j in worker_items[worker_id])\n        if file_size:\n            worker_size = sum(file_sizes[j] for j in worker_items[worker_id])\n            print(f\"Worker {worker_id}: {worker_size:.2f} MB, {worker_weight} items\")\n        else:\n            print(f\"Worker {worker_id}: {worker_weight} items\")\n\n    return [user_items[i] for i in worker_items[worker_id]] for worker_id in worker_ids_this_node]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    num_workers = num_workers * num_nodes\n    num_items = len(user_items)\n    num_items_per_worker = num_items // num_workers\n    num_items_per_worker_remainder = num_items % num_workers\n\n    start_indices = [i * num_items_per_worker for i in range(num_workers)]\n    end_indices = [(i + 1) * num_items_per_worker for i in range(num_workers)]\n\n    for i in range(num_items_per_worker_remainder):\n        start_indices[i] += i\n        end_indices[i] += i + 1\n\n    items = [user_items[start_indices[i] : end_indices[i]] for i in range(num_workers)]\n\n    if len(items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_workers = _get_num_nodes() * num_workers\n    items_per_worker = len(user_items) // total_workers\n    remainder = len(user_items) % total_workers\n\n    if remainder > 0:\n        items_per_worker += 1\n\n    start_indices = np.cumsum([0] + [items_per_worker] * (total_workers - 1))\n    end_indices = np.cumsum([items_per_worker] * total_workers)\n\n    if len(user_items) > end_indices[-1]:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    items = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    return items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    num_workers_per_node = num_workers\n    num_workers = num_workers_per_node * num_nodes\n\n    num_items = len(user_items)\n    items_per_worker = num_items // num_workers\n    remainder = num_items % num_workers\n\n    start_indices = list(range(0, num_items, items_per_worker))\n    end_indices = start_indices[1:] + [num_items]\n\n    if remainder > 0:\n        for i in range(remainder):\n            start_indices[-i - 1] += 1\n\n    items_per_worker = [end_indices[i] - start_indices[i] for i in range(num_workers)]\n\n    items_per_worker_per_node = items_per_worker[node_rank * num_workers_per_node : (node_rank + 1) * num_workers_per_node]\n    start_indices_per_node = start_indices[node_rank * num_workers_per_node : (node_rank + 1) * num_workers_per_node]\n    end_indices_per_node = end_indices[node_rank * num_workers_per_node : (node_rank + 1) * num_workers_per_node]\n\n    items_per_worker_per_node_cumsum = np.cumsum(items_per_worker_per_node)\n    start_indices_per_node_cumsum = np.cumsum(start_indices_per_node)\n    end_indices_per_node_cumsum = np.cumsum(end_indices_per_node)\n\n    items_per_worker_per_node_cumsum = np.insert(items_per_worker_per_node_cumsum, 0, 0)\n    start_indices_per_node"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    num_workers_per_node = num_workers\n    num_workers = num_workers_per_node * num_nodes\n\n    num_items = len(user_items)\n    items_per_worker = num_items // num_workers\n    num_items_per_worker = [items_per_worker] * num_workers\n\n    remainder = num_items % num_workers\n    if remainder > 0:\n        num_items_per_worker[-remainder:] = [items_per_worker + 1] * remainder\n\n    cumsum = np.cumsum(num_items_per_worker)\n\n    start_indices = cumsum - num_items_per_worker\n    end_indices = cumsum\n\n    start_index = start_indices[node_rank * num_workers_per_node : (node_rank + 1) * num_workers_per_node]\n    end_index = end_indices[node_rank * num_workers_per_node : (node_rank + 1) * num_workers_per_node]\n\n    items = [user_items[start:end] for start, end in zip(start_index, end_index)]\n\n    if len(items) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    num_workers_per_node = num_workers // num_nodes\n    num_workers_per_node_remainder = num_workers % num_nodes\n\n    num_workers_per_node += int(node_rank < num_workers_per_node_remainder)\n\n    num_workers = num_workers_per_node * num_nodes\n\n    num_items = len(user_items)\n\n    num_items_per_worker = num_items // num_workers\n    num_items_per_worker_remainder = num_items % num_workers\n\n    num_items_per_worker += int(node_rank < num_items_per_worker_remainder)\n\n    num_items = num_items_per_worker * num_workers\n\n    cumsum = np.cumsum([num_items_per_worker] * num_workers)\n\n    items = []\n\n    for i in range(num_workers):\n        start = cumsum[i - 1] if i > 0 else 0\n        end = cumsum[i]\n\n        items.append(user_items[start:end])\n\n    if len(items) != num_workers:\n        raise RuntimeError(\"Improper assignment\")\n\n    return items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    num_workers_total = num_workers * num_nodes\n    num_items = len(user_items)\n\n    num_items_per_worker = num_items // num_workers_total\n    num_items_remainder = num_items % num_workers_total\n\n    num_items_per_worker_list = [num_items_per_worker] * num_workers_total\n\n    for i in range(num_items_remainder):\n        num_items_per_worker_list[-i - 1] += 1\n\n    cumsum = np.cumsum(num_items_per_worker_list)\n\n    if len(cumsum) != num_workers_total:\n        raise RuntimeError(\"Improper assignment\")\n\n    items_per_worker = [\n        user_items[cumsum[i] - num_items_per_worker_list[i] : cumsum[i]] for i in range(num_workers_total)\n    ]\n\n    return items_per_worker[\n        _get_node_rank() * num_workers : (_get_node_rank() + 1) * num_workers\n    ]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    num_workers_total = num_workers * num_nodes\n    num_items = len(user_items)\n    num_items_per_worker = num_items // num_workers_total\n    num_items_per_worker_remainder = num_items % num_workers_total\n    num_items_per_worker_list = [num_items_per_worker] * num_workers_total\n    num_items_per_worker_list[-num_items_per_worker_remainder:] = [\n        num_items_per_worker + 1 for _ in range(num_items_per_worker_remainder)\n    ]\n\n    start_indices = np.cumsum([0] + num_items_per_worker_list[:-1])\n    end_indices = np.cumsum(num_items_per_worker_list)\n\n    items_per_worker = [\n        user_items[start_indices[i] : end_indices[i]] for i in range(len(start_indices))\n    ]\n\n    if len(items_per_worker) != num_workers_total:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return items_per_worker[node_rank * num_workers : (node_rank + 1) * num_workers]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    num_workers_per_node = num_workers\n    num_workers = num_workers_per_node * num_nodes\n\n    num_items = len(user_items)\n    num_items_per_worker = num_items // num_workers\n    num_items_remainder = num_items % num_workers\n\n    # Distribute the items to the workers\n    items_per_worker = [num_items_per_worker] * num_workers\n    for i in range(num_items_remainder):\n        items_per_worker[-(i + 1)] += 1\n\n    # Calculate the start and end indices for each worker\n    cumsum = np.cumsum([0] + items_per_worker)\n    start_indices = cumsum[:-1]\n    end_indices = cumsum[1:]\n\n    # Assign items to each worker\n    items_per_worker = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    if len(items_per_worker) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return items_per_worker"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    num_workers = num_workers * num_nodes\n\n    num_items = len(user_items)\n    num_items_per_worker = num_items // num_workers\n    remainder = num_items % num_workers\n\n    if remainder > 0:\n        num_items_per_worker += 1\n\n    start_index = node_rank * num_workers\n    end_index = start_index + num_workers\n\n    items_per_worker = [\n        user_items[i : i + num_items_per_worker] for i in range(start_index, end_index, num_items_per_worker)\n    ]\n\n    if len(items_per_worker) != num_workers:\n        raise RuntimeError(\"The number of items per worker is not equal to the number of workers.\")\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    total_workers = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // total_workers\n\n    # Calculate the remainder of items after distributing evenly among workers\n    remainder = len(user_items) % total_workers\n\n    # Initialize a list of lists to store the items assigned to each worker\n    worker_items = [[] for _ in range(total_workers)]\n\n    # Distribute the items among the workers sequentially\n    start = 0\n    for i in range(total_workers):\n        end = start + num_items_per_worker\n        if i < remainder:\n            end += 1\n        worker_items[i] = user_items[start:end]\n        start = end\n\n    # Ensure that the output list has a length equal to the number of workers\n    assert len(worker_items) == total_workers, f\"Improper assignment of items to workers: {len(worker_items)} != {total_workers}\"\n\n    # Return the list of items assigned to each worker\n    return worker_items\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    num_workers_per_node = num_workers\n    num_workers_across_nodes = num_workers_per_node * num_nodes\n    num_items = len(user_items)\n\n    num_items_per_worker = num_items // num_workers_across_nodes\n    num_items_per_worker_remainder = num_items % num_workers_across_nodes\n\n    items_per_worker = [num_items_per_worker for _ in range(num_workers_across_nodes)]\n\n    for i in range(num_items_per_worker_remainder):\n        items_per_worker[-1 - i] += 1\n\n    cumsum_items_per_worker = np.cumsum(items_per_worker)\n    cumsum_items_per_worker = np.insert(cumsum_items_per_worker, 0, 0)\n\n    start_indices = cumsum_items_per_worker[:-1]\n    end_indices = cumsum_items_per_worker[1:]\n\n    if len(start_indices) != num_workers_across_nodes:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    total_num_workers = num_workers * _get_num_nodes()\n\n    # Determine how many items each worker should process\n    items_per_worker = len(user_items) // total_num_workers\n    remainder = len(user_items) % total_num_workers\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = np.cumsum(np.repeat(items_per_worker, total_num_workers))\n    end_indices = np.cumsum(np.repeat(items_per_worker, total_num_workers))\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    for i in range(remainder):\n        end_indices[-i - 1] += 1\n\n    # Ensure that the output list has a length equal to the number of workers\n    if len(start_indices) != total_num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    # Create a list of lists, where each sublist contains the items assigned to a worker\n    items_per_worker_per_node = []\n    for i in range(total_num_workers):\n        items_per_worker_per_node.append(user_items[start_indices[i] : end_indices[i]])\n\n    # Split the items per worker per node into a list of lists, where each sublist contains the items assigned to a worker\n    items_per_worker_per_node = [\n        items_per_worker_per_node[i : i + num_workers] for i in range(0, len(items_per_worker_per_node), num_workers)\n    ]\n\n    # Return the items per worker per node\n    return items_per_worker_per_node[_get_node_rank()]"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    num_workers_per_node = num_workers // num_nodes\n    num_workers_per_node += int(node_rank < (num_workers % num_nodes))\n\n    num_workers = num_workers_per_node * num_nodes\n\n    num_items_per_worker = len(user_items) // num_workers\n    num_items_per_worker += int(len(user_items) % num_workers != 0)\n\n    start_indices = np.cumsum(\n        [\n            num_items_per_worker\n            for _ in range(num_workers - 1)\n            if num_items_per_worker * num_items_per_worker > 0\n        ]\n        + [len(user_items) - num_items_per_worker * (num_workers - 1)]\n    )\n\n    items_per_worker = [\n        user_items[start_indices[i] : start_indices[i] + num_items_per_worker]\n        if i < num_workers - 1\n        else user_items[start_indices[i] :]\n        for i in range(num_workers)\n    ]\n\n    if len(items_per_worker) != num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return items_per_worker"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    total_num_workers = num_workers * num_nodes\n    num_items = len(user_items)\n    num_items_per_worker = num_items // total_num_workers\n    num_items_per_worker_remainder = num_items % total_num_workers\n\n    # Adjust the number of items per worker based on the remainder\n    if num_items_per_worker_remainder:\n        num_items_per_worker += 1\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = np.cumsum([0] + [num_items_per_worker] * (total_num_workers - 1))\n    end_indices = np.cumsum([num_items_per_worker] * total_num_workers)\n\n    # Distribute the remainder items to the last workers\n    for i in range(num_items_per_worker_remainder):\n        start_indices[-(i + 1)] -= 1\n        end_indices[-(i + 1)] -= 1\n\n    # Determine the items assigned to each worker\n    items_per_worker = []\n    for i in range(total_num_workers):\n        if i % num_nodes == node_rank:\n            start_index = start_indices[i]\n            end_index = end_indices[i]\n            items_per_worker.append(user_items[start_index:end_index])\n\n    # Ensure the output list has a length equal to the number of workers\n    if len(items_per_worker) != total_num_workers:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    return items_per_worker"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n\n    num_workers = num_workers * num_nodes\n\n    num_items = len(user_items)\n\n    if num_items < num_workers:\n        return [user_items[i : i + 1] for i in range(num_items)]\n\n    items_per_worker = num_items // num_workers\n    remainder = num_items % num_workers\n\n    start_indices = np.cumsum([0] + [items_per_worker] * (num_workers - remainder) + [items_per_worker + 1] * remainder)\n    end_indices = np.cumsum([items_per_worker] * (num_workers - remainder) + [items_per_worker + 1] * remainder + [0])\n\n    start_indices += node_rank * num_workers\n    end_indices += node_rank * num_workers\n\n    worker_items = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    if len(worker_items) != num_workers:\n        raise RuntimeError(f\"The number of items ({len(worker_items)}) is not equal to the number of workers ({num_workers})\")\n\n    return worker_items"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    # Calculate the total number of workers across all nodes\n    num_workers_total = num_workers * _get_num_nodes()\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // num_workers_total\n\n    # Calculate the remainder of items\n    remainder = len(user_items) % num_workers_total\n\n    # Initialize an empty list to store the items for each worker\n    items_per_worker = []\n\n    # Initialize a variable to keep track of the current index in the user_items list\n    index = 0\n\n    # Iterate over the total number of workers\n    for i in range(num_workers_total):\n        # Calculate the number of items for the current worker\n        num_items = num_items_per_worker + (i < remainder)\n\n        # Append the items for the current worker to the items_per_worker list\n        items_per_worker.append(user_items[index : index + num_items])\n\n        # Update the index for the next worker\n        index += num_items\n\n    # Check if the length of items_per_worker matches the number of workers\n    if len(items_per_worker) != num_workers_total:\n        raise RuntimeError(\"Improper assignment of items to workers\")\n\n    # Return the items_per_worker list\n    return items_per_worker"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    num_workers_total = num_workers * num_nodes\n\n    # Calculate the number of items each worker should process\n    num_items_per_worker = len(user_items) // num_workers_total\n    num_items_remaining = len(user_items) % num_workers_total\n\n    # Calculate the start and end indices for each worker's items\n    worker_start_indices = [\n        i * num_items_per_worker + min(i, num_items_remaining) for i in range(num_workers_total)\n    ]\n    worker_end_indices = [\n        (i + 1) * num_items_per_worker + min(i + 1, num_items_remaining) for i in range(num_workers_total)\n    ]\n\n    # Adjust the indices to account for the current node's rank\n    node_rank = _get_node_rank()\n    worker_start_indices = [start + node_rank * num_items_per_worker for start in worker_start_indices]\n    worker_end_indices = [end + node_rank * num_items_per_worker for end in worker_end_indices]\n\n    # Create a list of lists, where each sublist contains the items assigned to a worker\n    items_per_worker = [user_items[start:end] for start, end in zip(worker_start_indices, worker_end_indices)]\n\n    # Check if the output list has the correct length\n    if len(items_per_worker) != num_workers_total:\n        raise RuntimeError(\"Improper assignment of items to workers.\")\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    num_workers_per_node = num_workers\n    num_workers_total = num_workers_per_node * num_nodes\n    num_items = len(user_items)\n\n    num_items_per_worker = num_items // num_workers_total\n    num_items_per_worker_remainder = num_items % num_workers_total\n\n    if num_items_per_worker == 0:\n        raise RuntimeError(\n            f\"The number of items ({num_items}) is smaller than the number of workers ({num_workers_total}).\"\n        )\n\n    # Adjust for any remainder by adding extra items to the workers starting from the end of the list\n    num_items_per_worker_adjusted = [num_items_per_worker] * num_workers_total\n    for i in range(num_items_per_worker_remainder):\n        num_items_per_worker_adjusted[i] += 1\n\n    # Calculate the start and end indices for each worker's items\n    cumsum = np.cumsum(num_items_per_worker_adjusted)\n    start_indices = [0] + cumsum[:-1].tolist()\n    end_indices = cumsum.tolist()\n\n    # Assign items to workers\n    items_per_worker = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    # Ensure the output list has a length equal to the number of workers\n    assert len(items_per_worker) == num_workers_total\n\n    return items_per_worker"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    num_nodes = _get_num_nodes()\n    node_rank = _get_node_rank()\n    num_workers = num_workers * num_nodes\n    num_items = len(user_items)\n    num_items_per_worker = num_items // num_workers\n    num_remainder = num_items % num_workers\n    start_idx = num_items_per_worker * node_rank\n    end_idx = num_items_per_worker * (node_rank + 1)\n    if node_rank == (num_nodes - 1):\n        end_idx += num_remainder\n    items = user_items[start_idx:end_idx]\n    if num_remainder > 0:\n        for i in range(num_remainder):\n            items.append(user_items[end_idx + i])\n    items_per_worker = [[] for _ in range(num_workers)]\n    cumsum = 0\n    for i in range(num_workers):\n        cumsum += len(items_per_worker[i])\n        items_per_worker[i] = user_items[cumsum : cumsum + num_items_per_worker]\n        if i == (num_workers - 1) and num_remainder > 0:\n            items_per_worker[i] += user_items[end_idx : end_idx + num_remainder]\n    if len(items_per_worker) != num_workers:\n        raise RuntimeError(f\"Improper assignment of items to workers. Expected {num_workers} workers, got {len(items_per_worker)}.\")\n    return items_per_worker"}
{"namespace": "litdata.processing.data_processor._map_items_to_workers_sequentially", "completion": "    total_workers = num_workers * _get_num_nodes()\n    num_items = len(user_items)\n    num_items_per_worker = num_items // total_workers\n    remainder = num_items % total_workers\n\n    # Adjust for any remainder\n    if remainder > 0:\n        num_items_per_worker += 1\n        remainder -= 1\n\n    # Calculate the start and end indices for each worker's items\n    start_indices = list(range(0, num_items, num_items_per_worker))\n    end_indices = list(range(num_items_per_worker, num_items + num_items_per_worker, num_items_per_worker))\n\n    # Adjust for any remainder\n    if remainder > 0:\n        end_indices[-remainder:] = [end_indices[-remainder - 1] + num_items_per_worker] * remainder\n\n    # Assign items to workers\n    items_per_worker = [user_items[start:end] for start, end in zip(start_indices, end_indices)]\n\n    # Check if the number of items per worker is correct\n    if len(items_per_worker) != total_workers:\n        raise RuntimeError(f\"Improper assignment of items to workers. Expected {total_workers} workers, but got {len(items_per_worker)}.\")\n\n    return items_per_worker\n\n"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": ""}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": ""}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": ""}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": ""}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": ""}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": ""}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": ""}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": ""}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": ""}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": ""}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": ""}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": ""}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": ""}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)\n\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\"\n        \"\"\"\n        The function cleans up cache directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_dir = _get_cache_dir()\n\n        # Cleanup the cache dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_dir):\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        os.makedirs(cache_dir, exist_ok=True)"}
{"namespace": "litdata.processing.data_processor.DataProcessor._cleanup_cache", "completion": "        cache_data_dir = _get_cache_data_dir()\n\n        # Cleanup the cache data dir folder to avoid corrupted files from previous run to be there.\n        if os.path.exists(cache_data_dir):\n            shutil.rmtree(cache_data_dir, ignore_errors=True)\n\n        os.makedirs(cache_data_dir, exist_ok=True)\n\n        \"\"\"\n        The function cleans up cache data directories by removing them if they exist to prevent issues from corrupted files from previous runs, and then recreates these directories to ensure they are available for use.\n\n        Input-Output Arguments\n        :param self: DataProcessor. An instance of the DataProcessor class. It uses this instance to access the method.\n        :return: No return values. This method performs operations on the filesystem but does not return any value.\n        \"\"\""}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": ""}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": ""}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": ""}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": ""}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    return [future.result() for future in futures]\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    return [future.result() for future in futures]\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    for future in concurrent.futures.as_completed(futures):\n        item_sizes.append(future.result())\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    return [future.result() for future in futures]\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    return [future.result() for future in futures]\n\n"}
{"namespace": "litdata.processing.data_processor._get_item_filesizes", "completion": "    item_sizes = [f.result() for f in futures]\n\n    return item_sizes\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": ""}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if input_dir is not None:\n        return element.startswith(input_dir)\n    return os.path.exists(element)"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return element.startswith(input_dir) if input_dir else os.path.exists(element)"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    return os.path.exists(element) or (input_dir and element.startswith(input_dir))\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if input_dir is not None:\n        if element.startswith(input_dir):\n            return True\n\n    if _IS_IN_STUDIO and element.startswith(\"/teamspace\"):\n        return True\n\n    element = str(Path(element).resolve())\n\n    if os.path.exists(element):\n        return True\n\n    return False"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if input_dir is not None and os.path.isabs(element) and element.startswith(input_dir):\n        return True\n\n    if os.path.exists(element):\n        return True\n\n    return False\n\n"}
{"namespace": "litdata.processing.data_processor._is_path", "completion": "    if input_dir is None:\n        return os.path.exists(element)\n    return element.startswith(input_dir) or os.path.exists(element)\n\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            network_fn = tcnn.Network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                encoding=tcnn.Encoding(\n                    n_levels=16,\n                    n_features_per_level=2,\n                    base_resolution=16,\n                    log2_hashmap_size=19,\n                ),\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            )\n        else:\n            network_fn = nn.Sequential(\n                nn.Linear(n_input_dims, n_neurons),\n                nn.ReLU(),\n                *[\n                    nn.Linear(n_neurons, n_neurons)\n                    for _ in range(n_layers - 2)\n                ],\n                nn.Linear(n_neurons, n_output_dims),\n                nn.Sigmoid(),\n            )\n\n        return network_fn"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            network_fn = tcnn.Network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            )\n        else:\n            network_fn = NetworkWithSkipLayers(\n                skip_layers=nn.ModuleList(\n                    [\n                        nn.Linear(n_input_dims, n_neurons)\n                        for _ in range(n_layers - 1)\n                    ]\n                ),\n                output_layers=nn.Linear(n_neurons * n_layers, n_output_dims),\n            )\n\n        return network_fn"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            network_fn = tcnn.NetworkWithInputEncoding(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                encoding_config={\n                    \"otype\": \"Frequency\",\n                    \"n_frequencies\": 10,\n                },\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            )\n        else:\n            network_fn = NetworkWithSkipLayers(\n                skip_layers=nn.ModuleList(\n                    [\n                        nn.Linear(\n                            in_features=n_input_dims,\n                            out_features=n_neurons,\n                            bias=True,\n                        ),\n                        *[\n                            nn.Linear(\n                                in_features=n_neurons,\n                                out_features=n_neurons,\n                                bias=True,\n                            )\n                            for _ in range(n_layers - 2)\n                        ],\n                    ]\n                ),\n                output_layers=nn.Linear(\n                    in_features=n_neurons,\n                    out_features=n_output_dims,\n                    bias=True,\n                ),\n            )\n\n        return network_fn"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            network_fn = tcnn.NetworkWithInputEncoding\n            network_cfg = {\n                \"n_input_dims\": n_input_dims,\n                \"n_output_dims\": n_output_dims,\n                \"encoding_config\": {\n                    \"otype\": \"HashGrid\",\n                    \"n_levels\": 16,\n                    \"n_features_per_level\": 2,\n                    \"log2_hashmap_size\": 19,\n                    \"base_resolution\": 16,\n                    \"per_level_scale\": 1.3819,\n                },\n                \"network_config\": {\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            }\n            return network_fn(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                network_config=network_cfg,\n            )\n        else:\n            network = nn.Sequential()\n            network.append(nn.Linear(n_input_dims, n_neurons))\n            if activation == \"ReLU\":\n                network.append(nn.ReLU())\n            for i in range(n_layers - 2):\n                network.append(nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    network.append(nn.ReLU())\n            network.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                network.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                network."}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            network_fn = tcnn.Network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            )\n        else:\n            network_layers = []\n            for i in range(n_layers - 1):\n                network_layers.append(\n                    nn.Linear(\n                        in_features=n_input_dims if i == 0 else n_neurons,\n                        out_features=n_neurons,\n                    )\n                )\n                network_layers.append(nn.ReLU())\n            network_layers.append(\n                nn.Linear(\n                    in_features=n_input_dims if n_layers == 1 else n_neurons,\n                    out_features=n_output_dims,\n                )\n            )\n            if output_activation == \"ReLU\":\n                network_layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                network_layers.append(nn.Sigmoid())\n\n            network_fn = nn.Sequential(*network_layers)\n\n        return network_fn"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_neurons <= 128:\n                network_type = tcnn.NetworkWithInputEncoding\n            elif n_neurons <= 512:\n                network_type = tcnn.NetworkWithInputEncodingHashGrid\n            else:\n                network_type = tcnn.Network\n\n            return network_type(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                encoding_config={\n                    \"otype\": \"HashGrid\",\n                    \"n_levels\": 16,\n                    \"n_features_per_level\": 2,\n                    \"log2_hashmap_size\": 19,\n                    \"base_resolution\": 16,\n                    \"per_level_scale\": 1.3819,\n                },\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            )\n        else:\n            layers = []\n            for i in range(n_layers - 1):\n                layers.append(\n                    nn.Linear(\n                        n_input_dims if i == 0 else n_neurons,\n                        n_neurons,\n                    )\n                )\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n\n            layers.append(\n                nn.Linear(\n                    n_input_dims if n_layers == 1 else n_neurons,\n                    n_output_dims,\n                )\n            )\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n               "}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            network = tcnn.Network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                encoding=tcnn.Encoding(\n                    n_levels=16,\n                    n_features_per_level=2,\n                    base_resolution=16,\n                    log2_hashmap_size=19,\n                ),\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            )\n        else:\n            network = nn.Sequential()\n            network.append(nn.Linear(n_input_dims, n_neurons))\n            if activation == \"ReLU\":\n                network.append(nn.ReLU())\n            for i in range(n_layers - 2):\n                network.append(nn.Linear(n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    network.append(nn.ReLU())\n            network.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                network.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                network.append(nn.Sigmoid())\n            elif output_activation == \"None\":\n                pass\n            else:\n                raise ValueError(f\"Unknown output activation {output_activation}\")\n        return network"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_neurons <= 128:\n                network_type = tcnn.NetworkWithInputEncoding\n            elif n_neurons <= 256:\n                network_type = tcnn.NetworkWithInputEncoding\n            elif n_neurons <= 512:\n                network_type = tcnn.NetworkWithInputEncoding\n            elif n_neurons <= 1024:\n                network_type = tcnn.NetworkWithInputEncoding\n            else:\n                network_type = tcnn.NetworkWithInputEncoding\n\n            return network_type(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                encoding_config={\n                    \"otype\": \"HashGrid\",\n                    \"n_levels\": 16,\n                    \"n_features_per_level\": 2,\n                    \"log2_hashmap_size\": 15,\n                    \"base_resolution\": 16,\n                    \"per_level_scale\": 1.3819,\n                },\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            )\n        else:\n            layers = []\n            for i in range(n_layers - 1):\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                layers.append(nn.ReLU())\n                n_input_dims = n_neurons\n            layers.append(nn.Linear(n_input_dims, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_neurons > 1024:\n                network_type = tcnn.NetworkWithInputEncoding\n            elif n_neurons > 64:\n                network_type = tcnn.Network\n            else:\n                network_type = tcnn.UNet\n\n            return network_type(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                encoding_config={\n                    \"otype\": \"Frequency\",\n                    \"n_frequencies\": 10,\n                },\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n                seed=self._get_seed(),\n            )\n\n        else:\n            layers = [\n                nn.Linear(n_input_dims, n_neurons),\n                nn.ReLU(),\n            ]\n            for _ in range(n_layers - 1):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(nn.ReLU())\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            network_fn = tcnn.Network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                encoding=tcnn.Encoding(\n                    n_levels=16,\n                    n_features_per_level=2,\n                    base_resolution=16,\n                    log2_hashmap_size=19,\n                ),\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            )\n        else:\n            network_fn = NetworkWithSkipLayers(\n                skip_layers=nn.ModuleList(\n                    [\n                        nn.Linear(\n                            n_input_dims + i * n_neurons,\n                            n_neurons,\n                        )\n                        for i in range(n_layers - 1)\n                    ]\n                ),\n                output_layers=nn.Linear(\n                    n_input_dims + (n_layers - 1) * n_neurons,\n                    n_output_dims,\n                ),\n            )\n\n        return network_fn\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_neurons < 16:\n                network_type = \"fully_fused_mlp\"\n            elif n_neurons < 64:\n                network_type = \"mlp\"\n            else:\n                network_type = \"cutlass\"\n\n            return tcnn.Network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                network_config={\n                    \"otype\": network_type,\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n                seed=self._get_seed(),\n            )\n        else:\n            layers = [\n                nn.Linear(n_input_dims, n_neurons),\n                nn.ReLU() if activation == \"ReLU\" else nn.Identity(),\n            ]\n\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            layers.append(\n                nn.ReLU()\n                if output_activation == \"ReLU\"\n                else nn.Sigmoid()\n                if output_activation == \"Sigmoid\"\n                else nn.Identity()\n            )\n\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_neurons < 16:\n                network_type = tcnn.NetworkWithInputEncoding\n            elif n_neurons < 64:\n                network_type = tcnn.NetworkWithInputSkips\n            else:\n                network_type = tcnn.Network\n            return network_type(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                encoding_config={\n                    \"otype\": \"HashGrid\",\n                    \"n_levels\": 16,\n                    \"n_features_per_level\": 2,\n                    \"log2_hashmap_size\": 19,\n                    \"base_resolution\": 16,\n                    \"per_level_scale\": 1.3819,\n                },\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            )\n        else:\n            if n_layers == 1:\n                return nn.Linear(n_input_dims, n_output_dims)\n            layers = [\n                nn.Linear(n_input_dims, n_neurons),\n                self._get_activation(activation),\n            ]\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(self._get_activation(activation))\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            layers.append(self._get_activation(output_activation))\n            return nn.Sequential(*layers)\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            network = tcnn.Network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                encoding=tcnn.Encoding(n_levels=12),\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            )\n        else:\n            network = nn.Sequential()\n            network.append(nn.Linear(n_input_dims, n_neurons))\n            network.append(self._get_activation(activation))\n            for i in range(n_layers - 1):\n                network.append(nn.Linear(n_neurons, n_neurons))\n                network.append(self._get_activation(activation))\n            network.append(nn.Linear(n_neurons, n_output_dims))\n            network.append(self._get_activation(output_activation))\n        return network\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            network_fn = tcnn.Network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            )\n        else:\n            network_layers = []\n            for i in range(n_layers):\n                network_layers.append(\n                    nn.Linear(\n                        n_input_dims if i == 0 else n_neurons,\n                        n_output_dims if i == n_layers - 1 else n_neurons,\n                    )\n                )\n                if i != n_layers - 1:\n                    if activation == \"ReLU\":\n                        network_layers.append(nn.ReLU())\n                    elif activation != \"None\":\n                        raise NotImplementedError(\n                            f\"Activation {activation} not implemented\"\n                        )\n            network_fn = nn.Sequential(*network_layers)\n\n        return network_fn\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            if n_neurons == 1:\n                network_type = tcnn.NetworkWithInputEncoding\n            elif n_neurons <= 64:\n                network_type = tcnn.EncodingCompressionDecoder\n            elif n_neurons <= 256:\n                network_type = tcnn.FullyFusedMLP\n            else:\n                network_type = tcnn.Network\n\n            return network_type(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                encoding_config={\n                    \"otype\": \"HashGrid\",\n                    \"n_levels\": 16,\n                    \"n_features_per_level\": 2,\n                    \"log2_hashmap_size\": 15,\n                    \"base_resolution\": 16,\n                    \"per_level_scale\": 1.3819,\n                },\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n                seed=self._get_seed(),\n            )\n\n        else:\n            layers = []\n            for i in range(n_layers - 1):\n                layers.append(nn.Linear(n_input_dims if i == 0 else n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n            layers.append(nn.Linear(n_input_dims if n_layers == 1 else n_neurons, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activ"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons < 16:\n                network_type = \"fully_connected\"\n            elif n_neurons < 64:\n                network_type = \"resnet\"\n            else:\n                network_type = \"mlp\"\n\n            return getattr(\n                importlib.import_module(\"tinycudann\"),\n                f\"NetworkWithInputEncoding{network_type}\",\n            )(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                encoding_config={\n                    \"otype\": \"HashGrid\",\n                    \"n_levels\": 16,\n                    \"n_features_per_level\": 2,\n                    \"log2_hashmap_size\": 19,\n                    \"base_resolution\": 16,\n                    \"per_level_scale\": 1.3819,\n                },\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n                seed=self._get_seed(),\n            )\n\n        layers = []\n        for i in range(n_layers - 1):\n            layers.append(nn.Linear(n_input_dims if i == 0 else n_neurons, n_neurons))\n            if i < n_layers - 2:\n                layers.append(getattr(nn, activation)())\n            else:\n                layers.append(getattr(nn, output_activation)())\n\n        return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            network_fn = tcnn.NetworkWithInputEncoding(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                encoding_config={\n                    \"otype\": \"Frequency\",\n                    \"n_frequencies\": 0,\n                },\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            )\n            return network_fn\n        else:\n            layers = []\n            for i in range(n_layers - 1):\n                layers.append(nn.Linear(n_input_dims if i == 0 else n_neurons, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n\n            layers.append(\n                nn.Linear(\n                    n_input_dims if n_layers == 1 else n_neurons, n_output_dims\n                )\n            )\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n\n            return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0\n        assert n_neurons > 0\n\n        if self.tcnn:\n            if n_neurons == 1:\n                return nn.Linear(n_input_dims, n_output_dims)\n            return nn.Sequential(\n                nn.Linear(n_input_dims, n_neurons),\n                nn.ReLU(),\n                *[\n                    nn.Linear(n_neurons, n_neurons)\n                    if i < n_layers - 2\n                    else nn.Linear(n_neurons, n_output_dims)\n                    for i in range(n_layers - 1)\n                ],\n            )\n\n        layers = []\n        for i in range(n_layers - 1):\n            layers.append(nn.Linear(n_input_dims if i == 0 else n_neurons, n_neurons))\n            layers.append(nn.ReLU() if activation == \"ReLU\" else nn.Identity())\n        layers.append(\n            nn.Linear(\n                n_input_dims if n_layers == 1 else n_neurons, n_output_dims\n            )\n        )\n        layers.append(\n            nn.ReLU()\n            if output_activation == \"ReLU\"\n            else nn.Sigmoid()\n            if output_activation == \"Sigmoid\"\n            else nn.Identity()\n        )\n        return nn.Sequential(*layers)"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"There should be at least one layer\"\n        assert n_neurons > 0, \"There should be at least one neuron per layer\"\n\n        if self.tcnn:\n            import tinycudann as tcnn\n\n            network = tcnn.Network(\n                n_input_dims=n_input_dims,\n                n_output_dims=n_output_dims,\n                encoding=tcnn.Encoding(n_levels=16),\n                network_config={\n                    \"otype\": \"FullyFusedMLP\",\n                    \"activation\": activation,\n                    \"output_activation\": output_activation,\n                    \"n_neurons\": n_neurons,\n                    \"n_hidden_layers\": n_layers - 1,\n                },\n            )\n\n            return network\n\n        else:\n            layers = []\n            for i in range(n_layers - 1):\n                layers.append(nn.Linear(n_input_dims, n_neurons))\n                if activation == \"ReLU\":\n                    layers.append(nn.ReLU())\n                n_input_dims = n_neurons\n            layers.append(nn.Linear(n_input_dims, n_output_dims))\n            if output_activation == \"ReLU\":\n                layers.append(nn.ReLU())\n            elif output_activation == \"Sigmoid\":\n                layers.append(nn.Sigmoid())\n            return nn.Sequential(*layers)\n"}
{"namespace": "internal.utils.network_factory.NetworkFactory.get_network", "completion": "        assert n_layers > 0, \"Must have at least one layer\"\n        assert n_neurons > 0, \"Must have at least one neuron\"\n\n        if self.tcnn:\n            if n_neurons > 1024:\n                return self.get_tcnn_network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    seed=self._get_seed(),\n                )\n            else:\n                return self.get_tcnn_network(\n                    n_input_dims=n_input_dims,\n                    n_output_dims=n_output_dims,\n                    n_layers=n_layers,\n                    n_neurons=n_neurons,\n                    activation=activation,\n                    output_activation=output_activation,\n                    seed=self._get_seed(),\n                )\n        else:\n            layers = [\n                nn.Linear(n_input_dims, n_neurons),\n                self._get_activation(activation),\n            ]\n\n            for _ in range(n_layers - 2):\n                layers.append(nn.Linear(n_neurons, n_neurons))\n                layers.append(self._get_activation(activation))\n\n            layers.append(nn.Linear(n_neurons, n_output_dims))\n            layers.append(self._get_activation(output_activation))\n\n            return nn.Sequential(*layers)\n"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n        median_signal = np.median(shifted_signals, axis=0)\n        return median_signal[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n        median_array = np.median(shifted_signals, axis=0)\n        return median_array[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        shifted_signals = [np.roll(signal, offset) for offset in range(-kernel_offset, kernel_offset + 1)]\n        median_array = np.median(shifted_signals, axis=0)\n        return median_array[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        shifted_signals = np.array([np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)])\n        median_array = np.median(shifted_signals, axis=0)\n        return median_array[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        shifted_signals = [np.roll(signal, shift) for shift in range(-kernel_offset, kernel_offset + 1)]\n        median_array = np.median(shifted_signals, axis=0)\n        return median_array[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        shifted_signals = [np.roll(signal, offset) for offset in range(-kernel_offset, kernel_offset + 1)]\n        median_array = np.median(shifted_signals, axis=0)\n        return median_array[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        shifted_signals = [np.roll(signal, offset) for offset in range(-kernel_offset, kernel_offset + 1)]\n        median_array = np.median(shifted_signals, axis=0)\n        return median_array[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n        median_signal = np.median(shifted_signals, axis=0)\n        return median_signal[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n        median_signal = np.median(shifted_signals, axis=0)\n        trimmed_median_signal = median_signal[kernel_offset:-kernel_offset]\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        signal_length = len(signal)\n        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n        median_signal = np.median(shifted_signals, axis=0)\n        trimmed_median_signal = median_signal[kernel_offset : signal_length - kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Shift the signal by the kernel offset in both directions\n        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n\n        # Compute the median of the shifted signals\n        median_signal = np.median(shifted_signals, axis=0)\n\n        # Trim the median signal to remove edge effects\n        trimmed_median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Shift the signal by a range defined by the kernel offset\n        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n\n        # Compute the median of the shifted signals\n        median_array = np.median(shifted_signals, axis=0)\n\n        # Trim the median array to remove edge effects introduced by the shifting process\n        trimmed_median_array = median_array[kernel_offset:-kernel_offset]\n\n        return trimmed_median_array"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        signal_length = len(signal)\n\n        # Compute the shifted signals\n        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n\n        # Compute the median of the shifted signals\n        median_signal = np.median(shifted_signals, axis=0)\n\n        # Trim the median signal to remove edge effects\n        trimmed_median_signal = median_signal[kernel_offset : signal_length - kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Generate shifted signals\n        shifted_signals = np.vstack(\n            [np.roll(signal, shift) for shift in range(-kernel_offset, kernel_offset + 1)]\n        )\n\n        # Calculate rolling median\n        median_signal = np.median(shifted_signals, axis=0)\n\n        # Trim the median array to remove edge effects\n        trimmed_median = median_signal[kernel_offset:-kernel_offset]\n\n        return trimmed_median"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Create a range of offsets to apply to the signal\n        offsets = np.arange(-kernel_offset, kernel_offset + 1)\n\n        # Shift the signal by each offset and compute the median along the last axis\n        shifted_signals = np.stack([np.roll(signal, offset) for offset in offsets], axis=-1)\n        median_signal = np.median(shifted_signals, axis=-1)\n\n        # Trim the median signal to remove edge effects introduced by the shifting process\n        trimmed_median_signal = median_signal[kernel_offset:-kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        offsets = np.arange(2 * kernel_offset + 1) - kernel_offset\n        shifted_signals = np.vstack([np.roll(signal, offset) for offset in offsets])\n        median_array = np.median(shifted_signals, axis=0)\n        return median_array[kernel_offset:-kernel_offset]"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        signal_length = len(signal)\n        shifted_signals = [np.roll(signal, i) for i in range(-kernel_offset, kernel_offset + 1)]\n        median_signal = np.median(shifted_signals, axis=0)\n        trimmed_median_signal = median_signal[kernel_offset : signal_length - kernel_offset]\n        return trimmed_median_signal\n"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        # Compute the number of shifts required to cover the entire range of the kernel offset\n        num_shifts = 2 * kernel_offset + 1\n\n        # Create an array of indices to shift the signal by\n        shift_indices = np.arange(-kernel_offset, kernel_offset + 1)\n\n        # Shift the signal by each offset and compute the median of the resulting signals\n        shifted_signals = np.array([np.roll(signal, shift) for shift in shift_indices])\n        median_signals = np.median(shifted_signals, axis=0)\n\n        # Trim the median signal to remove edge effects introduced by the shifting process\n        trimmed_median_signal = median_signals[kernel_offset:-kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        signal_length = len(signal)\n\n        # Compute the indices for the shifted signals\n        shifted_indices = np.arange(-kernel_offset, kernel_offset + 1)\n\n        # Shift the signal by the indices and compute the median along the axis\n        shifted_signals = np.vstack([np.roll(signal, shift) for shift in shifted_indices])\n        median_signal = np.median(shifted_signals, axis=0)\n\n        # Trim the median signal to remove edge effects introduced by the shifting process\n        trimmed_median_signal = median_signal[kernel_offset : signal_length - kernel_offset]\n\n        return trimmed_median_signal"}
{"namespace": "iris.nodes.geometry_refinement.smoothing.Smoothing._rolling_median", "completion": "        signal_length = len(signal)\n        signal_padded = np.concatenate((signal[-kernel_offset:], signal, signal[:kernel_offset]))\n        signal_padded_left_neighbor = np.roll(signal_padded, kernel_offset)\n        signal_padded_right_neighbor = np.roll(signal_padded, -kernel_offset)\n        signal_padded_left_neighbor_right = np.roll(signal_padded_left_neighbor, kernel_offset)\n        signal_padded_right_neighbor_left = np.roll(signal_padded_right_neighbor, -kernel_offset)\n\n        signal_padded_median = np.median(\n            np.array(\n                [\n                    signal_padded,\n                    signal_padded_left_neighbor,\n                    signal_padded_right_neighbor,\n                    signal_padded_left_neighbor_right,\n                    signal_padded_right_neighbor_left,\n                ]\n            ),\n            axis=0,\n        )\n\n        return signal_padded_median[kernel_offset : signal_length + kernel_offset]"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if the templates have the same number of iris codes\n    if len(template_probe.iriscode) != len(template_gallery.iriscode):\n        raise MatcherError(\"The templates must have the same number of iris codes.\")\n\n    # Check if the templates have the same number of masks\n    if len(template_probe.mask) != len(template_gallery.mask):\n        raise MatcherError(\"The templates must have the same number of masks.\")\n\n    # Check if the templates have the same number of orientations\n    if len(template_probe.orientation) != len(template_gallery.orientation):\n        raise MatcherError(\"The templates must have the same number of orientations.\")\n\n    # Check if the templates have the same number of orientations\n    if len(template_probe.iriscode) != len(template_probe.orientation):\n        raise MatcherError(\"The templates must have the same number of iris codes and orientations.\")\n\n    # Check if the templates have the same number of orientations\n    if len(template_gallery.iriscode) != len(template_gallery.orientation):\n        raise MatcherError(\"The templates must have the same number of iris codes and orientations.\")\n\n    # Check if the templates have the same number of orientations\n    if len(template_probe.mask) != len(template_probe.orientation):\n        raise MatcherError(\"The templates must have the same number of masks and orientations.\")\n\n    # Check if the templates have the same number of orientations\n    if len(template_gallery.mask) != len(template_gallery.orientation):\n        raise MatcherError(\"The templates must have the same number of masks and orientations.\")\n\n    # Check if the templates have the same number of orientations\n    if len(template_probe.iriscode) != len(template_probe.mask):\n        raise MatcherError(\"The templates must have the same number of iris codes and masks.\")\n\n    # Check if the templates have the same number of orientations\n    if len(template_gallery."}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.iriscode.shape != template_gallery.iriscode.shape:\n        raise MatcherError(\"Iris codes must have the same shape\")\n\n    if template_probe.iriscode.dtype != template_gallery.iriscode.dtype:\n        raise MatcherError(\"Iris codes must have the same data type\")\n\n    if template_probe.maskcode.shape != template_gallery.maskcode.shape:\n        raise MatcherError(\"Mask codes must have the same shape\")\n\n    if template_probe.maskcode.dtype != template_gallery.maskcode.dtype:\n        raise MatcherError(\"Mask codes must have the same data type\")\n\n    if template_probe.iriscode.ndim != 3:\n        raise MatcherError(\"Iris codes must be 3D arrays\")\n\n    if template_probe.maskcode.ndim != 3:\n        raise MatcherError(\"Mask codes must be 3D arrays\")\n\n    if template_probe.iriscode.shape[0] != 1:\n        raise MatcherError(\"Iris codes must have 1 row\")\n\n    if template_probe.maskcode.shape[0] != 1:\n        raise MatcherError(\"Mask codes must have 1 row\")\n\n    if template_probe.iriscode.shape[2] != template_gallery.iriscode.shape[2]:\n        raise MatcherError(\"Iris codes must have the same number of channels\")\n\n    if template_probe.maskcode.shape[2] != template_gallery.maskcode.shape[2]:\n        raise MatcherError(\"Mask codes must have the same number of channels\")\n\n    if template_probe.iriscode.shape[1] != template_gallery.iriscode.shape[1]:\n        raise MatcherError(\"Iris codes must have the same number of columns\")\n\n    if template_probe.maskcode.shape[1] != template_gallery.maskcode.shape[1]:\n        raise MatcherError(\"Mask codes must have the same number of columns\")\n\n    if weights"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if the template_probe and template_gallery are of type IrisTemplate\n    if not isinstance(template_probe, IrisTemplate) or not isinstance(template_gallery, IrisTemplate):\n        raise MatcherError(\"The input templates must be of type IrisTemplate\")\n\n    # Check if the rotation_shift is of type int\n    if not isinstance(rotation_shift, int):\n        raise MatcherError(\"The rotation_shift must be of type int\")\n\n    # Check if the nm_dist is of type float or None\n    if nm_dist is not None and not isinstance(nm_dist, float):\n        raise MatcherError(\"The nm_dist must be of type float or None\")\n\n    # Check if the weights is of type List[np.ndarray] or None\n    if weights is not None and not isinstance(weights, List):\n        raise MatcherError(\"The weights must be of type List[np.ndarray] or None\")\n\n    # Check if the weights is a list of np.ndarray\n    if weights is not None and not all(isinstance(w, np.ndarray) for w in weights):\n        raise MatcherError(\"The weights must be a list of np.ndarray\")\n\n    # Check if the weights and template_probe.codes are of the same length\n    if weights is not None and len(weights) != len(template_probe.codes):\n        raise MatcherError(\"The weights and template_probe.codes must be of the same length\")\n\n    # Check if the weights and template_gallery.codes are of the same length\n    if weights is not None and len(weights) != len(template_gallery.codes):\n        raise MatcherError(\"The weights and template_gallery.codes must be of the same length\")\n\n    # Check if the weights and template_probe.codes[0].shape are of the same length\n    if weights is not None and len(weights[0].shape) != len(template_probe.codes[0].shape):\n        raise MatcherError(\"The weights and template_probe.codes[0"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    half_width = [template_probe.width // 2, template_gallery.width // 2]\n    toal_codesize = template_probe.code_size + template_gallery.code_size\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    irisbits = [template_probe.iriscode, template_gallery.iriscode]\n    maskbits = [template_probe.maskcode, template_gallery.maskcode]\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits, maskbits, half_width, weights\n    )\n\n    if nm_dist is None:\n        nm_dist = toal_codesize\n\n    HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n    HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n\n    HD_top = min(HD_top, HD_bot)\n    HD_bot = HD_top\n\n    if rotation_shift > 0:\n        irisbits_rot = [np.roll(x, rotation_shift, axis=2) for x in irisbits]\n        maskbits_rot = [np.roll(x, rotation_shift, axis=2) for x in maskbits]\n\n        irisbitcount_top_rot, maskbitcount_top_rot, irisbitcount_bot_rot, maskbitcount_bot_rot = count_nonmatchbits(\n            irisbits_rot, maskbits_rot, half_width, weights\n        )\n\n        HD_top_rot = normalized_HD(irisbitcount_top_rot, maskbitcount_top_rot, sqrt_totalbitcount_top, nm_dist)\n        HD"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.iriscode.shape[0] != template_gallery.iriscode.shape[0]:\n        raise MatcherError(\"IrisTemplate probe and gallery must have the same number of iriscodes.\")\n\n    if template_probe.maskcode.shape[0] != template_gallery.maskcode.shape[0]:\n        raise MatcherError(\"IrisTemplate probe and gallery must have the same number of maskcodes.\")\n\n    if template_probe.iriscode.shape[1] != template_gallery.iriscode.shape[1]:\n        raise MatcherError(\"IrisTemplate probe and gallery must have the same number of rows.\")\n\n    if template_probe.iriscode.shape[2] != template_gallery.iriscode.shape[2]:\n        raise MatcherError(\"IrisTemplate probe and gallery must have the same number of columns.\")\n\n    if template_probe.iriscode.shape[3] != template_gallery.iriscode.shape[3]:\n        raise MatcherError(\"IrisTemplate probe and gallery must have the same number of channels.\")\n\n    if template_probe.iriscode.shape[1] % 2 != 0:\n        raise MatcherError(\"IrisTemplate probe and gallery must have an even number of rows.\")\n\n    if weights:\n        if template_probe.iriscode.shape[0] != len(weights):\n            raise MatcherError(\"The number of weights tables must match the number of iriscodes.\")\n\n    half_width = [int(template_probe.iriscode.shape[2] / 2)] * template_probe.iriscode.shape[0]\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.iriscode.shape[2] * template_probe.iriscode.shape[3], half_width, weights\n    )\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits("}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.code_size != template_gallery.code_size:\n        raise MatcherError(\"Cannot calculate Hamming distance between iris codes of different sizes.\")\n\n    toal_codesize = template_probe.code_size\n    half_width = [int(toal_codesize / 2)] * 3\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    irisbits_top = np.unpackbits(template_probe.iriscode[:, :half_width[0], ...], axis=1, bitorder=\"little\")\n    irisbits_bot = np.unpackbits(template_probe.iriscode[:, half_width[0] :, ...], axis=1, bitorder=\"little\")\n    maskbits_top = np.unpackbits(template_gallery.iriscode[:, :half_width[0], ...], axis=1, bitorder=\"little\")\n    maskbits_bot = np.unpackbits(template_gallery.iriscode[:, half_width[0] :, ...], axis=1, bitorder=\"little\")\n\n    irisbits = np.concatenate([irisbits_top, irisbits_bot], axis=1)\n    maskbits = np.concatenate([maskbits_top, maskbits_bot], axis=1)\n\n    irisbits = np.roll(irisbits, rotation_shift, axis=1)\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits, maskbits, half_width, weights\n    )\n\n    if nm_dist is None:\n        HD_top = irisbitcount_top / maskbitcount_top\n        HD_bot = irisbitcount_bot / maskbitcount_bot\n    else:\n        HD_top = normalized_HD(irisbit"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if the input templates have the same number of iris codes\n    if len(template_probe.iriscode) != len(template_gallery.iriscode):\n        raise MatcherError(\"The number of iris codes in the templates must be the same.\")\n\n    # Check if the input templates have the same number of mask codes\n    if len(template_probe.maskcode) != len(template_gallery.maskcode):\n        raise MatcherError(\"The number of mask codes in the templates must be the same.\")\n\n    # Check if the input templates have the same number of half widths\n    if len(template_probe.half_width) != len(template_gallery.half_width):\n        raise MatcherError(\"The number of half widths in the templates must be the same.\")\n\n    # Check if the input templates have the same number of weights\n    if weights is not None and len(weights) != len(template_probe.iriscode):\n        raise MatcherError(\"The number of weights in the templates must be the same as the number of iris codes.\")\n\n    # Calculate the total number of iris codes\n    toal_codesize = np.sum([x.size for x in template_probe.iriscode])\n\n    # Calculate the square root of the total number of iris codes\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, template_probe.half_width, weights\n    )\n\n    # Initialize the minimum Hamming distance and the corresponding rotation shift\n    min_hamming_distance = np.inf\n    min_rotation_shift = 0\n\n    # Iterate through the rotation shifts\n    for rotation_shift in range(rotation_shift):\n        # Calculate the Hamming distance for the current rotation shift\n        irisbits = [\n            np.roll(x, rotation_shift, axis=2) & y for x, y in zip(template_probe.iriscode, template_gallery.iriscode)\n        ]\n        maskbits = ["}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.shape != template_gallery.shape:\n        raise MatcherError(\"Template shapes do not match\")\n\n    if rotation_shift < 0:\n        raise MatcherError(\"rotation_shift must be non-negative\")\n\n    if nm_dist is not None and nm_dist < 0:\n        raise MatcherError(\"nm_dist must be non-negative\")\n\n    half_width = [int(hw) for hw in template_probe.half_width]\n    toal_codesize = template_probe.code_size * 3 / 4\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    irisbits_probe = template_probe.irisbits\n    irisbits_gallery = np.roll(template_gallery.irisbits, rotation_shift, axis=1)\n\n    maskbits_probe = template_probe.maskbits\n    maskbits_gallery = np.roll(template_gallery.maskbits, rotation_shift, axis=1)\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits_probe, maskbits_gallery, half_width, weights\n    )\n\n    irisbitcount_top_inv, maskbitcount_top_inv, irisbitcount_bot_inv, maskbitcount_bot_inv = count_nonmatchbits(\n        irisbits_gallery, maskbits_probe, half_width, weights\n    )\n\n    if nm_dist is not None:\n        HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        HD_top_inv = normalized_HD(irisbitcount_top"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    half_width = [int(template_probe.code.shape[1] / 2) for _ in range(template_probe.code.shape[0])]\n\n    # rotate the gallery template\n    template_gallery_rotated = template_gallery.rotate(rotation_shift)\n\n    # calculate the Hamming distance between the probe and the rotated gallery templates\n    irisbits = np.bitwise_xor(template_probe.code, template_gallery_rotated.code)\n    maskbits = np.bitwise_and(template_probe.mask, template_gallery_rotated.mask)\n\n    # count nonmatch bits for Hammming distance\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits, maskbits, half_width, weights\n    )\n\n    # count total amount of sqrt bits\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.code.shape[0] * template_probe.code.shape[1] * template_probe.code.shape[2],\n        half_width,\n        weights,\n    )\n\n    # calculate normalized Hamming distance\n    if nm_dist:\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD = max(norm_HD_top, norm_HD_bot)\n    else:\n        norm_HD = None\n\n    # calculate weighted Hamming distance\n    if weights:\n        irisbitcount = irisbitcount_top + irisbitcount_bot\n        maskbitcount = maskbitcount_top + maskbitcount_bot\n        HD = np.sum([np.sum(np.multiply(x & y, z"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if rotation_shift < 0:\n        raise MatcherError(\"Rotation shift must be greater than 0\")\n\n    if nm_dist and nm_dist < 0:\n        raise MatcherError(\"Nonmatch distance must be greater than 0\")\n\n    if nm_dist and weights:\n        raise MatcherError(\"Only one of normalized or weighted Hamming distance can be used\")\n\n    if weights:\n        if len(weights) != len(template_probe.iriscode) or len(weights) != len(template_gallery.iriscode):\n            raise MatcherError(\"Number of weights tables must match number of iris codes\")\n\n    toal_codesize = np.sum([x.shape[1] for x in template_probe.iriscode])\n    half_width = [x.shape[1] // 2 for x in template_probe.iriscode]\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    irisbits = [\n        np.unpackbits(x, axis=1, bitorder=\"little\").astype(np.uint8)\n        for x in template_probe.iriscode\n    ]\n    maskbits = [\n        np.unpackbits(x, axis=1, bitorder=\"little\").astype(np.uint8)\n        for x in template_gallery.iriscode\n    ]\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits, maskbits, half_width, weights\n    )\n\n    if nm_dist:\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.iriscode.shape != template_gallery.iriscode.shape:\n        raise MatcherError(\"Both templates must have the same shape\")\n\n    if weights and len(weights) != template_probe.iriscode.shape[0]:\n        raise MatcherError(\"The number of weights tables must be equal to the number of iris codes\")\n\n    if rotation_shift == 0:\n        return 0, 0\n\n    half_width = [int(template_probe.iriscode.shape[2] / 2) for _ in range(template_probe.iriscode.shape[0])]\n\n    toal_codesize = np.sum(template_probe.iriscode.shape[1:])\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    irisbits, maskbits = get_irismask_bits(template_probe, template_gallery, rotation_shift)\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits, maskbits, half_width, weights\n    )\n\n    if nm_dist:\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD_bot = normalized_HD(irisbitcount_bot, maskbitcount_bot, sqrt_totalbitcount_bot, nm_dist)\n        norm_HD = norm_HD_top + norm_HD_bot\n        return norm_HD, 0\n\n    HD_top = irisbitcount_top / maskbitcount_top\n    HD_bot = irisbitcount_bot / maskbitcount_bot\n    HD = HD_top + HD_bot\n    return HD, 0\n\n"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if the templates have the same number of rows\n    if template_probe.rows != template_gallery.rows:\n        raise MatcherError(\"The templates must have the same number of rows\")\n\n    # Get the number of rows, half width, and total size of the codes\n    rows = template_probe.rows\n    half_width = template_probe.half_width\n    toal_codesize = template_probe.total_code_size\n\n    # Calculate the square root of the total bit count for the whole iris, top iris, and bottom iris\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Initialize the minimum Hamming distance and rotation shift\n    min_HD = float(\"inf\")\n    min_rotation_shift = 0\n\n    # Iterate over the rotation shifts\n    for rotation_shift in range(rotation_shift):\n        # Shift the iris code of the probe template to the right by the rotation shift\n        irisbits = np.roll(template_probe.iriscode, rotation_shift, axis=1)\n\n        # Calculate the nonmatch bits for the Hamming distance calculation\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits, template_gallery.iriscode, half_width, weights\n        )\n\n        # Calculate the Hamming distances for the top and bottom iris\n        HD_top = irisbitcount_top / maskbitcount_top\n        HD_bot = irisbitcount_bot / maskbitcount_bot\n\n        # Calculate the normalized Hamming distances for the top and bottom iris\n        if nm_dist:\n            norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n            norm_HD_bot = normalized_HD(irisbitcount_bot, maskbit"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.data.shape[1] != template_gallery.data.shape[1]:\n        raise MatcherError(\"Template probe and gallery must have same code length\")\n\n    if template_probe.data.shape[2] != template_gallery.data.shape[2]:\n        raise MatcherError(\"Template probe and gallery must have same code width\")\n\n    if template_probe.data.shape[3] != template_gallery.data.shape[3]:\n        raise MatcherError(\"Template probe and gallery must have same number of views\")\n\n    if template_probe.data.shape[4] != template_gallery.data.shape[4]:\n        raise MatcherError(\"Template probe and gallery must have same number of channels\")\n\n    if weights:\n        if len(weights) != template_probe.data.shape[4]:\n            raise MatcherError(\"Number of weights tables must match number of channels\")\n\n    irisbits_probe = template_probe.data\n    irisbits_gallery = template_gallery.data\n\n    maskbits_probe = template_probe.mask\n    maskbits_gallery = template_gallery.mask\n\n    half_width = [template_probe.data.shape[2] // 2] * template_probe.data.shape[4]\n    toal_codesize = template_probe.data.shape[1] * template_probe.data.shape[2]\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits_probe, maskbits_gallery, half_width, weights\n    )\n\n    if nm_dist:\n        norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        norm_HD"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.iriscode.shape != template_gallery.iriscode.shape:\n        raise MatcherError(\"Template shape mismatch\")\n\n    if rotation_shift < 0 or rotation_shift >= template_probe.iriscode.shape[1]:\n        raise MatcherError(\"Rotation shift out of bounds\")\n\n    iriscode_probe = template_probe.iriscode\n    iriscode_gallery = template_gallery.iriscode\n\n    if weights:\n        if len(weights) != iriscode_probe.shape[0]:\n            raise MatcherError(\"Weights table length mismatch\")\n\n    irisbits_probe = np.unpackbits(iriscode_probe, axis=2, bitorder=\"little\")\n    irisbits_gallery = np.unpackbits(iriscode_gallery, axis=2, bitorder=\"little\")\n\n    maskbits_probe = np.unpackbits(template_probe.maskcode, axis=2, bitorder=\"little\")\n    maskbits_gallery = np.unpackbits(template_gallery.maskcode, axis=2, bitorder=\"little\")\n\n    half_width = [int(w / 2) for w in template_probe.iriscode.shape[2]]\n    total_codesize = np.sum(template_probe.iriscode.shape[2])\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        total_codesize, half_width, weights\n    )\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits_probe, maskbits_gallery, half_width, weights\n    )\n\n    norm_HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n    norm_HD_bot = normalized_HD(irisbitcount_bot"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.codesize != template_gallery.codesize:\n        raise MatcherError(\"Both templates must have the same code size\")\n\n    if rotation_shift < 0:\n        raise MatcherError(\"Rotation shift must be a positive integer\")\n\n    if weights is not None and len(weights) != len(template_probe.irisbits):\n        raise MatcherError(\"Weights must have the same number of elements as irisbits\")\n\n    half_width = [hw // 2 for hw in template_probe.half_width]\n    toal_codesize = template_probe.codesize * 3 // 4\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    irisbits = [np.roll(ib, rotation_shift, axis=2) for ib in template_probe.irisbits]\n\n    min_HD = np.inf\n    min_HD_rotation = -1\n\n    for rotation in range(rotation_shift + 1):\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits, template_gallery.irisbits, half_width, weights\n        )\n\n        if maskbitcount_top == 0 or maskbitcount_bot == 0:\n            continue\n\n        if nm_dist is None:\n            HD_top = (irisbitcount_top + maskbitcount_top - irisbitcount_top) / maskbitcount_top\n            HD_bot = (irisbitcount_bot + maskbitcount_bot - irisbitcount_bot) / maskbitcount_bot\n            HD = (HD_top + HD_bot) / 2\n        else:\n            HD_top = normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n            HD_bot = normalized_HD"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if the templates have the same number of iris codes\n    if len(template_probe.iris_codes) != len(template_gallery.iris_codes):\n        raise MatcherError(\"The templates have different number of iris codes.\")\n\n    # Get the total number of iris codes\n    toal_codesize = sum([x.shape[1] for x in template_probe.iris_codes])\n\n    # Get the half width of the iris codes\n    half_width = [x.shape[2] // 2 for x in template_probe.iris_codes]\n\n    # Calculate the square root of the total number of iris codes\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        toal_codesize, half_width, weights\n    )\n\n    # Initialize the minimum Hamming distance and the corresponding rotation shift\n    min_HD = np.inf\n    min_rotation_shift = 0\n\n    # Iterate over the rotation shifts\n    for r in range(rotation_shift):\n        # Shift the iris codes in the gallery template\n        shifted_gallery_iris_codes = [\n            np.roll(x, r, axis=2) for x in template_gallery.iris_codes\n        ]\n\n        # Calculate the nonmatch bits for the Hamming distance calculation\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            template_probe.iris_codes, shifted_gallery_iris_codes, half_width, weights\n        )\n\n        # Calculate the Hamming distance for the top and bottom iris codes\n        HD_top = (irisbitcount_top + maskbitcount_top - 2 * irisbitcount_top) / maskbitcount_top\n        HD_bot = (irisbitcount_bot + maskbitcount_bot - 2 * irisbitcount_bot) / maskbitcount_bot"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Check if the input templates are valid\n    if not template_probe.is_valid():\n        raise MatcherError(\"Invalid template_probe\")\n    if not template_gallery.is_valid():\n        raise MatcherError(\"Invalid template_gallery\")\n\n    # Check if the rotation shift is valid\n    if rotation_shift < 0:\n        raise MatcherError(\"rotation_shift must be non-negative\")\n\n    # Get the total size of the iris codes\n    total_codesize = template_probe.code.size + template_gallery.code.size\n\n    # Get the half width of the iris codes\n    half_width = [template_probe.code.shape[1] // 2, template_gallery.code.shape[1] // 2]\n\n    # Calculate the number of columns for the Hamming distance calculation\n    cols = total_codesize - rotation_shift\n\n    # Get the iris code bits from the templates\n    irisbits = [template_probe.code, template_gallery.code]\n\n    # Initialize variables for the Hamming distance calculation\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = 0, 0, 0, 0\n\n    # Calculate the number of sqrt bits for the Hamming distance calculation\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        total_codesize, half_width, weights\n    )\n\n    # Calculate the number of nonmatch bits for the Hamming distance calculation\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits, irisbits, half_width, weights\n    )\n\n    # Calculate the Hamming distance\n    HD = (\n        normalized_HD(irisbitcount_top, maskbitcount_top, sqrt_totalbitcount_top, nm_dist)\n        + normalized_HD(irisbitcount_bot, maskbitcount"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if rotation_shift > template_probe.width / 2:\n        raise MatcherError(\"rotation_shift cannot be more than half of the template width\")\n\n    irisbits_probe = template_probe.irisbits\n    maskbits_probe = template_probe.maskbits\n    irisbits_gallery = template_gallery.irisbits\n    maskbits_gallery = template_gallery.maskbits\n\n    if weights:\n        if len(weights) != len(irisbits_probe):\n            raise MatcherError(\"weights must have the same length as irisbits\")\n        weights_probe = weights\n        weights_gallery = weights\n    else:\n        weights_probe = [np.ones(irisbit.shape, dtype=np.int32) for irisbit in irisbits_probe]\n        weights_gallery = [np.ones(irisbit.shape, dtype=np.int32) for irisbit in irisbits_gallery]\n\n    half_width = [irisbit.shape[1] // 2 for irisbit in irisbits_probe]\n\n    irisbits_probe_rotated = [\n        np.roll(irisbit, rotation_shift, axis=1) for irisbit, rotation_shift in zip(irisbits_probe, half_width)\n    ]\n    maskbits_probe_rotated = [\n        np.roll(maskbit, rotation_shift, axis=1) for maskbit, rotation_shift in zip(maskbits_probe, half_width)\n    ]\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.codesize, half_width, weights_probe\n    )\n\n    irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n        irisbits_probe_rotated, maskbits_gallery, half_width, weights_probe\n    )\n\n    if nm_dist is None:"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    # Initialize variables\n    iriscode_size = template_probe.iriscode.shape[1]\n    maskcode_size = template_probe.maskcode.shape[1]\n    toal_codesize = iriscode_size + maskcode_size\n    half_width = [iriscode_size // 2, maskcode_size // 2]\n    rotation_shift_cols = rotation_shift * 2\n\n    # Calculate Hamming distance\n    if weights:\n        if len(weights) != len(half_width):\n            raise MatcherError(\"weights length must be equal to half_width length\")\n\n        sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n            toal_codesize, half_width, weights\n        )\n\n        irisbits = [\n            np.unpackbits(np.ascontiguousarray(template_probe.iriscode), axis=1)[:, ::-1, :],\n            np.unpackbits(np.ascontiguousarray(template_probe.maskcode), axis=1)[:, ::-1, :],\n        ]\n        maskbits = [\n            np.unpackbits(np.ascontiguousarray(template_gallery.iriscode), axis=1)[:, ::-1, :],\n            np.unpackbits(np.ascontiguousarray(template_gallery.maskcode), axis=1)[:, ::-1, :],\n        ]\n\n        irisbits = [\n            np.pad(\n                x,\n                [(0, 0), (0, 0), (0, rotation_shift_cols)],\n                mode=\"constant\",\n            )\n            for x in irisbits\n        ]\n        maskbits = [\n            np.pad(\n                x,\n                [(0, 0), (0, 0), (0, rotation_shift_cols)],\n                mode=\"constant\",\n            )\n            for x in maskbits\n        ]\n\n        iris"}
{"namespace": "iris.nodes.matcher.utils.hamming_distance", "completion": "    if template_probe.data.shape != template_gallery.data.shape:\n        raise MatcherError(\"IrisTemplates must have the same shape.\")\n\n    if rotation_shift < 0:\n        raise MatcherError(\"rotation_shift must be a positive integer.\")\n\n    if nm_dist is not None and (nm_dist < 0 or nm_dist > 1):\n        raise MatcherError(\"nm_dist must be between 0 and 1.\")\n\n    if weights is not None and len(weights) != len(template_probe.data):\n        raise MatcherError(\"weights must have the same length as the number of iris images in the template.\")\n\n    half_width = [int(w / 2) for w in template_probe.data[0].shape[1:]]\n\n    sqrt_totalbitcount, sqrt_totalbitcount_top, sqrt_totalbitcount_bot = count_sqrt_totalbits(\n        template_probe.data.size, half_width, weights\n    )\n\n    min_HD = np.inf\n    min_rotation_shift = -1\n\n    for rs in range(rotation_shift + 1):\n        irisbits_probe = np.unpackbits(template_probe.data[:, :, :, rs:], axis=3, bitorder=\"little\").astype(int)\n        irisbits_gallery = np.unpackbits(template_gallery.data[:, :, :, :-rs], axis=3, bitorder=\"little\").astype(int)\n\n        maskbits = np.unpackbits(template_probe.mask, axis=1, bitorder=\"little\").astype(int)\n\n        irisbitcount_top, maskbitcount_top, irisbitcount_bot, maskbitcount_bot = count_nonmatchbits(\n            irisbits_probe, irisbits_gallery, half_width, weights\n        )\n\n        HD_top = (maskbitcount_top - irisbitcount_top) / maskbitcount_top\n        HD_bot = (maskbitcount"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            for j in range(self.params.max_iterations):\n                point_1 = polygon[np.random.randint(0, len(polygon))]\n                point_2 = polygon[np.random.randint(0, len(polygon))]\n\n                if np.linalg.norm(point_1 - point_2) > min_distance_between_sector_points_in_px:\n                    first_bisectors_point[i] = point_1\n                    second_bisectors_point[i] = point_2\n                    break\n            else:\n                raise EyeCentersEstimationError(\n                    f\"Could not find {self.params.num_bisectors} pairs of points that meet the minimum distance criterion within {self.params.max_iterations} iterations.\"\n                )\n\n        return first_bisectors_point, second_bisectors_point"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = []\n        second_bisectors_point = []\n        for _ in range(self.params.num_bisectors):\n            first_point, second_point = self._find_random_points_pair(polygon, min_distance_between_sector_points_in_px)\n            first_bisectors_point.append(first_point)\n            second_bisectors_point.append(second_point)\n\n        return np.array(first_bisectors_point), np.array(second_bisectors_point)\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        for i in range(num_bisectors):\n            for j in range(max_iterations):\n                point_1_idx, point_2_idx = np.random.choice(len(polygon), size=2, replace=False)\n                point_1 = polygon[point_1_idx]\n                point_2 = polygon[point_2_idx]\n\n                distance = np.linalg.norm(point_1 - point_2)\n\n                if distance > min_distance_between_sector_points_in_px:\n                    first_bisectors_point[i] = point_1\n                    second_bisectors_point[i] = point_2\n                    break\n            else:\n                raise EyeCentersEstimationError(\n                    \"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed.\"\n                )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        num_vertices = len(polygon)\n\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        for i in range(num_bisectors):\n            for _ in range(max_iterations):\n                first_point_index, second_point_index = np.random.choice(num_vertices, 2, replace=False)\n\n                first_point = polygon[first_point_index]\n                second_point = polygon[second_point_index]\n\n                distance_between_points = np.linalg.norm(first_point - second_point)\n\n                if distance_between_points >= min_distance_between_sector_points_in_px:\n                    first_bisectors_point[i] = first_point\n                    second_bisectors_point[i] = second_point\n                    break\n            else:\n                raise EyeCentersEstimationError(\n                    \"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed.\"\n                )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize variables\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        num_iterations = 0\n        num_valid_pairs = 0\n\n        # Loop until we have enough valid pairs of points or reach the maximum number of iterations\n        while num_valid_pairs < self.params.num_bisectors and num_iterations < self.params.max_iterations:\n            # Randomly select two points from the polygon\n            point1 = polygon[np.random.randint(len(polygon))]\n            point2 = polygon[np.random.randint(len(polygon))]\n\n            # Calculate the distance between the two points\n            distance = np.linalg.norm(point1 - point2)\n\n            # Check if the distance between the two points is greater than the minimum distance\n            if distance > min_distance_between_sector_points_in_px:\n                # Calculate the perpendicular bisector of the line connecting the two points\n                midpoint = (point1 + point2) / 2\n                slope = -(point2[0] - point1[0]) / (point2[1] - point1[1])\n                bisector_slope = -1 / slope\n                bisector_intercept = midpoint[1] - bisector_slope * midpoint[0]\n\n                # Store the starting and ending points of the perpendicular bisector\n                first_bisectors_point[num_valid_pairs] = point1\n                second_bisectors_point[num_valid_pairs] = point2\n                num_valid_pairs += 1\n\n            # Increment the iteration counter\n            num_iterations += 1\n\n        # Check if we have enough valid pairs of points\n        if num_valid_pairs < self.params.num_bisectors:\n            raise EyeCentersEstimationError(\"Failed to find enough valid pairs of points.\")\n\n        return first_bisectors_point, second"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        for i in range(num_bisectors):\n            for j in range(max_iterations):\n                # Randomly choose two points from the polygon's vertices\n                point1, point2 = np.random.choice(polygon, 2, replace=False)\n\n                # Calculate the distance between the two points\n                distance = np.linalg.norm(point1 - point2)\n\n                # Check if the distance is greater than the minimum distance\n                if distance > min_distance_between_sector_points_in_px:\n                    # Calculate the perpendicular bisector\n                    midpoint = (point1 + point2) / 2\n                    slope = (point2[1] - point1[1]) / (point2[0] - point1[0])\n                    slope_perp = -1 / slope\n                    b = midpoint[1] - slope_perp * midpoint[0]\n\n                    # Store the starting and ending points of the perpendicular bisector\n                    first_bisectors_point[i] = point1\n                    second_bisectors_point[i] = point2\n                    break\n\n            else:\n                raise EyeCentersEstimationError(\"Failed to find a sufficient number of point pairs.\")\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.empty((self.params.num_bisectors, 2))\n        second_bisectors_point = np.empty((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            for _ in range(self.params.max_iterations):\n                first_point_index, second_point_index = np.random.choice(\n                    range(polygon.shape[0]), size=2, replace=False\n                )\n\n                first_point = polygon[first_point_index]\n                second_point = polygon[second_point_index]\n\n                if np.linalg.norm(first_point - second_point) > min_distance_between_sector_points_in_px:\n                    break\n            else:\n                raise EyeCentersEstimationError(\n                    \"Failed to find sufficient number of point pairs that meet the distance criterion.\"\n                )\n\n            first_bisectors_point[i] = first_point\n            second_bisectors_point[i] = second_point\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            for j in range(self.params.max_iterations):\n                point1, point2 = self._select_random_points(polygon)\n                distance = np.linalg.norm(point1 - point2)\n\n                if distance > min_distance_between_sector_points_in_px:\n                    first_bisectors_point[i] = point1\n                    second_bisectors_point[i] = point2\n                    break\n            else:\n                raise EyeCentersEstimationError(\n                    f\"Failed to find a sufficient number of point pairs that meet the distance criterion within {self.params.max_iterations} iterations.\"\n                )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        first_bisectors_point = np.zeros((num_bisectors, 2))\n        second_bisectors_point = np.zeros((num_bisectors, 2))\n\n        for i in range(num_bisectors):\n            for _ in range(max_iterations):\n                # Randomly choose two points from the polygon\n                point1_idx, point2_idx = np.random.choice(len(polygon), 2, replace=False)\n                point1 = polygon[point1_idx]\n                point2 = polygon[point2_idx]\n\n                # Calculate the distance between the two points\n                distance = np.linalg.norm(point1 - point2)\n\n                # Check if the distance is greater than the minimum distance\n                if distance > min_distance_between_sector_points_in_px:\n                    # Calculate the midpoint between the two points\n                    midpoint = (point1 + point2) / 2\n\n                    # Calculate the slope of the line connecting the two points\n                    slope = (point2[1] - point1[1]) / (point2[0] - point1[0])\n\n                    # Calculate the perpendicular slope\n                    perpendicular_slope = -1 / slope\n\n                    # Calculate the intercept of the perpendicular line\n                    intercept = midpoint[1] - perpendicular_slope * midpoint[0]\n\n                    # Calculate the starting and ending points of the perpendicular bisector\n                    start_x = midpoint[0] - 0.5 * distance\n                    start_y = perpendicular_slope * start_x + intercept\n                    end_x = midpoint[0] + 0.5 * distance\n                    end_y = perpendicular_slope * end_x + intercept\n\n                    # Store the starting and ending points of the perpendicular bisector\n                    first_bisectors_point[i] = [start_x, start_y]\n                    second_bisectors_point[i] = [end_x"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = np.empty((self.params.num_bisectors, 2))\n        second_bisectors_point = np.empty((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            for _ in range(self.params.max_iterations):\n                first_point, second_point = self._get_random_points_from_polygon(polygon)\n                if np.linalg.norm(first_point - second_point) > min_distance_between_sector_points_in_px:\n                    break\n            else:\n                raise EyeCentersEstimationError(\n                    f\"Failed to find {self.params.num_bisectors} pairs of points with a distance greater than {min_distance_between_sector_points_in_px}.\"\n                )\n\n            first_bisectors_point[i] = first_point\n            second_bisectors_point[i] = second_point\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        for _ in range(max_iterations):\n            first_bisectors_point = []\n            second_bisectors_point = []\n\n            for _ in range(num_bisectors):\n                point_a, point_b = self._find_random_points_pair(polygon, min_distance_between_sector_points_in_px)\n                first_bisectors_point.append(point_a)\n                second_bisectors_point.append(point_b)\n\n            if len(first_bisectors_point) == num_bisectors:\n                break\n\n        if len(first_bisectors_point) != num_bisectors:\n            raise EyeCentersEstimationError(\"Failed to find sufficient number of point pairs within the maximum number of iterations.\")\n\n        return np.array(first_bisectors_point), np.array(second_bisectors_point)\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        for _ in range(max_iterations):\n            first_bisectors_point, second_bisectors_point = self._find_random_pair_of_points(polygon, num_bisectors)\n\n            distances = np.linalg.norm(first_bisectors_point - second_bisectors_point, axis=1)\n\n            if np.all(distances >= min_distance_between_sector_points_in_px):\n                return first_bisectors_point, second_bisectors_point\n\n        raise EyeCentersEstimationError(\n            \"Failed to find a sufficient number of point pairs that meet the distance criterion within the maximum number of iterations allowed.\"\n        )\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        first_bisectors_point = []\n        second_bisectors_point = []\n\n        for _ in range(self.params.num_bisectors):\n            for _ in range(self.params.max_iterations):\n                first_point_index, second_point_index = self._get_random_pair_of_points(polygon)\n                first_point = polygon[first_point_index]\n                second_point = polygon[second_point_index]\n                distance_between_points = np.linalg.norm(first_point - second_point)\n\n                if distance_between_points > min_distance_between_sector_points_in_px:\n                    first_bisectors_point.append(first_point)\n                    second_bisectors_point.append(second_point)\n                    break\n            else:\n                raise EyeCentersEstimationError(\n                    f\"Could not find {self.params.num_bisectors} pairs of points with distance > {min_distance_between_sector_points_in_px} in {self.params.max_iterations} iterations.\"\n                )\n\n        return np.array(first_bisectors_point), np.array(second_bisectors_point)\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n\n        for _ in range(max_iterations):\n            first_bisectors_point = np.zeros((num_bisectors, 2))\n            second_bisectors_point = np.zeros((num_bisectors, 2))\n            for i in range(num_bisectors):\n                first_point, second_point = self._randomly_choose_points(polygon, min_distance_between_sector_points_in_px)\n                first_bisectors_point[i], second_bisectors_point[i] = self._calculate_perpendicular_bisector(\n                    first_point, second_point\n                )\n\n            if self._check_bisectors_distance(first_bisectors_point, second_bisectors_point, min_distance_between_sector_points_in_px):\n                break\n        else:\n            raise EyeCentersEstimationError(\"Failed to find sufficient number of point pairs that meet the distance criterion\")\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        for i in range(self.params.max_iterations):\n            first_bisectors_point, second_bisectors_point = self._find_random_points_pair(\n                polygon, min_distance_between_sector_points_in_px\n            )\n            if first_bisectors_point is not None and second_bisectors_point is not None:\n                return first_bisectors_point, second_bisectors_point\n\n        raise EyeCentersEstimationError(\"Could not find enough points pairs with sufficient distance\")\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_vertices = len(polygon)\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        for i in range(self.params.num_bisectors):\n            for j in range(self.params.max_iterations):\n                point1 = polygon[np.random.randint(num_vertices)]\n                point2 = polygon[np.random.randint(num_vertices)]\n                distance_between_points = np.linalg.norm(point1 - point2)\n\n                if distance_between_points > min_distance_between_sector_points_in_px:\n                    midpoint = (point1 + point2) / 2\n                    slope = (point1[1] - point2[1]) / (point1[0] - point2[0])\n                    slope_perpendicular = -1 / slope\n                    intercept = midpoint[1] - slope_perpendicular * midpoint[0]\n\n                    first_bisectors_point[i] = point1\n                    second_bisectors_point[i] = point2\n                    break\n\n            else:\n                raise EyeCentersEstimationError(\n                    f\"Failed to find {self.params.num_bisectors} pairs of points that meet the minimum distance criterion within {self.params.max_iterations} iterations.\"\n                )\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize empty arrays to store the starting and ending points of the perpendicular bisectors\n        first_bisectors_point = np.array([])\n        second_bisectors_point = np.array([])\n\n        # Loop through the specified number of bisectors\n        for _ in range(self.params.num_bisectors):\n            # Initialize variables to track the number of iterations and whether a suitable pair of points has been found\n            iterations = 0\n            pair_found = False\n\n            # Loop until a suitable pair of points is found or the maximum number of iterations is reached\n            while not pair_found:\n                # Increment the iteration count\n                iterations += 1\n\n                # If the maximum number of iterations has been reached, raise an error\n                if iterations > self.params.max_iterations:\n                    raise EyeCentersEstimationError(\n                        \"Failed to find a suitable pair of points after the maximum number of iterations.\"\n                    )\n\n                # Randomly choose two points from the polygon's vertices\n                point_1, point_2 = np.random.choice(polygon, 2, replace=False)\n\n                # Calculate the distance between the two points\n                distance = np.linalg.norm(point_1 - point_2)\n\n                # If the distance between the points is greater than the minimum distance, continue with the calculation\n                if distance > min_distance_between_sector_points_in_px:\n                    # Calculate the midpoint between the two points\n                    midpoint = (point_1 + point_2) / 2\n\n                    # Calculate the vector representing the line between the two points\n                    line_vector = point_2 - point_1\n\n                    # Calculate the normal vector to the line\n                    normal_vector = np.array([-line_vector[1], line_vector[0]])\n\n                    # Normalize the normal vector\n                    normal_vector = normal_vector / np.linalg.norm(normal_vector)\n\n                    # Calculate the starting point of the perpendicular bisector\n                    start_point = midpoint - normal_vector * distance / 2\n\n                    # Calculate the ending"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize arrays to store the starting and ending points of the perpendicular bisectors\n        first_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n        second_bisectors_point = np.zeros((self.params.num_bisectors, 2))\n\n        # Initialize a counter for the number of pairs of points that meet the distance criterion\n        num_pairs_found = 0\n\n        # Initialize a flag to indicate whether the distance criterion has been met\n        distance_criterion_met = False\n\n        # Loop until the distance criterion has been met or the maximum number of iterations has been reached\n        for _ in range(self.params.max_iterations):\n            # Randomly choose two points from the polygon's vertices\n            point1_idx = np.random.randint(len(polygon))\n            point2_idx = np.random.randint(len(polygon))\n\n            # Calculate the distance between the chosen points\n            distance_between_points = np.linalg.norm(polygon[point1_idx] - polygon[point2_idx])\n\n            # Check if the distance between the points is greater than the minimum distance\n            if distance_between_points > min_distance_between_sector_points_in_px:\n                # Store the starting and ending points of the perpendicular bisector\n                first_bisectors_point[num_pairs_found] = polygon[point1_idx]\n                second_bisectors_point[num_pairs_found] = polygon[point2_idx]\n\n                # Increment the counter for the number of pairs of points that meet the distance criterion\n                num_pairs_found += 1\n\n                # Check if the distance criterion has been met\n                if num_pairs_found == self.params.num_bisectors:\n                    distance_criterion_met = True\n                    break\n\n        # Check if the distance criterion was met\n        if not distance_criterion_met:\n            raise EyeCentersEstimationError(\n                f\"Failed to find {self.params.num_bisectors} pairs"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        # Initialize empty lists to store the starting and ending points of the perpendicular bisectors\n        first_bisectors_point = []\n        second_bisectors_point = []\n\n        # Initialize a counter to keep track of the number of iterations\n        iteration = 0\n\n        # Loop until we have enough pairs of points or reach the maximum number of iterations\n        while len(first_bisectors_point) < self.params.num_bisectors and iteration < self.params.max_iterations:\n            # Increment the iteration counter\n            iteration += 1\n\n            # Choose two random points from the polygon's vertices\n            point_1_index = np.random.randint(0, len(polygon))\n            point_2_index = np.random.randint(0, len(polygon))\n\n            # If the chosen points are the same or too close, skip this iteration and try again\n            if (\n                point_1_index == point_2_index\n                or np.linalg.norm(polygon[point_1_index] - polygon[point_2_index]) < min_distance_between_sector_points_in_px\n            ):\n                continue\n\n            # Calculate the midpoint between the two points\n            midpoint = (polygon[point_1_index] + polygon[point_2_index]) / 2\n\n            # Calculate the perpendicular bisector of the line segment formed by the two points\n            perpendicular_bisector = np.array([-midpoint[1], midpoint[0]])\n\n            # Calculate the distance from the midpoint to the edge of the polygon\n            distance_to_edge = np.abs(np.dot(polygon - midpoint, perpendicular_bisector)) / np.linalg.norm(perpendicular_bisector)\n\n            # Calculate the distance between the midpoint and the edge of the polygon\n            distance_between_midpoint_and_edge = np.linalg.norm(midpoint - polygon[point_1_index]) - distance_to_edge\n\n            # If the distance between the midpoint and the edge is less than the minimum distance, skip this"}
{"namespace": "iris.nodes.eye_properties_estimation.bisectors_method.BisectorsMethod._calculate_perpendicular_bisectors", "completion": "        num_bisectors = self.params.num_bisectors\n        max_iterations = self.params.max_iterations\n        num_vertices = polygon.shape[0]\n        num_points = num_bisectors * 2\n\n        for i in range(max_iterations):\n            point_pairs = np.random.randint(0, num_vertices, (num_points, 2))\n            distances = np.linalg.norm(point_pairs[:, 0, :] - point_pairs[:, 1, :], axis=1)\n            if np.all(distances >= min_distance_between_sector_points_in_px):\n                break\n        else:\n            raise EyeCentersEstimationError(\"Failed to find sufficient point pairs\")\n\n        first_bisectors_point = (point_pairs[:, 0, :] + point_pairs[:, 1, :]) / 2\n        second_bisectors_point = np.array([-point_pairs[:, 1, 1] + point_pairs[:, 0, 1], point_pairs[:, 1, 0] - point_pairs[:, 0, 0]]).T / 2\n\n        return first_bisectors_point, second_bisectors_point\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": ""}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": ""}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": ""}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": ""}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": ""}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": ""}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": ""}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": ""}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": ""}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": ""}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": ""}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.before_execution(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.after_execution(self, *args, **kwargs)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.before_execute(self)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.after_execute(self)\n\n        return result"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.on_pre_execute(self, *args, **kwargs)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.on_post_execute(self, *args, **kwargs)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        self.pre_execute(*args, **kwargs)\n        result = self.run(*args, **kwargs)\n        self.post_execute(*args, **kwargs)\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.pre_execute(self)\n\n        result = self.run(*args, **kwargs)\n\n        for callback in self._callbacks:\n            callback.post_execute(self)\n\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        for callback in self._callbacks:\n            callback.before_execution(self, *args, **kwargs)\n        result = self._execute(*args, **kwargs)\n        for callback in self._callbacks:\n            callback.after_execution(self, *args, **kwargs)\n        return result\n"}
{"namespace": "iris.io.class_configs.Algorithm.execute", "completion": "        self.pre_execute(*args, **kwargs)\n        result = self.run(*args, **kwargs)\n        self.post_execute(*args, **kwargs)\n        return result\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except (json.JSONDecodeError, TypeError):\n            return False\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_dict = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n        return self.check_type(output_dict, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            output_dict = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n        return self.check_type(output_dict, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n        except json.JSONDecodeError:\n            return False\n\n        return self.check_type(deserialized_output, type_definition)\n"}
{"namespace": "tanuki.validator.Validator.validate_output", "completion": "        try:\n            deserialized_output = json.loads(output)\n            return self.check_type(deserialized_output, type_definition)\n        except json.JSONDecodeError:\n            return False\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n        for param_name, param in signature.parameters.items():\n            if param.kind == param.POSITIONAL_OR_KEYWORD:\n                input_type_hints[param_name] = type_hints.get(param_name, None)\n            elif param.kind == param.VAR_POSITIONAL:\n                input_type_hints[param_name] = Tuple[type_hints.get(param_name, None)]\n            elif param.kind == param.VAR_KEYWORD:\n                input_type_hints[param_name] = Dict[str, type_hints.get(param_name, None)]\n\n        output_type_hint = type_hints.get('return', None)\n        output_class_definition = get_class_definition(output_type_hint)\n\n        if issubclass(output_class_definition, Embedding) or (\n                get_origin(output_type_hint) == Union and any(\n            issubclass(get_class_definition(arg), Embedding) for arg in get_args(output_type_hint))):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions={param_name: get_class_definition(type_hint) for param_name, type_hint in\n                                     input_type_hints.items()},\n            output_class_definitions=output_class_definition,\n            type=function_type,\n            source=get_source(func_object)"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n\n        input_type_hints = {}\n        output_type_hints = {}\n        for param_name, param in signature.parameters.items():\n            if param.kind == param.POSITIONAL_OR_KEYWORD:\n                input_type_hints[param_name] = type_hints.get(param_name)\n            elif param.kind == param.VAR_POSITIONAL:\n                input_type_hints[param_name] = Tuple[type_hints.get(param_name)]\n            elif param.kind == param.VAR_KEYWORD:\n                input_type_hints[param_name] = Dict[str, type_hints.get(param_name)]\n\n        output_type_hint = type_hints.get('return')\n        output_class_definition = get_class_definition(output_type_hint)\n\n        if issubclass(output_class_definition, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        elif issubclass(output_class_definition, Union):\n            for arg in output_class_definition.__args__:\n                if issubclass(arg, Embedding):\n                    function_type = FunctionType.EMBEDDABLE\n                    output_class_definition = arg\n                    break\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions={param_name: get_class_definition(type_hint) for param_name, type_hint in input_type_hints.items()},\n            output_class_definition=output_class_definition,\n            source="}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n\n        input_type_hints = {}\n        output_type_hints = {}\n\n        for param_name, param in signature.parameters.items():\n            if param.kind == param.POSITIONAL_OR_KEYWORD:\n                input_type_hints[param_name] = type_hints.get(param_name, None)\n            elif param.kind == param.VAR_POSITIONAL:\n                input_type_hints[param_name] = Tuple[type_hints.get(param_name, None)]\n            elif param.kind == param.VAR_KEYWORD:\n                input_type_hints[param_name] = Dict[str, type_hints.get(param_name, None)]\n\n        output_type_hint = type_hints.get('return', None)\n\n        if output_type_hint is None:\n            output_type_hint = Literal[None]\n\n        if get_origin(output_type_hint) is Union:\n            output_type_hint = get_origin(output_type_hint).__args__[0]\n\n        if issubclass(output_type_hint, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n            output_class_definition = get_class_definition(output_type_hint)\n        else:\n            function_type = FunctionType.SYMBOLIC\n            output_class_definition = None\n\n        function_description = FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hint,\n            output_class_definition=output_class_definition,\n            function_type=function_type,\n            source=get_source(func_object)\n        )\n\n        return function_description\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n        source = get_source(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n\n        for param_name, param in signature.parameters.items():\n            if param.kind == param.POSITIONAL_OR_KEYWORD:\n                input_type_hints[param_name] = type_hints.get(param_name, None)\n            elif param.kind == param.VAR_POSITIONAL:\n                input_type_hints[param_name] = Tuple[type_hints.get(param_name, None)]\n            elif param.kind == param.VAR_KEYWORD:\n                input_type_hints[param_name] = Dict[str, type_hints.get(param_name, None)]\n\n        output_type_hint = type_hints.get('return', None)\n\n        if output_type_hint:\n            if inspect.isclass(output_type_hint):\n                output_class_definition = get_class_definition(output_type_hint)\n            elif get_origin(output_type_hint) is Union:\n                output_class_definition = get_class_definition(get_args(output_type_hint)[0])\n            else:\n                output_class_definition = None\n\n            if output_class_definition and issubclass(output_class_definition, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            output_class_definition = None\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_defin"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n\n        for param_name, param in signature.parameters.items():\n            if param.kind == param.POSITIONAL_OR_KEYWORD:\n                input_type_hints[param_name] = type_hints.get(param_name, None)\n\n        if signature.return_annotation is not None:\n            output_type_hints['return'] = type_hints.get('return', None)\n\n        def get_class_definition(type_hint):\n            if type_hint is None:\n                return None\n            elif inspect.isclass(type_hint):\n                return type_hint\n            elif get_origin(type_hint) is Union:\n                return get_class_definition(type_hint.__args__[0])\n            else:\n                return None\n\n        input_class_definitions = {param_name: get_class_definition(type_hint) for param_name, type_hint in input_type_hints.items()}\n        output_class_definition = get_class_definition(output_type_hints.get('return', None))\n\n        function_type = FunctionType.SYMBOLIC\n        if output_class_definition is not None and issubclass(output_class_definition, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_class_definition=output_class_definition,\n            type=function_type,\n            source=get_source(func_object)\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n\n        input_type_hints = {}\n        output_type_hints = {}\n\n        for param_name, param in signature.parameters.items():\n            if param.kind == param.VAR_POSITIONAL:\n                input_type_hints[param_name] = param.annotation\n            elif param.kind == param.VAR_KEYWORD:\n                input_type_hints[param_name] = param.annotation\n            else:\n                input_type_hints[param_name] = param.annotation\n\n        for param_name, param in signature.parameters.items():\n            if param.kind == param.VAR_POSITIONAL:\n                output_type_hints[param_name] = param.annotation\n            elif param.kind == param.VAR_KEYWORD:\n                output_type_hints[param_name] = param.annotation\n            else:\n                output_type_hints[param_name] = param.annotation\n\n        def get_class_definition(type_hint):\n            if type_hint is None:\n                return None\n            elif get_origin(type_hint) is Union:\n                # Handle Union types\n                for arg in get_args(type_hint):\n                    if issubclass(arg, Embedding):\n                        return arg\n                return None\n            elif inspect.isclass(type_hint):\n                return type_hint\n            else:\n                return None\n\n        output_class_definition = get_class_definition(signature.return_annotation)\n\n        if output_class_definition is None:\n            function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n        for parameter_name, parameter in signature.parameters.items():\n            if parameter.kind == inspect.Parameter.POSITIONAL_OR_KEYWORD:\n                input_type_hints[parameter_name] = type_hints.get(parameter_name, None)\n            elif parameter.kind == inspect.Parameter.VAR_POSITIONAL:\n                input_type_hints[parameter_name] = Tuple[type_hints.get(parameter_name, None)]\n            elif parameter.kind == inspect.Parameter.VAR_KEYWORD:\n                input_type_hints[parameter_name] = Dict[str, type_hints.get(parameter_name, None)]\n\n        if 'return' in type_hints:\n            output_type_hints['return'] = type_hints['return']\n\n        input_class_definitions = {}\n        output_class_definitions = {}\n        for parameter_name, parameter_type in input_type_hints.items():\n            input_class_definitions[parameter_name] = Register.get_class_definition(parameter_type)\n\n        for parameter_name, parameter_type in output_type_hints.items():\n            output_class_definitions[parameter_name] = Register.get_class_definition(parameter_type)\n\n        if len(output_class_definitions) == 0:\n            function_type = FunctionType.SYMBOLIC\n        else:\n            output_class_definition = list(output_class_definitions.values())[0]\n            if issubclass(output_class_definition, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            elif get_origin(output_class_definition) == Union:\n                if any(issubclass(arg, Embedding) for arg in get_args(output_class_definition)):\n                   "}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n\n        input_type_hints = {\n            param_name: param_type\n            for param_name, param_type in type_hints.items()\n            if param_name in signature.parameters\n        }\n\n        output_type_hint = type_hints.get('return')\n\n        input_class_definitions = {\n            param_name: get_class_definition(param_type)\n            for param_name, param_type in input_type_hints.items()\n        }\n\n        if output_type_hint:\n            if get_origin(output_type_hint) is Union:\n                output_class_definitions = {\n                    param_type: get_class_definition(param_type)\n                    for param_type in get_args(output_type_hint)\n                }\n            else:\n                output_class_definitions = {\n                    output_type_hint: get_class_definition(output_type_hint)\n                }\n        else:\n            output_class_definitions = {}\n\n        if any(issubclass(cls, Embedding) for cls in output_class_definitions.values()):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_type_hint=output_type_hint,\n            output_class_definitions=output_class_definitions,\n            function_type=function_type,\n            source=get_source(func_object)\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n        for param_name, param in signature.parameters.items():\n            if param.annotation != inspect._empty:\n                if param.kind == param.POSITIONAL_ONLY or param.kind == param.POSITIONAL_OR_KEYWORD:\n                    input_type_hints[param_name] = param.annotation\n                elif param.kind == param.KEYWORD_ONLY:\n                    output_type_hints[param_name] = param.annotation\n\n        def get_class_definition(type_hint):\n            if get_origin(type_hint) is Union:\n                args = get_args(type_hint)\n                for arg in args:\n                    if issubclass(arg, Embedding):\n                        return arg\n            else:\n                if issubclass(type_hint, Embedding):\n                    return type_hint\n                else:\n                    return None\n\n        output_class_definition = get_class_definition(signature.return_annotation)\n\n        if output_class_definition is None:\n            function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions={\n                param_name: get_class_definition(param_type_hint)\n                for param_name, param_type_hint in input_type_hints.items()\n            },\n            output_class_definition=output_class_definition,\n            type=function_type,\n            source=get_source(func_object)\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        sig = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n\n        for key, value in type_hints.items():\n            if key in sig.parameters:\n                input_type_hints[key] = value\n            else:\n                output_type_hints[key] = value\n\n        def get_class_definition(type_hint):\n            if get_origin(type_hint) is Union:\n                args = get_args(type_hint)\n                for arg in args:\n                    if isinstance(arg, type) and issubclass(arg, Embedding):\n                        return arg\n            elif isinstance(type_hint, type) and issubclass(type_hint, Embedding):\n                return type_hint\n\n        output_class_definition = get_class_definition(list(output_type_hints.values())[0])\n\n        if output_class_definition is not None:\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=func_object.__doc__,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions={key: get_class_definition(value) for key, value in input_type_hints.items()},\n            output_class_definition=output_class_definition,\n            type=function_type,\n            source=get_source(func_object)\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n        source = get_source(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n        for param_name, param in signature.parameters.items():\n            if param.annotation != param.empty:\n                if param.kind == param.POSITIONAL_OR_KEYWORD:\n                    input_type_hints[param_name] = param.annotation\n                elif param.kind == param.KEYWORD_ONLY:\n                    output_type_hints[param_name] = param.annotation\n\n        input_class_definitions = {}\n        output_class_definitions = {}\n        for param_name, param_type in input_type_hints.items():\n            input_class_definitions[param_name] = Register.get_class_definition(param_type)\n\n        output_class_definitions = {}\n        for param_name, param_type in output_type_hints.items():\n            output_class_definitions[param_name] = Register.get_class_definition(param_type)\n\n        function_type = FunctionType.SYMBOLIC\n        if len(output_type_hints) > 0:\n            output_type_hint = list(output_type_hints.values())[0]\n            if inspect.isclass(output_type_hint) and issubclass(output_type_hint, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            elif get_origin(output_type_hint) == Union:\n                for arg in get_args(output_type_hint):\n                    if inspect.isclass(arg) and issubclass(arg, Embedding):\n                        function_type = FunctionType.EMBEDDABLE\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n        input_type_hints = {key: type_hints[key] for key in type_hints if key in signature.parameters}\n        output_type_hints = type_hints.get(\"return\", None)\n        input_class_definitions = {key: get_class_definition(input_type_hints[key]) for key in input_type_hints}\n\n        if get_origin(output_type_hints) is Union:\n            output_class_definitions = [get_class_definition(arg) for arg in get_args(output_type_hints)]\n        else:\n            output_class_definitions = [get_class_definition(output_type_hints)]\n\n        if Embedding in output_class_definitions:\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_class_definitions=output_class_definitions,\n            type=function_type,\n            source=get_source(func_object)\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the signature of the function\n        sig = inspect.signature(func_object)\n\n        # Get the type hints of the function's parameters and return value\n        type_hints = get_type_hints(func_object)\n\n        # Get the docstring of the function\n        docstring = inspect.getdoc(func_object)\n\n        # Get the function's name\n        func_name = func_object.__name__\n\n        # Determine the input and output type hints\n        input_type_hints = {}\n        output_type_hints = {}\n        for param_name, param in sig.parameters.items():\n            if param.kind == param.POSITIONAL_OR_KEYWORD:\n                input_type_hints[param_name] = type_hints.get(param_name, None)\n            elif param.kind == param.VAR_POSITIONAL:\n                input_type_hints[param_name] = Tuple[type_hints.get(param_name, None)]\n            elif param.kind == param.VAR_KEYWORD:\n                input_type_hints[param_name] = Dict[str, type_hints.get(param_name, None)]\n\n        output_type_hints = type_hints.get(\"return\", None)\n\n        # Determine the input and output class definitions\n        input_class_definitions = {}\n        output_class_definitions = {}\n\n        for param_name, param_type in input_type_hints.items():\n            input_class_definitions[param_name] = Register.get_class_definition(param_type)\n\n        if output_type_hints:\n            output_class_definitions = Register.get_class_definition(output_type_hints)\n\n        # Determine the function type\n        if output_type_hints and issubclass(output_type_hints, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        elif output_type_hints and get_origin(output_type_hints) == Union:\n            if any(issub"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n\n        for param_name, param in signature.parameters.items():\n            if param.kind == param.POSITIONAL_OR_KEYWORD:\n                input_type_hints[param_name] = type_hints.get(param_name, None)\n\n        output_type_hint = type_hints.get('return', None)\n        output_type_hints['return'] = output_type_hint\n\n        input_class_definitions = {}\n        output_class_definitions = {}\n\n        for param_name, param_type in input_type_hints.items():\n            input_class_definitions[param_name] = Register.get_class_definition(param_type)\n\n        output_class_definitions['return'] = Register.get_class_definition(output_type_hint)\n\n        if isinstance(output_class_definitions['return'], Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_class_definitions=output_class_definitions,\n            function_type=function_type,\n            source=get_source(func_object),\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        sig = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n        input_type_hints = {}\n        output_type_hints = {}\n        input_class_definitions = {}\n        output_class_definitions = {}\n\n        for param_name, param in sig.parameters.items():\n            if param.kind == inspect.Parameter.POSITIONAL_OR_KEYWORD:\n                if param.annotation != inspect.Parameter.empty:\n                    input_type_hints[param_name] = param.annotation\n                    input_class_definitions[param_name] = get_class_definition(param.annotation)\n\n        if sig.return_annotation != inspect.Signature.empty:\n            output_type_hints['return'] = sig.return_annotation\n            output_class_definitions['return'] = get_class_definition(sig.return_annotation)\n\n        # Determine function type\n        if sig.return_annotation == inspect.Signature.empty:\n            function_type = FunctionType.SYMBOLIC\n        else:\n            if get_origin(sig.return_annotation) is Union:\n                function_type = FunctionType.SYMBOLIC\n            elif issubclass(sig.return_annotation, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions=input_class_definitions,\n            output_class_definitions=output_class_definitions,\n            type=function_type,\n            source=get_source(func_object)\n        )\n"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n        function_name = func_object.__name__\n        input_type_hints = {k: v for k, v in type_hints.items() if k in signature.parameters}\n        output_type_hints = type_hints.get('return')\n        input_class_definitions = {k: get_class_definition(v) for k, v in input_type_hints.items()}\n\n        if output_type_hints is not None:\n            if inspect.isclass(output_type_hints) and issubclass(output_type_hints, Embedding):\n                output_class_definition = get_class_definition(output_type_hints)\n                function_type = FunctionType.EMBEDDABLE\n            elif get_origin(output_type_hints) is Union:\n                output_types = get_args(output_type_hints)\n                for output_type in output_types:\n                    if inspect.isclass(output_type) and issubclass(output_type, Embedding):\n                        output_class_definition = get_class_definition(output_type)\n                        function_type = FunctionType.EMBEDDABLE\n                        break\n                else:\n                    raise ValueError(f\"Output type {output_type_hints} is not a subclass of Embedding or a Union of Embedding subclasses\")\n            else:\n                output_class_definition = get_class_definition(output_type_hints)\n                function_type = FunctionType.SYMBOLIC\n        else:\n            output_class_definition = None\n            function_type = FunctionType.SYMBOLIC\n\n        function_description = FunctionDescription(\n            name=function_name,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions=input_class_defin"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        # Get the function signature\n        signature = inspect.signature(func_object)\n\n        # Get the type hints of the function\n        type_hints = get_type_hints(func_object)\n\n        # Get the docstring of the function\n        docstring = inspect.getdoc(func_object)\n\n        # Determine the input and output type hints\n        input_type_hints = {}\n        output_type_hint = None\n        for parameter_name, parameter in signature.parameters.items():\n            if parameter.annotation is not inspect.Parameter.empty:\n                input_type_hints[parameter_name] = parameter.annotation\n            else:\n                input_type_hints[parameter_name] = None\n\n        if signature.return_annotation is not inspect.Signature.empty:\n            output_type_hint = signature.return_annotation\n        else:\n            output_type_hint = None\n\n        # Get the class definitions for the input and output type hints\n        input_class_definitions = {parameter_name: get_class_definition(parameter_type)\n                                  for parameter_name, parameter_type in input_type_hints.items()}\n        output_class_definition = get_class_definition(output_type_hint)\n\n        # Determine the function type based on the output type hint\n        if isinstance(output_type_hint, type) and issubclass(output_type_hint, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        elif isinstance(output_type_hint, Union):\n            if any(issubclass(arg, Embedding) for arg in get_args(output_type_hint)):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        # Create and return the FunctionDescription object\n        return FunctionDescription(func_object.__name__, docstring, input_type_hints, output_type_hint,\n                                   input_class_definitions, output_"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        sig = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n        for param in sig.parameters.values():\n            if param.kind == param.VAR_POSITIONAL:\n                input_type_hints[param.name] = type_hints[param.name]\n            elif param.kind == param.VAR_KEYWORD:\n                output_type_hints[param.name] = type_hints[param.name]\n            else:\n                input_type_hints[param.name] = type_hints[param.name]\n\n        def get_class_definition(type_hint):\n            if get_origin(type_hint) is Literal:\n                return type_hint\n            elif get_origin(type_hint) is Union:\n                return type_hint.__args__[0]\n            elif hasattr(type_hint, \"__name__\"):\n                return type_hint\n            else:\n                return None\n\n        input_class_definitions = {k: get_class_definition(v) for k, v in input_type_hints.items()}\n        output_class_definitions = {k: get_class_definition(v) for k, v in output_type_hints.items()}\n\n        output_type = next(iter(output_type_hints.values()))\n        output_class_definition = get_class_definition(output_type)\n\n        if issubclass(output_class_definition, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            docstring=docstring,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            input_class_definitions="}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        signature = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = inspect.getdoc(func_object)\n        source = get_source(func_object)\n\n        input_type_hints = {}\n        output_type_hints = {}\n        for parameter_name, parameter in signature.parameters.items():\n            if parameter.annotation != inspect._empty:\n                if parameter.kind == inspect.Parameter.POSITIONAL_ONLY or parameter.kind == inspect.Parameter.POSITIONAL_OR_KEYWORD:\n                    input_type_hints[parameter_name] = parameter.annotation\n                elif parameter.kind == inspect.Parameter.KEYWORD_ONLY:\n                    output_type_hints[parameter_name] = parameter.annotation\n\n        def get_class_definition(type_hint):\n            origin = get_origin(type_hint)\n            if origin is not None:\n                if issubclass(origin, Union):\n                    args = getattr(type_hint, '__args__', None)\n                    if args is not None:\n                        for arg in args:\n                            if arg is not None and not isinstance(arg, type(...)):\n                                return get_class_definition(arg)\n                else:\n                    return origin\n            else:\n                return type_hint\n\n        output_class_definition = None\n        if len(output_type_hints) == 1:\n            output_class_definition = get_class_definition(list(output_type_hints.values())[0])\n            if issubclass(output_class_definition, Embedding):\n                function_type = FunctionType.EMBEDDABLE\n            else:\n                function_type = FunctionType.SYMBOLIC\n        else:\n            function_type = FunctionType.SYMBOLIC\n\n        return FunctionDescription(\n            name=func_object.__name__,\n            input_type_hints=input_type_hints,\n            output_type_hints=output_type_hints,\n            output_class_definition=output_class_definition"}
{"namespace": "tanuki.register.Register.load_function_description", "completion": "        sig = inspect.signature(func_object)\n        type_hints = get_type_hints(func_object)\n        docstring = func_object.__doc__\n\n        input_type_hints = {}\n        output_type_hints = {}\n\n        for param_name, param in sig.parameters.items():\n            if param.kind == param.POSITIONAL_OR_KEYWORD:\n                if param.annotation != inspect._empty:\n                    input_type_hints[param_name] = param.annotation\n\n        if sig.return_annotation != inspect._empty:\n            output_type_hints = sig.return_annotation\n\n        def get_class_definition(type_hint):\n            if type_hint is inspect._empty:\n                return None\n            elif inspect.isclass(type_hint):\n                if hasattr(type_hint, '__origin__') and type_hint.__origin__ is Union:\n                    return {arg.__name__: get_class_definition(arg) for arg in type_hint.__args__}\n                else:\n                    return type_hint.__name__\n            elif get_origin(type_hint) is Union:\n                return {arg.__name__: get_class_definition(arg) for arg in type_hint.__args__}\n            else:\n                return None\n\n        input_class_definitions = {param_name: get_class_definition(type_hint) for param_name, type_hint in input_type_hints.items()}\n        output_class_definition = get_class_definition(output_type_hints)\n\n        if output_class_definition is None:\n            function_type = FunctionType.SYMBOLIC\n        elif issubclass(output_class_definition, Embedding):\n            function_type = FunctionType.EMBEDDABLE\n        elif type(output_class_definition) is dict:\n            function_type = FunctionType.SYMBOLIC\n        else:\n            raise ValueError(f\"Unknown output type: {output_class_definition}\")\n\n        return FunctionDescription("}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[seed] = index\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n\n        self.persistence.save(self)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[seed] = index\n\n        #print(f\"Added: {string}\")\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n\n        self.persistence.save(self)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] = self.indices[index] + 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n        self.indices[self.bit_array.search(1)] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] = seed\n        self.persistence.save(self.bit_array, self.indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n        self.persistence.save(self)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            self.bit_array[index] = 1\n            self.indices[index] += 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.add", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for seed in range(self.hash_count):\n            index = (hash1 + seed * hash2) % self.size\n            #print(f\"Add: Seed={seed}, Digest={index}, BitValue={self.bit_array[index]}\")\n            self.bit_array[index] = 1\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(bit_array) != expected_length:\n            logging.warning(f\"BloomFilter bit array length mismatch. Expected {expected_length}, got {len(bit_array)}. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n            self.indices = np.zeros(self.size, dtype=np.int32)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array, self.indices = self.persistence.load(self.size)\n        if len(self.bit_array) != self.size:\n            logging.warning(\"BloomFilter bit array length mismatch. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array, self.indices = self.persistence.load()\n        if len(self.bit_array) != self.size:\n            logging.warning(\"BloomFilter bit array length does not match expected size. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(self.bit_array) != expected_length:\n            logging.warning(f\"BloomFilter bit array length mismatch. Expected {expected_length}, but got {len(self.bit_array)}. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(loaded_bit_array) != expected_length:\n            logging.warning(\n                f\"Loaded bit array length ({len(loaded_bit_array)}) does not match expected length ({expected_length}). Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n            self.indices = np.zeros(self.size, dtype=np.int32)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(loaded_bit_array) != expected_length:\n            logging.warning(f\"Loaded bit array length ({len(loaded_bit_array)}) does not match expected length ({expected_length}). Reinitializing and saving...\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(bit_array) != expected_length:\n            logging.warning(f\"Loaded bit array length ({len(bit_array)}) does not match expected length ({expected_length}). Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array, self.indices = self.persistence.load()\n\n        expected_length = self.size\n        if len(self.bit_array) != expected_length:\n            logging.warning(f\"Bloom filter bit array length mismatch. Expected {expected_length}, but got {len(self.bit_array)}. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(loaded_bit_array) != expected_length:\n            logging.warning(f\"Loaded bit array length {len(loaded_bit_array)} does not match expected length {expected_length}. \"\n                            f\"Reinitializing and saving new state.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(loaded_bit_array) != expected_length:\n            logging.warning(f\"Loaded bit array length ({len(loaded_bit_array)}) does not match expected length ({expected_length}). Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n            self.indices = np.zeros(self.size, dtype=np.int32)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(bit_array) != expected_length:\n            logging.warning(\"BloomFilter bit array length mismatch. Expected: %d, Actual: %d. Reinitializing and saving...\", expected_length, len(bit_array))\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(loaded_bit_array) != expected_length:\n            logging.warning(\"Loaded bit array length does not match the expected length. Possible corruption detected. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n            self.indices = np.zeros(self.size, dtype=np.int32)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(loaded_bit_array) != expected_length:\n            logging.warning(f\"Loaded bit array length {len(loaded_bit_array)} does not match expected length {expected_length}. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if len(loaded_bit_array) != self.size:\n            logging.warning(\"BloomFilter bit array length mismatch. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if loaded_bit_array is None:\n            logging.warning(\"Bloom filter bit array is empty. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        elif len(loaded_bit_array) != self.size:\n            logging.warning(\"Bloom filter bit array length mismatch. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n            self.indices = np.zeros(self.size, dtype=np.int32)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(loaded_bit_array) != expected_length:\n            logging.warning(\"Loaded bit array length does not match expected length. Possible corruption. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n            self.indices = np.zeros(self.size, dtype=np.int32)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        self.bit_array = self.persistence.load()\n        expected_length = self.size\n        if len(self.bit_array) != expected_length:\n            logging.warning(f\"BloomFilter bit array length mismatch. Expected {expected_length}, got {len(self.bit_array)}. Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n        if loaded_bit_array is not None:\n            expected_length = self.size\n            if len(loaded_bit_array) != expected_length:\n                logging.warning(f\"BloomFilter bit array length mismatch. Expected: {expected_length}, Actual: {len(loaded_bit_array)}\")\n                self.bit_array, self.indices = self.init_bit_array(self.size)\n                self.save()\n            else:\n                self.bit_array = loaded_bit_array\n        else:\n            logging.warning(\"BloomFilter bit array not found in persistence.\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        bit_array = self.persistence.load()\n        expected_length = self.size\n\n        if len(bit_array) != expected_length:\n            logging.warning(f\"BloomFilter: Loaded bit array length ({len(bit_array)}) does not match expected length ({expected_length}). Reinitializing and saving.\")\n            self.bit_array, self.indices = self.init_bit_array(expected_length)\n            self.save()\n        else:\n            self.bit_array = bit_array\n            self.indices = np.zeros(expected_length, dtype=np.int32)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.load", "completion": "        loaded_bit_array = self.persistence.load()\n\n        expected_length = self.size\n        actual_length = len(loaded_bit_array)\n\n        if actual_length != expected_length:\n            logging.warning(f\"BloomFilter bit array length mismatch. Expected: {expected_length}, Actual: {actual_length}\")\n            self.bit_array, self.indices = self.init_bit_array(self.size)\n            self.save()\n        else:\n            self.bit_array = loaded_bit_array\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        indices = self.get_indices(string)\n        for i in indices:\n            if self.bit_array[i] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            # generate a new index using the hash functions\n            index = self.hash_functions(string + str(i))[0] % self.size\n            # check if the bit at the index is not set\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        indices = self.get_indices(string)\n        for index in indices:\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        indices = self.get_indices(string)\n        for index in indices:\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        indices = self.get_indices(string)\n        for index in indices:\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            # bit_index = (hash1 + i * hash2) % self.size\n            bit_index = (self.hash_functions(string)[0] + i * self.hash_functions(string)[1]) % self.size\n            if self.bit_array[bit_index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # Generate hash values\n        hash1, hash2 = self.hash_functions(string)\n\n        # Generate indices\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n\n        # Check if all bits at the generated indices are set\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        indices = self.get_indices(string)\n        for i in indices:\n            if not self.bit_array[i]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        for i in range(self.hash_count):\n            index = (hash1 + i * hash2) % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            # bit array index\n            index = self.hash_functions(string)[i] % self.size\n            # if any of the bits is not set, return False\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            # generate a new seed hash value by combining the hash values from the current string with the seed hash\n            seed = self.hash_functions(string + str(i))\n            index = seed % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            # Bitwise AND operation with 2^32 - 1 to ensure the index is within the valid range of the bit array\n            index = (self.hash_functions(string)[0] + i * self.hash_functions(string)[1]) & (2 ** 32 - 1) % self.size\n            # Check if the bit at the index is not set\n            if not self.bit_array[index]:\n                # If any bit is not set, the string is definitely not in the filter\n                return False\n        # If all bits are set, the string might be in the filter (with a possibility of false positives)\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            # generate a new index using the i-th hash function\n            index = self.hash_functions(string)[i] % self.size\n            # check if the bit at the index is not set\n            if not self.bit_array[index]:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        # Generate hash values\n        hash1, hash2 = self.hash_functions(string)\n\n        # Generate indices using the hash values and the hash count\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n\n        # Check if all bits at the generated indices are set\n        for index in indices:\n            if not self.bit_array[index]:\n                return False\n\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        hash1, hash2 = self.hash_functions(string)\n        indices = [(hash1 + i * hash2) % self.size for i in range(self.hash_count)]\n        return all(self.bit_array[i] for i in indices)\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        for i in range(self.hash_count):\n            # Bitwise AND operation with 2^32 - 1 to ensure the index is within the range of the bit array\n            index = (self.hash_functions(string)[0] + i * self.hash_functions(string)[1]) & (2 ** 32 - 1)\n            index = index % self.size\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.bloom_filter.BloomFilter.lookup", "completion": "        indices = self.get_indices(string)\n        for index in indices:\n            if self.bit_array[index] == 0:\n                return False\n        return True\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_model_config(teacher_model_dict) for teacher_model_dict in json_dict[\"teacher_models\"]]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if DISTILLED_MODEL in json_dict:\n            self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if TEACHER_MODEL in json_dict:\n            self.teacher_models = [config_factory.get_model_config(teacher_model_dict) for teacher_model_dict in json_dict[TEACHER_MODEL]]"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_config(json_dict[\"distilled_model\"][\"name\"], DISTILLED_MODEL)\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_config(teacher_model[\"name\"], TEACHER_MODEL) for teacher_model in json_dict[\"teacher_models\"]]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_from_dict(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.load_from_dict(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_model_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.load_model_config(teacher_model_dict) for teacher_model_dict in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_model_config(json_dict.get(\"distilled_model\", {}))\n        self.current_model_stats = json_dict.get(\"current_model_stats\", {})\n        self.last_training_run = json_dict.get(\"last_training_run\", {})\n        self.current_training_run = json_dict.get(\"current_training_run\", {})\n        self.nr_of_training_runs = json_dict.get(\"nr_of_training_runs\", 0)\n        self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict.get(\"teacher_models\", [])]\n        return self"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_model_config(teacher_model_dict) for teacher_model_dict in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        else:\n            self.teacher_models = [DEFAULT_TEACHER_MODELS[teacher_model_name] for teacher_model_name in DEFAULT_TEACHER_MODEL_NAMES]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        self.teacher_models = [config_factory.get_model_config(teacher_model_config) for teacher_model_config in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.create_model_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.create_model_config(teacher_model) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if \"distilled_model\" in json_dict:\n            self.distilled_model = config_factory.get_model_config(json_dict[\"distilled_model\"][\"name\"], json_dict[\"distilled_model\"][\"model_type\"])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_model_config(teacher_model[\"name\"], teacher_model[\"model_type\"]) for teacher_model in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.get_config(teacher_model_dict) for teacher_model_dict in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_model_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if \"teacher_models\" in json_dict:\n            self.teacher_models = [config_factory.load_model_config(teacher_model_dict) for teacher_model_dict in json_dict[\"teacher_models\"]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        if DISTILLED_MODEL in json_dict:\n            self.distilled_model = config_factory.create_config(json_dict[DISTILLED_MODEL])\n        if \"current_model_stats\" in json_dict:\n            self.current_model_stats = json_dict[\"current_model_stats\"]\n        if \"last_training_run\" in json_dict:\n            self.last_training_run = json_dict[\"last_training_run\"]\n        if \"current_training_run\" in json_dict:\n            self.current_training_run = json_dict[\"current_training_run\"]\n        if \"nr_of_training_runs\" in json_dict:\n            self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        if TEACHER_MODEL in json_dict:\n            self.teacher_models = [config_factory.create_config(teacher_model) for teacher_model in json_dict[TEACHER_MODEL]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.get_model_config(json_dict[DISTILLED_MODEL])\n        self.current_model_stats = json_dict[\"current_model_stats\"]\n        self.last_training_run = json_dict[\"last_training_run\"]\n        self.current_training_run = json_dict[\"current_training_run\"]\n        self.nr_of_training_runs = json_dict[\"nr_of_training_runs\"]\n        self.teacher_models = [config_factory.get_model_config(teacher_model) for teacher_model in json_dict[TEACHER_MODEL]]\n        return self\n"}
{"namespace": "tanuki.models.function_config.FunctionConfig.load_from_dict", "completion": "        self.distilled_model = config_factory.load_model_config(json_dict.get(DISTILLED_MODEL, self.distilled_model))\n        self.current_model_stats = json_dict.get(\"current_model_stats\", self.current_model_stats)\n        self.last_training_run = json_dict.get(\"last_training_run\", self.last_training_run)\n        self.current_training_run = json_dict.get(\"current_training_run\", self.current_training_run)\n        self.nr_of_training_runs = json_dict.get(\"nr_of_training_runs\", self.nr_of_training_runs)\n        teacher_models_json = json_dict.get(TEACHER_MODEL, [])\n        self.teacher_models = [config_factory.load_model_config(teacher_model_json) for teacher_model_json in teacher_models_json]\n        return self\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the parameters\n        for parameter in LLM_GENERATION_PARAMETERS:\n            if parameter in kwargs:\n                assert parameter in model.parameters, f\"{parameter} is not a valid parameter for the {model.model_name} model.\"\n\n        # Set the default parameters\n        for parameter in LLM_GENERATION_PARAMETERS:\n            if parameter not in kwargs:\n                kwargs[parameter] = model.parameters[parameter]\n\n        # Set the default max_new_tokens if not specified\n        if \"max_new_tokens\" not in kwargs:\n            kwargs[\"max_new_tokens\"] = model.parameters[\"max_new_tokens\"]\n\n        # Set the default temperature if not specified\n        if \"temperature\" not in kwargs:\n            kwargs[\"temperature\"] = model.parameters[\"temperature\"]\n\n        # Set the default top_p if not specified\n        if \"top_p\" not in kwargs:\n            kwargs[\"top_p\"] = model.parameters[\"top_p\"]\n\n        # Set the default frequency_penalty if not specified\n        if \"frequency_penalty\" not in kwargs:\n            kwargs[\"frequency_penalty\"] = model.parameters[\"frequency_penalty\"]\n\n        # Set the default presence_penalty if not specified\n        if \"presence_penalty\" not in kwargs:\n            kwargs[\"presence_penalty\"] = model.parameters[\"presence_penalty\"]\n\n        # Set the default model if not specified\n        if \"model\" not in kwargs:\n            kwargs[\"model\"] = model.model_name\n\n        # Set the default messages if not specified\n        if \"messages\" not in kwargs:\n            kwargs[\"messages\"] = [\n                {\"role\": \"system\", \"content\": system_message},\n                {\"role\": \"user\", \"content\": prompt},\n            ]\n\n        # Set the default stop if not specified\n        if \"stop\" not in kwargs:"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Check if any of the required parameters are missing\n        if not all(param in kwargs for param in LLM_GENERATION_PARAMETERS):\n            raise ValueError(f\"Missing required parameters: {LLM_GENERATION_PARAMETERS}\")\n\n        # Set default values for missing parameters\n        kwargs.setdefault(\"temperature\", 0.7)\n        kwargs.setdefault(\"top_p\", 1)\n        kwargs.setdefault(\"frequency_penalty\", 0)\n        kwargs.setdefault(\"presence_penalty\", 0)\n        kwargs.setdefault(\"max_new_tokens\", 256)\n\n        # Validate the parameters\n        if not isinstance(model, OpenAIConfig):\n            raise ValueError(\"Invalid model type. Expected OpenAIConfig.\")\n        if not isinstance(system_message, str):\n            raise ValueError(\"Invalid system_message type. Expected str.\")\n        if not isinstance(prompt, str):\n            raise ValueError(\"Invalid prompt type. Expected str.\")\n        if not isinstance(kwargs[\"temperature\"], float) or not 0 <= kwargs[\"temperature\"] <= 1:\n            raise ValueError(\"Invalid temperature value. Expected a float between 0 and 1.\")\n        if not isinstance(kwargs[\"top_p\"], float) or not 0 <= kwargs[\"top_p\"] <= 1:\n            raise ValueError(\"Invalid top_p value. Expected a float between 0 and 1.\")\n        if not isinstance(kwargs[\"frequency_penalty\"], float) or not 0 <= kwargs[\"frequency_penalty\"] <= 1:\n            raise ValueError(\"Invalid frequency_penalty value. Expected a float between 0 and 1.\")\n        if not isinstance(kwargs[\"presence_penalty\"], float) or not 0 <= kwargs[\"presence_penalty\"] <= 1:\n            raise ValueError(\"Invalid presence_penalty value. Expected a float between 0 and 1.\")\n        if not isinstance(kwargs[\"max"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Check if the API key is set\n        self.check_api_key()\n\n        # Validate the parameters\n        for parameter in LLM_GENERATION_PARAMETERS:\n            if parameter in kwargs:\n                if parameter == \"temperature\" and not (0 <= kwargs[parameter] <= 1):\n                    raise ValueError(f\"{parameter} must be between 0 and 1\")\n                elif parameter == \"top_p\" and not (0 <= kwargs[parameter] <= 1):\n                    raise ValueError(f\"{parameter} must be between 0 and 1\")\n                elif parameter == \"frequency_penalty\" and not (0 <= kwargs[parameter] <= 1):\n                    raise ValueError(f\"{parameter} must be between 0 and 1\")\n                elif parameter == \"presence_penalty\" and not (0 <= kwargs[parameter] <= 1):\n                    raise ValueError(f\"{parameter} must be between 0 and 1\")\n                elif parameter == \"max_new_tokens\" and not (1 <= kwargs[parameter] <= 4096):\n                    raise ValueError(f\"{parameter} must be between 1 and 4096\")\n\n        # Set the default values for the parameters if not provided\n        kwargs[\"temperature\"] = kwargs.get(\"temperature\", 0.7)\n        kwargs[\"top_p\"] = kwargs.get(\"top_p\", 1)\n        kwargs[\"frequency_penalty\"] = kwargs.get(\"frequency_penalty\", 0)\n        kwargs[\"presence_penalty\"] = kwargs.get(\"presence_penalty\", 0)\n        kwargs[\"max_new_tokens\"] = kwargs.get(\"max_new_tokens\", 1024)\n\n        # Set the default values for the parsing helper tokens if not provided\n        model.start_sequence = model.start_sequence or \"\"\n        model.end_sequence = model.end_sequence or \"\"\n\n        # Set the default value for the system message if not provided"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        # Check if the API key is set\n        self.check_api_key()\n\n        # Validate the parameters\n        self.validate_parameters(**kwargs)\n\n        # Set the default values for the parameters\n        temperature = kwargs.get(\"temperature\", 0.7)\n        top_p = kwargs.get(\"top_p\", 1)\n        frequency_penalty = kwargs.get(\"frequency_penalty\", 0)\n        presence_penalty = kwargs.get(\"presence_penalty\", 0)\n        max_new_tokens = kwargs.get(\"max_new_tokens\", 200)\n\n        # Set the messages for the API request\n        messages = [\n            {\"role\": \"system\", \"content\": system_message},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n\n        # Set the parameters for the API request\n        params = {\n            \"model\": model.model_name,\n            \"messages\": messages,\n            \"temperature\": temperature,\n            \"top_p\": top_p,\n            \"frequency_penalty\": frequency_penalty,\n            \"presence_penalty\": presence_penalty,\n            \"max_tokens\": max_new_tokens,\n        }\n\n        # Set the headers for the API request\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.api_key}\",\n        }\n\n        # Set the number of retries and the initial retry delay\n        num_retries = 5\n        retry_delay = 1\n\n        # Try to generate the response from the API\n        for i in range(num_retries):\n            try:\n                # Send the API request\n                response = requests.post(\n                    OPENAI_URL,\n                    json=params,\n                    headers=headers,\n                    timeout=10,\n                )\n\n                # Check if the request was successful\n                if response.status_code == 200:\n                    # Parse the response\n                    response_json = response."}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate parameters\n        for param in LLM_GENERATION_PARAMETERS:\n            if param in kwargs and not isinstance(kwargs[param], (int, float)):\n                raise ValueError(f\"{param} must be a number\")\n\n        # Set default values for optional parameters\n        temperature = kwargs.get(\"temperature\", 0.5)\n        top_p = kwargs.get(\"top_p\", 1)\n        frequency_penalty = kwargs.get(\"frequency_penalty\", 0)\n        presence_penalty = kwargs.get(\"presence_penalty\", 0)\n        max_new_tokens = kwargs.get(\"max_new_tokens\", 500)\n\n        # Set up the request payload\n        payload = {\n            \"model\": model.model_name,\n            \"messages\": [\n                {\"role\": \"system\", \"content\": system_message},\n                {\"role\": \"user\", \"content\": prompt},\n            ],\n            \"temperature\": temperature,\n            \"top_p\": top_p,\n            \"frequency_penalty\": frequency_penalty,\n            \"presence_penalty\": presence_penalty,\n            \"max_tokens\": max_new_tokens,\n        }\n\n        # Set up the request headers\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.api_key}\",\n        }\n\n        # Make the API request with exponential backoff\n        max_retries = 5\n        retry_count = 0\n        while retry_count < max_retries:\n            try:\n                response = requests.post(OPENAI_URL, headers=headers, json=payload)\n                response.raise_for_status()\n                break\n            except requests.exceptions.RequestException as e:\n                if retry_count == max_retries - 1:\n                    raise e\n                wait_time = 2 ** retry_count\n                logging.warning"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the parameters\n        if not isinstance(model, OpenAIConfig):\n            raise TypeError(\"model must be an instance of OpenAIConfig\")\n        if not isinstance(system_message, str):\n            raise TypeError(\"system_message must be a string\")\n        if not isinstance(prompt, str):\n            raise TypeError(\"prompt must be a string\")\n        for param in kwargs:\n            if param not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter: {param}\")\n\n        # Set the default values for the parameters\n        temperature = kwargs.get(\"temperature\", 0.7)\n        top_p = kwargs.get(\"top_p\", 1)\n        frequency_penalty = kwargs.get(\"frequency_penalty\", 0)\n        presence_penalty = kwargs.get(\"presence_penalty\", 0)\n        max_new_tokens = kwargs.get(\"max_new_tokens\", 1024)\n\n        # Define the retry parameters\n        max_retries = 5\n        retry_delay = 1  # Start with a 1-second delay\n\n        # Loop until we get a response or run out of retries\n        for i in range(max_retries):\n            try:\n                # Make the API request\n                response = self.client.chat.completions.create(\n                    model=model.model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt},\n                    ],\n                    temperature=temperature,\n                    top_p=top_p,\n                    frequency_penalty=frequency_penalty,\n                    presence_penalty=presence_penalty,\n                    max_tokens=max_new_tokens,\n                    **kwargs,\n                )\n\n                # Process the response and remove any parsing helper tokens\n                text = response.choices[0].message.content\n                for token in"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the model name\n        if model.model_name not in self.model_names:\n            raise ValueError(f\"Invalid model name: {model.model_name}. Supported models are: {self.model_names}\")\n\n        # Validate the parsing helper tokens\n        if model.parsing_helper_tokens is not None:\n            if not isinstance(model.parsing_helper_tokens, dict):\n                raise ValueError(\"parsing_helper_tokens must be a dictionary\")\n            for key, value in model.parsing_helper_tokens.items():\n                if not isinstance(key, str) or not isinstance(value, str):\n                    raise ValueError(\"parsing_helper_tokens keys and values must be strings\")\n\n        # Validate the additional parameters\n        for param in kwargs:\n            if param not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter: {param}. Supported parameters are: {LLM_GENERATION_PARAMETERS}\")\n\n        # Retry logic\n        max_retries = 5\n        retry_count = 0\n        while True:\n            try:\n                # Generate the response\n                response = self.client.chat.completions.create(\n                    model=model.model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt},\n                    ],\n                    **kwargs\n                )\n\n                # Process the response\n                text = response.choices[0].message.content\n                if model.parsing_helper_tokens is not None:\n                    for key, value in model.parsing_helper_tokens.items():\n                        text = text.replace(key, value)\n\n                return text\n\n            except Exception as e:\n                logging.error(f\"Error while generating response: {e}\")\n\n                # Check if we've reached the maximum number of retries\n                if retry_count >= max_retries:\n                    raise e\n\n               "}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the parameters\n        for param in LLM_GENERATION_PARAMETERS:\n            if param not in kwargs:\n                raise ValueError(f\"Missing required parameter: {param}\")\n\n        # Set the default values for parameters\n        temperature = kwargs.get(\"temperature\", 0.7)\n        top_p = kwargs.get(\"top_p\", 1)\n        frequency_penalty = kwargs.get(\"frequency_penalty\", 0)\n        presence_penalty = kwargs.get(\"presence_penalty\", 0)\n        max_new_tokens = kwargs.get(\"max_new_tokens\", 1024)\n\n        # Set the retry parameters\n        max_retries = 5\n        retry_delay = 1\n\n        # Initialize the response text\n        response_text = None\n\n        # Retry the request with exponential backoff\n        for i in range(max_retries):\n            try:\n                # Make the API request\n                response = self.client.chat.completions.create(\n                    model=model.model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    temperature=temperature,\n                    top_p=top_p,\n                    frequency_penalty=frequency_penalty,\n                    presence_penalty=presence_penalty,\n                    max_tokens=max_new_tokens\n                )\n\n                # Process the response\n                response_text = response.choices[0].message.content\n\n                # Remove any parsing helper tokens from the response\n                for token in model.parsing_helper_tokens:\n                    response_text = response_text.replace(token, \"\")\n\n                # Exit the loop if the request was successful\n                break\n            except Exception as e:\n                # Log the error\n                logging.error(f\"Error during API request: {e}\")\n\n                # Calculate"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the parameters\n        for parameter in LLM_GENERATION_PARAMETERS:\n            if parameter in kwargs:\n                assert type(kwargs[parameter]) == float, f\"{parameter} must be a float\"\n\n        # Set default values for parameters\n        temperature = kwargs.get(\"temperature\", 0.0)\n        top_p = kwargs.get(\"top_p\", 1.0)\n        frequency_penalty = kwargs.get(\"frequency_penalty\", 0.0)\n        presence_penalty = kwargs.get(\"presence_penalty\", 0.0)\n        max_new_tokens = kwargs.get(\"max_new_tokens\", 1024)\n\n        # Set the model name and parsing helper tokens\n        model_name = model.model_name\n        parsing_helper_tokens = model.parsing_helper_tokens\n\n        # Set the retry parameters\n        max_retries = 5\n        retry_delay = 1\n\n        # Set the initial retry counter\n        retry_count = 0\n\n        # Set the initial response to None\n        response = None\n\n        # Set the initial error to None\n        error = None\n\n        # Loop until a response is received or the maximum number of retries is reached\n        while response is None and retry_count < max_retries:\n            try:\n                # Make the API call\n                response = self.client.chat.completions.create(\n                    model=model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt},\n                    ],\n                    temperature=temperature,\n                    top_p=top_p,\n                    frequency_penalty=frequency_penalty,\n                    presence_penalty=presence_penalty,\n                    max_tokens=max_new_tokens,\n                    **kwargs,\n                )\n            except Exception as e:\n                # If an error occurs, set the"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the parameters\n        for param in LLM_GENERATION_PARAMETERS:\n            if param in kwargs:\n                assert isinstance(kwargs[param], (int, float)), f\"{param} must be a number\"\n\n        # Set the default values for parameters that are not provided\n        kwargs.setdefault(\"temperature\", 0.7)\n        kwargs.setdefault(\"top_p\", 1)\n        kwargs.setdefault(\"frequency_penalty\", 0)\n        kwargs.setdefault(\"presence_penalty\", 0)\n        kwargs.setdefault(\"max_new_tokens\", 100)\n\n        # Set the model name and parsing helper tokens\n        model_name = model.model_name\n        start_token = model.start_token\n        end_token = model.end_token\n\n        # Define the retry function\n        def retry_with_exponential_backoff(retries=5, delay=1):\n            for i in range(retries):\n                try:\n                    response = self.client.chat.create(\n                        model=model_name,\n                        messages=[\n                            {\"role\": \"system\", \"content\": system_message},\n                            {\"role\": \"user\", \"content\": prompt},\n                        ],\n                        **kwargs\n                    )\n                    return response\n                except Exception as e:\n                    logging.warning(f\"Error while generating text: {e}\")\n                    if i == retries - 1:\n                        raise\n                    time.sleep(delay)\n                    delay *= 2\n\n        # Retry the API call with exponential backoff\n        response = retry_with_exponential_backoff()\n\n        # Process the response to remove any parsing helper tokens\n        text = response.choices[0].message.content.strip()\n        if start_token and text.startswith(start_token):\n            text = text[len(start_token):]\n        if end_token and text.endswith(end_token):\n            text = text[:-len(end"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate that the model is an instance of OpenAIConfig\n        if not isinstance(model, OpenAIConfig):\n            raise ValueError(\"Model must be an instance of OpenAIConfig\")\n\n        # Validate that the system_message is a string\n        if not isinstance(system_message, str):\n            raise ValueError(\"system_message must be a string\")\n\n        # Validate that the prompt is a string\n        if not isinstance(prompt, str):\n            raise ValueError(\"prompt must be a string\")\n\n        # Validate that the kwargs are valid parameters for the OpenAI API\n        for key in kwargs:\n            if key not in LLM_GENERATION_PARAMETERS:\n                raise ValueError(f\"Invalid parameter: {key}\")\n\n        # Set the default values for the generation parameters\n        params = {\n            \"temperature\": 0.7,\n            \"top_p\": 1,\n            \"frequency_penalty\": 0,\n            \"presence_penalty\": 0,\n            \"max_new_tokens\": 1024,\n        }\n\n        # Update the default parameters with any user-provided values\n        params.update(kwargs)\n\n        # Set the model name and parameters in the request body\n        request_body = {\n            \"model\": model.model_name,\n            \"messages\": [\n                {\"role\": \"system\", \"content\": system_message},\n                {\"role\": \"user\", \"content\": prompt},\n            ],\n            \"max_new_tokens\": params[\"max_new_tokens\"],\n            \"temperature\": params[\"temperature\"],\n            \"top_p\": params[\"top_p\"],\n            \"frequency_penalty\": params[\"frequency_penalty\"],\n            \"presence_penalty\": params[\"presence_penalty\"],\n        }\n\n        # Initialize the number of retries and the delay between retries\n        num_retries = 0\n        retry_delay = 1\n\n        # Loop until a successful response is received or the maximum number of retries is"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        self.validate_parameters(kwargs)\n\n        # Set default values for parameters\n        kwargs.setdefault(\"temperature\", 0.7)\n        kwargs.setdefault(\"top_p\", 1)\n        kwargs.setdefault(\"frequency_penalty\", 0)\n        kwargs.setdefault(\"presence_penalty\", 0)\n        kwargs.setdefault(\"max_new_tokens\", 100)\n\n        # Set up the request body\n        request_body = {\n            \"model\": model.model_name,\n            \"messages\": [\n                {\"role\": \"system\", \"content\": system_message},\n                {\"role\": \"user\", \"content\": prompt},\n            ],\n            **kwargs,\n        }\n\n        # Send the request to the OpenAI API\n        for attempt in range(5):\n            try:\n                response = requests.post(\n                    OPENAI_URL,\n                    headers={\n                        \"Content-Type\": \"application/json\",\n                        \"Authorization\": f\"Bearer {self.api_key}\",\n                    },\n                    json=request_body,\n                )\n                response.raise_for_status()\n                break\n            except requests.exceptions.RequestException as e:\n                if attempt == 4:\n                    raise e\n                time.sleep(2 ** attempt)\n\n        # Process the response\n        response_text = response.json()[\"choices\"][0][\"message\"][\"content\"]\n        response_text = response_text.replace(model.parsing_helper_token, \"\")\n        return response_text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the parameters\n        for parameter in LLM_GENERATION_PARAMETERS:\n            if parameter in kwargs:\n                assert type(kwargs[parameter]) == float, f\"{parameter} must be a float\"\n\n        # Retry up to 5 times with exponential backoff\n        for i in range(5):\n            try:\n                response = self.client.chat.create(\n                    model=model.model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt},\n                    ],\n                    **kwargs\n                )\n                break\n            except Exception as e:\n                print(f\"An error occurred: {e}\")\n                if i < 4:\n                    time.sleep(2 ** i)\n                else:\n                    raise e\n\n        # Process the response\n        text = response.choices[0].message.content\n        text = text.replace(model.parsing_helper_token, \"\")\n\n        return text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate parameters\n        for parameter in LLM_GENERATION_PARAMETERS:\n            if parameter in kwargs:\n                assert kwargs[parameter] >= 0\n\n        # Set default parameters\n        if \"temperature\" not in kwargs:\n            kwargs[\"temperature\"] = 0.5\n        if \"top_p\" not in kwargs:\n            kwargs[\"top_p\"] = 1\n        if \"frequency_penalty\" not in kwargs:\n            kwargs[\"frequency_penalty\"] = 0\n        if \"presence_penalty\" not in kwargs:\n            kwargs[\"presence_penalty\"] = 0\n        if \"max_new_tokens\" not in kwargs:\n            kwargs[\"max_new_tokens\"] = 100\n\n        # Initialize variables\n        response = None\n        retries = 0\n        max_retries = 5\n        backoff_time = 1\n\n        # Loop until a valid response is received or maximum retries are reached\n        while response is None and retries < max_retries:\n            try:\n                # Send request to OpenAI API\n                response = self.client.chat.completions.create(\n                    model=model.model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt},\n                    ],\n                    **kwargs\n                )\n\n                # Extract generated text from response\n                generated_text = response.choices[0].message.content\n\n                # Remove parsing helper tokens from generated text\n                for token in model.parsing_helper_tokens:\n                    generated_text = generated_text.replace(token, \"\")\n\n                return generated_text\n\n            except Exception as e:\n                # Handle API errors and retry with exponential backoff\n                logging.warning(f\"Error occurred while generating text: {e}\")\n                retries += 1\n                if retries < max_retries:\n                    backoff_time *= 2\n                    time."}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate parameters\n        self.validate_parameters(**kwargs)\n\n        # Retry logic\n        max_retries = 5\n        retry_delay = 1\n        for i in range(max_retries):\n            try:\n                response = self.client.chat.completions.create(\n                    model=model.model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt},\n                    ],\n                    **kwargs\n                )\n                break\n            except Exception as e:\n                logging.warning(f\"An error occurred: {e}\")\n                if i < max_retries - 1:\n                    retry_delay *= 2\n                    logging.info(f\"Retrying in {retry_delay} seconds...\")\n                    time.sleep(retry_delay)\n                else:\n                    raise Exception(f\"Failed to generate text after {max_retries} attempts.\")\n\n        # Process response\n        text = response.choices[0].message.content\n        if model.parsing_helper_tokens:\n            for token in model.parsing_helper_tokens:\n                text = text.replace(token, \"\")\n        return text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the parameters\n        for parameter in LLM_GENERATION_PARAMETERS:\n            if parameter in kwargs:\n                assert kwargs[parameter] >= 0, f\"{parameter} must be non-negative\"\n\n        # Set the default values for parameters that are not provided\n        if \"temperature\" not in kwargs:\n            kwargs[\"temperature\"] = 0.7\n        if \"top_p\" not in kwargs:\n            kwargs[\"top_p\"] = 1\n        if \"frequency_penalty\" not in kwargs:\n            kwargs[\"frequency_penalty\"] = 0\n        if \"presence_penalty\" not in kwargs:\n            kwargs[\"presence_penalty\"] = 0\n        if \"max_new_tokens\" not in kwargs:\n            kwargs[\"max_new_tokens\"] = 100\n\n        # Set the default value for the model name\n        if model is None:\n            model = DEFAULT_DISTILLED_MODEL_NAME\n\n        # Set the default value for the system message\n        if system_message is None:\n            system_message = \"You are a helpful assistant.\"\n\n        # Set the default value for the prompt\n        if prompt is None:\n            prompt = \"Hello, how are you?\"\n\n        # Create the messages list with the system message and the user prompt\n        messages = [\n            {\"role\": \"system\", \"content\": system_message},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n\n        # Retry the API call with exponential backoff up to 5 times\n        for attempt in range(5):\n            try:\n                # Call the OpenAI API to generate a response\n                response = self.client.chat.create(\n                    model=model.model_name,\n                    messages=messages,\n                    **kwargs\n                )\n                break  # Break out of the loop if the API call is successful\n            except Exception as e:\n                logging.warning(f\"An error occurred: {e}\")\n                if attempt < 4:"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate the parameters\n        for parameter in LLM_GENERATION_PARAMETERS:\n            if parameter in kwargs:\n                if parameter in model.parameters:\n                    kwargs[parameter] = model.parameters[parameter]\n                else:\n                    logging.warning(f\"Parameter {parameter} not found in model configuration. Using default value.\")\n\n        # Retry with exponential backoff\n        for retry in range(5):\n            try:\n                response = self.client.chat.completions.create(\n                    model=model.model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt}\n                    ],\n                    **kwargs\n                )\n                break\n            except Exception as e:\n                logging.warning(f\"An error occurred: {e}\")\n                time.sleep(2 ** retry)\n        else:\n            raise Exception(\"Failed to generate response after 5 retries.\")\n\n        # Process the response\n        text = response.choices[0].message.content\n        if model.parsing_helper_tokens:\n            text = text.replace(model.parsing_helper_tokens[\"start\"], \"\").replace(model.parsing_helper_tokens[\"end\"], \"\")\n\n        return text\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # validate parameters\n        for parameter in LLM_GENERATION_PARAMETERS:\n            if parameter in kwargs:\n                assert kwargs[parameter] is not None, f\"{parameter} must be specified\"\n\n        # set default values\n        if \"temperature\" not in kwargs:\n            kwargs[\"temperature\"] = 0\n        if \"top_p\" not in kwargs:\n            kwargs[\"top_p\"] = 1\n        if \"max_new_tokens\" not in kwargs:\n            kwargs[\"max_new_tokens\"] = 1024\n        if \"frequency_penalty\" not in kwargs:\n            kwargs[\"frequency_penalty\"] = 0\n        if \"presence_penalty\" not in kwargs:\n            kwargs[\"presence_penalty\"] = 0\n\n        # set up request\n        request_data = {\n            \"model\": model.model_name,\n            \"messages\": [\n                {\"role\": \"system\", \"content\": system_message},\n                {\"role\": \"user\", \"content\": prompt},\n            ],\n            **kwargs,\n        }\n\n        # make request\n        response = None\n        for i in range(5):\n            try:\n                response = requests.post(\n                    OPENAI_URL,\n                    headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n                    json=request_data,\n                )\n                response.raise_for_status()\n                break\n            except requests.exceptions.HTTPError as e:\n                if e.response.status_code == 429:\n                    # handle rate limit\n                    time.sleep(2 ** i)\n                else:\n                    raise e\n\n        # process response\n        if response is None:\n            raise Exception(\"Failed to generate text after 5 attempts\")\n        response_json = response.json()\n        if \"error\" in response_json:\n            raise Exception(f\"OpenAI API error: {response_json['error']}\")\n        text = response_json[\"choices"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n        self.validate_parameters(kwargs)\n\n        # Retry up to 5 times with exponential backoff\n        max_retries = 5\n        retry_count = 0\n        while retry_count < max_retries:\n            try:\n                # Generate response\n                response = self.client.chat.completions.create(\n                    model=model.model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt},\n                    ],\n                    **kwargs\n                )\n                # Process response\n                text = self.process_response(response, model)\n                return text\n            except Exception as e:\n                if retry_count == max_retries - 1:\n                    raise e\n                else:\n                    retry_count += 1\n                    sleep_time = 2 ** retry_count\n                    logging.warning(f\"Request failed, retrying in {sleep_time} seconds. Error: {e}\")\n                    time.sleep(sleep_time)\n"}
{"namespace": "tanuki.language_models.openai_api.OpenAI_API.generate", "completion": "        self.check_api_key()\n\n        # Validate and process parameters\n        params = copy.deepcopy(kwargs)\n        for param in LLM_GENERATION_PARAMETERS:\n            if param in params:\n                if not isinstance(params[param], (int, float)):\n                    raise ValueError(f\"Invalid value for parameter {param}: {params[param]}\")\n                if param in [\"temperature\", \"top_p\"]:\n                    if not 0 <= params[param] <= 1:\n                        raise ValueError(f\"Invalid value for parameter {param}: {params[param]}\")\n                elif param in [\"frequency_penalty\", \"presence_penalty\"]:\n                    if not -2.0 <= params[param] <= 2.0:\n                        raise ValueError(f\"Invalid value for parameter {param}: {params[param]}\")\n                elif param == \"max_new_tokens\":\n                    if not isinstance(params[param], int) or params[param] < 0:\n                        raise ValueError(f\"Invalid value for parameter {param}: {params[param]}\")\n\n        # Add helper tokens to the prompt\n        prompt = model.pre_prompt + system_message + model.post_prompt + prompt\n\n        # Retry on failure up to 5 times with exponential backoff\n        max_retries = 5\n        retry_count = 0\n        while retry_count < max_retries:\n            try:\n                response = self.client.chat.completions.create(\n                    model=model.model_name,\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_message},\n                        {\"role\": \"user\", \"content\": prompt},\n                    ],\n                    **params\n                )\n                break\n            except Exception as e:\n                logging.warning(f\"Error occurred while generating response: {e}\")\n                retry_count += 1\n                if retry_count < max_retries:\n                    time.sleep(2 ** retry_count)\n                else:\n                    raise e\n\n        # Process response and remove helper tokens\n        text = response.choices[0].message."}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    if x.ndim != 2 or x.shape[0] != x.shape[1]:\n        raise ValueError(\"The matrix must be square\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_symmetric", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix is not symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x.diagonal(), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x.diagonal(), 0):\n        raise ValueError(\"The matrix must have zero diagonal elements\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zero diagonal elements\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x.diagonal(), 0):\n        raise ValueError(\"The matrix diagonal must be close to zero\")\n    if not is_symmetric(x):\n        raise ValueError(\"The matrix must be symmetric\")"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(x.diagonal(), np.zeros(x.shape[0])):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix's diagonal elements must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zero diagonal elements\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x.diagonal(), np.zeros(x.shape[0])):\n        raise ValueError(\"The matrix must have zero diagonal elements\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The matrix must have zero diagonal elements\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(np.diag(x), 0):\n        raise ValueError(\"The diagonal elements of the matrix must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n    if not np.allclose(x.diagonal(), 0):\n        raise ValueError(\"The diagonal elements must be close to zero\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x.diagonal(), 0):\n        raise ValueError(\"The matrix must have a zero diagonal\")\n    if not is_symmetric(x):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "skfolio.utils.stats.assert_is_distance", "completion": "    assert_is_square(x)\n    if not np.allclose(x.diagonal(), 0):\n        raise ValueError(\"The matrix must have zero diagonal elements\")\n    if not np.allclose(x, x.T):\n        raise ValueError(\"The matrix must be symmetric\")\n\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            self.token_counts[func_hash] = 0\n\n        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            self.token_counts[func_hash] = 0\n\n        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            self.token_counts[func_hash] = 0\n\n        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            self.token_counts[func_hash] = 0\n\n        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            self.token_counts[func_hash] = 0\n\n        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            self.token_counts[func_hash] = 0\n\n        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # initialize the function\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            self.token_counts[func_hash] = 0\n\n        # check if the function is already"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if function is already initialized\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            is_initialized = False\n        else:\n            is_initialized = True\n\n        # check if function is already initialized\n        if func_hash not in self.token_counts:\n            self.token_counts[func_hash] = 0\n\n        # check if function is already initialized\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            is_initialized = False\n        else:\n            is_initialized = True\n\n        # check if function is already initialized\n        if func_hash not in self.token_counts:\n            self.token_counts[func_hash] = 0\n\n        # check if function is already initialized\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            is_initialized = False\n        else:\n            is_initialized = True\n\n        # check if function is already initialized\n        if func_hash not in self.token_counts:\n            self.token_counts[func_hash] = 0\n\n        # check if function is already initialized\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            is_initialized = False\n        else:\n            is_initialized = True\n\n        # check if function is already initialized\n        if func_hash not in self.token_counts:\n            self.token_counts[func_hash] = 0\n\n        # check if function is already initialized\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            is_initialized = False\n        else:\n            is_initialized = True"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        model = self.function_modeler.get_model(function_description)\n        # if the function is not initialized, initialize it\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": []\n            }\n            self.token_counts[func_hash] = 0\n        # if the function is not initialized, initialize it\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": []\n            }\n            self.token_counts[func_hash] = 0\n\n        # check if the function is already initialized and does not require saving examples for fine-tuning\n        if self.initialized_functions[func_hash][\"model\"] != \"\":\n            return self.function_modeler.construct_prompt(args, kwargs, function_description), model, False, False\n\n        # check if the function is already initialized and does not require saving examples for fine-tuning\n        if self.initialized_functions[func_hash][\"model\"] != \"\":\n            return self.function_modeler.construct_prompt(args, kwargs, function_description), model, False, False\n\n        # check if the function is already initialized and does not require saving examples for fine-tuning\n        if self.initialized_functions[func_hash][\"model\"] != \"\":\n            return self.function_modeler.construct_prompt(args, kwargs, function_description), model, False, False\n\n        # check if the function is already initialized and does not require saving examples for fine-tuning\n        if self.initialized_functions[func_hash][\"model\"] != \"\":\n            return self.function_modeler.construct_prompt(args, kwargs, function_description), model, False, False\n\n        # check if the function is already initialized and does not require saving examples for fine-tuning\n        if self.initialized_functions[func_hash][\"model\"] != \"\":"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            return self._get_generation_case_initialized(args, kwargs, function_description, llm_parameters, func_hash)\n        else:\n            return self._get_generation_case_uninitialized(args, kwargs, function_description, llm_parameters, func_hash)\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the function hash\n        func_hash = function_description.__hash__()\n        # get the function description\n        func_description = function_description\n        # get the function name\n        func_name = func_description.name\n        # get the function signature\n        func_signature = func_description.signature\n        # get the function docstring\n        func_docstring = func_description.docstring\n        # get the function examples\n        func_examples = func_description.examples\n        # get the function type hints\n        func_type_hints = func_description.type_hints\n        # get the function return type hint\n        func_return_type_hint = func_description.return_type_hint\n        # get the function arguments\n        func_args = func_description.args\n        # get the function kwargs\n        func_kwargs = func_description.kwargs\n        # get the function return type hint\n        func_return_type_hint = func_description.return_type_hint\n        # get the function docstring\n        func_docstring = func_description.docstring\n        # get the function examples\n        func_examples = func_description.examples\n        # get the function type hints\n        func_type_hints = func_description.type_hints\n        # get the function signature\n        func_signature = func_description.signature\n        # get the function name\n        func_name = func_description.name\n        # get the function hash\n        func_hash = func_description.__hash__()\n        # get the function description\n        func_description = func_description\n        # get the function name\n        func_name = func_description.name\n        # get the function signature\n        func_signature = func_description.signature\n        # get the function docstring\n        func_docstring = func_description.docstring\n        # get the function examples\n        func_examples = func_description.examples\n        # get the function type hints\n        func_type_hints = func_description.type_hints\n        # get the function return type hint\n        func_return_type_hint = func_description.return_type_h"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the model and prompt\n        model, prompt = self.function_modeler.get_model_and_prompt(args, kwargs, function_description)\n\n        # check if the model is suitable for distillation\n        is_distilled_model = self.function_modeler.is_model_suitable_for_distillation(args, kwargs, function_description, model)\n\n        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # if not, initialize it\n            self.initialized_functions[func_hash] = {\"model\": model.model_name, \"examples\": []}\n            save_to_finetune = False\n        else:\n            # if it is, check if it is suitable for distillation\n            if is_distilled_model:\n                save_to_finetune = False\n            else:\n                # if it is not, check if it is already initialized\n                if self.initialized_functions[func_hash][\"model\"] == \"\":\n                    save_to_finetune = False\n                else:\n                    # if it is, check if it is already initialized with the same model\n                    if self.initialized_functions[func_hash][\"model\"] == model.model_name:\n                        save_to_finetune = False\n                    else:\n                        # if it is not, check if it is suitable for distillation\n                        if self.function_modeler.is_model_suitable_for_distillation(args, kwargs, function_description, model):\n                            save_to_finetune = False\n                        else:\n                            # if it is not, check if it is already initialized with the same model\n                            if self.initialized_functions[func_hash][\"model\"] == model.model_name:\n                                save_to_finetune = False\n                            else:\n                                # if it is not, check if it is already initialized with the same model\n                                if self.initialized_functions[func_hash][\"model\"] == model.model_name:\n                                    save_to_finetune = False\n                               "}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            # Get the initialized model and examples for the function\n            model = self.initialized_functions[func_hash][\"model\"]\n            examples = self.initialized_functions[func_hash][\"examples\"]\n            # Update the examples for the function\n            self._update_examples(examples, args, kwargs, function_description)\n            # Construct the prompt using the updated examples\n            prompt = self._construct_prompt(examples, args, kwargs, function_description)\n            # Return the prompt, model, and a boolean indicating that the function is already initialized\n            return prompt, model, False, False\n\n        # Check if the function is suitable for distillation\n        if function_description.suitable_for_distillation:\n            # Get the distilled model\n            model = self.api_provider[function_description.distilled_model_provider].get_distilled_model(\n                function_description.distilled_model_name)\n            # Construct the prompt\n            prompt = self._construct_prompt([], args, kwargs, function_description)\n            # Return the prompt, model, and a boolean indicating that the model is suitable for distillation\n            return prompt, model, True, True\n\n        # Get the teacher model\n        model = self.api_provider[function_description.teacher_model_provider].get_teacher_model(\n            function_description.teacher_model_name)\n        # Initialize the function data\n        self._initialize_function_data(func_hash, model)\n        # Get the examples for the function\n        examples = self.initialized_functions[func_hash][\"examples\"]\n        # Update the examples for the function\n        self._update_examples(examples, args, kwargs, function_description)\n        # Construct the prompt using the updated examples\n        prompt = self._construct_prompt(examples, args, kwargs, function_description)\n        # Return the prompt, model, and a boolean indicating that the function is not already initialized\n        return prompt, model, False, False\n\n   "}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # get the function model\n        model = self.function_modeler.get_function_model(function_description)\n        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            # if the function is not initialized, then we need to initialize it\n            self.initialized_functions[func_hash][\"model\"] = model.model_name\n            # initialize the function\n            self.function_modeler.initialize_function(function_description, model)\n            # get the prompt\n            prompt = self.function_modeler.get_prompt(function_description, args, kwargs, model)\n            # check if the function is suitable for distillation\n            is_distilled_model = self.function_modeler.is_suitable_for_distillation(function_description, args, kwargs, model)\n            # check if the function is already initialized\n            return prompt, model, False, is_distilled_model\n        else:\n            # if the function is already initialized, then we need to check if the function is suitable for distillation\n            is_distilled_model = self.function_modeler.is_suitable_for_distillation(function_description, args, kwargs, model)\n            if is_distilled_model:\n                # if the function is suitable for distillation, then we need to use the distilled model\n                model = self.function_modeler.get_distilled_model(function_description)\n                # get the prompt\n                prompt = self.function_modeler.get_prompt(function_description, args, kwargs, model)\n                # check if the function is already initialized\n                return prompt, model, False, is_distilled_model\n            else:\n                # if the function is not suitable for distillation, then we need to use the teacher model\n                model = self.function_modeler.get_teacher_model(function_description)\n                # get the prompt\n                prompt = self.function_modeler.get"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": []\n            }\n            self.token_counts[func_hash] = 0\n\n        # Get the function initialization data\n        function_data = self.initialized_functions[func_hash]\n        model = function_data[\"model\"]\n\n        # Check if the function is already initialized and does not require saving examples for fine-tuning\n        if model != \"\":\n            return self._construct_prompt(args, kwargs, function_description, func_hash), self.api_provider[model.provider][model], False, False\n\n        # Get the model and token count for the function\n        model, token_count = self._get_model_and_token_count(function_description, llm_parameters)\n\n        # Check if the model is suitable for distillation\n        if self._is_suitable_for_distillation(function_description, token_count):\n            # Update the function initialization data\n            self.initialized_functions[func_hash][\"model\"] = model\n            self.token_counts[func_hash] = token_count\n\n            # Construct the prompt and return the result\n            return self._construct_prompt(args, kwargs, function_description, func_hash), model, True, False\n\n        # Check if the function is already initialized and does not require saving examples for fine-tuning\n        if model != \"\":\n            return self._construct_prompt(args, kwargs, function_description, func_hash), self.api_provider[model.provider][model], False, False\n\n        # Update the function initialization data\n        self.initialized_functions[func_hash][\"model\"] = model\n        self.token_counts[func_hash] = token_count\n\n        # Construct the prompt and return the result\n        return self._construct_prompt(args, kwargs, function_description, func_hash), model, False, False\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        model = self.api_provider.get_model(function_description.model_type)\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n        if model.model_type == \"teacher\":\n            prompt = self.function_modeler.generate_prompt(args, kwargs, function_description,\n                                                           self.initialized_functions[func_hash][\"examples\"])\n            return prompt, model, False, False\n        if self.initialized_functions[func_hash][\"model\"] == \"\":\n            prompt = self.function_modeler.generate_prompt(args, kwargs, function_description,\n                                                           self.initialized_functions[func_hash][\"examples\"])\n            return prompt, model, False, False\n        if self.initialized_functions[func_hash][\"model\"] != model.model_name:\n            prompt = self.function_modeler.generate_prompt(args, kwargs, function_description,\n                                                           self.initialized_functions[func_hash][\"examples\"])\n            return prompt, model, False, False\n        if self.function_modeler.suitable_for_distillation(args, kwargs, function_description):\n            prompt = self.function_modeler.generate_prompt(args, kwargs, function_description,\n                                                           self.initialized_functions[func_hash][\"examples\"])\n            return prompt, model, True, True\n        if self.initialized_functions[func_hash][\"examples\"] == []:\n            self.initialized_functions[func_hash][\"examples\"] = self.function_modeler.generate_align_statements(\n                args, kwargs, function_description)\n            prompt = self.function_modeler.generate_prompt(args, kwargs, function_description,\n                                                           self.initialized_functions[func_hash][\"examples\"])\n            return prompt, model, False, False\n        else:\n            self.initialized_functions[func_hash][\"examples"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        model, prompt = self.function_modeler.get_generation_case(args, kwargs, function_description, func_hash)\n        is_distilled_model = model.model_name.endswith(\"-distilled\")\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n        return prompt, model, False, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Get the function model from the function modeler\n        function_model = self.function_modeler.get_function_model(function_description)\n\n        # Check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            # If not, initialize the function with the function model\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            # Set the function as not initialized\n            is_initialized = False\n        else:\n            # If the function is already initialized, set the function as initialized\n            is_initialized = True\n\n        # Check if the function is suitable for distillation\n        if function_model.is_suitable_for_distillation(args, kwargs):\n            # If the function is suitable for distillation, set the model as the distilled model\n            model = function_model.distilled_model\n            # Set the function as not suitable for saving examples for fine-tuning\n            save_to_finetune = False\n            # Set the function as suitable for distillation\n            is_distilled_model = True\n        else:\n            # If the function is not suitable for distillation, set the model as the teacher model\n            model = function_model.teacher_model\n            # Set the function as suitable for saving examples for fine-tuning\n            save_to_finetune = True\n            # Set the function as not suitable for distillation\n            is_distilled_model = False\n\n        # Get the token count for the function description\n        token_count = self.token_counts.get(func_hash, None)\n\n        # If the token count is not available or the token count is greater than the maximum token limit\n        if token_count is None or token_count > self.default_generation_length:\n            # Initialize the function with the function model\n            self.initialized_functions[func_hash] = {\"model\": \"\", \"examples\": []}\n            # Set the function as not initialized\n            is_initialized = False\n            # Set the token count to 0\n            token_count = 0\n\n        #"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            # if it is, update the examples for fine-tuning\n            self.update_examples_for_finetune(args, kwargs, function_description, func_hash)\n            # and return the appropriate model and prompt\n            model = self.api_provider[self.initialized_functions[func_hash][\"model\"]]\n            prompt = self.construct_prompt(args, kwargs, function_description, func_hash)\n            return prompt, model, False, False\n\n        # if not, check if the function is suitable for distillation\n        if function_description.suitable_for_distillation:\n            # if it is, get the distilled model\n            model = self.api_provider.distilled_model\n            # and check if it is suitable for the given prompt\n            if self.is_suitable_for_distillation(args, kwargs, function_description, llm_parameters, func_hash):\n                # if it is, construct the prompt and return the model and prompt\n                prompt = self.construct_prompt(args, kwargs, function_description, func_hash)\n                return prompt, model, True, True\n\n        # if the function is not suitable for distillation, get the teacher model\n        model = self.api_provider.teacher_model\n        # and construct the prompt\n        prompt = self.construct_prompt(args, kwargs, function_description, func_hash)\n        # check if the model is suitable for the given prompt\n        if self.is_suitable_for_teacher(args, kwargs, function_description, llm_parameters, func_hash):\n            # if it is, return the model and prompt\n            return prompt, model, False, False\n        else:\n            # if it is not, return the model and prompt, but indicate that the function is not initialized\n            return prompt, model, False, True\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            # Get the model and examples for the function\n            model, examples = self.initialized_functions[func_hash][\"model\"], self.initialized_functions[func_hash][\"examples\"]\n        else:\n            # Initialize the function\n            model, examples = self.initialize_function(function_description, func_hash)\n\n        # Check if the model is suitable for distillation\n        if self.is_model_suitable_for_distillation(model, examples, function_description, llm_parameters):\n            # Use a distilled model for zero-shot prompting\n            prompt = self.construct_prompt_for_distillation(args, kwargs, function_description, examples)\n            return prompt, model, True, True\n\n        # Check if the model is suitable for fine-tuning\n        if self.is_model_suitable_for_finetuning(model, examples, function_description, llm_parameters):\n            # Update examples for fine-tuning\n            self.update_examples_for_finetuning(function_description, args, kwargs, examples)\n            # Use a teacher model for fine-tuning\n            prompt = self.construct_prompt_for_finetuning(args, kwargs, function_description, examples)\n            return prompt, model, True, False\n\n        # Use a general model for zero-shot prompting\n        prompt = self.construct_prompt_for_general_model(args, kwargs, function_description)\n        return prompt, model, False, False\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            function_data = self.initialized_functions[func_hash]\n            model = function_data[\"model\"]\n            if model == \"\":\n                model = self.api_provider[function_description.model.provider].get_model(function_description.model)\n                function_data[\"model\"] = model\n\n            # Update the examples for fine-tuning if necessary\n            if function_data[\"examples\"]:\n                function_description.update_examples(function_data[\"examples\"])\n                function_data[\"examples\"] = []\n\n            # Construct the prompt\n            prompt = self.function_modeler.construct_prompt(args, kwargs, function_description)\n            return prompt, model, False, False\n\n        # Check if the function is suitable for distillation\n        distilled_model = self.api_provider[function_description.distilled_model.provider].get_model(function_description.distilled_model)\n        distilled_prompt = self.function_modeler.construct_prompt(args, kwargs, function_description)\n        distilled_token_count = approximate_token_count(distilled_prompt)\n        if distilled_token_count <= llm_parameters.get(\"max_new_tokens\", self.default_generation_length):\n            self.initialized_functions[func_hash] = {\n                \"model\": distilled_model,\n                \"examples\": []\n            }\n            return distilled_prompt, distilled_model, True, True\n\n        # Check if the function is suitable for fine-tuning\n        teacher_model = self.api_provider[function_description.model.provider].get_model(function_description.model)\n        teacher_prompt = self.function_modeler.construct_prompt(args, kwargs, function_description)\n        teacher_token_count = approximate_token_count(teacher_prompt)\n        if teacher_token_count <= llm_parameters.get(\"max_new_tokens\", self.default_generation"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            # if it is, update the examples\n            self.function_modeler.update_examples(func_hash, function_description, args, kwargs)\n            # get the model and prompt\n            model, prompt = self.function_modeler.get_prompt(func_hash, function_description, args, kwargs)\n            # check if the model is suitable for distillation\n            is_distilled_model = self.function_modeler.is_model_suitable_for_distillation(func_hash)\n            # return the model, prompt, and whether the model is suitable for distillation\n            return prompt, model, False, is_distilled_model\n        else:\n            # if the function is not initialized, initialize it\n            self.function_modeler.initialize_function(func_hash, function_description, args, kwargs)\n            # get the model and prompt\n            model, prompt = self.function_modeler.get_prompt(func_hash, function_description, args, kwargs)\n            # check if the model is suitable for distillation\n            is_distilled_model = self.function_modeler.is_model_suitable_for_distillation(func_hash)\n            # return the model, prompt, and whether the model is suitable for distillation\n            return prompt, model, True, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # check if the function is already initialized\n        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": []\n            }\n            self.token_counts[func_hash] = 0\n\n        # get the model for the function\n        model = self.function_modeler.get_model(function_description)\n\n        # check if the function is suitable for distillation\n        if self.function_modeler.is_suitable_for_distillation(function_description):\n            is_distilled_model = True\n        else:\n            is_distilled_model = False\n\n        # construct the prompt\n        prompt = self.function_modeler.construct_prompt(args, kwargs, function_description)\n\n        # check if the function is already initialized and does not require saving examples for fine-tuning\n        if self.initialized_functions[func_hash][\"model\"] == model.model_name:\n            save_to_finetune = False\n        else:\n            save_to_finetune = True\n\n        return prompt, model, save_to_finetune, is_distilled_model\n\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        if func_hash not in self.initialized_functions:\n            self.initialized_functions[func_hash] = {\n                \"model\": \"\",\n                \"examples\": []\n            }\n\n        model, prompt = self.function_modeler.get_prompt(args, kwargs, function_description, llm_parameters)\n        # check if the model is suitable for distillation\n        is_distilled_model = False\n        if model.suitable_for_distillation and self.function_modeler.is_suitable_for_distillation(function_description):\n            is_distilled_model = True\n            # get the distilled model\n            model = self.function_modeler.get_distilled_model(function_description)\n        # check if the model is suitable for fine-tuning\n        save_to_finetune = False\n        if model.suitable_for_finetuning and self.function_modeler.is_suitable_for_finetuning(function_description):\n            save_to_finetune = True\n            # update the examples for fine-tuning\n            self.initialized_functions[func_hash][\"examples\"] = self.function_modeler.get_examples_for_finetuning(\n                function_description)\n        return prompt, model, save_to_finetune, is_distilled_model\n"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Check if the function is already initialized\n        if func_hash in self.initialized_functions:\n            # Get the current function setup\n            current_function_setup = self.initialized_functions[func_hash]\n            # Check if the function is already initialized and does not require saving examples for fine-tuning\n            if len(current_function_setup[\"examples\"]) == 0:\n                return None, None, None, None\n            else:\n                # Get the selected model\n                model = self.api_provider[current_function_setup[\"model\"]]\n                # Check if the function is suitable for distillation\n                if current_function_setup[\"suitable_for_distillation\"]:\n                    # Construct the prompt for distillation\n                    prompt = self.function_modeler.construct_distillation_prompt(function_description, args, kwargs)\n                    # Return the prompt, model, and distilled model flag\n                    return prompt, model, True, True\n                else:\n                    # Construct the prompt for fine-tuning\n                    prompt = self.function_modeler.construct_prompt(function_description, args, kwargs)\n                    # Update the examples for fine-tuning\n                    self.update_examples(function_description, args, kwargs, func_hash)\n                    # Return the prompt, model, and fine-tuning flag\n                    return prompt, model, False, False\n        else:\n            # Get the token count for the function description\n            token_count = self.token_counts.get(func_hash, None)\n            # Check if the token count is None\n            if token_count is None:\n                # Calculate the token count for the function description\n                token_count = approximate_token_count(function_description)\n                # Save the token count\n                self.token_counts[func_hash] = token_count\n            # Check if the token count is less than or equal to the maximum token count\n            if token_count <= self.default_generation_length:\n                # Get the model for zero-shot prompting\n                model = self.api_provider[\"zero_shot_prompting\"]\n                #"}
{"namespace": "tanuki.language_models.language_model_manager.LanguageModelManager.get_generation_case", "completion": "        # Get the function hash\n        func_hash = function_description.__hash__()\n\n        # Get the function-specific data\n        function_data = self.initialized_functions.get(func_hash, None)\n\n        # Check if the function is already initialized\n        if function_data is None:\n            # Initialize the function-specific data\n            function_data = {\"model\": \"\", \"examples\": []}\n            self.initialized_functions[func_hash] = function_data\n\n        # Get the model for the function\n        model = self.function_modeler.get_model(function_description)\n\n        # Check if the model is suitable for distillation\n        suitable_for_distillation = self.function_modeler.is_suitable_for_distillation(function_description)\n\n        # Check if the function is already initialized\n        if function_data[\"model\"] != \"\":\n            # The function is already initialized, so check if it needs to be updated\n            if suitable_for_distillation:\n                # The function is suitable for distillation, so update the examples for fine-tuning\n                self.function_modeler.update_examples(function_description, function_data[\"examples\"])\n\n            # Set the model to the selected model\n            model = self.api_provider[function_data[\"model\"]]\n\n            # Set the model to the selected model\n            model = self.api_provider[function_data[\"model\"]]\n\n            # Construct the prompt for the function\n            prompt = self.function_modeler.construct_prompt(args, kwargs, function_description, function_data[\"examples\"])\n\n            # Return the prompt, model, and boolean indicating if the function is already initialized\n            return prompt, model, False, False\n\n        # The function is not already initialized, so check if it is suitable for distillation\n        if suitable_for_distillation:\n            # The function is suitable for distillation, so get the distilled model\n            model = self.api_provider[model.model_name]\n\n            # Construct the prompt for the function\n            prompt = self.function_model"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        cov = _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        cov = _cov_nearest_clipped(cov)\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if not is_positive_definite(cov):\n        if higham:\n            cov = cov_nearest_higham(cov, max_iteration=higham_max_iteration)\n        else:\n            cov = cov_nearest_clip(cov)\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        return cov_nearest_clipped(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if not is_positive_definite(cov):\n        if higham:\n            cov = _cov_nearest_higham(cov, max_iteration=higham_max_iteration)\n        else:\n            cov = _cov_nearest_clipped(cov)\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if not isinstance(cov, np.ndarray):\n        raise TypeError(\"`cov` must be a numpy array\")\n    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"`cov` must be a square matrix\")\n\n    if higham:\n        cov = cov_nearest_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        cov = cov_nearest_clipped(cov)\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    assert_is_symmetric(cov)\n    if higham:\n        cov = cov_nearest_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        cov = cov_nearest_clipped(cov)\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        return _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        return _cov_nearest_clipped(cov)\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(f\"`cov` must be a 2D array, got a {cov.ndim}D array\")\n    if not is_positive_definite(cov):\n        raise ValueError(\"The covariance matrix must be positive definite\")\n\n    if higham:\n        n = cov.shape[0]\n        cov_ = cov.copy()\n        for _ in range(higham_max_iteration):\n            eigvals, eigvecs = np.linalg.eigh(cov_)\n            if np.all(eigvals > 0):\n                break\n            cov_ = eigvecs @ np.diag(np.maximum(eigvals, 0)) @ eigvecs.T\n        return cov_\n\n    eigvals, eigvecs = np.linalg.eigh(cov)\n    eigvals = np.maximum(eigvals, 0)\n    cov_ = eigvecs @ np.diag(eigvals) @ eigvecs.T\n    return cov_\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    cov = np.array(cov)\n    assert_is_symmetric(cov)\n    if higham:\n        cov = _cov_nearest_higham(cov, higham_max_iteration)\n    else:\n        cov = _cov_nearest_clipped(cov)\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if not is_positive_definite(cov):\n        if higham:\n            cov = _cov_nearest_higham(cov, max_iteration=higham_max_iteration)\n        else:\n            cov = _cov_nearest_clip(cov)\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Check if the input covariance matrix is square\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"The input covariance matrix is not square.\")\n\n    # Check if the input covariance matrix is symmetric\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"The input covariance matrix is not symmetric.\")\n\n    # Check if the input covariance matrix is positive definite\n    if not is_positive_definite(cov):\n        raise ValueError(\"The input covariance matrix is not positive definite.\")\n\n    # Check if the input covariance matrix is symmetric\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"The input covariance matrix is not symmetric.\")\n\n    # Compute the nearest positive definite matrix using the Higham & Nick (2002) algorithm\n    if higham:\n        cov_nearest = cov.copy()\n        for _ in range(higham_max_iteration):\n            eigvals, eigvecs = np.linalg.eigh(cov_nearest)\n            eigvals = np.maximum(eigvals, 0)\n            cov_nearest = eigvecs @ np.diag(eigvals) @ eigvecs.T\n            if is_positive_definite(cov_nearest):\n                break\n        else:\n            raise ValueError(\n                \"The Higham & Nick (2002) algorithm did not converge after the specified number of iterations.\"\n            )\n\n    # Clip eigenvalues to ensure the resulting matrix is positive definite\n    else:\n        eigvals, eigvecs = np.linalg.eigh(cov)\n        eigvals = np.maximum(eigvals, 0)\n        cov_nearest = eigvecs @ np.diag(eigvals) @ eigvecs.T\n\n    # Check if the resulting matrix is positive definite\n    if not is_positive_definite(cov_nearest):\n        raise ValueError(\"The resulting matrix is not positive definite.\")\n\n    return cov_nearest\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        cov_ = cov.copy()\n        for _ in range(higham_max_iteration):\n            cov_ = (cov_ + cov_.T) / 2\n            eigvals, eigvecs = np.linalg.eigh(cov_)\n            if np.all(eigvals >= 0):\n                break\n            eigvals[eigvals < 0] = 0\n            cov_ = eigvecs @ np.diag(eigvals) @ eigvecs.T\n    else:\n        eigvals, eigvecs = np.linalg.eigh(cov)\n        eigvals[eigvals < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov_ = eigvecs @ np.diag(eigvals) @ eigvecs.T\n    return cov_\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if not higham:\n        cov = _clip_eigenvalues(cov)\n    else:\n        cov = _higham_nearest_positive_definite(cov, higham_max_iteration)\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if cov.ndim != 2:\n        raise ValueError(\"`cov` must be a 2D array\")\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"`cov` must be a square matrix\")\n    if not is_positive_definite(cov):\n        raise ValueError(\"`cov` must be a positive definite matrix\")\n\n    if higham:\n        cov_ = cov.copy()\n        for _ in range(higham_max_iteration):\n            cov_old = cov_.copy()\n            cov_ = (cov_ + cov_.T) / 2\n            eig_values, eig_vectors = np.linalg.eigh(cov_)\n            eig_values = np.maximum(eig_values, _CLIPPING_VALUE)\n            cov_ = eig_vectors @ np.diag(eig_values) @ eig_vectors.T\n            if np.allclose(cov_, cov_old):\n                break\n    else:\n        eig_values, eig_vectors = np.linalg.eigh(cov)\n        eig_values = np.maximum(eig_values, _CLIPPING_VALUE)\n        cov = eig_vectors @ np.diag(eig_values) @ eig_vectors.T\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Compute the nearest positive definite covariance matrix\n    if higham:\n        # Use the Higham & Nick (2002) algorithm\n        cov_nearest = cov_nearest_higham(cov, max_iteration=higham_max_iteration)\n    else:\n        # Clip the eigenvalues of the covariance matrix\n        cov_nearest = cov_nearest_clip(cov)\n\n    return cov_nearest\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Check if the input matrix is a covariance matrix\n    if not is_symmetric(cov):\n        raise ValueError(\"The input matrix must be a covariance matrix.\")\n\n    # Compute the nearest positive definite matrix using the Higham & Nick (2002) algorithm\n    if higham:\n        cov = nearest_positive_definite_matrix(cov, max_iteration=higham_max_iteration)\n\n    # Clip the eigenvalues to ensure the resulting matrix is positive definite\n    else:\n        cov = np.clip(cov, a_min=_CLIPPING_VALUE, a_max=None)\n\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if not is_positive_definite(cov):\n        if higham:\n            cov = _higham(cov, max_iteration=higham_max_iteration)\n        else:\n            cov = _clip_eigenvalues(cov)\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Check if the input covariance matrix is symmetric\n    if not np.allclose(cov, cov.T):\n        raise ValueError(\"The covariance matrix must be symmetric\")\n\n    # Compute the eigenvalues and eigenvectors of the covariance matrix\n    eigen_values, eigen_vectors = np.linalg.eigh(cov)\n\n    # If Higham's algorithm is selected, use it to find the nearest positive definite matrix\n    if higham:\n        # Initialize the iteration counter and the previous eigenvalues\n        iteration = 0\n        prev_eigen_values = eigen_values\n\n        # Iterate until the maximum number of iterations is reached or the eigenvalues converge\n        while iteration < higham_max_iteration:\n            # Compute the nearest positive eigenvalues\n            eigen_values = np.maximum(eigen_values, _CLIPPING_VALUE)\n\n            # Compute the nearest covariance matrix\n            cov = eigen_vectors @ np.diag(eigen_values) @ eigen_vectors.T\n\n            # Check if the eigenvalues have converged\n            if np.allclose(eigen_values, prev_eigen_values):\n                break\n\n            # Update the previous eigenvalues and increment the iteration counter\n            prev_eigen_values = eigen_values\n            iteration += 1\n\n    # If Higham's algorithm is not selected, clip the eigenvalues to ensure positive definiteness\n    else:\n        # Clip the eigenvalues to ensure positive definiteness\n        eigen_values = np.maximum(eigen_values, _CLIPPING_VALUE)\n\n        # Compute the nearest covariance matrix\n        cov = eigen_vectors @ np.diag(eigen_values) @ eigen_vectors.T\n\n    # Return the nearest covariance matrix\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    # Check if the input covariance matrix is a square matrix\n    if cov.shape[0] != cov.shape[1]:\n        raise ValueError(\"The input covariance matrix must be a square matrix\")\n\n    # Compute the eigenvalues and eigenvectors of the covariance matrix\n    eigenvalues, eigenvectors = np.linalg.eigh(cov)\n\n    # If the Higham & Nick (2002) algorithm is used\n    if higham:\n        # Initialize the iteration counter and the scaling factor\n        iteration = 0\n        scaling_factor = 1\n\n        # Repeat the following until the covariance matrix is positive definite or the maximum number of iterations is reached\n        while not is_positive_definite(cov) and iteration < higham_max_iteration:\n            # Compute the diagonal matrix of eigenvalues\n            eigenvalues_matrix = np.diag(eigenvalues)\n\n            # Compute the diagonal matrix of the eigenvalues clipped to a minimum value\n            eigenvalues_clipped = np.diag(\n                np.maximum(eigenvalues, _CLIPPING_VALUE * scaling_factor)\n            )\n\n            # Compute the nearest covariance matrix using the Higham & Nick (2002) algorithm\n            cov = eigenvectors @ eigenvalues_clipped @ eigenvectors.T\n\n            # Increase the iteration counter and the scaling factor\n            iteration += 1\n            scaling_factor *= 10\n\n    # If the Higham & Nick (2002) algorithm is not used\n    else:\n        # Compute the diagonal matrix of eigenvalues clipped to a minimum value\n        eigenvalues_clipped = np.diag(np.maximum(eigenvalues, _CLIPPING_VALUE))\n\n        # Compute the nearest covariance matrix by clipping the eigenvalues\n        cov = eigenvectors @ eigenvalues_clipped @ eigenvectors.T\n\n    # Return the nearest covariance matrix\n    return cov\n\n"}
{"namespace": "skfolio.utils.stats.cov_nearest", "completion": "    if higham:\n        # Higham & Nick (2002) algorithm\n        for _ in range(higham_max_iteration):\n            try:\n                cov = np.linalg.cholesky(cov)\n                cov = np.dot(cov, cov.T)\n                return cov\n            except np.linalg.LinAlgError:\n                pass\n\n        # If Higham & Nick (2002) algorithm does not converge, clip eigenvalues\n        cov = cov_nearest(cov, higham=False)\n    else:\n        # Clip eigenvalues\n        eig_values, eig_vectors = np.linalg.eigh(cov)\n        eig_values[eig_values < _CLIPPING_VALUE] = _CLIPPING_VALUE\n        cov = np.dot(eig_vectors * eig_values, eig_vectors.T)\n    return cov\n\n"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "skfolio.datasets._base.clear_data_home", "completion": "    data_home = get_data_home(data_home)\n    shutil.rmtree(data_home)"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise TypeError(f\"Unsupported type {type(obj)}\")"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise NotImplementedError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Cannot flatten object of type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Sequence):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, torch.Tensor):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, nn.Module):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, (list, tuple)):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        return (obj,), IdentitySchema()\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str) or isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise ValueError(\"Unsupported type {}\".format(type(obj)))\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Sequence):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str) or isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Cannot flatten type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return obj, IdentitySchema()\n    if isinstance(obj, bytes):\n        return obj, IdentitySchema()\n    if isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unknown type: {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, (str, bytes)):\n        return IdentitySchema.flatten(obj)\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, collections.abc.Sequence):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    if isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    if isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    if isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    if isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    if isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    if isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    raise TypeError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "detectron2.export.flatten.flatten_to_tuple", "completion": "    if isinstance(obj, str):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, bytes):\n        return (obj,), IdentitySchema()\n    elif isinstance(obj, collections.abc.Mapping):\n        return DictSchema.flatten(obj)\n    elif isinstance(obj, list):\n        return ListSchema.flatten(obj)\n    elif isinstance(obj, tuple):\n        return TupleSchema.flatten(obj)\n    elif isinstance(obj, Instances):\n        return InstancesSchema.flatten(obj)\n    elif isinstance(obj, Boxes):\n        return TensorWrapSchema.flatten(obj)\n    elif isinstance(obj, ROIMasks):\n        return TensorWrapSchema.flatten(obj)\n    else:\n        raise ValueError(f\"Unsupported type {type(obj)}\")\n\n"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if groups is a numpy array\n    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n\n    # Check if equations is a numpy array\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n\n    # Check if groups and equations have the same number of columns\n    if groups.shape[1] != equations.shape[1]:\n        raise EquationToMatrixError(\n            f\"{names[0]} and {names[1]} must have the same number of columns\"\n        )\n\n    # Check if groups is a 2D array\n    if groups.ndim != 2:\n        raise EquationToMatrixError(f\"{names[0]} must be a 2D array\")\n\n    # Check if equations is a 1D array\n    if equations.ndim != 1:\n        raise EquationToMatrixError(f\"{names[1]} must be a 1D array\")\n\n    # Check if groups and equations have the same number of rows\n    if groups.shape[0] != equations.shape[0]:\n        raise EquationToMatrixError(\n            f\"{names[0]} and {names[1]} must have the same number of rows\"\n        )\n\n    # Check if groups and equations have the same number of columns\n    if groups.shape[1] != equations.shape[1]:\n        raise EquationToMatrixError(\n            f\"{names[0]} and {names[1]} must have the same number of columns\"\n        )\n\n    # Check if groups is a 2D array\n    if groups.ndim != 2:\n        raise EquationToMatrixError(f\"{names[0]} must be a 2D array\")\n\n    # Check if equations is a 1D array\n    if equations.ndim != 1:\n        raise EquationToMatrixError(f\"{names[1]} must be a 1D array\")\n\n    # Check if groups and equations have the same number of rows\n    if groups.shape[0] != equations.shape[0]:\n        raise EquationToMatrixError(\n           "}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if groups and equations are numpy arrays\n    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n\n    # Check if groups and equations are 2D and 1D, respectively\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"{names[0]} must be a 2D array, but got {groups.ndim}D array instead.\"\n        )\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"{names[1]} must be a 1D array, but got {equations.ndim}D array instead.\"\n        )\n\n    # Check if groups and equations have the same number of columns\n    if groups.shape[1] != equations.shape[0]:\n        raise EquationToMatrixError(\n            f\"{names[0]} and {names[1]} must have the same number of columns.\"\n        )\n\n    # Check if groups and equations have the same number of rows\n    if groups.shape[0] != equations.shape[1]:\n        raise EquationToMatrixError(\n            f\"{names[0]} and {names[1]} must have the same number of rows.\"\n        )\n\n    # Check if groups and equations have the same number of rows\n    if groups.shape[0] != equations.shape[1]:\n        raise EquationToMatrixError(\n            f\"{names[0]} and {names[1]} must have the same number of rows.\"\n        )\n\n    # Check if all elements in groups are integers\n    if not np.issubdtype(groups.dtype, np.integer):\n        raise EquationToMatrixError(\n            f\"All elements in {names[0]} must be integers, but got {groups.dtype} instead.\"\n        )\n\n    # Check if all elements in equations are strings\n    if not np.issubdtype(equations.dtype, np.str_):\n        raise EquationToMatrixError(\n            f\"All elements in {names["}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if groups is a numpy array, if not convert it\n    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n\n    # Check if equations is a numpy array, if not convert it\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n\n    # Check if groups is a 2D array\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"The {names[0]} array should be a 2D array, but it has {groups.ndim} dimensions.\"\n        )\n\n    # Check if equations is a 1D array\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"The {names[1]} array should be a 1D array, but it has {equations.ndim} dimensions.\"\n        )\n\n    # Check if groups is a 2D array\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"The {names[0]} array should be a 2D array, but it has {groups.ndim} dimensions.\"\n        )\n\n    # Check if equations is a 1D array\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"The {names[1]} array should be a 1D array, but it has {equations.ndim} dimensions.\"\n        )\n\n    # Check if groups is a 2D array\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"The {names[0]} array should be a 2D array, but it has {groups.ndim} dimensions.\"\n        )\n\n    # Check if equations is a 1D array\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"The {names[1]} array should be a 1D array, but it has {equations.ndim} dimensions.\"\n        )\n\n    # Initialize left and right matrices\n    left = np.zeros((len(equations), groups.shape[1]))\n    right = np.zeros(len("}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n\n    # Check if the input groups and equations are of the correct type\n    if not isinstance(groups, np.ndarray):\n        raise TypeError(f\"{names[0]} must be a numpy array.\")\n    if not isinstance(equations, np.ndarray):\n        raise TypeError(f\"{names[1]} must be a numpy array.\")\n\n    # Check if the input groups and equations are 2D and 1D, respectively\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array.\")\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array.\")\n\n    # Check if the input groups and equations are of the correct type\n    if not np.issubdtype(groups.dtype, np.integer):\n        raise TypeError(f\"{names[0]} must be an array of integers.\")\n    if not np.issubdtype(equations.dtype, np.str_):\n        raise TypeError(f\"{names[1]} must be an array of strings.\")\n\n    # Check if the input groups and equations are of the correct shape\n    if groups.shape[0] == 0:\n        raise ValueError(f\"{names[0]} must have at least one row.\")\n    if groups.shape[1] == 0:\n        raise ValueError(f\"{names[0]} must have at least one column.\")\n    if equations.shape[0] == 0:\n        raise ValueError(f\"{names[1]} must have at least one element.\")\n\n    # Check if the input groups and equations are of the correct type\n    if not np.issubdtype(groups.dtype, np.integer):\n        raise TypeError(f\"{names[0]} must be an array of integers.\")\n    if not np.issubdtype(equations.dtype,"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check that the inputs are of the correct type\n    if not isinstance(groups, np.ndarray):\n        groups = np.array(groups)\n    if not isinstance(equations, np.ndarray):\n        equations = np.array(equations)\n\n    # Check that the inputs have the correct shape\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"{names[0]} must be a 2D array, but got {groups.ndim}D array instead.\"\n        )\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"{names[1]} must be a 1D array, but got {equations.ndim}D array instead.\"\n        )\n\n    # Check that the inputs have the correct data type\n    if groups.dtype != np.dtype(\"object\"):\n        raise EquationToMatrixError(\n            f\"{names[0]} must have dtype 'object', but got {groups.dtype} instead.\"\n        )\n    if equations.dtype != np.dtype(\"object\"):\n        raise EquationToMatrixError(\n            f\"{names[1]} must have dtype 'object', but got {equations.dtype} instead.\"\n        )\n\n    # Check that the inputs have the correct shape\n    if groups.shape[0] == 0:\n        raise EquationToMatrixError(f\"{names[0]} must have at least one row.\")\n    if groups.shape[1] == 0:\n        raise EquationToMatrixError(f\"{names[0]} must have at least one column.\")\n    if equations.shape[0] == 0:\n        raise EquationToMatrixError(f\"{names[1]} must have at least one element.\")\n\n    # Check that the inputs have the correct data type\n    if groups.dtype != np.dtype(\"object\"):\n        raise EquationToMatrixError(\n            f\"{names[0]} must have dtype 'object', but got {groups.dtype} instead.\"\n        )\n    if equations.dtype != np.dtype(\"object\"):\n        raise EquationToMatrix"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    # Check if any of the groups in the equations are part of the input groups\n    groups_in_equations = np.any(\n        np.isin(np.unique(groups), np.unique(equations)).reshape(-1, 1), axis=1\n    )\n\n    # If none of the groups in the equations are part of the input groups, return None\n    if not np.any(groups_in_equations):\n        if raise_if_group_missing:\n            raise GroupNotFoundError(\n                f\"None of the groups in the {names[1]} parameter are part of the {names[0]} parameter.\"\n            )\n        else:\n            warnings.warn(\n                f\"None of the groups in the {names[1]} parameter are part of the {names[0]} parameter.\"\n            )\n            return None\n\n    # Filter the groups to keep only those that are part of the equations\n    groups = groups[groups_in_equations]\n\n    # Create a dictionary to map group names to indices\n    group_indices = {group: i for i, group in enumerate(groups)}\n\n    # Initialize the left and right matrices\n    left = []\n    right = []\n\n    # Iterate over the equations\n    for equation in equations:\n        # Split the equation into left and right parts\n        left_part, right_part = equation.split(\"=\")\n\n        # Remove any whitespace from the left and right parts\n        left_part = left_part.strip()\n        right_part = right_part.strip()\n\n        # Initialize the left and right vectors\n        left_vector = np.zeros(groups.shape[0])\n        right_vector = np.zeros(groups.shape[0])\n\n        # Parse the left part of the equation\n        left_parts = re.split(r\"\\s+(?=[+-])\", left_part)\n        for left_part in left_parts:\n            # Split the left part into coefficient and group name\n            coefficient, group_name = re.split"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert groups and equations to numpy arrays\n    groups = np.array(groups)\n    equations = np.array(equations)\n\n    # Initialize the left and right matrices\n    left = []\n    right = []\n\n    # Iterate over the equations\n    for equation in equations:\n        # Split the equation into two parts\n        parts = equation.split(\"=\")\n\n        # Check if the equation has exactly two parts\n        if len(parts) != 2:\n            raise EquationToMatrixError(\n                f\"Equation '{equation}' does not have exactly two parts.\"\n            )\n\n        # Extract the left and right parts\n        left_part = parts[0].strip()\n        right_part = parts[1].strip()\n\n        # Check if the left part is a group\n        if not left_part.startswith(\"(\") or not left_part.endswith(\")\"):\n            raise EquationToMatrixError(\n                f\"Left part of equation '{equation}' is not a group.\"\n            )\n\n        # Extract the group name from the left part\n        group_name = left_part[1:-1]\n\n        # Find the group in the groups array\n        group_index = np.where(np.all(groups == group_name, axis=1))[0]\n\n        # Check if the group was found\n        if len(group_index) == 0:\n            if raise_if_group_missing:\n                raise GroupNotFoundError(\n                    f\"Group '{group_name}' not found in the {names[0]} array.\"\n                )\n            else:\n                warnings.warn(\n                    f\"Group '{group_name}' not found in the {names[0]} array.\",\n                    stacklevel=2,\n                )\n                return None\n\n        # Get the group\n        group = groups[group_index[0]]\n\n        # Check if the right part is a number\n        if not re.match(r\"^-?\\d+(\\.\\d+)?$\", right_part):\n            raise EquationToMatrixError(\n                f\"Right part of equation '{equation}' is not a number"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array.\")\n\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array.\")\n\n    # Create a dictionary mapping group names to their indices\n    group_indices = {group: i for i, group in enumerate(groups[0])}\n\n    # Initialize the left and right matrices\n    left = []\n    right = []\n\n    # Iterate over the equations\n    for equation in equations:\n        # Split the equation into the left and right sides\n        left_side, right_side = equation.split(\"=\")\n\n        # Initialize the left and right sides of the equation\n        left_equation = np.zeros(groups.shape[1])\n        right_equation = 0\n\n        # Iterate over the terms in the left side\n        for term in left_side.split(\"+\"):\n            # Remove any whitespace from the term\n            term = term.strip()\n\n            # Check if the term is a number\n            if re.match(r\"^[-+]?\\d+(\\.\\d+)?$\", term):\n                # If the term is a number, add it to the right side\n                right_equation += float(term)\n            else:\n                # If the term is a group name, add the corresponding column to the left side\n                if term in group_indices:\n                    left_equation[group_indices[term]] += 1\n                else:\n                    if raise_if_group_missing:\n                        raise GroupNotFoundError(f\"Group '{term}' not found in {names[0]}.\")\n                    else:\n                        warnings.warn(f\"Group '{term}' not found in {names[0]}.\", UserWarning)\n\n        # Iterate over the terms in the right side\n        for term in right_side.split(\"+\"):\n            # Remove any whitespace from the term\n            term = term.strip()"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert groups and equations to numpy arrays\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    # Check if groups and equations have the correct dimensions\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            \"Groups array must have exactly 2 dimensions. \"\n            f\"Provided array has {groups.ndim} dimensions.\"\n        )\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            \"Equations array must have exactly 1 dimension. \"\n            f\"Provided array has {equations.ndim} dimensions.\"\n        )\n\n    # Check if all groups are unique\n    if not np.all(np.all(groups[i] != groups[j]) for i in range(len(groups)) for j in range(i + 1, len(groups))):\n        raise EquationToMatrixError(\"All groups must be unique.\")\n\n    # Check if all equations are unique\n    if not np.all(equations[i] != equations[j] for i in range(len(equations)) for j in range(i + 1, len(equations))):\n        raise EquationToMatrixError(\"All equations must be unique.\")\n\n    # Initialize left and right matrices\n    left = []\n    right = []\n\n    # Iterate over each equation\n    for equation in equations:\n        # Split the equation into groups and coefficients\n        equation_groups = re.findall(r\"[a-zA-Z]+\", equation)\n        equation_coefficients = re.findall(r\"[+-]?\\d+\", equation)\n\n        # Check if all groups in the equation are part of the input groups\n        for group in equation_groups:\n            if group not in groups:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(\n                        f\"Group '{group}' mentioned in the equation '{equation}' \"\n                        f\"is not found in the {names[0]} array.\"\n                    )\n                else:\n                    warnings.warn(\n                        f\"Group '{group}' mentioned in the equation '{equation}' \""}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert input arrays to numpy arrays\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    # Check if groups is a 2D array\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"{names[0]} must be a 2D array, but it has {groups.ndim} dimensions.\"\n        )\n\n    # Check if equations is a 1D array\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"{names[1]} must be a 1D array, but it has {equations.ndim} dimensions.\"\n        )\n\n    # Initialize the left and right matrices\n    left = []\n    right = []\n\n    # Iterate over each equation\n    for equation in equations:\n        # Split the equation into individual groups and coefficients\n        equation_groups = re.findall(r\"[a-zA-Z]+\", equation)\n        equation_coeffs = re.findall(r\"[-+]?\\d*\\.?\\d+\", equation)\n\n        # Check if the equation has at least one group\n        if len(equation_groups) == 0:\n            raise EquationToMatrixError(\n                f\"Equation '{equation}' does not contain any groups.\"\n            )\n\n        # Check if the equation has at least one coefficient\n        if len(equation_coeffs) == 0:\n            raise EquationToMatrixError(\n                f\"Equation '{equation}' does not contain any coefficients.\"\n            )\n\n        # Initialize the left and right sides of the equation\n        left_side = np.zeros(groups.shape[1])\n        right_side = 0\n\n        # Iterate over each group in the equation\n        for group, coeff in zip(equation_groups, equation_coeffs):\n            # Check if the group is in the groups array\n            if group not in groups:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(\n                        f\"Group '{group}' mentioned in the equation '{equation}' is not found in the"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Check if the number of groups and equations are the same\n    if len(groups) != len(equations):\n        raise EquationToMatrixError(\n            f\"The number of {names[0]} and {names[1]} must be the same.\"\n        )\n\n    # Initialize the left and right matrices\n    left = []\n    right = []\n\n    # Loop through the equations\n    for i, equation in enumerate(equations):\n        # Split the equation into terms\n        terms = re.findall(r\"[+-]?\\d*\\.?\\d+[a-zA-Z]+\", equation)\n\n        # Initialize the row for the left matrix\n        row = np.zeros(len(groups))\n\n        # Loop through the terms\n        for term in terms:\n            # Extract the coefficient and group name\n            coefficient = float(term[:-1])\n            group_name = term[-1]\n\n            # Find the index of the group in the groups array\n            group_index = np.where(groups == group_name)[0]\n\n            # If the group is not found, raise an error or a warning\n            if len(group_index) == 0:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(\n                        f\"Group '{group_name}' not found in {names[0]}.\"\n                    )\n                else:\n                    warnings.warn(\n                        f\"Group '{group_name}' not found in {names[0]}. Skipping equation.\",\n                        UserWarning,\n                    )\n                    break\n\n            # Set the coefficient for the group in the row\n            row[group_index[0]] = coefficient\n\n        # If the row is not empty, append it to the left matrix\n        if np.any(row):\n            left.append(row)\n\n            # Append the right side of the equation to the right matrix\n            right.append(float(equation.split(\"=\")[-1]))\n\n    # Convert the left and right matrices to numpy arrays\n    left = np.array(left)\n    right = np.array(right)\n\n    # If"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    # Check if any of the groups in the equations are not found in the groups array\n    groups_in_equations = set(re.findall(r\"\\w+\", \" \".join(equations)))\n    groups_in_groups = set(groups.flatten())\n    missing_groups = groups_in_equations - groups_in_groups\n\n    if missing_groups:\n        if raise_if_group_missing:\n            raise GroupNotFoundError(\n                f\"The following groups are mentioned in the {names[1]} but not found in the {names[0]}: {missing_groups}\"\n            )\n        else:\n            warnings.warn(\n                f\"The following groups are mentioned in the {names[1]} but not found in the {names[0]}: {missing_groups}\",\n                UserWarning,\n            )\n            return None\n\n    # Check if the number of equations matches the number of groups\n    if len(equations) != groups.shape[0]:\n        raise EquationToMatrixError(\n            f\"The number of {names[1]} ({len(equations)}) does not match the number of {names[0]} ({groups.shape[0]})\"\n        )\n\n    # Initialize the left and right matrices\n    left = np.zeros((len(equations), groups.shape[1]))\n    right = np.zeros(len(equations))\n\n    # Iterate over the equations and groups\n    for i, equation in enumerate(equations):\n        # Split the equation into the left and right sides\n        left_side, right_side = equation.split(\"=\")\n        # Remove any spaces from the left and right sides\n        left_side = left_side.replace(\" \", \"\")\n        right_side = right_side.replace(\" \", \"\")\n\n        # Check if the left side of the equation is empty\n        if not left_side:\n            raise EquationToMatrixError(\n                f\"The left side of equation {i} is empty\"\n            )\n\n        # Check if the right side of the equation is empty"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert input to numpy arrays\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    # Check if groups is 2D and equations is 1D\n    if groups.ndim != 2 or equations.ndim != 1:\n        raise ValueError(\n            \"groups and equations must be 2D and 1D arrays, respectively.\"\n        )\n\n    # Check if all elements in equations are strings\n    if not np.issubdtype(equations.dtype, np.str_):\n        raise TypeError(\"equations must be an array of strings.\")\n\n    # Check if all elements in groups are strings\n    if not np.issubdtype(groups.dtype, np.str_):\n        raise TypeError(\"groups must be an array of strings.\")\n\n    # Check if all elements in equations are valid equations\n    for equation in equations:\n        if not re.match(r\"^[+-]?\\d+(?:\\.\\d+)?\\s*[<>=]\\s*[+-]?\\d+(?:\\.\\d+)?$\", equation):\n            raise EquationToMatrixError(\n                f\"Invalid equation: {equation}. Expected format: '<group1> <operator> <group2>'.\"\n            )\n\n    # Extract groups and operators from equations\n    group1 = []\n    operator = []\n    group2 = []\n    for equation in equations:\n        match = re.match(r\"^([+-]?\\d+(?:\\.\\d+)?)\\s*([<>=])\\s*([+-]?\\d+(?:\\.\\d+)?)$\", equation)\n        if match:\n            group1.append(match.group(1))\n            operator.append(match.group(2))\n            group2.append(match.group(3))\n        else:\n            raise EquationToMatrixError(\n                f\"Invalid equation: {equation}. Expected format: '<group1> <operator> <group2>'.\"\n            )\n\n    # Check if all groups in equations are present in groups\n    missing_groups = set(group1"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert groups and equations to numpy arrays\n    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    # Get the number of groups and assets\n    n_groups, n_assets = groups.shape\n\n    # Initialize the left and right matrices\n    left = np.zeros((len(equations), n_assets))\n    right = np.zeros(len(equations))\n\n    # Define regular expressions to match the equation components\n    pattern = re.compile(r\"([a-zA-Z0-9_]+)\\s*([<>=]+)\\s*([a-zA-Z0-9_]+)\")\n\n    # Iterate over the equations\n    for i, equation in enumerate(equations):\n        # Extract the equation components\n        match = pattern.match(equation)\n        if match is None:\n            raise EquationToMatrixError(f\"Invalid equation: {equation}\")\n        left_group, operator, right_group = match.groups()\n\n        # Find the indices of the left and right groups\n        left_idx = None\n        right_idx = None\n        for j in range(n_groups):\n            if left_group == groups[j, 0]:\n                left_idx = j\n            if right_group == groups[j, 0]:\n                right_idx = j\n\n        # Check if both groups are found\n        if left_idx is None or right_idx is None:\n            if raise_if_group_missing:\n                raise GroupNotFoundError(\n                    f\"Group {left_group} or {right_group} not found in {names[0]}\"\n                )\n            else:\n                warnings.warn(\n                    f\"Group {left_group} or {right_group} not found in {names[0]}\"\n                )\n                return None\n\n        # Set the left and right matrices based on the equation operator\n        if operator == \"<=\":\n            left[i, :] = groups[left_idx, 1:] - groups[right_idx, 1:]\n            right[i] = 0\n        elif operator == \">="}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"{names[0]} must be a 2D array, but it has {groups.ndim} dimensions.\"\n        )\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"{names[1]} must be a 1D array, but it has {equations.ndim} dimensions.\"\n        )\n\n    groups_names = groups[:, 0]\n    groups_values = groups[:, 1:]\n\n    if groups_values.dtype.kind not in [\"i\", \"f\"]:\n        raise EquationToMatrixError(\n            f\"{names[0]} must contain numeric values, but it contains values of type {groups_values.dtype}.\"\n        )\n\n    # Define regular expression to match group names\n    pattern = re.compile(r\"\\[(.*?)\\]\")\n\n    # Initialize left and right matrices\n    left = []\n    right = []\n\n    # Iterate over equations\n    for equation in equations:\n        # Find all matches of the pattern in the equation\n        matches = pattern.findall(equation)\n\n        # If no matches are found, skip this equation\n        if not matches:\n            continue\n\n        # Initialize left and right sides of the equation\n        left_side = []\n        right_side = 0\n\n        # Iterate over matches\n        for match in matches:\n            # Split match into sign and group name\n            sign, group_name = match[0], match[1:]\n\n            # Find index of group name in groups_names\n            group_index = np.where(groups_names == group_name)[0]\n\n            # If group name is not found, skip this match\n            if len(group_index) == 0:\n                if raise_if_group_missing:\n                    raise GroupNotFoundError(\n                        f\"Group '{group_name}' not found in {names[0]}.\"\n                    )\n                else:\n                    warnings.warn("}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array.\")\n\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array.\")\n\n    # Create a dictionary to map group names to their indices\n    group_indices = {group: i for i, group in enumerate(groups)}\n\n    # Initialize the left and right matrices\n    left = np.zeros((len(equations), groups.shape[1]))\n    right = np.zeros(len(equations))\n\n    # Compile a regular expression to match the equation pattern\n    equation_pattern = re.compile(\n        r\"^(?P<left>[^<>=]+)\\s*(?P<operator>[<>]=?)\\s*(?P<right>[^<>=]+)$\"\n    )\n\n    # Iterate over the equations\n    for i, equation in enumerate(equations):\n        # Split the equation into left and right sides\n        match = equation_pattern.match(equation)\n        if match is None:\n            raise EquationToMatrixError(\n                f\"Equation {equation} is not a valid equation. It should be of the form 'left_side operator right_side', where 'operator' is one of '<', '>', '<=', '>=', '='.\"\n            )\n\n        left_side = match.group(\"left\")\n        operator = match.group(\"operator\")\n        right_side = match.group(\"right\")\n\n        # Split the left and right sides into individual groups\n        left_groups = re.findall(r\"\\w+\", left_side)\n        right_groups = re.findall(r\"\\w+\", right_side)\n\n        # Check if all groups in the equation are present in the groups array\n        missing_groups = set(left_groups + right_groups) - set(group_indices)\n        if missing_groups:\n            if"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(f\"{names[0]} must be a 2D array.\")\n    if equations.ndim != 1:\n        raise ValueError(f\"{names[1]} must be a 1D array.\")\n\n    # Check if groups is a matrix of strings\n    if groups.dtype.kind in (\"U\", \"S\"):\n        groups = np.array([np.array(group, dtype=str) for group in groups])\n\n    # Check if equations is a matrix of strings\n    if equations.dtype.kind in (\"U\", \"S\"):\n        equations = np.array([str(equation) for equation in equations])\n\n    # Extract group names from equations\n    group_names = np.unique(\n        np.array(\n            [\n                re.findall(r\"\\w+\", equation)\n                for equation in equations\n                if re.findall(r\"\\w+\", equation)\n            ]\n        )\n    )\n\n    # Check if all group names in equations are in groups\n    if not np.all(np.isin(group_names, groups)):\n        missing_groups = np.setdiff1d(group_names, groups)\n        if raise_if_group_missing:\n            raise GroupNotFoundError(\n                f\"The following groups are not found in {names[0]}: {missing_groups}\"\n            )\n        else:\n            warnings.warn(\n                f\"The following groups are not found in {names[0]}: {missing_groups}\",\n                UserWarning,\n            )\n            return None, None\n\n    # Initialize left and right matrices\n    left = np.zeros((len(equations), groups.shape[1]))\n    right = np.zeros(len(equations))\n\n    # Loop over equations and groups\n    for i, equation in enumerate(equations):\n        # Split equation into left and right parts\n        left_part, right_part = equation.split(\"=\")"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.array(groups)\n    equations = np.array(equations)\n\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            f\"The {names[0]} array should be a 2D array, but it has {groups.ndim} dimensions.\"\n        )\n\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            f\"The {names[1]} array should be a 1D array, but it has {equations.ndim} dimensions.\"\n        )\n\n    left = []\n    right = []\n\n    for equation in equations:\n        left_equation = []\n        right_equation = 0\n\n        # Split the equation into terms\n        terms = re.split(r\"([+-])\", equation)\n\n        # Process each term\n        for i, term in enumerate(terms):\n            if term in [\"+\", \"-\"]:\n                continue\n\n            # Split the term into the group and coefficient\n            match = re.match(r\"([^0-9]+)([0-9.]*)\", term)\n            if match:\n                group_name, coefficient = match.groups()\n                if coefficient == \"\":\n                    coefficient = 1.0\n                else:\n                    coefficient = float(coefficient)\n\n                # Find the group in the groups array\n                group_idx = np.where(groups == group_name)[0]\n                if len(group_idx) == 0:\n                    if raise_if_group_missing:\n                        raise GroupNotFoundError(\n                            f\"Group '{group_name}' not found in the {names[0]} array.\"\n                        )\n                    else:\n                        warnings.warn(\n                            f\"Group '{group_name}' not found in the {names[0]} array. Skipping this equation.\",\n                            UserWarning,\n                        )\n                        break\n\n                # Append the group to the left equation\n                left_equation.append(group_idx[0])\n\n                # Add the coefficient to the right equation\n                if terms[i - 1] == \"-\":\n                    right_equation -= coefficient\n                else:"}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    # Convert groups to a numpy array\n    groups = np.asarray(groups)\n\n    # Convert equations to a numpy array\n    equations = np.asarray(equations)\n\n    # Check if groups is a 2D array\n    if groups.ndim != 2:\n        raise EquationToMatrixError(\n            \"groups\",\n            f\"{names[0]} must be a 2D array. {names[0]} has {groups.ndim} dimensions.\",\n        )\n\n    # Check if equations is a 1D array\n    if equations.ndim != 1:\n        raise EquationToMatrixError(\n            \"equations\",\n            f\"{names[1]} must be a 1D array. {names[1]} has {equations.ndim} dimensions.\",\n        )\n\n    # Check if groups and equations have the same number of columns\n    if groups.shape[1] != equations.shape[0]:\n        raise EquationToMatrixError(\n            \"groups\",\n            f\"{names[0]} and {names[1]} must have the same number of columns. {names[0]} has {groups.shape[1]} columns, and {names[1]} has {equations.shape[0]} columns.\",\n        )\n\n    # Initialize left and right matrices\n    left = np.zeros((equations.shape[0], groups.shape[1]))\n    right = np.zeros(equations.shape[0])\n\n    # Iterate over equations\n    for i, equation in enumerate(equations):\n        # Split equation into terms\n        terms = re.split(r\"\\s*(<=|>=|<|>|==)\\s*\", equation)\n\n        # Check if equation has a valid comparison operator\n        if len(terms) != 3:\n            raise EquationToMatrixError(\n                \"equations\",\n                f\"{names[1]} has an invalid comparison operator at index {i}.\",\n            )\n\n        # Check if equation has a valid comparison operator\n        if terms[1] not in [\"<=\", \">=\", \"<\", \">\", \"==\"]:\n            raise EquationToMatrixError(\n                \"equations\","}
{"namespace": "skfolio.utils.equations.equations_to_matrix", "completion": "    groups = np.asarray(groups)\n    equations = np.asarray(equations)\n\n    if groups.ndim != 2:\n        raise ValueError(\n            f\"The groups array must have exactly 2 dimensions, but {groups.ndim} were provided.\"\n        )\n    if equations.ndim != 1:\n        raise ValueError(\n            f\"The equations array must have exactly 1 dimension, but {equations.ndim} were provided.\"\n        )\n\n    if groups.shape[1] != equations.shape[0]:\n        raise EquationToMatrixError(\n            f\"The number of columns in groups ({groups.shape[1]}) must be equal to the number of elements in equations ({equations.shape[0]}).\"\n        )\n\n    # Check if the first element of each equation is a group\n    first_element_is_group = [\n        re.match(r\"^[a-zA-Z0-9_]+$\", equation.split(\" \")[0]) is not None\n        for equation in equations\n    ]\n\n    if not all(first_element_is_group):\n        raise EquationToMatrixError(\n            \"The first element of each equation must be a group.\"\n        )\n\n    # Check if the equation is a valid mathematical expression\n    valid_expression = [\n        re.match(r\"^[a-zA-Z0-9_+\\-*/ ]+$\", equation) is not None\n        for equation in equations\n    ]\n\n    if not all(valid_expression):\n        raise EquationToMatrixError(\n            \"The equation must be a valid mathematical expression.\"\n        )\n\n    # Check if the equation is a valid mathematical expression\n    valid_expression = [\n        re.match(r\"^[a-zA-Z0-9_+\\-*/ ]+$\", equation) is not None\n        for equation in equations\n    ]\n\n    if not all(valid_expression):\n        raise EquationToMatrixError(\n            \"The equation must be a valid mathematical expression.\"\n        )\n\n    # Check if the equation is a valid mathematical expression\n    valid_expression = [\n        re."}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    new_instances_name = f\"NewInstances{_counter}\"\n    new_instances_file = tempfile.NamedTemporaryFile(\n        mode=\"w\", suffix=\".py\", delete=False\n    )\n    new_instances_file.write(f\"import torch\\n\")\n    new_instances_file.write(f\"from detectron2.structures import Instances\\n\")\n    new_instances_file.write(f\"class {new_instances_name}(Instances):\\n\")\n    new_instances_file.write(f\"    def __init__(self, image_size):\\n\")\n    new_instances_file.write(f\"        super().__init__(image_size)\\n\")\n    for name, dtype in fields:\n        new_instances_file.write(f\"        self._{name} = torch.jit.Attribute({name}, {dtype})\\n\")\n    new_instances_file.close()\n\n    with ExitStack() as stack:\n        stack.enter_context(mock.patch(\"detectron2.structures.Instances\", new_instances_name))\n        stack.enter_context(mock.patch(\"detectron2.modeling.proposal_generator.Instances\", new_instances_name))\n        stack.enter_context(mock.patch(\"detectron2.modeling.roi_heads.Instances\", new_instances_name))\n        stack.enter_context(\n            mock.patch(\"detectron2.modeling.roi_heads.FastRCNNOutputLayers.Instances\", new_instances_name)\n        )\n        stack.enter_context(\n            mock.patch(\"detectron2.modeling.roi_heads.StandardROIHeads.Instances\", new_instances_name)\n        )\n        stack.enter_context(\n            mock.patch(\"detectron2.modeling.roi_heads.CascadeROIHeads.Instances\", new_instances_name)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    with tempfile.TemporaryDirectory(prefix=\"detectron2_patch_instances\") as tmpdir:\n        with open(os.path.join(tmpdir, \"new_instances.py\"), \"w\") as f:\n            f.write(f\"from detectron2.structures import Instances\\n\\n\\nclass newInstances(Instances):\\n\")\n            for name, val in fields:\n                f.write(f\"    {name}: {type(val).__name__}\\n\")\n        sys.path.insert(0, tmpdir)\n        newInstances = _import_file(\"new_instances.py\").newInstances\n        _add_instances_conversion_methods(newInstances)\n        with mock.patch(\"detectron2.structures.Instances\", newInstances, create=True):\n            yield newInstances\n        sys.path.remove(tmpdir)\n        _clear_jit_cache()\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # Set up a temporary module for the new class\n    global _counter\n    _counter += 1\n    new_module_name = f\"new_instances_{_counter}\"\n    new_module_path = os.path.join(tempfile.gettempdir(), f\"{new_module_name}.py\")\n    with open(new_module_path, \"w\") as f:\n        f.write(\n            f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    # create a new module that defines the new class\n    module_name = f\"new_instances_{_counter}\"\n    module_path = os.path.join(tempfile.gettempdir(), f\"{module_name}.py\")\n    with open(module_path, \"w\") as f:\n        f.write(f\"import torch\\nfrom detectron2.structures import Instances\\n\")\n        f.write(f\"class {module_name}(Instances):\\n\")\n        for name, type_ in fields:\n            f.write(f\"    {name}: torch.jit.ScriptObject\\n\")\n\n    # import the module and set up the environment\n    with ExitStack() as stack:\n        stack.enter_context(mock.patch(\"detectron2.structures.Instances\", module_name))\n        stack.enter_context(mock.patch(\"detectron2.modeling.meta_arch.build_top_module\", _build_top_module))\n        stack.enter_context(mock.patch(\"detectron2.modeling.meta_arch.build_bottom_up_feature_extractor\", _build_bottom_up_feature_extractor))\n        stack.enter_context(mock.patch(\"detectron2.modeling.meta_arch.build_proposal_generator\", _build_proposal_generator))\n        stack.enter_context(mock.patch(\"detectron2.modeling.meta_arch.build_roi_heads\", _build_roi_heads))\n        stack.enter_context(mock.patch(\"detectron2.modeling.meta_arch.build_box_head\", _build_box_head))\n        stack.enter_context(mock.patch(\"detectron2.modeling.meta_arch.build_mask_head\", _build_mask_head))\n        stack.enter_context(mock.patch(\"detectron2.modeling.meta_arch.build_keypoint_head\", _build_keypoint_head))\n        stack.enter_context(mock"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    new_module_name = f\"new_instances_{_counter}\"\n    new_module_path = os.path.join(tempfile.gettempdir(), f\"{new_module_name}.py\")\n\n    # Write the new class to a temporary file\n    with open(new_module_path, \"w\") as f:\n        f.write(\n            f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    newInstances = type(f\"Instances{_counter}\", (Instances,), {})\n    newInstances.__module__ = \"detectron2.structures.instances\"\n    for name, val in fields:\n        setattr(newInstances, name, val)\n\n    # add from_instances method to the scripted Instances class\n    _add_instances_conversion_methods(newInstances)\n\n    # write the new class to a temporary file\n    tmp_dir = tempfile.mkdtemp()\n    tmp_file = os.path.join(tmp_dir, \"instances.py\")\n    with open(tmp_file, \"w\") as f:\n        f.write(f\"from detectron2.structures import Instances\\n\\nclass Instances(Instances):\\n\")\n        for name, val in fields:\n            f.write(f\"    {name}: {val}\\n\")\n\n    # import the new class\n    sys.path.append(tmp_dir)\n    with _import_file(\"instances\", tmp_file):\n        with ExitStack() as stack:\n            stack.enter_context(\n                mock.patch(\n                    \"detectron2.structures.instances.Instances\", newInstances, create=True\n                )\n            )\n            stack.enter_context(\n                mock.patch(\n                    \"detectron2.structures.instances.Boxes\", newInstances, create=True\n                )\n            )\n            stack.enter_context(\n                mock.patch(\n                    \"detectron2.modeling.proposal_generator.instances.Instances\",\n                    newInstances,\n                    create=True,\n                )\n            )\n            stack.enter_context(\n                mock.patch(\n                    \"detectron2.modeling.roi_heads.fast_rcnn.instances.Instances\",\n                    newInstances,\n                    create=True,\n                )\n            )\n            stack.enter_context(\n                mock.patch(\n                    \"detectron"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    temp_dir = tempfile.TemporaryDirectory(prefix=\"detectron2_jit_instances\")\n    temp_file = os.path.join(temp_dir.name, f\"instances_{_counter}.py\")\n\n    with open(temp_file, \"w\") as f:\n        f.write(\n            f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    new_instances_name = \"NewInstances\" + str(_counter)\n    new_instances_module_name = \"new_instances_module\" + str(_counter)\n    new_instances_module_path = os.path.join(tempfile.gettempdir(), new_instances_module_name + \".py\")\n    with open(new_instances_module_path, \"w\") as f:\n        f.write(\n            f\"import torch\\nfrom detectron2.structures import Instances\\nclass {new_instances_name}(Instances):\\n\"\n        )\n        for name, type in fields:\n            f.write(f\"    {name}: {type}\\n\")\n\n    new_instances = _import_file(new_instances_module_name, new_instances_module_path)\n    _add_instances_conversion_methods(new_instances)\n    # mock the original instances class\n    with mock.patch(\"detectron2.structures.instances.Instances\", new_instances):\n        # mock the original Boxes class\n        with mock.patch(\"detectron2.structures.boxes.Boxes\", new_instances.Boxes):\n            # mock the original BoxMode class\n            with mock.patch(\"detectron2.structures.boxes.BoxMode\", new_instances.BoxMode):\n                # mock the original BitMasks class\n                with mock.patch(\"detectron2.structures.masks.BitMasks\", new_instances.BitMasks):\n                    # mock the original PolygonMasks class\n                    with mock.patch(\"detectron2.structures.masks.PolygonMasks\", new_instances.PolygonMasks):\n                        # mock the original RotatedBoxes class\n                        with mock.patch(\"detectron2.structures.rotated_boxes.RotatedBoxes\", new_instances.RotatedBoxes):\n                            yield new_instances\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    new_instances_name = f\"NewInstances_{_counter}\"\n    new_instances_module = f\"{new_instances_name}_module\"\n\n    # Create a new module for the new class\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        f.write(f\"import torch\\nfrom detectron2.structures import Instances\\n\\n\\nclass {new_instances_name}(Instances):\\n\")\n        for name, val in fields:\n            f.write(f\"    {name}: torch.jit.ScriptObject\\n\")\n        f.write(\"\\n\\n\")\n        f.write(f\"def from_instances(instances: Instances):\\n\")\n        f.write(f\"    ret = {new_instances_name}(instances.image_size)\\n\")\n        for name, val in fields:\n            f.write(f\"    ret.{name} = instances.get('{name}')\\n\")\n        f.write(f\"    return ret\\n\\n\")\n        f.write(f\"{new_instances_name}.from_instances = from_instances\\n\")\n        f.flush()\n        temp_file_name = f.name\n\n    # Import the new class\n    with ExitStack() as stack:\n        stack.enter_context(mock.patch.dict(sys.modules, {new_instances_module: mock.MagicMock()}))\n        stack.enter_context(mock.patch.dict(sys.modules, {new_instances_name: mock.MagicMock()}))\n        new_instances = _import_file(new_instances_module, temp_file_name)\n        new_instances = getattr(new_instances, new_instances_name)\n\n    # Set up the environment to recognize the new class\n    _clear_jit_cache()\n    torch.jit.frontend.torch_version = (1, 11)"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    with ExitStack() as stack:\n        # create a temporary file to write the new class to\n        temp_dir = tempfile.TemporaryDirectory()\n        temp_file = os.path.join(temp_dir.name, f\"instances_{_counter}.py\")\n        stack.enter_context(temp_dir)\n        # write the new class to the temporary file\n        with open(temp_file, \"w\") as f:\n            f.write(\n                f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # create a new class that inherits from Instances\n    newInstances = type(f\"NewInstances{_counter}\", (Instances,), {})\n    # add the fields to the class\n    for name, val in fields:\n        setattr(newInstances, name, val)\n    # add from_instances method to the class\n    _add_instances_conversion_methods(newInstances)\n    # create a temporary file for the new class\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n        # write the class definition to the file\n        f.write(f\"from detectron2.structures import Instances\\n\\n\\nclass {newInstances.__name__}(Instances):\\n\")\n        for name, val in fields:\n            f.write(f\"\\t{name} = {val}\\n\")\n        # get the path to the temporary file\n        tmp_file_path = f.name\n    # import the new class\n    newInstances = _import_file(tmp_file_path)\n    # remove the temporary file\n    os.remove(tmp_file_path)\n    # replace Instances with the new class\n    sys.modules[\"detectron2.structures.instances\"].Instances = newInstances\n    # clear the jit cache\n    _clear_jit_cache()\n    # yield the new class\n    yield newInstances\n    # remove the new class from the cache\n    del sys.modules[\"detectron2.structures.instances\"].Instances\n    # clear the jit cache again\n    _clear_jit_cache()\n    # restore the original Instances class\n    sys.modules[\"detectron2.structures.instances\"].Instances = Instances\n    # clear the jit cache one last time\n    _clear_jit_cache()\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    tmp_file = tempfile.NamedTemporaryFile(\n        suffix=\".py\", prefix=f\"instances_{_counter}_\", delete=False\n    )\n    with open(tmp_file.name, \"w\") as f:\n        f.write(\n            f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    with ExitStack() as stack:\n        newInstances = type(f\"NewInstances{_counter}\", (Instances,), {})\n        _add_instances_conversion_methods(newInstances)\n\n        # save the new class to a temporary file\n        tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".py\", mode=\"w\")\n        tmp_file.write(f\"from detectron2.structures import Instances\\n\\nclass {newInstances.__name__}(Instances):\\n\")\n        for name, type_ in fields:\n            tmp_file.write(f\"\\t_{name}: {type_}\\n\")\n        tmp_file.close()\n\n        # import the new class\n        module_name = os.path.splitext(os.path.basename(tmp_file.name))[0]\n        module = _import_file(module_name, tmp_file.name)\n        stack.enter_context(mock.patch.dict(sys.modules, {module_name: module}))\n\n        # patch the class\n        stack.enter_context(mock.patch.object(Instances, \"__class__\", newInstances))\n        yield newInstances\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    # create a new class with the given fields\n    newInstances = type(\n        f\"ScriptableInstances{_counter}\",\n        (Instances,),\n        {\n            \"__module__\": \"detectron2.structures\",\n            \"__annotations__\": {\"image_size\": torch.Tensor},\n        },\n    )\n\n    # add from_instances method to the new class\n    _add_instances_conversion_methods(newInstances)\n\n    # add fields to the new class\n    for name, val in fields:\n        setattr(newInstances, name, val)\n\n    # write the new class to a temporary file\n    with tempfile.TemporaryDirectory() as temp_dir:\n        temp_file = os.path.join(temp_dir, \"structures.py\")\n        with open(temp_file, \"w\") as f:\n            f.write(f\"from detectron2.structures import Instances\\n\\n{newInstances}\\n\")\n\n        # import the new class from the temporary file\n        with ExitStack() as stack:\n            # mock the import to prevent detectron2 from importing the original class\n            stack.enter_context(mock.patch(\"detectron2.structures.Instances\", newInstances))\n            # import the new class from the temporary file\n            stack.enter_context(mock.patch.dict(sys.modules, {\"detectron2.structures\": None}))\n            stack.enter_context(mock.patch.dict(sys.modules, {\"detectron2.structures.Instances\": None}))\n            new_module = _import_file(\"detectron2.structures\", temp_file)\n            stack.enter_context(mock.patch.dict(sys.modules, {\"detectron2.structures\": new_module}))\n            stack.enter_context(mock.patch.dict(sys.modules, {\"detectron2.structures.Instances\": newInstances}))\n            yield newInstances\n\n"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    new_name = f\"Instances{_counter}\"\n\n    with tempfile.TemporaryDirectory() as tempdir:\n        # write new class to temporary file\n        with open(os.path.join(tempdir, \"instances.py\"), \"w\") as f:\n            f.write(f\"from detectron2.structures import Instances\\n\\n\\nclass {new_name}(Instances):\\n\")\n            for name, val in fields:\n                f.write(f\"    {name}: {val}\\n\")\n\n        # import new class\n        module_name = f\"{tempdir}.instances\"\n        newInstances = _import_file(module_name, new_name)\n\n        # add from_instances method to new class\n        _add_instances_conversion_methods(newInstances)\n\n        # patch detectron2.structures.Instances\n        with ExitStack() as stack:\n            stack.enter_context(\n                mock.patch(\n                    \"detectron2.structures.Instances\",\n                    newInstances,\n                )\n            )\n            stack.enter_context(\n                mock.patch(\n                    \"detectron2.modeling.roi_heads.fast_rcnn.fast_rcnn.FastRCNNOutputLayers.get_boxes\",\n                    lambda self, *args, **kwargs: Boxes(\n                        torch.rand(1, 4, device=\"cpu\", dtype=torch.float32)\n                    ),\n                )\n            )\n            stack.enter_context(\n                mock.patch(\n                    \"detectron2.modeling.roi_heads.fast_rcnn.fast_rcnn.FastRCNNOutputLayers.predict_probs\",\n                    lambda self, *args, **kwargs: torch.rand(1, 81, device=\"cpu\", dtype=torch.float32),\n                )\n            )\n            stack.enter_context(\n                mock.patch(\n                    \"detectron2.modeling.roi_head"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    # fields is a list of (name, type) tuples.\n    # Each field is a class attribute.\n    # The first field must be 'image_size'.\n    # The last field must be 'gt_boxes'.\n    # The second last field must be 'gt_classes'.\n    # The rest are optional.\n    assert fields[0][0] == \"image_size\"\n    assert fields[-1][0] == \"gt_boxes\"\n    assert fields[-2][0] == \"gt_classes\"\n\n    global _counter\n    _counter += 1\n    new_instances_module_name = f\"new_instances_{_counter}\"\n    new_instances_module_path = os.path.join(tempfile.gettempdir(), f\"{new_instances_module_name}.py\")\n    with open(new_instances_module_path, \"w\") as f:\n        f.write(f\"import torch\\n\")\n        f.write(f\"from detectron2.structures import Instances\\n\")\n        f.write(f\"class {new_instances_module_name}(Instances):\\n\")\n        f.write(f\"    def __init__(self, image_size):\\n\")\n        f.write(f\"        super().__init__(image_size)\\n\")\n        for name, typ in fields:\n            f.write(f\"        self._{name} = torch.jit.Attribute({name}, {typ})\\n\")\n\n    with ExitStack() as stack:\n        stack.enter_context(mock.patch(\"detectron2.structures.Instances\", newInstances))\n        sys.modules.pop(new_instances_module_name, None)\n        newInstances = _import_file(new_instances_module_name, new_instances_module_path)\n        stack.enter_context(mock.patch(\"detectron2.structures.Instances\", newInstances))\n        _add_instances_conversion_methods(newInstances)\n        _clear_jit_cache()\n        yield newInst"}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    # Create a temporary file for the scripted class\n    temp_file = tempfile.NamedTemporaryFile(\n        suffix=\".py\", prefix=\"instances_{}\".format(_counter), delete=False\n    )\n    temp_file_name = temp_file.name\n    temp_file.close()\n\n    # Write the class to the temporary file\n    with open(temp_file_name, \"w\") as f:\n        f.write(\n            \"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n\n    # Create a new module with the new class\n    new_module = \"detectron2.structures.new_instances_%d\" % _counter\n    new_module_file = tempfile.NamedTemporaryFile(suffix=\".py\", delete=False)\n    new_module_file.write(\n        f\"\"\""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    # TODO: support nested fields\n    # TODO: support fields with default values\n\n    with tempfile.TemporaryDirectory() as tmpdir:\n        # write a new class with the specified fields\n        class_name = f\"NewInstances_{_counter}\"\n        with open(os.path.join(tmpdir, \"instances.py\"), \"w\") as f:\n            f.write(f\"from detectron2.structures import Instances\\n\\n\\n\")\n            f.write(f\"class {class_name}(Instances):\\n\")\n            f.write(f\"    def __init__(self, image_size):\\n\")\n            f.write(f\"        super().__init__(image_size)\\n\")\n            for name, type_ in fields:\n                f.write(f\"        self._{name} = nn.Parameter(torch.empty(0), requires_grad=False)\\n\")\n        # import the class\n        new_instances = _import_file(\n            \"instances\", os.path.join(tmpdir, \"instances.py\"), \"instances\"\n        )\n        new_instances = getattr(new_instances, class_name)\n        # add from_instances method\n        _add_instances_conversion_methods(new_instances)\n        # replace Instances with the new class\n        with ExitStack() as stack:\n            stack.enter_context(mock.patch.object(sys, \"modules\", {__name__: sys.modules[__name__]}))\n            stack.enter_context(mock.patch.object(sys, \"modules\", {__name__: sys.modules[__name__]}))\n            stack.enter_context(\n                mock.patch.object(detectron2, \"structures\", sys.modules[__name__])\n            )\n            stack.enter_context(mock.patch.object(detectron2, \"structures\", sys.modules[__name__]))\n            stack.enter_context(\n                mock.patch.object(\n                    detectron2.structures, \""}
{"namespace": "detectron2.export.torchscript_patch.patch_instances", "completion": "    global _counter\n    _counter += 1\n    with ExitStack() as stack:\n        # write the new class to a temporary file\n        tmp_file = tempfile.NamedTemporaryFile(\n            suffix=f\"{_counter}.py\", prefix=\"detectron2_\", delete=False\n        )\n        tmp_file.close()\n        stack.callback(_clear_jit_cache)\n        stack.callback(os.unlink, tmp_file.name)\n        with open(tmp_file.name, \"w\") as f:\n            f.write(\n                f\"\"\""}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n        try:\n            image = _apply_exif_orientation(image)\n        except Exception:\n            pass\n\n        image = convert_PIL_to_numpy(image, format)\n\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n        try:\n            image = _apply_exif_orientation(image)\n        except Exception:\n            pass\n\n        image = convert_PIL_to_numpy(image, format)\n\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n        try:\n            image = _apply_exif_orientation(image)\n        except Exception:\n            pass\n\n        image = convert_PIL_to_numpy(image, format)\n    return image"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    image = Image.open(file_name)\n    # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n    try:\n        image = _apply_exif_orientation(image)\n    except Exception:\n        pass\n    return convert_PIL_to_numpy(image, format)"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    image = Image.open(file_name)\n\n    # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n    try:\n        image = _apply_exif_orientation(image)\n    except Exception:\n        pass\n\n    return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n        try:\n            image = _apply_exif_orientation(image)\n        except Exception:\n            pass\n\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n        try:\n            image = _apply_exif_orientation(image)\n        except Exception:\n            pass\n\n        image = convert_PIL_to_numpy(image, format)\n\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n        try:\n            image = _apply_exif_orientation(image)\n        except Exception:\n            pass\n\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n        try:\n            image = _apply_exif_orientation(image)\n        except Exception:\n            pass\n\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n        try:\n            image = _apply_exif_orientation(image)\n        except Exception:\n            pass\n\n        image = convert_PIL_to_numpy(image, format)\n\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n        try:\n            image = _apply_exif_orientation(image)\n        except Exception:\n            pass\n\n        image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n        try:\n            image = _apply_exif_orientation(image)\n        except Exception:\n            pass\n\n        image = convert_PIL_to_numpy(image, format)\n\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n        try:\n            image = _apply_exif_orientation(image)\n        except Exception:\n            pass\n\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n        image = _apply_exif_orientation(image)\n        return convert_PIL_to_numpy(image, format)\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    image = Image.open(file_name)\n\n    # capture and ignore this bug: https://github.com/python-pillow/Pillow/issues/3973\n    try:\n        image = _apply_exif_orientation(image)\n    except Exception:\n        pass\n\n    image = convert_PIL_to_numpy(image, format)\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.read_image", "completion": "    with PathManager.open(file_name, \"rb\") as f:\n        image = Image.open(f)\n\n        # work around this bug: https://github.com/python-pillow/Pillow/issues/3973\n        image = _apply_exif_orientation(image)\n        image = convert_PIL_to_numpy(image, format)\n\n    return image\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # segmentation = polygon\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, list):\n        # polygons\n        polygons = [np.asarray(p).reshape(-1, 2) for p in segmentation]\n        annotation[\"segmentation\"] = [\n            p.reshape(-1) for p in transforms.apply_polygons(polygons)\n        ]\n    else:\n        # RLE\n        mask = mask_util.decode(segmentation)\n        mask = transforms.apply_segmentation(mask)\n        assert tuple(mask.shape[:2]) == image_size\n        annotation[\"segmentation\"] = mask"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform polygon or uncompressed RLE to tight polygon\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, list):\n        # polygon\n        segmentation = [transforms.apply_segmentation(x) for x in segmentation]\n    else:\n        # uncompressed RLE\n        segmentation = transforms.apply_segmentation(segmentation)\n    annotation[\"segmentation\"] = segmentation\n\n    # Transform keypoints\n    keypoints = utils.transform_keypoint_annotations(\n        annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n    )\n    annotation[\"keypoints\"] = keypoints\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # segmentation = [poly]\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, list):\n        # polygons\n        polygons = [np.asarray(p).reshape(-1, 2) for p in segmentation]\n        annotation[\"segmentation\"] = [\n            p.reshape(-1) for p in transforms.apply_polygons(polygons)\n        ]\n    else:\n        # RLE\n        mask = mask_util.decode(segmentation)\n        mask = transforms.apply_segmentation(mask)\n        annotation[\"segmentation\"] = mask_util.encode(\n            np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\")[0, :, 0]\n        )\n\n    # keypoints = (K, 3)\n    keypoints = transforms.apply_coords(annotation[\"keypoints\"].reshape(-1, 3))\n    keypoints = keypoints.reshape(-1, 3)\n\n    if keypoint_hflip_indices is not None:\n        keypoints = keypoints[keypoint_hflip_indices, :]\n        keypoints[:, 0] = image_size[1] - keypoints[:, 0]\n\n    annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform polygon or RLE masks\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # Polygon\n            annotation[\"segmentation\"] = [\n                transforms.apply_segmentation(obj) for obj in annotation[\"segmentation\"]\n            ]\n        else:\n            # RLE\n            annotation[\"segmentation\"] = transforms.apply_segmentation(\n                annotation[\"segmentation\"]\n            )\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transforms.apply_coords(annotation[\"keypoints\"])\n        annotation[\"keypoints\"] = keypoints\n        if keypoint_hflip_indices is not None:\n            keypoints = annotation[\"keypoints\"]\n            keypoints = keypoints[:, keypoint_hflip_indices]\n            annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # segmentation = polygon\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, list):\n        # polygons\n        polygons = [np.asarray(p).reshape(-1, 2) for p in segmentation]\n        annotation[\"segmentation\"] = [\n            p.reshape(-1) for p in transforms.apply_polygons(polygons)\n        ]\n    else:\n        # RLE\n        mask = mask_util.decode(segmentation)\n        mask = transforms.apply_segmentation(mask)\n        mask = mask_util.encode(np.asarray(mask, order=\"F\", dtype=\"uint8\"))\n        annotation[\"segmentation\"] = mask\n\n    # keypoints\n    keypoints = transforms.apply_coords(annotation[\"keypoints\"].reshape(-1, 3))\n    keypoints = keypoints.reshape(-1)\n\n    if keypoint_hflip_indices is not None:\n        keypoints = transforms.apply_coords(keypoints.reshape(-1, 3))[keypoint_hflip_indices, :]\n    annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # segmentation = polygons\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, list):\n        # polygons\n        polygons = [np.asarray(p).reshape(-1, 2) for p in segmentation]\n        annotation[\"segmentation\"] = [\n            p.reshape(-1) for p in transforms.apply_polygons(polygons)\n        ]\n    elif isinstance(segmentation, dict):\n        # RLE\n        mask = mask_util.decode(segmentation)\n        mask = transforms.apply_segmentation(mask)\n        assert tuple(mask.shape[:2]) == image_size\n        annotation[\"segmentation\"] = mask_util.encode(\n            np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\")[0, :, 0]\n        )\n    else:\n        raise ValueError(\n            \"Cannot transform segmentation into polygons for {}!\".format(\n                type(segmentation)\n            )\n        )\n\n    # keypoints\n    keypoints = utils.transform_keypoint_annotations(\n        annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n    )\n    annotation[\"keypoints\"] = keypoints\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # segmentation = polygons\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, list):\n        # polygons\n        polygons = [np.asarray(p).reshape(-1, 2) for p in segmentation]\n        annotation[\"segmentation\"] = [\n            p.reshape(-1) for p in transforms.apply_polygons(polygons)\n        ]\n    else:\n        # RLE\n        mask = mask_util.decode(segmentation)\n        mask = transforms.apply_segmentation(mask)\n        assert tuple(mask.shape[:2]) == image_size\n        annotation[\"segmentation\"] = mask_util.encode(\n            np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\")[mask]\n        )\n\n    # keypoints\n    keypoints = transforms.apply_coords(annotation[\"keypoints\"].reshape(-1, 3))\n    keypoints = keypoints.reshape(-1, 17, 3)\n\n    if keypoint_hflip_indices is not None:\n        keypoints = keypoints[:, keypoint_hflip_indices, :]\n\n    annotation[\"keypoints\"] = keypoints\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform polygon or uncompressed RLE to tight polygon\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, list):\n        # Polygon\n        segmentation = [transforms.apply_segmentation(obj) for obj in segmentation]\n    else:\n        # uncompressed RLE\n        segmentation = transforms.apply_segmentation(segmentation)\n    annotation[\"segmentation\"] = segmentation\n\n    if \"keypoints\" in annotation:\n        keypoints = transforms.apply_coords(annotation[\"keypoints\"])\n        annotation[\"keypoints\"] = keypoints\n        if keypoint_hflip_indices is not None:\n            annotation[\"keypoints\"] = keypoints[keypoint_hflip_indices]\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # segmentation = polygon\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, list):\n        # polygons\n        polygons = [np.asarray(p).reshape(-1, 2) for p in segmentation]\n        # useful for inference if no annotations\n        annotation[\"segmentation\"] = [p.ravel() for p in polygons]\n        annotation[\"segmentation\"] = transforms.apply_polygons(polygons)\n    else:\n        # RLE\n        mask = mask_util.decode(segmentation)\n        mask = transforms.apply_segmentation(mask)\n        annotation[\"segmentation\"] = mask_util.encode(\n            np.asarray(mask, order=\"F\", dtype=\"uint8\")\n        )\n\n    # keypoints\n    keypoints = transforms.apply_coords(annotation[\"keypoints\"].reshape(-1, 3))\n    keypoints = keypoints.reshape(-1)\n\n    if keypoint_hflip_indices is not None:\n        keypoints = keypoints[keypoint_hflip_indices]\n\n    annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform polygon or uncompressed RLE to tight polygon\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, list):\n        # polygon\n        segmentation = [\n            transforms.apply_segmentation(obj)\n            for obj in segmentation\n        ]\n    else:\n        # RLE\n        segmentation = transforms.apply_segmentation(segmentation)\n    annotation[\"segmentation\"] = segmentation\n\n    if \"keypoints\" in annotation:\n        keypoints = transforms.apply_coords(annotation[\"keypoints\"])\n        annotation[\"keypoints\"] = keypoints\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints.reshape(-1, 3)\n            keypoints[:, 0] = image_size[1] - keypoints[:, 0]\n            keypoints = keypoints[keypoint_hflip_indices, :]\n            annotation[\"keypoints\"] = keypoints.reshape(-1)\n\n    return annotation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform polygon or uncompressed RLE to tight 4-point RLE\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygon\n            polygons = [np.asarray(p).reshape(-1, 2) for p in annotation[\"segmentation\"]]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        else:\n            # uncompressed RLE\n            annotation[\"segmentation\"] = transforms.apply_segmentation(\n                annotation[\"segmentation\"]\n            )\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transforms.apply_coords(annotation[\"keypoints\"])\n        annotation[\"keypoints\"] = keypoints\n\n        if keypoint_hflip_indices is not None:\n            keypoints = annotation[\"keypoints\"].reshape(-1, 3)\n            keypoints[:, 0] = image_size[1] - keypoints[:, 0]\n            keypoints = keypoints[keypoint_hflip_indices, :]\n            annotation[\"keypoints\"] = keypoints.reshape(-1)\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Needs to be updated if we support more flexible way\n    # to deal with polygons in the future.\n    if \"segmentation\" in annotation:\n        segmentation = annotation[\"segmentation\"]\n        if isinstance(segmentation, list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in segmentation]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        else:\n            # RLE\n            mask = mask_util.decode(segmentation)\n            mask = transforms.apply_segmentation(mask)\n            mask = mask_util.encode(\n                np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\")[0, :, :]\n            )\n            annotation[\"segmentation\"] = mask\n\n    # keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transforms.apply_coords(annotation[\"keypoints\"])\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[:, keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # segmentation = polygon\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, list):\n        # polygons\n        polygons = [np.asarray(p).reshape(-1, 2) for p in segmentation]\n        # transform polygons\n        polygons = transforms.apply_polygons(polygons)\n        # clip to image size\n        polygons = [p.clip(0, image_size) for p in polygons]\n        # area check\n        annotation[\"segmentation\"] = [p.reshape(-1) for p in polygons if PolygonMasks([p]).area() > 0]\n\n    # segmentation = uncompressed RLE\n    elif isinstance(segmentation, dict):\n        rle = mask_util.decode(segmentation)\n        rle = transforms.apply_segmentation(rle)\n        rle = mask_util.encode(np.array(rle[:, :, None], order=\"F\", dtype=\"uint8\"))[0]\n        area = mask_util.area(rle)\n        if area > 0:\n            annotation[\"segmentation\"] = rle\n        else:\n            annotation.pop(\"segmentation\")\n\n    # keypoints\n    keypoints = annotation.get(\"keypoints\", [])  # return [] if it doesn't exist\n    for idx, _ in enumerate(keypoints):\n        if keypoints[idx][2] > 0:\n            keyp"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform polygon and RLE masks\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, PolygonMasks):\n        # polygons\n        segmentation = transforms.apply_polygons(segmentation.polygons)\n    elif isinstance(segmentation, BitMasks):\n        # RLE\n        segmentation = transforms.apply_segmentation(segmentation.get_arr())\n\n    annotation[\"segmentation\"] = segmentation\n\n    # Transform keypoints\n    keypoints = utils.transform_keypoint_annotations(\n        annotation[\"keypoints\"], transforms, image_size, keypoint_hflip_indices\n    )\n    annotation[\"keypoints\"] = keypoints\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Needs to be updated if there is a crop without crop_size\n    # See https://github.com/facebookresearch/detectron2/issues/871\n    if \"segmentation\" in annotation:\n        if isinstance(annotation[\"segmentation\"], list):\n            # polygons\n            polygons = [np.asarray(p).reshape(-1, 2) for p in annotation[\"segmentation\"]]\n            annotation[\"segmentation\"] = [\n                p.reshape(-1) for p in transforms.apply_polygons(polygons)\n            ]\n        else:\n            # RLE\n            mask = mask_util.decode(annotation[\"segmentation\"])\n            mask = transforms.apply_segmentation(mask)\n            annotation[\"segmentation\"] = mask_util.encode(\n                np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\")[0]\n            )\n\n    # keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transforms.apply_coords(annotation[\"keypoints\"])\n        annotation[\"keypoints\"] = keypoints\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints.reshape(-1, 3)\n            keypoints[:, 0] = image_size[1] - keypoints[:, 0]\n            keypoints = keypoints"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # segmentation = polygon\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, list):\n        # polygons\n        polygons = [np.asarray(p).reshape(-1, 2) for p in segmentation]\n        # transform polygons\n        polygons = transforms.apply_polygons(polygons)\n        # use float32 coords\n        segmentation = [p.reshape(-1) for p in polygons]\n        annotation[\"segmentation\"] = segmentation\n    else:\n        # RLE\n        mask = mask_util.decode(segmentation)\n        mask = transforms.apply_segmentation(mask)\n        assert tuple(mask.shape[:2]) == image_size\n        annotation[\"segmentation\"] = mask_util.encode(\n            np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\")[np.newaxis]\n        )[0]\n\n    # keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transforms.apply_coords(annotation[\"keypoints\"])\n        if keypoint_hflip_indices is not None:\n            keypoints = keypoints[:, keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform polygon or uncompressed RLE masks\n    segmentation = annotation.get(\"segmentation\", None)\n    if segmentation is not None:\n        # Pytorch transforms are not supported by polygons\n        if isinstance(transforms, T.Transform):\n            transforms = [transforms]\n        assert all(\n            isinstance(t, T.HFlipTransform) for t in transforms\n        ), \"Masks only support HFlipTransform\"\n        assert len(segmentation) == 1\n        segmentation = transforms[0].apply_segmentation(segmentation[0])\n        annotation[\"segmentation\"] = [segmentation]\n\n    # Transform keypoints\n    keypoints = annotation.get(\"keypoints\", None)\n    if keypoints is not None:\n        for t in transforms:\n            if isinstance(t, T.HFlipTransform):\n                keypoints = t.apply_coords(keypoints)\n                if keypoint_hflip_indices is not None:\n                    keypoints = keypoints[keypoint_hflip_indices]\n        annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # Transform polygon/mask if exist\n    if \"segmentation\" in annotation:\n        # each segment is a list of float\n        if isinstance(annotation[\"segmentation\"], list):\n            # one RLE or polygons\n            if isinstance(annotation[\"segmentation\"][0], list):\n                # Merge all segments into a single list\n                annotation[\"segmentation\"] = [\n                    s\n                    for segments in annotation[\"segmentation\"]\n                    for s in segments\n                ]\n            annotation[\"segmentation\"] = transforms.apply_segmentation(\n                annotation[\"segmentation\"]\n            )\n        else:\n            annotation[\"segmentation\"] = transforms.apply_segmentation(\n                annotation[\"segmentation\"]\n            )\n\n    # Transform keypoints\n    if \"keypoints\" in annotation:\n        keypoints = transforms.apply_coords(annotation[\"keypoints\"])\n        annotation[\"keypoints\"] = keypoints\n        if keypoint_hflip_indices is not None:\n            keypoints = annotation[\"keypoints\"]\n            keypoints = keypoints[keypoint_hflip_indices]\n            annotation[\"keypoints\"] = keypoints\n\n    return annotation\n\n"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # segmentation = polygon\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, list):\n        # polygons\n        polygons = [np.asarray(p).reshape(-1, 2) for p in segmentation]\n        # useful when inference from a pkl that contains data outside an image size,\n        # in that case, pkl knows the original image size and we need to crop the box\n        # out of the pkl\n        valid = [\n            (x.min() < image_size[1] and y.min() < image_size[0]\n             and x.max() > 0 and y.max() > 0)\n            for x, y in polygons\n        ]\n        if not all(valid):\n            logger = logging.getLogger(__name__)\n            logger.warning(\n                \"Segmentation polygon extends outside of image. \"\n                \"Clipping will be applied.\"\n            )\n        segmentation = [\n            p.clip(min(image_size)) for p, v in zip(polygons, valid) if v\n        ]\n        annotation[\"segmentation\"] = segmentation\n        annotation[\"segmentation_masks\"] = PolygonMasks(segmentation)\n    else:\n        # RLE\n        rle = mask_util.decode(segmentation)\n        rle = transforms.apply_segmentation(rle)\n        rle = mask_util.encode(np.asarray(rle, order=\"F\", dtype=\"uint8\"))\n        annotation[\"segmentation"}
{"namespace": "detectron2.data.detection_utils.transform_instance_annotations", "completion": "    if isinstance(transforms, (list, tuple)):\n        transforms = T.TransformList(transforms)\n    # bbox is 1d (per-instance bounding box)\n    bbox = BoxMode.convert(annotation[\"bbox\"], annotation[\"bbox_mode\"], BoxMode.XYXY_ABS)\n    # clip transformed bbox to image size\n    bbox = transforms.apply_box([bbox])[0].clip(image_size)\n    annotation[\"bbox\"] = bbox\n    annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n\n    # segmentation = [poly]\n    segmentation = annotation[\"segmentation\"]\n    if isinstance(segmentation, list):\n        # PolygonMasks are used when the segmentation is a list[list[float]]:\n        # COCO, DensePose, ...\n        # It can be converted to BitMasks via PolygonMasks.\n        if len(segmentation) and isinstance(segmentation[0], list):\n            masks = PolygonMasks(segmentation, *image_size)\n            masks = transforms.apply_polygons(masks.polygons)\n            segmentation = masks.polygons\n\n    # segmentation = RLE\n    elif isinstance(segmentation, dict):\n        # BitMasks are used when the segmentation is a dict:\n        # CityscapesInstanceDataset, MapillaryInstanceDataset, ...\n        # They can be passed directly to transforms.apply_segmentation\n        segmentation = transforms.apply_segmentation(segmentation)\n\n    annotation[\"segmentation\"] = segmentation\n\n    # keypoints = (Nx3) in absolute coordinates\n    keypoints = annotation[\"keypoints\"].reshape(-1, 3)\n    keypoints[..., :2] = transforms.apply_coords(keypoints[..., :2])\n    keypoints[..., :2] = keypoints[..., :2].clip(0, image_size[::-1])\n    if keypoint"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0:\n            return coords\n        coords[:, 0] -= self.center[0]\n        coords[:, 1] -= self.center[1]\n        coords = np.dot(coords, self.rm_coords.T)\n        coords[:, 0] += self.center[0]\n        coords[:, 1] += self.center[1]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = coords.astype(np.float32)\n        coords = np.hstack(\n            (coords, np.ones((coords.shape[0], 1), dtype=np.float32))\n        )\n        coords = np.dot(coords, self.rm_coords.T)\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0:\n            return coords\n        assert coords.shape[1] == 2\n        coords = coords.astype(np.float32)\n        new_coords = np.zeros_like(coords)\n        new_coords[:, 0] = (\n            coords[:, 0] * self.rm_coords[0, 0] + coords[:, 1] * self.rm_coords[0, 1] + self.rm_coords[0, 2]\n        )\n        new_coords[:, 1] = (\n            coords[:, 0] * self.rm_coords[1, 0] + coords[:, 1] * self.rm_coords[1, 1] + self.rm_coords[1, 2]\n        )\n        return new_coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = coords[:, [1, 0]]  # hw -> wh\n        transformed_coords = np.dot(coords - self.center, self.rm_coords) + self.center\n        transformed_coords = transformed_coords[:, [1, 0]]  # wh -> hw\n        return transformed_coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0:\n            return coords\n        assert coords.shape[1] == 2\n        coords = coords.astype(np.float32)\n        coords = np.concatenate(\n            [coords, np.ones((coords.shape[0], 1), dtype=np.float32)], axis=1\n        )\n        coords = np.dot(coords, self.rm_coords.T)\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0:\n            return coords\n        coords[:, 0] -= self.center[0]\n        coords[:, 1] -= self.center[1]\n        coords = np.dot(coords, self.rm_coords.T)\n        coords[:, 0] += self.center[0]\n        coords[:, 1] += self.center[1]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords[:, 0] -= self.center[0]\n        coords[:, 1] -= self.center[1]\n        coords = np.dot(coords, self.rm_coords.T)\n        coords[:, 0] += self.center[0]\n        coords[:, 1] += self.center[1]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return cv2.transform(coords[:, np.newaxis, :], self.rm_coords)[:, 0, :]\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = coords - self.center\n        coords = np.dot(coords, self.rm_coords.T)\n        coords = coords + self.center\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = coords[:, :2].astype(np.float32)\n        return np.matmul(coords, self.rm_coords[:, :2].T) + self.rm_coords[:, 2].reshape(1, 2)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0:\n            return coords\n        assert coords.shape[1] == 2\n        coords = coords.astype(np.float32)\n        coords = np.matmul(coords, self.rm_coords.T)\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = coords[:, :2].copy()\n        # Note: for mathcal purposes, the image coordinate system is flipped in the y-axis.\n        # This is taken care of by the below where (x, y) -> (y, -x)\n        coords -= self.center\n        coords = np.asarray(np.matmul(coords, self.rm_coords.T), dtype=np.float32)\n        coords += self.center\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0:\n            return coords\n        # NOTE: each row of coords is (x, y)\n        coords = coords + 0.5\n        coords = np.dot(coords, self.rm_coords.T)\n        coords = coords - 0.5\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = coords[:, [1, 0]]  # swap (x, y) to (y, x)\n        coords = coords - self.center\n        coords = np.dot(coords, self.rm_coords.T)\n        coords = coords + self.center\n        coords = coords[:, [1, 0]]\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = coords[:, :2].copy()\n        # Note that for coordinates, x is the rows or Y-axis, y is the\n        # columns or X-axis.\n        coords = np.dot(coords - self.center, self.rm_coords[:, :2]) + self.center\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        return self.apply_coords_to_point(coords, self.rm_coords)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = coords.astype(np.float32)\n        coords = np.dot(coords, self.rm_coords[:, :2].T) + self.rm_coords[:, 2].T\n        return coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if len(coords) == 0 or self.angle % 360 == 0:\n            return coords\n        coords = coords[:, [1, 0]]  # hw to wh\n        # Transform image center from source coordinates into output coordinates\n        # and then map the new origin to the corner of the output image.\n        new_coords = np.dot(coords - self.center, self.rm_coords) + self.center\n        new_coords = new_coords[:, [1, 0]]  # wh to hw\n        return new_coords\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_coords", "completion": "        if self.angle % 360 == 0:\n            return coords\n        # Transform coordinates into the local coordinate system of the image\n        # where (0, 0) is the center of the image, and the x-axis points right,\n        # and the y-axis points down.\n        coords[:, 0] -= self.image_center[0]\n        coords[:, 1] -= self.image_center[1]\n        # Apply the rotation transformation to the coordinates\n        rotated_coords = coords.dot(self.rm_coords[:, :2])\n        # Transform the coordinates back to the global coordinate system\n        rotated_coords[:, 0] += self.image_center[0] + self.offset[0]\n        rotated_coords[:, 1] += self.image_center[1] + self.offset[1]\n        return rotated_coords\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Create a TracingAdapter to support non-tensor inputs\n    tracing_adapter = TracingAdapter(model, inputs, allow_non_tensor=True)\n\n    # Create a FlopCountAnalysis object\n    flop_counter = FlopCountAnalysis(tracing_adapter, tracing_adapter.flattened_inputs)\n\n    # Set the ignored operators\n    flop_counter.set_op_handle(**{k: None for k in _IGNORED_OPS})\n\n    # Compute the flops\n    flop_counter.total()\n\n    # Convert the flops to a dictionary\n    flops_dict = flop_counter.by_operator()\n\n    # Convert the flops to Gflops\n    for op_name in flops_dict:\n        flops_dict[op_name] /= 1e9\n\n    return flops_dict"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Compute flops for each operator in the model\n    flops = FlopCountAnalysis(model, inputs)\n    flops.unsupported_ops_warnings(False)\n    flops.uncalled_modules_warnings(False)\n    flops_dict = flops.by_operator()\n\n    # Convert the flops to gigaflops\n    flops_dict = {k: v / 1e9 for k, v in flops_dict.items()}\n\n    return flops_dict"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Compute flops for each operator in the model\n    flops = FlopCountAnalysis(model, inputs)\n    flops.unsupported_ops_warnings(False)\n    flops.uncalled_modules_warnings(False)\n    flops_dict = flops.by_operator()\n\n    # Convert flops to a dictionary with operator names as keys and Gflop counts as values\n    flops_dict = {k: v / 1e9 for k, v in flops_dict.items()}\n    return flops_dict"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Create a list of inputs for the model\n    inputs = [{\"image\": x[\"image\"]} for x in inputs]\n\n    # Initialize the FlopCountAnalysis object\n    flops = FlopCountAnalysis(model, inputs)\n\n    # Compute the flops for each operator\n    flops.unsupported_ops_warnings(False)\n    flops.uncalled_modules_warnings(False)\n    flops.by_operator()\n\n    # Convert the flops to Gflop and return the result\n    return flops.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    \"\"\"\n    wrapper = TracingAdapter(model, inputs, allow_non_tensor=True)\n    flops = FlopCountAnalysis(model, inputs)\n    flops.unsupported_ops_warnings(False)\n    flops.uncalled_modules_warnings(False)\n    flops.tracer_.ignore_ops(ignore_ops=_IGNORED_OPS)\n    flops.by_operator()\n    dict_flops = flops.by_operator()\n    return dict_flops\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    wrapped_model = TracingAdapter(model, inputs, allow_non_tensor=True)\n    flops = FlopCountAnalysis(wrapped_model, inputs)\n    flops.set_op_handle(**{k: None for k in _IGNORED_OPS})\n    flops.unsupported_ops_warnings(False)\n    flops.uncalled_modules_warnings(False)\n    flops_dict = flops.by_operator()\n    return flops_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Wrap the model with TracingAdapter\n    tracing_model = TracingAdapter(model, inputs, allow_non_tensor=True)\n\n    # Create a FlopCountAnalysis object\n    flops = fvcore.nn.FlopCountAnalysis(tracing_model, tracing_model.flattened_inputs)\n\n    # Set the handle for ignored operators\n    flops.set_op_handle(**{k: None for k in _IGNORED_OPS})\n\n    # Compute the flops\n    flops.total()\n\n    # Get the flops count for each operator\n    flops_count = flops.by_operator()\n\n    # Convert the flops count to Gflops\n    flops_count_giga = {op: flops / 1e9 for op, flops in flops_count.items()}\n\n    return flops_count_giga"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Create a TracingAdapter to handle non-tensor inputs\n    wrapper = TracingAdapter(model, inputs, allow_non_tensor=True)\n\n    # Create a FlopCountAnalysis object\n    flops = fvcore.nn.FlopCountAnalysis(wrapper, wrapper.flattened_inputs)\n\n    # Set the handle for ignored operators to None\n    flops.set_op_handle(**{k: None for k in _IGNORED_OPS})\n\n    # Return the computed flops as a dictionary\n    return flops.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Create a TracingAdapter to support non-tensor inputs\n    tracing_adapter = TracingAdapter(model, inputs, allow_non_tensor=True)\n\n    # Set the operator handle for ignored operators\n    tracing_adapter.set_op_handle(**{k: None for k in _IGNORED_OPS})\n\n    # Compute flops using the tracing adapter\n    flops = flop_count(tracing_adapter, tracing_adapter.flattened_inputs)\n\n    # Convert the flops to a dictionary\n    flops_dict = flops.by_operator()\n\n    # Return the flops dictionary\n    return flops_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Create a TracingAdapter to support detectron2 models\n    wrapper = TracingAdapter(model, inputs, allow_non_tensor=True)\n\n    # Initialize the FlopCountAnalysis with the wrapper and flattened inputs\n    flops = FlopCountAnalysis(wrapper, wrapper.flattened_inputs)\n\n    # Set the ignored operations\n    flops.set_op_handle(**{k: None for k in _IGNORED_OPS})\n\n    # Return the operator flops as a dictionary\n    return flops.by_operator()"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Compute flops for each operator in the model\n    flops = FlopCountAnalysis(model, inputs)\n    flops.unsupported_ops_warnings(False)\n    flops.uncalled_modules_warnings(False)\n    flops_dict = flops.by_operator()\n\n    # Convert flops from scounts to Gflops\n    flops_dict = {k: v / 1e9 for k, v in flops_dict.items()}\n\n    return flops_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Create a TracingAdapter to handle the given inputs\n    tracing_adapter = TracingAdapter(model, inputs, allow_non_tensor=True)\n\n    # Create a FlopCountAnalysis object using the TracingAdapter\n    flop_counter = fvcore.nn.FlopCountAnalysis(tracing_adapter, tracing_adapter.flattened_inputs)\n\n    # Set the ignored operators\n    flop_counter.set_op_handle(**{k: None for k in _IGNORED_OPS})\n\n    # Return the operator counts\n    return flop_counter.by_operator()\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Wrap the model with a TracingAdapter\n    tracing_model = TracingAdapter(model, inputs)\n\n    # Create a FlopCountAnalysis object\n    flop_analyzer = FlopCountAnalysis(tracing_model, tracing_model.flattened_inputs)\n\n    # Set the ignored ops\n    flop_analyzer.set_op_handle(**{k: None for k in _IGNORED_OPS})\n\n    # Run the model with the given inputs\n    tracing_model(*tracing_model.flattened_inputs)\n\n    # Compute the flops count\n    flops_count = flop_analyzer.by_operator()\n\n    # Convert the flops count to GFLOPs\n    gflops_count = {k: v / 1e9 for k, v in flops_count.items()}\n\n    return gflops_count"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    \"\"\"\n    Computes the floating-point operations (flops) count for each operator in a given model using just-in-time (jit) compilation.\n\n    Input-Output Arguments\n    :param model: nn.Module. A detectron2 model that is expected to take a list of dictionaries as input. The model is used to compute the flops by running it with the provided inputs.\n    :param inputs: list of dictionaries. These are the inputs to the model, adhering to detectron2's standard input format. Only the \"image\" key within these dictionaries is utilized for the flops computation.\n    :return: DefaultDict[str, float]. A dictionary where keys are operator names and values are the corresponding Gflop counts. This provides an overview of the computational cost associated with each operator in the model.\n    \"\"\"\n    # Convert inputs to a list of dictionaries\n    inputs = [{\"image\": input} for input in inputs]\n\n    # Create a FlopCountAnalysis object\n    flops_analysis = FlopCountAnalysis(model, inputs)\n\n    # Run the model with the provided inputs\n    flops_analysis.run()\n\n    # Compute the flops for each operator\n    flops_per_operator = flops_analysis.by_operator()\n\n    # Convert the flops to Gflops\n    flops_per_operator_gflops = {op: flops / 1e9 for op, flops in flops_per_operator.items()}\n\n    return flops_per_operator_gflops"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Create a list of inputs for jit tracing\n    inputs = [{\"image\": x[\"image\"]} for x in inputs]\n\n    # Wrap the model with the TracingAdapter\n    tracing_model = TracingAdapter(model, inputs, allow_non_tensor=True)\n\n    # Create a FlopCountAnalysis object\n    flop_analyzer = FlopCountAnalysis(tracing_model, inputs)\n\n    # Set the handle for ignored operations\n    flop_analyzer.set_op_handle(**{k: None for k in _IGNORED_OPS})\n\n    # Run the model with the inputs\n    tracing_model(*inputs)\n\n    # Get the flops count for each operator\n    flops_dict = flop_analyzer.by_operator()\n\n    # Convert the flops count to Gflop\n    gflops_dict = {op: flops / 1e9 for op, flops in flops_dict.items()}\n\n    return gflops_dict"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Create a TracingAdapter to handle inputs that are not tensors\n    tracing_adapter = TracingAdapter(model, inputs, allow_non_tensor=True)\n\n    # Run the model with the inputs to trigger tracing\n    tracing_adapter(*tracing_adapter.flattened_inputs)\n\n    # Create a FlopCountAnalysis object\n    flop_analysis = FlopCountAnalysis(tracing_adapter, tracing_adapter.flattened_inputs)\n\n    # Set the ignored ops\n    flop_analysis.set_op_handle(**{k: None for k in _IGNORED_OPS})\n\n    # Compute the flops\n    flop_analysis.unsupported_ops_warnings(False).uncalled_modules_warnings(False).uncalled_functions_warnings(False)\n    flop_dict = flop_analysis.by_operator()\n\n    # Convert the flops to GFLOPs and round to two decimal places\n    for op, flops in flop_dict.items():\n        flop_dict[op] = round(flops / 1e9, 2)\n\n    return flop_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Note: we run this within a no_grad context,\n    # as we don't need gradients for flops computation.\n    with torch.no_grad():\n        # Add a hook to the model to extract flops information\n        flops_model = FlopCountAnalysis(model, inputs)\n        flops_model.start_flop_count()\n        model(*inputs)\n        flops_model.stop_flop_count()\n\n    # The returned flops_count is a dictionary where keys are operator names and values are the corresponding flops counts\n    # Sum up the total flops count\n    total_flops = sum(flops_model.by_operator().values())\n\n    # Convert the flops count to a dictionary where keys are operator names and values are the corresponding Gflop counts\n    flops_dict = {op: flops / 1e9 for op, flops in flops_model.by_operator().items()}\n\n    return flops_dict\n\n"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Initialize a dictionary to store the total Gflops for each operator\n    operator_flops = {}\n\n    # Iterate over the inputs\n    for i, input_dict in enumerate(inputs):\n        # Get the image tensor from the input dictionary\n        image = input_dict[\"image\"]\n\n        # Create a new dictionary with a single \"image\" key and the current image tensor\n        new_input_dict = {\"image\": image}\n\n        # Create a FlopCountAnalysis object for the model and the current input\n        flops_model = FlopCountAnalysis(model, new_input_dict)\n\n        # Get the operator-wise flops for the current input\n        flops_dict = flops_model.by_operator()\n\n        # Update the total Gflops for each operator\n        for op, flops in flops_dict.items():\n            if op not in operator_flops:\n                operator_flops[op] = flops\n            else:\n                operator_flops[op] += flops\n\n    # Convert the total Gflops to Gflops\n    total_gflops = {op: flops / 1e9 for op, flops in operator_flops.items()}\n\n    # Return the total Gflops for each operator\n    return total_gflops"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Support both list[dict] and dict[str, Tensor] as input\n    if isinstance(inputs, dict):\n        inputs = [{\"image\": inputs[\"image\"]}]\n\n    # Run the model with the provided inputs to compute the flops\n    # This is done by creating a TracingAdapter and passing it to the FlopCountAnalysis class\n    # The adapter allows the model to be run with the provided inputs\n    # The analysis computes the flops by tracing the execution of the model\n    # The output is a dictionary where keys are operator names and values are the corresponding Gflop counts\n    flops = FlopCountAnalysis(model, inputs)\n    flops.unsupported_ops_warnings(False)\n    flops.uncalled_modules_warnings(False)\n    flops_dict = flops.by_operator()\n\n    # Convert the flops dictionary to a defaultdict for easier manipulation\n    flops_dict = typing.cast(typing.DefaultDict[str, float], flops_dict)\n\n    # Return the flops dictionary\n    return flops_dict"}
{"namespace": "detectron2.utils.analysis.flop_count_operators", "completion": "    # Wrap the model with TracingAdapter\n    tracing_inputs = [{\"image\": x[\"image\"]} for x in inputs]\n    tracing_model = TracingAdapter(model, tracing_inputs)\n\n    # Create a FlopCountAnalysis object and run the model with the tracing inputs\n    flops_analysis = FlopCountAnalysis(tracing_model, tracing_inputs)\n    flops_analysis.unsupported_ops_warnings(False)\n    flops_analysis.uncalled_modules_warnings(False)\n    flops_analysis.unsupported_ops_warnings(False)\n    flops_analysis.start_naming_reuse_after_this_module(tracing_model.model.backbone)\n    flops_analysis.unsupported_ops_warnings(True)\n    flops_analysis.uncalled_modules_warnings(True)\n    flops_analysis.unsupported_ops_warnings(True)\n    flops_analysis.by_operator()\n\n    # Compute the total number of FLOPs\n    total_flops = sum(flops_analysis.by_operator().values())\n\n    # Convert the FLOPs to a more readable format (GigaFLOPs)\n    total_flops_giga = total_flops / 1e9\n\n    # Create a dictionary with the operator names and their corresponding FLOPs\n    flops_dict = {k: v / total_flops_giga for k, v in flops_analysis.by_operator().items()}\n\n    return flops_dict"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.h * self.w * self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        assert img.shape[:2] == (self.h, self.w)\n        interp = interp if interp is not None else self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.h == 0 or self.w == 0:\n            return img\n        img = cv2.warpAffine(\n            img,\n            self.rm_image,\n            (self.bound_w, self.bound_h),\n            flags=cv2.INTER_LINEAR,\n            borderMode=cv2.BORDER_CONSTANT,\n        )\n        if self.expand:\n            img = cv2.resize(img, (self.w, self.h), interpolation=cv2.INTER_NEAREST)\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.h == 0 or self.w == 0:\n            return img\n        img = cv2.warpAffine(\n            img,\n            self.rm_image,\n            (self.bound_w, self.bound_h),\n            flags=cv2.INTER_LINEAR,\n            borderValue=0,\n        )\n        if self.expand:\n            img = img[\n                int(self.bound_h / 2 - self.h / 2) : int(self.bound_h / 2 + self.h / 2),\n                int(self.bound_w / 2 - self.w / 2) : int(self.bound_w / 2 + self.w / 2),\n            ]\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.h == 0 or self.w == 0:\n            return img\n        img = cv2.warpAffine(\n            img,\n            self.rm_image,\n            (self.bound_w, self.bound_h),\n            flags=cv2.INTER_LINEAR,\n            borderValue=self.fill,\n        )\n        if self.expand:\n            img = img[\n                int(self.ymin) : int(self.ymax), int(self.xmin) : int(self.xmax)\n            ]\n        return img\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.angle % 360 == 0:\n            return img\n        if interp is None:\n            interp = self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.h * self.w * len(img.shape) == 0:\n            return img\n        return cv2.warpAffine(\n            img,\n            self.rm_image,\n            (self.bound_w, self.bound_h),\n            flags=cv2.INTER_LINEAR,\n            borderMode=cv2.BORDER_CONSTANT,\n        )\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.h < 1 or self.w < 1:\n            return img\n        interp_method = interp if interp is not None else self.interp\n        if img.shape[:2] == (self.h, self.w):\n            return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp_method)\n        assert img.shape[:2] == (self.bound_h, self.bound_w)\n        return cv2.warpAffine(img, self.rm_image, (self.w, self.h), flags=interp_method)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.h * self.w * len(img.shape) == 0:\n            return img\n        return cv2.warpAffine(\n            img,\n            self.rm_image,\n            (self.bound_w, self.bound_h),\n            flags=cv2.INTER_LINEAR,\n            borderMode=cv2.BORDER_CONSTANT,\n        )\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.h < 1 or self.w < 1:\n            return img\n        interp = interp if interp is not None else self.interp\n        if interp != cv2.INTER_NEAREST:\n            img = cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n        else:\n            import math\n\n            # opencv says: when the interpolation method is INTER_NEAREST,\n            # the pixel contributing to the transform output pixel is\n            # rounded to its nearest integer value.\n            rm = np.eye(3, dtype=np.float32)\n            rm[:2] = self.rm_image\n            rm[0, 2] += self.bound_w / 2 - self.image_center[0]\n            rm[1, 2] += self.bound_h / 2 - self.image_center[1]\n            # warpAffine does not support negative coordinates in OpenCV<=3.1.1\n            # and will assert when used.\n            # see https://github.com/opencv/opencv/pull/9403\n            offset = -np.matmul(rm[:2, :2], self.image_center) + self.image_center\n            rm[:2, 2] += offset\n            warp_dst = np.matmul(rm[:2, :2], np.array([[0, 0], [self.w, 0], [self.w, self.h], [0, self.h]]).T).T\n            warp_dst = np.clip(warp_dst, 0, np.array([self.w, self.h]) - 1)\n            warp_dst = warp_dst.astype(np.float32)\n            M = cv2.getPerspectiveTransform(\n                np.array([[0, 0], [self.w, 0], [self.w, self.h], [0, self.h]]).ast"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.h * self.w * self.angle % 360 == 0:\n            return img\n        assert img.shape[:2] == (self.h, self.w)\n        interp = interp if interp is not None else self.interp\n        return cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n"}
{"namespace": "detectron2.data.transforms.transform.RotationTransform.apply_image", "completion": "        if self.h < 1 or self.w < 1:\n            return img\n        interp = interp if interp is not None else self.interp\n        if interp != cv2.INTER_NEAREST:\n            img = cv2.warpAffine(img, self.rm_image, (self.bound_w, self.bound_h), flags=interp)\n        else:\n            import math\n\n            # opencv says:\n            # When the interpolation method is INTER_NEAREST, the pixel of\n            # destination image \u2018u\u2019 is calculated from the pixel of source image at\n            # position \u2018(u, v)\u2019:\n            # .   If \u2018u\u2019 and \u2018v\u2019 are floating-point numbers, they are rounded\n            #     to the nearest integer coordinates and used as the coordinates\n            #     of source pixels. In this case, the coordinates of the pixel\n            #     (u, v) don\u2019t contribute to the calculation of the new pixel\n            #     intensity.\n            # .   If \u2018u\u2019 and \u2018v\u2019 are integer coordinates, the pixel at (u, v)\n            #     contributes to the calculation of the new pixel intensity.\n            #     The coordinates are not rounded in this case.\n            rm = self.rm_coords.astype(np.float32)\n            # add alpha channel to mask when working with cv2\n            ch = img.shape[-1] if len(img.shape) > 2 else 1\n            cv_mask = np.zeros(\n                (self.bound_h, self.bound_w, ch), dtype=img.dtype)\n            new_h, new_w = img.shape[:2]\n            yy, xx = np.meshgrid(np.arange(self.bound_h), np.arange(self.bound_w))\n            xx, yy = xx.astype(np.float32), yy.astype(np.float32)\n            # rotate center pixel to src coord\n            yy_rm, xx_rm = yy - 0.5, xx"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor.numpy() if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.numpy() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints[0].numpy() if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:  # grayscale image\n            self.output.reset_image(\n                self._create_grayscale_image(\n                    (predictions.pred_masks.numpy().sum(0) > 0).numpy().astype(\"uint8\") * 255\n                    if predictions.has(\"pred_masks\")\n                    else np.zeros((self.output.height, self.output.width), dtype=np.uint8)\n                )\n            )\n            alpha = 0.3\n        else:\n            self.output.reset_image(self.img)\n            alpha = 0.5\n\n        if predictions.has(\"pred_masks\"):\n            self.overlay_instances(\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n                keypoints=keypoints,\n                assigned_colors=None,\n                alpha=alpha,\n            )\n        else:\n            self.overlay_boxes(boxes=boxes, labels=labels, assigned_colors=None)\n        if predictions.has(\"pred_keypoints\"):\n            self.draw_keypoints"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.tolist() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\") is None:\n            # The default colors in fastai are for things.\n            # This will give poor visualizations unless a thing_colors class is provided.\n            self.metadata.set(thing_colors=[random_color(rgb=True) for _ in self.metadata.thing_classes])\n\n        if self._instance_mode == ColorMode.IMAGE_BW and self.metadata.get(\"thing_colors\") is None:\n            # The default colors in fastai are for things.\n            # This will give poor visualizations unless a thing_colors class is provided.\n            self.metadata.set(thing_colors=[_BLACK, _WHITE])\n\n        if self._instance_mode == ColorMode.IMAGE and self.metadata.get(\"thing_colors\") is None:\n            # The default colors in fastai are for things.\n            # This will give poor visualizations unless a thing_colors class is provided.\n            self.metadata.set(thing_colors=[_OFF_WHITE])\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=ke"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.tolist() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, predictions.image_size[0], predictions.image_size[1]) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:  # grayscale image\n            self.output.reset_image(self._create_grayscale_image(self.img.shape))\n            alpha = 0.3\n        else:\n            self.output.reset_image(self.img)\n            alpha = 0.5\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=None,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor.numpy() if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.numpy() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints[0].numpy() if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:  # change color of text to black\n            self.output.ax.xaxis.label.set_color(\"black\")\n            self.output.ax.tick_params(axis=\"x\", colors=\"black\")\n            self.output.ax.yaxis.label.set_color(\"black\")\n            self.output.ax.tick_params(axis=\"y\", colors=\"black\")\n\n        if self.metadata.get(\"thing_colors\"):\n            colors = [\n                self.metadata.thing_colors[c] for c in classes\n            ]  # if None, will use cmap\n            alpha = 0.3\n        else:\n            colors = None\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW and not self.metadata.get(\"thing_colors\"):\n            alpha = 0.3\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.tolist() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:  # change color of text to white\n            self.output.ax.text(\n                x=10,\n                y=20,\n                s=\"Score threshold {} for visualization\".format(self.keypoint_threshold),\n                color=\"white\",\n                horizontalalignment=\"left\",\n                verticalalignment=\"top\",\n                fontsize=15,\n                bbox={\"facecolor\": \"black\", \"alpha\": 0.8, \"pad\": 10},\n            )\n        else:\n            self.output.ax.text(\n                x=10,\n                y=20,\n                s=\"Score threshold {} for visualization\".format(self.keypoint_threshold),\n                color=\"black\",\n                horizontalalignment=\"left\",\n                verticalalignment=\"top\",\n                fontsize=15,\n                bbox={\"facecolor\": \"white\", \"alpha\": 0.8, \"pad\": 10},\n            )\n\n        if predictions.has(\"pred_masks\"):\n            areas = np.asarray([x.area() for x in predictions.pred_masks])\n            sorted_idxs = np.argsort(-areas).tolist()"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.tolist() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\") is None:\n            self.metadata.set(thing_colors=[random_color(rgb=True, maximum=1) for _ in self.metadata.thing_classes])\n\n        if self._instance_mode == ColorMode.IMAGE_BW and self.img.shape[0] > 1:\n            self.img = np.mean(self.img, axis=2, keepdims=True)\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=self.metadata.thing_colors,\n            alpha=0.5,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor.numpy() if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.numpy() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints[0].numpy() if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE_BW and predictions.has(\"pred_masks\"):\n            self.output.reset_image(self._create_grayscale_image(self.img))\n            alpha = 0.3\n            for i, (mask, sinfo) in enumerate(zip(masks, predictions.pred_masks_info)):\n                color = self._jitter([0, 0, 0]) if sinfo.get(\"isthing\", True) else self._jitter([255, 255, 255])\n                self.output.ax.imshow(mask.mask, alpha=alpha, interpolation=\"nearest\", extent=(0, self.output.width, 0, self.output.height), cmap=mpl.colors.ListedColormap([color]))\n            self.overlay_instances(boxes=boxes, labels=labels, keypoints=keypoints)\n            return self.output\n\n        if self._instance_mode == ColorMode.IMAGE:\n            self.overlay_instances(\n                masks=masks, boxes=boxes, labels=labels, keypoints=keypoints, assigned_colors"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor.numpy() if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.numpy() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints[0].numpy() if predictions.has(\"pred_keypoints\") else None\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if predictions.has(\"pred_masks_rle\"):\n            masks = predictions.pred_masks_rle\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\") is None:\n            # TODO: add a better way to get the colors\n            self.metadata.thing_colors = [\n                random_color(rgb=True, maximum=1) for _ in range(len(self.metadata.thing_classes))\n            ]\n        if self._instance_mode == ColorMode.IMAGE_BW and self.metadata.get(\"thing_colors\") is None:\n            self.metadata.thing_colors = [(0, 0, 0)] * len(self.metadata.thing_classes)\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=self.metadata.thing_colors,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor.to(self.cpu_device)\n        boxes = BoxMode.convert(boxes, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n        num_instances = len(predictions)\n        if num_instances == 0:\n            return self.output\n\n        if self._instance_mode == ColorMode.SEGMENTATION and (\n            predictions.has(\"pred_masks\") or predictions.has(\"pred_masks_rle\")\n        ):\n            # Use RGBA masks for all segments\n            alpha = 0.3\n            colors = [\n                mplc.to_rgba(x) for x in self._jitter([random_color(rgb=True) for _ in range(num_instances)])\n            ]\n            colors = [(c[0], c[1], c[2], alpha) for c in colors]\n            if predictions.has(\"pred_masks\"):\n                rles = predictions.pred_masks\n                masks = [GenericMask(x, self.output.height, self.output.width) for x in rles]\n            else:\n                assert predictions.has(\"pred_masks_rle\")\n                rles = predictions.pred_masks_rle\n                masks = [\n                    GenericMask(x, self.output.height, self.output.width)\n                    for x in mask_util.decode(rles)\n                ]\n            area = np.asarray([x.area() for x in masks])\n            sorted_idxs = np.argsort(-area)\n            # Re-order overlapped instances in descending order.\n            boxes = boxes[sorted_idxs]\n            classes = predictions.pred_classes[sorted_idxs]\n            scores = predictions.scores[sorted_idxs] if predictions.has(\"scores\") else None\n            labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n            colors = [colors[idx] for idx in sorted_idxs]\n            masks = [mas"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.tolist() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\") is None:\n            self.metadata.set(thing_colors=[random_color(rgb=True, maximum=1) for _ in self.metadata.thing_classes])\n        if self._instance_mode == ColorMode.IMAGE_BW and self.metadata.get(\"thing_colors\") is None:\n            self.metadata.set(thing_colors=[_OFF_WHITE] * len(self.metadata.thing_classes))\n\n        if self.metadata.get(\"thing_colors\") is not None and len(self.metadata.thing_colors) < len(self.metadata.thing_classes):\n            self.metadata.thing_colors += [random_color(rgb=True, maximum=1) for _ in range(len(self.metadata.thing_classes))]\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.reset_image(self.img)\n            self.overlay_instances(\n                masks=masks,\n                boxes=boxes,\n                labels=labels,\n                keypoints=keypoints,\n                assigned_colors=self.metadata.thing_colors,"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.tolist() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            self.output.reset_image(\n                self._create_grayscale_image(\n                    (masks is not None) or (keypoints is not None),\n                    self._create_grayscale_image(masks is None, self.img, bg_color=(105, 105, 105)),\n                )\n            )\n            alpha = 0.3\n        else:\n            self.output.reset_image(self.img)\n            alpha = 0.5\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=None,\n            alpha=alpha,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.tolist() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\") is None:\n            # if we don't have colors, use matplotlib color map\n            self.metadata.thing_colors = [\n                mplc.hsv_to_rgb([x / self.metadata.thing_dataset_id_to_contiguous_id[i] for i in range(len(self.metadata.thing_dataset_id_to_contiguous_id))])\n                for x in range(len(self.metadata.thing_dataset_id_to_contiguous_id))\n            ]\n\n        if self._instance_mode == ColorMode.IMAGE_BW and self.img.shape[0] > 4:\n            # uint8: 255, empty: 1\n            self.img = np.ones(self.img.shape, dtype=\"uint8\") * 255\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=self.metadata.thing_colors,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.tolist() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:  # change color of text to white\n            self.output.ax.text(\n                x=0,\n                y=0,\n                s=\"Predictions\",\n                color=\"white\",\n                verticalalignment=\"top\",\n                horizontalalignment=\"left\",\n                fontsize=\"x-large\",\n                bbox={\"facecolor\": \"black\", \"alpha\": 1.0, \"pad\": 10},\n            )\n            # draw each mask by its own color\n            for mask, _class in zip(masks, classes):\n                color_mask = self._random_color(rgb=False, maximum=1)\n                mask.draw_polygon(self.output.ax, alpha=0.3, color=color_mask)\n        else:\n            # draw masks, i.e. boundaries and fillings, if existing\n            # some detectors use different scores for bbox and mask\n            if predictions.has(\"pred_masks\"):\n                for mask, _class in zip(masks, classes):\n                    color_mask = self._random_color(rgb=False, maximum=1)\n                    mask.draw_polygon(self.output.ax, alpha=0.3, color=color_mask)"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor.cpu().numpy()\n        boxes = BoxMode.convert(boxes, predictions.pred_boxes.mode, BoxMode.XYXY_ABS)\n        scores = predictions.scores.tolist()\n        classes = predictions.pred_classes.tolist()\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints\n        if keypoints is not None:\n            keypoints = keypoints.cpu().numpy()\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\") is None:\n            # Draw the masks on the CPU to avoid GPU OOM.\n            # Other coordinate ops will be faster.\n            masks = [x.to(self.cpu_device) for x in masks]\n            boxes = boxes.astype(\"int\")\n            # use round(scale * 1.25) + 1 to enlarge the mask by 1 pixel\n            # in case that there is no mask pixel covering it\n            boxes = BoxMode.convert(boxes, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n            if predictions.has(\"pred_masks\"):\n                rles = [\n                    mask_util.encode(np.array(x.mask[:, :, None], order=\"F\", dtype=\"uint8\"))[0]\n                    for x in masks\n                ]\n                for rle in rles:\n                    rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n            else:\n                rles = [x.rle for x in masks]\n            self.overlay"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor.to(self.cpu_device)\n        boxes = BoxMode.convert(boxes, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n        num_instances = len(predictions)\n\n        if num_instances == 0:\n            return self.output\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]])\n                for c in predictions.pred_classes\n            ]\n            alpha = 0.8\n        else:\n            # default to random color\n            colors = self._random_colors(num_instances)\n            alpha = 0.5\n\n        self.overlay_instances(\n            masks=predictions.pred_masks,\n            boxes=boxes,\n            labels=predictions.pred_classes,\n            keypoints=predictions.pred_keypoints,\n            assigned_colors=colors,\n            alpha=alpha,\n        )\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor.to(self.cpu_device)\n        boxes = BoxMode.convert(boxes, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n        num_instances = len(predictions)\n\n        if num_instances == 0:\n            return self.output\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]])\n                for c in predictions.pred_classes\n            ]\n            alpha = 0.8\n        else:\n            # Take the color from the first instance\n            colors = [\n                [\n                    c / 255\n                    for c in self.metadata.thing_colors[predictions.pred_classes[0]]\n                ]\n            ] * num_instances\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            # any() returns uint8 tensor\n            has_mask = (predictions.pred_masks.any(dim=1) > 0).cpu().numpy()\n            np_fg_color = np.array([220, 220, 220], dtype=np.uint8)\n            colors = [\n                np_fg_color if has_mask[i] else colors[i]\n                for i in range(len(colors))\n            ]\n            alpha = 0.5\n\n        if self._instance_mode == ColorMode.IMAGE:\n            # Create a simple linear colormap for the masks\n            colors = (\n                np.asarray([random_color(rgb=True) for c in predictions.pred_classes])\n                * alpha\n            )\n            colors = np.concatenate(\n                [np.zeros((1, 3)), colors], axis=0\n            )  # Transparent background\n\n        assert len(boxes) == len(\n            colors\n        ), \"{} != {}\"."}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor.to(self.cpu_device)\n        boxes = BoxMode.convert(boxes, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n        num_instances = len(predictions)\n\n        if num_instances == 0:\n            return self.output\n\n        if self._instance_mode == ColorMode.SEGMENTATION and (\n            predictions.has(\"pred_masks\") or predictions.has(\"pred_masks_rle\")\n        ):\n            # Use the colors in metadata\n            colors = self.metadata.get(\"thing_colors\", None)\n            if colors is None:\n                # default to random color\n                colors = [\n                    random_color(rgb=True, maximum=1) for _ in range(num_instances)\n                ]\n            else:\n                colors = [mplc.to_rgb(x) for x in colors]\n            alpha = 0.5\n            # Draw segmentation masks\n            if predictions.has(\"pred_masks\"):\n                rles = predictions.pred_masks\n            elif predictions.has(\"pred_masks_rle\"):\n                rles = predictions.pred_masks_rle\n            for rle, color in zip(rles, colors):\n                self.draw_polygon(\n                    rle.numpy(),\n                    color,\n                    alpha=alpha,\n                    edge_color=color if self._instance_mode == ColorMode.IMAGE_BW else \"none\",\n                )\n            del rles\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            # Grayscale image\n            self.output.reset_image(self._create_grayscale_image(self.img))\n            alpha = 0.3\n\n        if predictions.has(\"pred_boxes\"):\n            boxes = predictions.pred_boxes.tensor\n            boxes = boxes.to(self.cpu_device)\n            boxes = BoxMode.convert(boxes, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n            labels ="}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor.to(self.cpu_device)\n        boxes = BoxMode.convert(boxes, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n        num_instances = len(predictions)\n        if num_instances == 0:\n            return self.output\n\n        if self._instance_mode == ColorMode.SEGMENTATION:\n            assert (\n                \"pred_masks\" in predictions\n            ), \"Predictions must contain segmentation masks when using SEGMENTATION\"\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            assert (\n                \"pred_masks\" in predictions\n            ), \"Predictions must contain segmentation masks when using IMAGE_BW\"\n\n        boxes = boxes.tensor.numpy()\n        classes = predictions.pred_classes.numpy()\n        scores = predictions.scores.numpy()\n        category_colors = self.metadata.get(\"thing_colors\", None)\n\n        # We do not support polygons as masks.\n        masks = predictions.pred_masks.to(self.cpu_device)\n        masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        keypoints = predictions.pred_keypoints.numpy() if predictions.has(\"pred_keypoints\") else None\n\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints.numpy() if predictions.has(\"pred_keypoints\") else None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            # convert grayscale image to RGB\n            self.output.reset_image(\n                self.img[:, :, (2, 1, 0)]\n            )  # RGB -> BGR for vis\n            self.output = self.overlay_instances(\n                masks=masks,\n                labels=labels,\n               "}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor.cpu().numpy()\n        boxes = BoxMode.convert(boxes, predictions.pred_boxes.mode, BoxMode.XYXY_ABS)\n        classes = predictions.pred_classes.cpu().numpy()\n        scores = predictions.scores.cpu().numpy()\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints.cpu() if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, predictions.image_size[0], predictions.image_size[1]) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.IMAGE_BW:  # change color of mask\n            if masks is not None:\n                masks = [x.convert(\"BW\") for x in masks]\n            if keypoints is not None:\n                keypoints = keypoints * _OFF_WHITE\n\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n            assigned_colors=None,\n        )\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_instance_predictions", "completion": "        boxes = predictions.pred_boxes.tensor.numpy() if predictions.has(\"pred_boxes\") else None\n        scores = predictions.scores if predictions.has(\"scores\") else None\n        classes = predictions.pred_classes.numpy() if predictions.has(\"pred_classes\") else None\n        labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n        keypoints = predictions.pred_keypoints[0].numpy() if predictions.has(\"pred_keypoints\") else None\n\n        if predictions.has(\"pred_masks\"):\n            masks = np.asarray(predictions.pred_masks)\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n        else:\n            masks = None\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\") is None:\n            # Draw the masks on the CPU to avoid GPU OOM\n            # This is a workaround since the masks are not drawn in the correct order\n            # due to the implementation of the `draw_text` function\n            # See https://github.com/facebookresearch/detectron2/issues/565#issuecomment-567266137\n            masks = [x.cpu() for x in predictions.pred_masks]\n            masks = [GenericMask(x, self.output.height, self.output.width) for x in masks]\n\n        if self._instance_mode == ColorMode.IMAGE_BW and self.img.shape[0] > 4:\n            # large images are slow to render, so we require the original image\n            # to be RGBA for visualization.\n            self.img = self.img[:, :, :3]\n        self.overlay_instances(\n            masks=masks,\n            boxes=boxes,\n            labels=labels,\n            keypoints=keypoints,\n        )\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        buffer = np.frombuffer(s, np.uint8)\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        img = rgb.astype(\"uint8\")\n        return img"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        buffer = np.frombuffer(s, np.uint8)\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Get the RGBA image from the canvas\n        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n\n        # Convert the RGBA image to RGB format\n        buf = np.frombuffer(s, np.uint8)\n        img_rgba = buf.reshape(height, width, 4)\n        img_rgb = img_rgba[:, :, :3].astype(\"uint8\")\n\n        # Return the RGB image\n        return img_rgb"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # get_image() has 1 return value(s)\n        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Get the RGBA image from the canvas\n        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        # Convert to a NumPy array\n        buffer = np.frombuffer(s, np.uint8)\n        # Reshape to (w, h, ARGB)\n        buffer = buffer.reshape((height, width, 4))\n        # Convert to RGB\n        buffer = buffer[:, :, :3]\n        return buffer"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Get the image from the canvas and convert it to RGBA format\n        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        img = rgb.astype(\"uint8\")\n        return img"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # get_image() is renamed to uint8_image() in later versions of detectron2\n        return self.get_image()"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Get the RGBA image from canvas\n        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n\n        # Convert the RGBA image to RGB format\n        buf = np.frombuffer(s, np.uint8)\n        img_rgba = buf.reshape(height, width, 4)\n        rgb_channels = [img_rgba[:, :, 0], img_rgba[:, :, 1], img_rgba[:, :, 2]]\n        img = np.stack(rgb_channels, axis=2)\n        return img"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        self.canvas.draw()\n        s, (width, height) = self.canvas.print_to_buffer()\n        logger.info(\n            \"Image size: %dx%d\" % (width, height)\n        )  # pylint: disable=logging-not-lazy\n        logger.info(\"Matplotlib backend: %s\" % mpl.get_backend())\n        logger.info(\"Matplotlib config file: %s\" % mpl.matplotlib_fname())\n\n        buf = np.frombuffer(s, np.uint8)\n        img_rgba = buf.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Get the RGBA image from the canvas\n        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n\n        # Convert the RGBA image to RGB format\n        buf = np.frombuffer(s, np.uint8)\n        img_rgba = buf.reshape(height, width, 4)\n        img_rgb = img_rgba[:, :, :3].astype(\"uint8\")\n\n        return img_rgb\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n        buffer = np.frombuffer(s, dtype=\"uint8\")\n        img_rgba = buffer.reshape(height, width, 4)\n        rgb, alpha = np.split(img_rgba, [3], axis=2)\n        return rgb.astype(\"uint8\")\n"}
{"namespace": "detectron2.utils.visualizer.VisImage.get_image", "completion": "        # Get the RGBA image from the canvas\n        canvas = self.canvas\n        s, (width, height) = canvas.print_to_buffer()\n\n        # Convert the RGBA image to an RGB image\n        buf = np.fromstring(s, np.uint8)\n        img_rgba = buf.reshape(height, width, 4)\n        img_rgb = img_rgba[:, :, :3]\n\n        return img_rgb\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypoints = [x[\"keypoints\"] for x in annos]\n            else:\n                keypoints = None\n            category_ids = [x[\"category_id\"] for x in annos]\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = _create_text_labels(category_ids, None, names)\n            colors = None\n            alpha = 0.7\n            if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n                colors = [\n                    self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in category_ids\n                ]\n                alpha = 0.5\n\n            self.overlay_instances(\n                labels=labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypoints,\n                assigned_colors=colors,\n                alpha=alpha,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"semantic\" in dic:\n            sem_seg = dic[\"semantic\"]\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.7)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        segments_info = dic.get(\"segments_info\", None)\n        if pan_seg is not None:\n            self.draw_panoptic_seg(pan_seg, segments_info,"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypoints = [x[\"keypoints\"] for x in annos]\n            else:\n                keypoints = None\n            category_ids = [x[\"category_id\"] for x in annos]\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = _create_text_labels(category_ids, None, names)\n            colors = None\n            alpha = 0.5\n            if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n                colors = [\n                    self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in category_ids\n                ]\n                alpha = 0.5\n\n            self.overlay_instances(\n                labels=labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypoints,\n                assigned_colors=colors,\n                alpha=alpha,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"semantic_seg\" in dic:\n            sem_seg = dic[\"semantic_seg\"]\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        segments_info = dic.get(\"segments_info\", None)\n        if pan_seg is not None:\n            self.draw_panoptic_seg(pan_seg, segments"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"].reshape(-1, 3) for x in annos]\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            labels = [x[\"category_id\"] for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = [names[i] for i in labels] if names else labels\n            colors = [x[\"color\"] for x in annos] if \"color\" in annos[0] else None\n            area = [x[\"area\"] for x in annos] if \"area\" in annos[0] else None\n            self.overlay_instances(\n                labels=labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypts,\n                assigned_colors=colors,\n                alpha=0.3,\n                area=area,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"sem_seg_file_name\" in dic:\n            sem_seg = PathManager.get_local_path(dic[\"sem_seg_file_name\"])\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        segments_info = dic.get(\"segments_info\", None)\n        if pan_seg is not None:\n            self.draw_panoptic_seg(pan_seg, segments_info, area_threshold=0,"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"].reshape(-1, 3) for x in annos]\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            boxes = Boxes(boxes)\n            labels = [x[\"category_id\"] for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = [names[i] for i in labels] if names else labels\n            colors = [x[\"color\"] for x in annos] if \"color\" in annos[0] else None\n            area = [x[\"area\"] for x in annos] if \"area\" in annos[0] else None\n            iscrowd = [x.get(\"iscrowd\", 0) for x in annos] if \"iscrowd\" in annos[0] else None\n            self.overlay_instances(\n                labels=labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypts,\n                assigned_colors=colors,\n                alpha=0.3,\n                area=area,\n                iscrowd=iscrowd,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"sem_seg_file_name\" in dic:\n            with PathManager.open(dic[\"sem_seg_file_name\"], \"rb\") as f:\n                sem_seg = Image.open(f)\n                sem_seg = np.asarray(sem_seg, dtype=\"uint8\")\n        if sem_seg is not None:\n            self.draw_"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypoints = [x[\"keypoints\"].reshape(-1, 3) for x in annos]\n            else:\n                keypoints = None\n            category_ids = [x[\"category_id\"] for x in annos]\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = _create_text_labels(category_ids, None, names)\n            colors = None\n            alpha = 0.7\n            if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n                colors = [\n                    self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in category_ids\n                ]\n                alpha = 0.5\n\n            self.overlay_instances(\n                labels=labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypoints,\n                assigned_colors=colors,\n                alpha=alpha,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"semantic_seg\" in dic:\n            sem_seg = dic[\"semantic_seg\"]\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.7)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        segments_info = dic.get(\"segments_info\", None)\n        if pan_seg is not None:\n            self.draw_panoptic"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"] for x in annos]\n                keypts = np.array(keypts).reshape(len(keypts), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            boxes = np.array([[x[0], x[1], x[2], x[3]] for x in boxes])\n            labels = [x[\"category_id\"] for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = [names[i] for i in labels]\n            colors = [self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in labels]\n            text = [\n                # class names\n                \"{}\".format(l) if l else \"\"\n                for l in labels\n            ]\n            self.overlay_instances(\n                labels=text,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypts,\n                assigned_colors=colors,\n                alpha=0.7,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"semantic\" in dic:\n            sem_seg = dic[\"semantic\"]\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        segments_info = dic.get(\"segments_info\", None)\n       "}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypoints = [x[\"keypoints\"] for x in annos]\n                keypoints = np.array(keypoints).reshape(len(annos), -1, 3)\n            else:\n                keypoints = None\n\n            category_ids = [x[\"category_id\"] for x in annos]\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n\n            try:\n                category_colors = [self.metadata.thing_colors[c] for c in category_ids]\n            except AttributeError:\n                category_colors = None\n\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = _create_text_labels(category_ids, None, names)\n            self.overlay_instances(\n                labels=labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypoints,\n                assigned_colors=category_colors,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"semantic\" in dic:\n            sem_seg = dic[\"semantic\"]\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.7)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        segments_info = dic.get(\"segments_info\", None)\n        if pan_seg is not None:\n            self.draw_panoptic_seg(pan_seg, segments_info, area_threshold=0, alpha=0.3)\n\n        return self"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypoints = [x[\"keypoints\"] for x in annos]\n                keypoints = np.array(keypoints).reshape(len(keypoints), -1, 3)\n            else:\n                keypoints = None\n\n            category_ids = [x[\"category_id\"] for x in annos]\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n\n            try:\n                category_colors = [self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in category_ids]\n            except AttributeError:\n                category_colors = None\n\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = _create_text_labels(category_ids, None, names)\n            self.overlay_instances(\n                labels=labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypoints,\n                assigned_colors=category_colors,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"sem_seg_file_name\" in dic:\n            sem_seg = PathManager.open(dic[\"sem_seg_file_name\"], \"rb\")\n            sem_seg = Image.open(sem_seg)\n            sem_seg = np.asarray(sem_seg, dtype=\"uint8\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0)\n\n        pan_seg = dic.get(\"pan_seg\", None)"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"] for x in annos]\n                keypts = np.array(keypts).reshape(len(keypts), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            boxes = Boxes(boxes)\n            labels = [x[\"category_id\"] for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = [names[i] for i in labels] if names else labels\n            colors = None\n            alpha = 0.5\n            if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n                colors = [\n                    self._jitter([x / 255 for x in self.metadata.thing_colors[c]])\n                    for c in labels\n                ]\n                alpha = 0.8\n\n            self.overlay_instances(\n                labels=labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypts,\n                assigned_colors=colors,\n                alpha=alpha,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"sem_seg_file_name\" in dic:\n            sem_seg = PathManager.get_local_path(dic[\"sem_seg_file_name\"])\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n\n        pan_seg = dic.get(\""}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"].reshape(-1, 3) for x in annos]\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            labels = [x[\"category_id\"] for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = [names[i] for i in labels]\n            colors = [self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in labels]\n            text = [\n                \"{}\".format(\", \".join(lbl)) if lbl else None\n                for lbl in labels\n            ]\n\n            self.overlay_instances(\n                labels=text,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypts,\n                assigned_colors=colors,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"semantic\" in dic:\n            sem_seg = dic[\"semantic\"]\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        if pan_seg is None and \"panoptic\" in dic:\n            pan_seg = dic[\"panoptic\"]\n        if pan_seg is not None:\n            segments_info = dic.get(\"segments_info\", None)\n            self.draw_panoptic_seg(pan_seg, segments_info"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"] for x in annos]\n                keypts = np.array(keypts).reshape(len(keypts), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            boxes = np.array([[x[0], x[1], x[2], x[3]] for x in boxes])\n            labels = [x[\"category_id\"] for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = _create_text_labels(labels, None, names)\n            colors = None\n            alpha = 0.7\n            self.overlay_instances(\n                labels=labels, boxes=boxes, masks=masks, keypoints=keypts, assigned_colors=colors, alpha=alpha\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"semantic\" in dic:\n            sem_seg = dic[\"semantic\"]\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.7)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        segments_info = dic.get(\"segments_info\", None)\n        if pan_seg is not None:\n            self.draw_panoptic_seg(pan_seg, segments_info, area_threshold=0, alpha=0.3)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"] for x in annos]\n                keypts = np.array(keypts).reshape(len(keypts), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            boxes = Boxes(boxes)\n            labels = [x[\"category_id\"] for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = [names[i] for i in labels] if names else labels\n            colors = None\n            alpha = 0.7\n            self.overlay_instances(\n                labels=labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypts,\n                assigned_colors=colors,\n                alpha=alpha,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"sem_seg_file_name\" in dic:\n            sem_seg = cv2.imread(dic[\"sem_seg_file_name\"], cv2.IMREAD_GRAYSCALE)\n\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        segments_info = dic.get(\"segments_info\", None)\n        if pan_seg is not None:\n            self.draw_panoptic_seg(pan_seg, segments_info, area_threshold=0, alpha=0.5)"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"].flatten() for x in annos]\n                keypts = np.array(keypts).reshape(len(annos), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n\n            labels = [x[\"category_id\"] for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = [names[i] for i in labels] if names else labels\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in labels\n            ]\n            alpha = 0.8\n            self.overlay_instances(\n                labels=labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypts,\n                assigned_colors=colors,\n                alpha=alpha,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"semantic_seg\" in dic:\n            sem_seg = dic[\"semantic_seg\"]\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        segments_info = dic.get(\"segments_info\", None)\n        if pan_seg is not None:\n            self.draw_panoptic_seg(pan_seg, segments_info, area_threshold=0, alpha=0.5)"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"] for x in annos]\n                keypts = np.array(keypts).reshape(len(keypts), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            boxes = np.array([[x[0], x[1], x[2], x[3]] for x in boxes])\n\n            labels = [x[\"category_id\"] for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = _create_text_labels(labels, None, names)\n            colors = None\n            if \"segmentation\" in annos[0]:\n                colors = [\n                    self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in labels\n                ]\n                alpha = 0.8\n            else:\n                alpha = 0.5\n            self.overlay_instances(\n                labels=labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypts,\n                assigned_colors=colors,\n                alpha=alpha,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"semantic\" in dic:\n            sem_seg = dic[\"semantic\"]\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        segments_info = dic."}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"] for x in annos]\n                keypts = np.array(keypts).reshape(len(keypts), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            boxes = Boxes(boxes)\n            labels = [x[\"category_id\"] for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = [names[i] for i in labels]\n            colors = [self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in labels]\n            text = [\n                \"{}\".format(\", \".join(lbl)) if lbl else None\n                for lbl in labels\n            ]\n            self.overlay_instances(\n                labels=text,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypts,\n                assigned_colors=colors,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"sem_seg_file_name\" in dic:\n            sem_seg = PathManager.open(dic[\"sem_seg_file_name\"], \"rb\")\n            sem_seg = Image.open(sem_seg)\n            sem_seg = np.asarray(sem_seg, dtype=\"uint8\")\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.7)\n\n        pan_seg ="}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"] for x in annos]\n                keypts = np.array(keypts).reshape(len(keypts), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            boxes = np.array(boxes)\n            boxes = Boxes(boxes)\n            labels = [x[\"category_id\"] for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = [names[i] for i in labels]\n            colors = self.metadata.get(\"thing_colors\", None)\n            if colors:\n                colors = [colors[l] for l in labels]\n\n            self.overlay_instances(\n                labels=labels, boxes=boxes, masks=masks, keypoints=keypts, assigned_colors=colors\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"semantic\" in dic:\n            sem_seg = dic[\"semantic\"]\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        if pan_seg is None and \"panoptic\" in dic:\n            pan_seg = dic[\"panoptic\"]\n        if pan_seg is not None:\n            segments_info = dic.get(\"segments_info\", None)\n            self.draw_panoptic_seg(pan_seg, segments_info"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"] for x in annos]\n                keypts = np.array(keypts).reshape(len(keypts), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            boxes = np.array(boxes)\n            boxes = Boxes(boxes)\n            labels = [x[\"category_id\"] for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = [names[i] for i in labels]\n            colors = [self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in labels]\n            text = [\n                # class names and scores\n                \"{}\".format(l) if l is not None else \"\"\n                for l in labels\n            ]\n            self.overlay_instances(\n                labels=text,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypts,\n                assigned_colors=colors,\n                alpha=0.7,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"semantic\" in dic:\n            sem_seg = dic[\"semantic\"]\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.7)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        segments_info = dic.get(\"segments_info\", None)\n        if pan_seg"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"] for x in annos]\n                keypts = np.array(keypts).reshape(len(keypts), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            boxes = np.array(boxes)\n            classes = [x[\"category_id\"] for x in annos]\n            labels = _create_text_labels(classes, None, self.metadata.get(\"thing_classes\", None))\n            names = [x[\"name\"] for x in annos]\n            colors = None\n            if \"colors\" in annos[0]:\n                colors = [x[\"colors\"] for x in annos]\n            self.overlay_instances(\n                labels=names if names else labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypts,\n                assigned_colors=colors,\n            )\n\n        sem_seg = dic.get(\"sem_seg\", None)\n        if sem_seg is None and \"sem_seg_file_name\" in dic:\n            sem_seg = PathManager.get_local_path(dic[\"sem_seg_file_name\"])\n        if sem_seg is not None:\n            self.draw_sem_seg(sem_seg, area_threshold=0, alpha=0.5)\n\n        pan_seg = dic.get(\"pan_seg\", None)\n        segments_info = dic.get(\"segments_info\", None)\n        if pan_seg is not None:\n            self.draw_panoptic_seg(pan_seg, segments"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypts = [x[\"keypoints\"] for x in annos]\n                keypts = np.array(keypts).reshape(len(keypts), -1, 3)\n            else:\n                keypts = None\n\n            boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n\n            labels = [x[\"category_id\"] for x in annos]\n            names = self.metadata.get(\"thing_classes\", None)\n            labels = [names[i] for i in labels] if names else labels\n            labels = [\n                \"{}{}{}\".format(\n                    labels[i], \"|crowd\" if is_crowd else \"\", \"|bbox\" if not is_crowd and boxes[i] is None else \"\"\n                )\n                for i, is_crowd in enumerate(iscrowd)\n            ]\n            colors = (\n                [x[\"color\"] for x in annos]\n                if \"color\" in annos[0]\n                else [\n                    (\n                        random_color(rgb=True, maximum=1)\n                        if self.metadata.get(\"thing_colors\") is None\n                        else self.metadata.thing_colors[labels[i]]\n                    )\n                    for i in range(len(annos))\n                ]\n            )\n            text_size = (\n                self._default_font_size\n                if not self._instance_mode == ColorMode.IMAGE_BW\n                else self._default_font_size / 3\n            )\n            self.overlay_instances(\n                labels=labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints="}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_dataset_dict", "completion": "        annos = dic.get(\"annotations\", None)\n        if annos:\n            if \"segmentation\" in annos[0]:\n                masks = [x[\"segmentation\"] for x in annos]\n            else:\n                masks = None\n            if \"keypoints\" in annos[0]:\n                keypoints = [x[\"keypoints\"] for x in annos]\n                keypoints = np.array(keypoints).reshape(len(keypoints), -1, 3)\n            else:\n                keypoints = None\n\n            category_ids = [x[\"category_id\"] for x in annos]\n            if \"iscrowd\" in annos[0]:\n                iscrowd = [x[\"iscrowd\"] for x in annos]\n            else:\n                iscrowd = [0] * len(annos)\n            if \"bbox\" in annos[0]:\n                boxes = [BoxMode.convert(x[\"bbox\"], x[\"bbox_mode\"], BoxMode.XYXY_ABS) for x in annos]\n            else:\n                boxes = None\n            if \"bbox_mode\" in annos[0]:\n                bbox_modes = [x[\"bbox_mode\"] for x in annos]\n            else:\n                bbox_modes = None\n\n            try:\n                scores = [x[\"score\"] for x in annos]\n            except KeyError:\n                scores = None\n\n            labels = _create_text_labels(\n                category_ids, scores, self.metadata.thing_classes, iscrowd\n            )\n            colors = [\n                self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in category_ids\n            ]\n            self.overlay_instances(\n                labels=labels,\n                boxes=boxes,\n                masks=masks,\n                keypoints=keypoints,\n                assigned_colors=colors,\n                bbox_modes=bbox_modes"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Convert the binary mask to a polygon mask\n        mask = GenericMask(binary_mask, self.output.height, self.output.width)\n\n        # Set the color of the mask if not specified\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        # Set the edge color of the mask if not specified\n        if edge_color is None:\n            edge_color = color\n\n        # Draw the mask as a polygon\n        for segment in mask.polygons:\n            segment = segment.reshape(-1, 2)\n            self.draw_polygon(segment, color, edge_color=edge_color, alpha=alpha)\n\n        # Draw the text on the mask if specified\n        if text is not None:\n            # Get the center of the mask\n            x0, y0, x1, y1 = mask.bbox()\n            text_pos = (x0 + x1) / 2, (y0 + y1) / 2\n\n            # Set the color of the text based on the mask color\n            text_color = self._change_color_brightness(color, brightness_factor=0.7)\n\n            # Set the font size based on the mask area\n            height_ratio = (y1 - y0) / np.sqrt(self.output.height * self.output.width)\n            font_size = (\n                np.clip((height_ratio - 0.02) / 0.08 + 1, 1.2, 2) * 0.5 * self._default_font_size\n            )\n\n            # Draw the text on the mask\n            self.draw_text(text, text_pos, color=text_color, font_size=font_size)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if edge_color is None:\n            edge_color = color\n\n        binary_mask = np.asarray(binary_mask)\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = np.array(mplc.to_rgb(color))\n        color = np.maximum(color, 0.2)\n        color[np.argmax(color)] = max(0.8, np.max(color))\n\n        for cnt in cv2.findContours(\n            binary_mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE\n        )[-2]:\n            if cv2.contourArea(cnt) < area_threshold:\n                continue\n            if len(cnt) == 0:\n                continue\n            if len(cnt) == 1:\n                p = cnt[0][0]\n                self.draw_text(\n                    text,\n                    (p[0] + 1, p[1] - 2),\n                    color=edge_color,\n                    horizontal_alignment=\"left\",\n                    font_size=self._default_font_size,\n                )\n                continue\n            cnt = cnt.astype(\"float\")\n            cnt *= self.output.scale\n            cnt = cv2.approxPolyDP(cnt, 3, closed=True)[:-1]\n            cnt = cnt.flatten().tolist()\n            self.draw_polygon(cnt, color, edge_color=edge_color, alpha=alpha)\n            if text is not None:\n                p = cnt[0]\n                s = cnt[1]\n                e = cnt[-1]\n                text_pos = (p[0] + s[0]) / 2, (p[1] + s[1]) / 2\n                height_ratio = np.clip(\n                    (e[1] - s[1]) * 1.0 / (e[0] - s[0]), 0.5, 2\n               "}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        binary_mask_to_draw = binary_mask\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            # any() returns uint8 instead of bool\n            binary_mask_to_draw = binary_mask_to_draw.astype(\"bool\")\n        fortran_mask = np.asfortranarray(binary_mask_to_draw)\n        mask = np.asarray(fortran_mask, dtype=np.uint8)\n\n        if edge_color is None:\n            edge_color = color\n\n        # draw holes\n        if self._instance_mode == ColorMode.IMAGE:\n            # Make the interior region white\n            _, contours, _ = cv2.findContours(\n                (mask == 0).astype(np.uint8), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE\n            )\n            if contours:\n                cv2.drawContours(mask, contours, -1, 255, -1)\n\n        # Draw polygons on the mask\n        rgb_mask = Image.fromarray(mask).convert(\"RGB\")\n        draw = ImageDraw.Draw(rgb_mask)\n        for binary_object in mask_util.find_contours(mask, 0.5):\n            for e, p in enumerate(binary_object):\n                rgb_mask = Image.fromarray(mask).convert(\"RGB\")\n                draw = ImageDraw.Draw(rgb_mask)\n                p = p.flatten().tolist()\n                draw.polygon(p, outline=edge_color, fill=color)\n                mask = np.array(rgb_mask)\n\n        object_ids = np.unique(binary_mask_to_draw)\n        object_ids = object_ids[1:]\n\n        # area < 10 pixels will be ignored\n        suitable_segment_ids = [\n            i for i in object_ids if (binary_mask_to_draw[binary_mask_to_draw == i].size) > area_threshold\n        ]\n        labels"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        binary_mask = np.asarray(binary_mask)\n        # Check if the binary mask is multi-colored.\n        if binary_mask.shape[-1] != 1:\n            # Find connected components.\n            num_instances, output, stats, _ = cv2.connectedComponentsWithStats(binary_mask.astype(np.uint8), connectivity=8)\n            # Map component indices to colors.\n            seg_colors = [random_color(rgb=True, maximum=1) for _ in range(num_instances)]\n            seg_colors[0] = (0, 0, 0)\n            segmask = np.zeros((output.shape[0], output.shape[1], 3), dtype=np.uint8)\n            for l in range(0, num_instances):\n                segmask[output == l] = seg_colors[l]\n            # Colorize the mask.\n            binary_mask = segmask\n\n        # Get the boundary line of the binary mask.\n        # Find contours in the binary mask.\n        contours = []\n        hierarchy = []\n        if int(cv2.__version__.split(\".\")[0]) >= 4:\n            # Opencv 4.0 and above\n            contours, hierarchy = cv2.findContours(\n                binary_mask.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n            )\n        else:\n            # Opencv 3.4\n            _, contours, hierarchy = cv2.findContours(\n                binary_mask.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n            )\n\n        # For each contour, draw the polygon.\n        for component in zip(contours, hierarchy[0]):\n            p = component[0"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        # convert to numpy array\n        if isinstance(binary_mask, torch.Tensor):\n            binary_mask = binary_mask.numpy()\n\n        # check type and perform conversion if necessary\n        if isinstance(binary_mask, BitMasks):\n            binary_mask = binary_mask.tensor\n        if isinstance(binary_mask, PolygonMasks):\n            binary_mask = binary_mask.get_mask_tensor()\n\n        binary_mask = np.asarray(binary_mask)\n\n        # Check if the mask is empty\n        if binary_mask.size == 0:\n            logger.warning(\"Empty binary mask received. Ignoring.\")\n            return self.output\n\n        # Check if the mask is not binary\n        if not np.array_equal(binary_mask, binary_mask.astype(bool)):\n            # Raise a warning for non-binary masks\n            logger.warning(\n                \"Non-binary mask received. \"\n                \"Expected 2D binary mask, got {}.\".format(binary_mask.dtype)\n            )\n            return self.output\n\n        # Check if the mask is too small\n        if binary_mask.sum() < area_threshold:\n            logger.warning(\n                \"Mask of shape {} is empty or too small to visualize, \"\n                \"mask_threshold={}.\".format(binary_mask.shape, area_threshold)\n            )\n            return self.output\n\n        # Check if the mask is too large\n        if binary_mask.sum() > _LARGE_MASK_AREA_THRESH:\n            logger.warning(\n                \"Mask of shape {} is too large to visualize, \"\n                \"mask_threshold={}.\".format(binary_mask.shape, _LARGE_MASK_AREA_THRESH)\n            )\n            return self.output\n\n        # Convert the mask to a polygon mask\n        mask = GenericMask("}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = np.array(mplc.to_rgb(color))\n        color = color * 255\n        color = color.astype(np.uint8)\n\n        if edge_color is None:\n            edge_color = color\n        edge_color = np.array(mplc.to_rgb(edge_color))\n        edge_color = edge_color * 255\n        edge_color = edge_color.astype(np.uint8)\n\n        if text is not None:\n            height_ratio = binary_mask.shape[0] / np.sqrt(self.output.height * self.output.width)\n            font_size = (\n                np.clip((height_ratio - 0.02) / 0.08 + 1, 1.2, 2) * 0.5 * self._default_font_size\n            )\n            text_pos = binary_mask.shape[::-1] / 2\n\n        if binary_mask.shape[0] * binary_mask.shape[1] > _LARGE_MASK_AREA_THRESH:\n            # obtain a mask image\n            binary_mask_image = np.repeat(\n                binary_mask[:, :, np.newaxis], repeats=3, axis=2\n            )\n            # upsample mask image to have the same size as the original image\n            binary_mask_image = self._resize_binary_mask(binary_mask_image, self.output.height, self.output.width)\n            # upsample the color and the edge color\n            color = np.array(mplc.to_rgb(color))\n            color = np.tile(color[:, np.newaxis, np.newaxis], (1, self.output.height, self.output.width))\n            edge_color = np.array(mplc.to_rgb(edge_color))\n            edge_color = np.tile(edge_color[:, np.newaxis, np.newaxis], (1"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n        if text is None:\n            text = \"\"\n\n        # convert to mask first\n        if isinstance(binary_mask, np.ndarray):\n            binary_mask = GenericMask(binary_mask, binary_mask.shape[0], binary_mask.shape[1])\n\n        # check type of the binary mask\n        if isinstance(binary_mask, GenericMask):\n            # the first check verifies the type of the variable\n            # the second check verifies that it contains mask itself\n            if binary_mask.has_holes:\n                # draw mask that may have holes\n                contours = []\n                for c in binary_mask.polygons:\n                    if len(c) >= 6:\n                        contours.append(c.reshape((-1, 2)))\n                if len(contours) == 0:\n                    return self.output\n                contour = np.concatenate(contours, axis=0)\n                self.output.ax.add_patch(\n                    mpl.patches.Polygon(\n                        contour,\n                        facecolor=mplc.to_rgba(color, alpha),\n                        edgecolor=mplc.to_rgba(edge_color),\n                        linewidth=max(self.output.scale / 2, 1),\n                    )\n                )\n            else:\n                # draw without holes\n                for segment in binary_mask.polygons:\n                    segment = segment.reshape((-1, 2))\n                    self.output.ax.add_patch(\n                        mpl.patches.Polygon(\n                            segment,\n                            facecolor=mplc.to_rgba(color, alpha),\n                            edgecolor=edge_color,\n                            linewidth=max(self.output.scale / 2, 1),\n                        )\n                    )\n\n        elif isinstance(binary_mask, PolygonMasks):\n            # draw polygons\n            for polygon in binary_mask.polygons:\n                self"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if binary_mask.ndim == 2:\n            binary_mask = np.stack([binary_mask] * 3, axis=-1)\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n        binary_mask = np.asarray(binary_mask)\n\n        # Convert the mask to polygons\n        polygons, has_holes = self._convert_mask_to_polygons(binary_mask)\n\n        # Draw the polygons on the image\n        for polygon in polygons:\n            # Check if the polygon has holes\n            if has_holes:\n                # If the polygon has holes, draw it as a polygon with a hole\n                self._draw_polygon_with_holes(polygon, color, edge_color, alpha)\n            else:\n                # If the polygon doesn't have holes, draw it as a regular polygon\n                self._draw_regular_polygon(polygon, color, edge_color, alpha)\n\n        # Draw text on the mask if specified\n        if text is not None:\n            # Get the bounding box of the mask\n            x0, y0, x1, y1 = self._get_bounding_box(binary_mask)\n            # Calculate the text position\n            text_pos = (x0, y0)\n            # Calculate the font size based on the mask size\n            height_ratio = (y1 - y0) / np.sqrt(self.output.height * self.output.width)\n            font_size = (\n                np.clip((height_ratio - 0.02) / 0.08 + 1, 1.2, 2) * 0.5 * self._default_font_size\n            )\n            # Draw the text on the image\n            self.draw_text(text, text_pos, color=edge_color, font_size=font_size)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        binary_mask = np.asarray(binary_mask)\n        assert binary_mask.dtype == np.uint8, binary_mask.dtype\n        binary_mask = binary_mask.astype(bool)\n\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        # draw mask\n        if binary_mask.shape[0] == 0 or binary_mask.shape[1] == 0:\n            return self.output\n        if edge_color is None:\n            edge_color = color\n\n        # Make the image area masked.\n        img = self.output.img\n        img[binary_mask] = img[binary_mask] * (1 - alpha) + alpha * np.array(color, dtype=np.uint8)\n\n        # Generate a random color.\n        color = np.maximum(list(mplc.to_rgb(color)), 0.2)\n        color[np.argmax(color)] = max(0.8, np.max(color))\n\n        # draw mask contours\n        binary_mask_uint8 = binary_mask.astype(np.uint8)\n        contours = cv2.findContours(\n            binary_mask_uint8, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n        )[0]\n\n        for contour in contours:\n            contour = np.flip(contour, axis=1)\n            self.output.ax.plot(contour[:, 0], contour[:, 1], linewidth=1, color=edge_color)\n\n        # Free memory\n        del binary_mask\n        del binary_mask_uint8\n        del contours\n\n        # draw text\n        if text is not None:\n            center = np.round(np.mean(np.array(np.nonzero(binary_mask), axis=1), axis=0)).astype(\n                int\n            )\n            center = (center[1], center[0])  # y, x -> x, y\n            self.draw"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        if binary_mask.shape[0] == 0:\n            return self.output\n\n        # Convert the binary mask to a polygon representation\n        polygons = []\n        for mask in binary_mask:\n            # Generate a polygon representation of the mask\n            polygons.append(mask_util.mask_to_polygons(mask, return_valid=False)[0])\n\n        # Draw the polygons on the image\n        for polygon in polygons:\n            # Extract the polygon vertices\n            vertices = polygon.reshape(-1, 2)\n\n            # Check if the polygon has at least three vertices\n            if len(vertices) < 3:\n                continue\n\n            # Check if the polygon is too small\n            if area_threshold is not None and cv2.contourArea(vertices) < area_threshold:\n                continue\n\n            # Draw the polygon on the image\n            self.draw_polygon(vertices, color, edge_color=edge_color, alpha=alpha)\n\n        # Draw the text on the image\n        if text is not None:\n            # Calculate the center of the mask\n            center = np.mean(vertices, axis=0)\n\n            # Draw the text on the image\n            self.draw_text(text, center, color=edge_color)\n\n        return self.output"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        # Convert binary mask to a polygon mask\n        binary_mask_polygon = PolygonMasks([binary_mask], self.output.height, self.output.width)\n\n        # Get the polygons of the polygon mask\n        polygons = binary_mask_polygon.polygons\n\n        # If there are no polygons, return the original image\n        if len(polygons) == 0:\n            return self.output\n\n        # If color is not specified, choose a random color\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        # If edge_color is not specified, use a lighter version of the color\n        if edge_color is None:\n            # Generate a lighter version of the color\n            edge_color = self._change_color_brightness(color, brightness_factor=0.7)\n\n        # Set the color to an RGB tuple\n        color = tuple(x / 255.0 for x in color)\n\n        # Set the edge color to an RGB tuple\n        edge_color = tuple(x / 255.0 for x in edge_color)\n\n        # Draw the polygon mask\n        for polygon in polygons:\n            # Skip small polygons\n            if polygon.area < area_threshold:\n                continue\n\n            # Draw the polygon\n            self.draw_polygon(polygon.reshape(-1, 2), color, alpha=alpha, edge_color=edge_color)\n\n        # If text is specified, draw it on the mask\n        if text is not None:\n            # Get the bounding box of the mask\n            bbox = binary_mask_polygon.bbox()\n\n            # Get the height and width of the bounding box\n            height = bbox[3] - bbox[1]\n            width = bbox[2] - bbox[0]\n\n            # Calculate the font size based on the height of the bounding box\n            font_size = height / 13 if height > 0 else self._default_font_size\n\n            # Draw the text on the mask\n            self.draw_text("}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n        if text is None:\n            text = \"\"\n\n        if self._instance_mode == ColorMode.SEGMENTATION and self.metadata.get(\"thing_colors\"):\n            color = self._jitter([x / 255 for x in self.metadata.thing_colors[0]])\n\n        if self._instance_mode == ColorMode.IMAGE_BW:\n            color = \"w\"\n\n        mask = GenericMask(binary_mask, self.output.height, self.output.width)\n        if mask.has_holes:\n            # Draw mask with holes using a different approach.\n            self._draw_mask_with_holes(mask, color, alpha)\n        else:\n            # Draw regular mask as polygons.\n            self._draw_polygons(mask, color, edge_color, text, alpha, area_threshold)\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        # Convert the binary mask to a polygon\n        binary_mask_polygon = GenericMask(binary_mask, self.output.height, self.output.width)\n        binary_mask_polygon_area = binary_mask_polygon.area()\n        if binary_mask_polygon_area < area_threshold:\n            return self.output\n\n        # If the mask has holes, use a different approach to draw it\n        if binary_mask_polygon.has_holes:\n            # Find the contours of the binary mask\n            contours = cv2.findContours(\n                binary_mask.astype(\"uint8\"), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE\n            )[-2]\n            # Draw the contours on the image\n            for contour in contours:\n                contour = contour.flatten().tolist()\n                # Draw the contour on the image\n                self.draw_polygon(contour, edge_color, alpha=alpha)\n            # Draw the text on the mask\n            if text is not None:\n                # Find the center of the mask\n                cx, cy = binary_mask_polygon.bbox()\n                cx = cx + (cx - binary_mask_polygon.bbox()[2]) / 2\n                cy = cy + (cy - binary_mask_polygon.bbox()[3]) / 2\n                # Draw the text on the mask\n                self.draw_text(text, (cx, cy), color=edge_color, horizontal_alignment=\"center\")\n        else:\n            # Draw the polygon on the image\n            for segment in binary_mask_polygon.polygons:\n                segment = segment.reshape(-1, 2)\n                self.draw_polygon(segment, edge_color, alpha=alpha)\n            # Draw the text on the mask\n            if text is not None:"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        binary_mask = np.asarray(binary_mask)\n        # Check if the binary mask is multi-channel or not\n        if binary_mask.ndim >= 3:\n            # Assuming the first channel is the binary mask\n            binary_mask = binary_mask[..., 0]\n\n        # Add padding to the mask to close contours\n        binary_mask = np.pad(binary_mask, pad_width=1, mode=\"constant\", constant_values=0)\n\n        contours = measure.find_contours(binary_mask, 0.5)\n        contours = np.subtract(contours, 1)\n        for verts in contours:\n            # Subtract the padding from the polygon\n            verts = np.core.numeric.normalize(verts.astype(np.float64), axis=0)\n            verts = verts.tolist()\n            self.draw_polygon(verts, color, alpha=alpha)\n\n        if text is not None:\n            # Compute the center of the contours\n            x, y = np.mean(contours, axis=1).astype(np.int32)\n            self.draw_text(text, (x, y), color=edge_color)\n\n        return self.output\n"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if edge_color is None:\n            edge_color = color\n\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if binary_mask.ndim == 3:\n            binary_mask = binary_mask[..., 0]\n\n        if binary_mask.shape[0] != self.output.height or binary_mask.shape[1] != self.output.width:\n            binary_mask = cv2.resize(binary_mask, (self.output.width, self.output.height))\n\n        # Find contours in the binary mask\n        contours, hierarchy = cv2.findContours(\n            binary_mask.astype(np.uint8), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE\n        )\n\n        # Create a new image with the same size as the original image\n        mask_image = np.zeros((self.output.height, self.output.width, 3), dtype=np.uint8)\n\n        # Draw the contours on the mask image\n        for i, contour in enumerate(contours):\n            # Check if the contour is a hole or an external contour\n            if hierarchy[0][i][3] == -1:\n                # Draw the external contour as a polygon\n                cv2.drawContours(mask_image, [contour], 0, color=color, thickness=-1)\n            else:\n                # Draw the hole as a polygon\n                cv2.drawContours(mask_image, [contour], 0, color=(0, 0, 0), thickness=-1)\n\n        # Apply a threshold to the mask image to remove noise\n        _, mask_image = cv2.threshold(mask_image, 0, 255, cv2.THRESH_BINARY)\n\n        # Find contours in the mask image\n        contours, hierarchy = cv2.findContours(\n            mask_image.astype(np.uint8), cv2.RETR_CCOMP"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if edge_color is None:\n            edge_color = color\n        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        color = np.array(mplc.to_rgb(color))\n        color = np.concatenate([color, [alpha]])\n        edge_color = mplc.to_rgb(edge_color)\n\n        if binary_mask.ndim == 2:\n            binary_mask = np.repeat(binary_mask[..., None], 3, axis=-1)\n        binary_mask = binary_mask.astype(\"uint8\")\n\n        if binary_mask.shape[2] == 1:\n            binary_mask = np.repeat(binary_mask, 3, axis=-1)\n\n        if binary_mask.shape[2] > 3:\n            binary_mask = binary_mask[:, :, :3]\n\n        # convert to mask first\n        binary_mask = np.asarray(binary_mask)\n        binary_mask = GenericMask(binary_mask, self.output.height, self.output.width)\n\n        # check if mask is empty\n        if binary_mask.area() == 0:\n            return self.output\n\n        # if mask is non-empty, check if mask has enough area\n        if area_threshold is not None and binary_mask.area() < area_threshold:\n            return self.output\n\n        # draw polygons on the mask\n        for poly in binary_mask.polygons:\n            poly = np.array(poly).reshape((-1, 2))\n            self.draw_polygon(poly, color, edge_color=edge_color)\n\n        # draw text\n        if text is not None:\n            pos = binary_mask.bbox()\n            horiz_align = \"left\"\n            font_size = self._default_font_size\n\n            # draw in the top right corner\n            pos[0] = pos[0] - 5\n            pos[1] = pos[1] - 5\n\n            height_ratio = (pos[1] -"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        if binary_mask.ndim == 2:\n            binary_mask = np.stack([binary_mask] * 3, axis=-1)\n        binary_mask = np.ascontiguousarray(binary_mask)\n\n        # find all connected components\n        if binary_mask.dtype == np.uint8:\n            binary_mask = binary_mask.astype(np.bool)\n        else:\n            # add 0.5 to convert to uint8 first\n            binary_mask = np.uint8(binary_mask * 255.0 + 0.5)\n        cv2_mask = np.ascontiguousarray(binary_mask.astype(np.uint8))\n        contours, _ = cv2.findContours(cv2_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n\n        # find all holes\n        holes = []\n        for i in range(len(contours)):\n            # hole is a contour inside another contour\n            if contours[i].size < 3 * 2:\n                holes.append(i)\n                continue\n            is_hole = True\n            for j in range(len(contours)):\n                if i != j and cv2.pointPolygonTest(contours[j], (contours[i][:, 0, 0]), False) >= 0:\n                    is_hole = False\n                    break\n            if is_hole:\n                holes.append(i)\n\n        # draw mask contours\n        for i in range(len(contours)):\n            if i in holes:\n                # draw holes with `edge_color`\n                color_mask = edge_color\n            else:\n                # draw regular contours with `color`\n                color_mask = color\n\n            contour = contours[i].astype(\"float\")\n            contour = np.flip(contour, axis"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if edge_color is None:\n            edge_color = color\n\n        if color is None:\n            color = [x / 255 for x in self.metadata.thing_colors[0]]\n\n        # Convert binary mask to polygons\n        polygons = []\n        has_holes = False\n        for c in range(3):\n            mask = binary_mask[:, :, c]\n            # Binary mask polygons have either 1 or 2 dimensions, depending on whether the mask is empty or not\n            # After vector operations, the original two dimensions are flattened\n            # The first dimension is the polygon index, and the second dimension is the operation index\n            # Add a column of ones to duplicate the first vertex at the end\n            padded_mask = np.pad(mask, ((1, 1), (1, 1)), \"constant\", constant_values=1)\n            contours = np.abs(np.diff(padded_mask, axis=1)) + np.abs(np.diff(padded_mask, axis=0))\n            contours = np.where(contours[0:, :] > 0)[0]\n            if contours.shape[0]:\n                contours = contours + 1\n                contours = np.vstack((contours, contours[0])).T\n                for region in contours:\n                    if not len(region) > 2:\n                        continue\n                    region = region.flatten()\n                    if len(region) > 2:\n                        # Make sure to keep an empty line between two close polygons\n                        region = np.append(region, region[0])\n                        region = np.insert(region, 0, region[-1])\n                    else:\n                        region = np.append(region, region[0])\n                    region = np.reshape(region, (-1, 2))\n                    region = np.flip(region, 1)\n                    polygons.append(region)\n                    has_holes = True\n            else:\n                has_holes = False\n\n        # Draw polygons on image\n        if has_holes:\n            # Draw polygons with holes\n            for"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n\n        if edge_color is None:\n            edge_color = color\n\n        if binary_mask.ndim == 2:\n            binary_mask = np.ascontiguousarray(binary_mask)\n\n        if binary_mask.ndim != 2:\n            raise ValueError(\n                \"Binary mask must be a 2D array (of shape (H, W)), \"\n                \"got an array of shape {} instead.\".format(binary_mask.shape)\n            )\n        binary_mask = np.ascontiguousarray(binary_mask.astype(\"uint8\"))\n\n        # Compute the bounding box of the mask\n        image_shape = binary_mask.shape\n        check_non_zero = binary_mask.nonzero()\n        if len(check_non_zero[0]) == 0:\n            # the mask is empty\n            return self.output\n        y0 = np.clip(np.min(check_non_zero[0]), 0, image_shape[0])\n        y1 = np.clip(np.max(check_non_zero[0]) + 1, 0, image_shape[0])\n        x0 = np.clip(np.min(check_non_zero[1]), 0, image_shape[1])\n        x1 = np.clip(np.max(check_non_zero[1]) + 1, 0, image_shape[1])\n\n        # If the mask is too small, ignore it\n        if (y1 - y0) * (x1 - x0) <= area_threshold:\n            return self.output\n\n        # Mask too small, ignore it\n        if (y1 - y0) * (x1 - x0) <= 1:\n            return self.output\n\n        # Find all connected components\n        mask = cv2.resize(\n            binary_mask, (image_shape[1], image_shape[0]), interpolation=cv2.INTER_NEAREST\n        )\n        mask = np.asarray(mask"}
{"namespace": "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "completion": "        if color is None:\n            color = random_color(rgb=True, maximum=1)\n        if edge_color is None:\n            edge_color = color\n\n        binary_mask = np.asarray(binary_mask)\n        if binary_mask.shape[0] == 0 or binary_mask.shape[1] == 0:\n            logger.warning(f\"The mask is empty: {binary_mask.shape}\")\n            return self.output\n\n        binary_mask = np.ascontiguousarray(binary_mask)\n        if binary_mask.dtype != np.uint8:\n            binary_mask = np.asarray(binary_mask, dtype=np.uint8)\n\n        if area_threshold > 0:\n            # Use cv2 to find connected components and filter by area.\n            # Mask values need to be 0 or 1\n            ret, labels = cv2.connectedComponents(binary_mask.astype(\"uint8\"))\n            label_area_dict = {i: 0 for i in range(ret)}\n            for y in range(binary_mask.shape[0]):\n                for x in range(binary_mask.shape[1]):\n                    if not binary_mask[y, x]:\n                        continue\n                    label = labels[y, x]\n                    label_area_dict[label] += 1\n            for i, area in label_area_dict.items():\n                if area <= area_threshold:\n                    binary_mask[labels == i] = 0\n\n        # find contours\n        contours, _ = cv2.findContours(binary_mask.astype(\"uint8\"), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n        # This polygon representation is new since version 3.2\n        # Before that, polygon contours were represented by a list of polygons.\n        # The new representation is slightly more efficient and allows more options.\n        polygon = PolygonMasks([np.squeeze(c) for c in contours])\n        polygon.draw_polygons(self.output.ax,"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(other, Instances), (\n        f\"{msg} Expect input and other to be Instances, but got {type(input)} and {type(other)}!\"\n    )\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), (\n            f\"{msg} Expect input.image_size and other.image_size to be equal, \"\n            f\"but got {input.image_size} and {other.image_size}!\"\n        )\n    else:\n        assert input.image_size == other.image_size, (\n            f\"{msg} Expect input.image_size and other.image_size to be equal, \"\n            f\"but got {input.image_size} and {other.image_size}!\"\n        )\n    for name in input._field_names:\n        val = getattr(input, name)\n        other_val = getattr(other, name)\n        if isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), (\n                f\"{msg} Expect input.{name} and other.{name} to be equal, \"\n                f\"but got {val.tensor} and {other_val.tensor}!\"\n            )\n        elif isinstance(val, ROIMasks):\n            assert val.tensor.allclose(other_val.tensor, rtol=rtol), (\n                f\"{msg} Expect input.{name} and other.{name} to be equal, \"\n                f\"but got {val.tensor} and {other_val.tensor}!\"\n            )\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol), (\n                f\"{msg} Expect input.{name} and other.{name} to be equal, \"\n                f\"but got {val} and {other_val}!\"\n            )\n        else:\n            raise ValueError"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(\n            f\"Expect input to be an Instances object, but got {type(input)}!\"\n        )\n    if not isinstance(other, Instances):\n        raise ValueError(\n            f\"Expect other to be an Instances object, but got {type(other)}!\"\n        )\n    if size_as_tensor:\n        assert torch.allclose(\n            torch.tensor(input.image_size), torch.tensor(other.image_size), rtol=rtol\n        ), f\"{msg} image_size does not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert (\n            input.image_size == other.image_size\n        ), f\"{msg} image_size does not match: {input.image_size} vs {other.image_size}\"\n\n    for name in input._field_names:\n        val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n        if val is None:\n            assert other_val is None, f\"{msg} {name} does not match: {val} vs {other_val}\"\n            continue\n        if isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), (\n                f\"{msg} {name} does not match: {val} vs {other_val}\"\n            )\n        elif isinstance(val, ROIMasks):\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), (\n                f\"{msg} {name} does not match: {val} vs {other_val}\"\n            )\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol), (\n                f\"{msg} {name} does not match: {val} vs {other_val}\"\n            )\n        else:\n            assert val == other_val"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances):\n        raise ValueError(\n            f\"Expect input to be an Instances object, but got {type(input)}!\"\n        )\n    if not isinstance(other, Instances):\n        raise ValueError(\n            f\"Expect other to be an Instances object, but got {type(other)}!\"\n        )\n    if size_as_tensor:\n        assert torch.allclose(\n            torch.tensor(input.image_size), torch.tensor(other.image_size), rtol=rtol\n        ), f\"{msg} image_size mismatch: {input.image_size} vs {other.image_size}\"\n    else:\n        assert (\n            input.image_size == other.image_size\n        ), f\"{msg} image_size mismatch: {input.image_size} vs {other.image_size}\"\n\n    for name in input._field_names:\n        val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n        if val is None and other_val is None:\n            continue\n        elif val is None or other_val is None:\n            raise ValueError(\n                f\"{msg} {name} mismatch: {val} vs {other_val} (one is None)\"\n            )\n        if isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), (\n                f\"{msg} {name} mismatch: {val} vs {other_val}\"\n            )\n        elif isinstance(val, ROIMasks):\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), (\n                f\"{msg} {name} mismatch: {val} vs {other_val}\"\n            )\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol), (\n                f\"{msg} {name} mismatch: {val} vs"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(\n        other, Instances\n    ), \"Expect input and other to be Instances, but got {} and {}\".format(\n        type(input), type(other)\n    )\n    if size_as_tensor:\n        assert (\n            isinstance(input.image_size, torch.Tensor)\n            and isinstance(other.image_size, torch.Tensor)\n        ) or (\n            isinstance(input.image_size, tuple) and isinstance(other.image_size, tuple)\n        ), \"Expect input.image_size and other.image_size to be both tensors or both tuples, but got {} and {}\".format(\n            type(input.image_size), type(other.image_size)\n        )\n        if isinstance(input.image_size, torch.Tensor):\n            assert torch.allclose(\n                input.image_size, other.image_size\n            ), \"image_size mismatch: {} vs {}\".format(input.image_size, other.image_size)\n    else:\n        assert (\n            isinstance(input.image_size, tuple) and isinstance(other.image_size, tuple)\n        ) or (\n            isinstance(input.image_size, torch.Tensor)\n            and isinstance(other.image_size, torch.Tensor)\n        ), \"Expect input.image_size and other.image_size to be both tuples or both tensors, but got {} and {}\".format(\n            type(input.image_size), type(other.image_size)\n        )\n        assert (\n            input.image_size == other.image_size\n        ), \"image_size mismatch: {} vs {}\".format(input.image_size, other.image_size)\n\n    for field in input._fields:\n        if field == \"image_size\":\n            continue\n        val1 = getattr(input, field)\n        val2 = getattr(other, field)\n        if isinstance(val1, Boxes) or isinstance(val1,"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(\n        other, Instances\n    ), f\"Expect input and other to be Instances, but got {type(input)} and {type(other)}!\"\n    if size_as_tensor:\n        assert torch.allclose(\n            torch.as_tensor(input.image_size), torch.as_tensor(other.image_size)\n        ), f\"{msg} image_size does not match: {input.image_size} vs {other.image_size}\"\n    else:\n        assert (\n            input.image_size == other.image_size\n        ), f\"{msg} image_size does not match: {input.image_size} vs {other.image_size}\"\n    for name in input._field_names:\n        val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n        if val is None:\n            assert (\n                other_val is None\n            ), f\"{msg} {name} does not match: {val} vs {other_val}\"\n        elif isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, other_val.tensor), f\"{msg} {name} does not match!\"\n        elif isinstance(val, ROIMasks):\n            assert val == other_val, f\"{msg} {name} does not match!\"\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol), f\"{msg} {name} does not match!\"\n        elif isinstance(val, (list, tuple)):\n            assert len(val) == len(\n                other_val\n            ), f\"{msg} {name} does not match: {len(val)} vs {len(other_val)}\"\n            for i, (v, ov) in enumerate(zip(val, other_val)):\n                if isinstance(v, (list, tuple)):\n                    assert_instances_allclose(v, ov, rtol=rtol, msg="}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(\n        other, Instances\n    ), \"Expect input and other to be Instances\"\n    assert (\n        input.image_size == other.image_size\n    ), f\"{msg} image_size not equal: {input.image_size} vs {other.image_size}\"\n    for name in input._field_names:\n        val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n        if val is None:\n            assert (\n                other_val is None\n            ), f\"{msg} {name} not equal: {val} vs {other_val}\"\n        elif other_val is None:\n            assert (\n                val is None\n            ), f\"{msg} {name} not equal: {val} vs {other_val}\"\n        elif isinstance(val, Boxes):\n            assert torch.allclose(\n                val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg} {name} not equal: {val} vs {other_val}\"\n        elif isinstance(val, ROIMasks):\n            assert (\n                val.image_size == other_val.image_size\n            ), f\"{msg} {name} image_size not equal: {val.image_size} vs {other_val.image_size}\"\n            assert torch.allclose(\n                val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg} {name} tensor not equal: {val.tensor} vs {other_val.tensor}\"\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(\n                val, other_val, rtol=rtol\n            ), f\"{msg} {name} not equal: {val} vs {other_val}\"\n        elif isinstance(val, (tuple, list)):\n            assert len(val) == len(\n                other_val\n            ), f\"{msg} {name} len not equal: {len(val)} vs {len(other_"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(\n        other, Instances\n    ), f\"Expect input and other to be Instances objects, but got {type(input)} and {type(other)}!\"\n\n    if size_as_tensor:\n        assert torch.equal(\n            input.image_size, other.image_size\n        ), f\"{msg} image_size mismatch: {input.image_size} vs. {other.image_size}\"\n    else:\n        assert (\n            input.image_size == other.image_size\n        ), f\"{msg} image_size mismatch: {input.image_size} vs. {other.image_size}\"\n\n    for name in input._field_names:\n        val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n\n        if val is None:\n            assert (\n                other_val is None\n            ), f\"{msg} {name} mismatch: {val} vs. {other_val}\"\n        elif other_val is None:\n            assert (\n                val is None\n            ), f\"{msg} {name} mismatch: {val} vs. {other_val}\"\n        elif isinstance(val, Boxes):\n            assert torch.allclose(\n                val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg} {name} mismatch: {val} vs. {other_val}\"\n        elif isinstance(val, ROIMasks):\n            assert val.tensor.shape == other_val.tensor.shape, f\"{msg} {name} shape mismatch\"\n            assert torch.allclose(\n                val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg} {name} mismatch: {val} vs. {other_val}\"\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(\n                val, other_val, rtol=rtol\n            ), f\"{msg} {name} mismatch: {val} vs. {"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(\n            f\"{msg} Expect input and other to be Instances, but got {type(input)} and {type(other)}\"\n        )\n\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), f\"{msg} image_size mismatch\"\n    else:\n        assert input.image_size == other.image_size, f\"{msg} image_size mismatch\"\n\n    for name in input._field_names:\n        val = getattr(input, name)\n        other_val = getattr(other, name)\n        if isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), (\n                f\"{msg} Boxes mismatch for field {name}: \"\n                f\"input={val.tensor}, other={other_val.tensor}\"\n            )\n        elif isinstance(val, ROIMasks):\n            assert val.tensor.shape == other_val.tensor.shape, (\n                f\"{msg} ROIMasks shape mismatch for field {name}: \"\n                f\"input={val.tensor.shape}, other={other_val.tensor.shape}\"\n            )\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), (\n                f\"{msg} ROIMasks mismatch for field {name}: \"\n                f\"input={val.tensor}, other={other_val.tensor}\"\n            )\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol), (\n                f\"{msg} Tensor mismatch for field {name}: \"\n                f\"input={val}, other={other_val}\"\n            )\n        elif isinstance(val, list):\n            assert len(val) == len(other_val), (\n                f\"{msg} List length mism"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(\n            f\"Expect input and other to be Instances, but got {type(input)} and {type(other)}!\"\n        )\n    assert (\n        input.image_size == other.image_size\n    ), f\"{msg} image_size {input.image_size} != {other.image_size}\"\n    assert len(input) == len(\n        other\n    ), f\"{msg} len(input) {len(input)} != {len(other)}\"\n\n    for name in input._field_names:\n        val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n        if isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), (\n                f\"{msg} {name} {val} != {other_val}\"\n            )\n        elif isinstance(val, ROIMasks):\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), (\n                f\"{msg} {name} {val} != {other_val}\"\n            )\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol), f\"{msg} {name} {val} != {other_val}\"\n        else:\n            assert val == other_val, f\"{msg} {name} {val} != {other_val}\""}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert isinstance(input.image_size, torch.Tensor), input.image_size\n        assert isinstance(other.image_size, torch.Tensor), other.image_size\n        assert torch.equal(input.image_size, other.image_size), (\n            f\"{msg} image_size mismatch: {input.image_size} vs {other.image_size}\"\n        )\n    else:\n        assert isinstance(input.image_size, tuple), input.image_size\n        assert isinstance(other.image_size, tuple), other.image_size\n        assert input.image_size == other.image_size, (\n            f\"{msg} image_size mismatch: {input.image_size} vs {other.image_size}\"\n        )\n\n    for name in input._field_names:\n        val = getattr(input, name)\n        other_val = getattr(other, name)\n        if isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, other_val.tensor), (\n                f\"{msg} Boxes mismatch in {name}: {val} vs {other_val}\"\n            )\n        elif isinstance(val, ROIMasks):\n            assert torch.allclose(val.tensor, other_val.tensor), (\n                f\"{msg} ROIMasks mismatch in {name}: {val} vs {other_val}\"\n            )\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol), (\n                f\"{msg} Tensor mismatch in {name}: {val} vs {other_val}\"\n            )\n        elif isinstance(val, Instances):\n            assert_instances_allclose(val, other_val, rtol=rtol, msg=f\"{msg} {name}.\")\n        else:\n            raise ValueError(f\"{msg} Unsupported type {type(val)} in {name}\")\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert torch.allclose(\n            torch.tensor(input.image_size), torch.tensor(other.image_size), rtol=rtol\n        ), f\"{msg} image_size mismatch: {input.image_size} vs {other.image_size}\"\n    else:\n        assert (\n            input.image_size == other.image_size\n        ), f\"{msg} image_size mismatch: {input.image_size} vs {other.image_size}\"\n    for name in input._field_names:\n        val = getattr(input, name)\n        val_other = getattr(other, name)\n        if isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, val_other.tensor, rtol=rtol), (\n                f\"{msg} Boxes mismatch for {name}: {val.tensor} vs {val_other.tensor}\"\n            )\n        elif isinstance(val, ROIMasks):\n            assert val.tensor.allclose(val_other.tensor, rtol=rtol), (\n                f\"{msg} ROIMasks mismatch for {name}: {val.tensor} vs {val_other.tensor}\"\n            )\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, val_other, rtol=rtol), (\n                f\"{msg} Tensor mismatch for {name}: {val} vs {val_other}\"\n            )\n        elif isinstance(val, Instances):\n            assert_instances_allclose(val, val_other, rtol=rtol, msg=msg + f\"[{name}]\")\n        elif isinstance(val, list):\n            assert len(val) == len(val_other), (\n                f\"{msg} List length mismatch for {name}: {len(val)} vs {len(val_other)}\"\n            )\n            for i, (v, v_other) in enumerate(zip(val, val_other)):\n                if isinstance(v, tor"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), type(input)\n    assert isinstance(other, Instances), type(other)\n    if size_as_tensor:\n        assert torch.allclose(\n            torch.as_tensor(input.image_size), torch.as_tensor(other.image_size)\n        ), f\"{msg} image_size {input.image_size} != {other.image_size}\"\n    else:\n        assert (\n            input.image_size == other.image_size\n        ), f\"{msg} image_size {input.image_size} != {other.image_size}\"\n\n    for name in input._field_names:\n        val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n        if val is None:\n            assert other_val is None, f\"{msg} {name} does not match\"\n        elif isinstance(val, Boxes):\n            assert torch.allclose(\n                val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg} {name} does not match\"\n        elif isinstance(val, ROIMasks):\n            assert torch.allclose(\n                val.tensor, other_val.tensor, rtol=rtol\n            ), f\"{msg} {name} does not match\"\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol), f\"{msg} {name} does not match\"\n        elif isinstance(val, BoxMode):\n            assert val == other_val, f\"{msg} {name} does not match\"\n        elif isinstance(val, bytes):\n            assert val == other_val, f\"{msg} {name} does not match\"\n        elif isinstance(val, dict):\n            assert val == other_val, f\"{msg} {name} does not match\"\n        elif isinstance(val, list):\n            assert all(a == b for a, b in zip(val, other_val)), f"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(\n        other, Instances\n    ), f\"Expect inputs to be Instances objects, but got {type(input)} and {type(other)}!\"\n    if size_as_tensor:\n        assert (\n            input.image_size == other.image_size\n        ), f\"{msg} image_size mismatch: {input.image_size} vs {other.image_size}\"\n    else:\n        assert (\n            input.image_size == other.image_size\n        ), f\"{msg} image_size mismatch: {tuple(input.image_size)} vs {tuple(other.image_size)}\"\n\n    for name in input._field_names:\n        val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n        if val is None:\n            assert (\n                other_val is None\n            ), f\"{msg} {name} mismatch: {val} vs {other_val}\"\n        elif isinstance(val, Boxes):\n            assert isinstance(\n                other_val, Boxes\n            ), f\"{msg} {name} mismatch: {type(val)} vs {type(other_val)}\"\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), (\n                f\"{msg} {name} mismatch: {val} vs {other_val}\"\n            )\n        elif isinstance(val, ROIMasks):\n            assert isinstance(\n                other_val, ROIMasks\n            ), f\"{msg} {name} mismatch: {type(val)} vs {type(other_val)}\"\n            assert val.tensor.shape == other_val.tensor.shape, (\n                f\"{msg} {name} mismatch: {val} vs {other_val}\"\n            )\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), (\n                f\"{msg} {name} mismatch: {val} vs {other_val}\"\n            )\n        elif"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if size_as_tensor:\n        assert isinstance(input.image_size, torch.Tensor)\n        assert isinstance(other.image_size, torch.Tensor)\n        assert torch.allclose(input.image_size, other.image_size)\n    else:\n        assert input.image_size == other.image_size\n\n    for name in input._field_names:\n        val = getattr(input, name)\n        other_val = getattr(other, name)\n        if isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(val, ROIMasks):\n            assert val.tensor.shape == other_val.tensor.shape, msg\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), msg\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol), msg\n        elif isinstance(val, list):\n            assert len(val) == len(other_val)\n            for i in range(len(val)):\n                assert_instances_allclose(val[i], other_val[i], rtol=rtol, msg=msg)\n        elif isinstance(val, dict):\n            assert len(val) == len(other_val)\n            for k in val:\n                assert k in other_val\n                assert_instances_allclose(val[k], other_val[k], rtol=rtol, msg=msg)\n        else:\n            raise ValueError(f\"{type(val)} is not supported.\")\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(\n        other, Instances\n    ), f\"Expect input and other to be Instances, but got {type(input)} and {type(other)}!\"\n    if size_as_tensor:\n        assert torch.allclose(\n            torch.as_tensor(input.image_size), torch.as_tensor(other.image_size)\n        ), f\"{msg} image_size mismatch: {input.image_size} vs {other.image_size}\"\n    else:\n        assert (\n            input.image_size == other.image_size\n        ), f\"{msg} image_size mismatch: {input.image_size} vs {other.image_size}\"\n\n    for name in input._field_names:\n        val = getattr(input, name)\n        other_val = getattr(other, name)\n        if isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, other_val.tensor), (\n                f\"{msg} {name} mismatch: {val} vs {other_val}\"\n            )\n        elif isinstance(val, ROIMasks):\n            assert val.tensor.allclose(other_val.tensor), (\n                f\"{msg} {name} mismatch: {val} vs {other_val}\"\n            )\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol), (\n                f\"{msg} {name} mismatch: {val} vs {other_val}\"\n            )\n        else:\n            raise ValueError(\n                f\"{msg} {name} is of unsupported type {type(val)} in Instances!\"\n            )\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(\n        input, Instances\n    ), f\"Expect input to be an Instances object, but got {type(input)}!\"\n    assert isinstance(\n        other, Instances\n    ), f\"Expect other to be an Instances object, but got {type(other)}!\"\n\n    if size_as_tensor:\n        assert isinstance(\n            input.image_size, torch.Tensor\n        ), f\"Expect input.image_size to be a tensor, but got {type(input.image_size)}!\"\n        assert isinstance(\n            other.image_size, torch.Tensor\n        ), f\"Expect other.image_size to be a tensor, but got {type(other.image_size)}!\"\n        assert torch.equal(\n            input.image_size, other.image_size\n        ), f\"Expect image_size to match, but got {input.image_size} and {other.image_size}!\"\n    else:\n        assert (\n            input.image_size == other.image_size\n        ), f\"Expect image_size to match, but got {input.image_size} and {other.image_size}!\"\n\n    for name in input._field_names:\n        val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n        assert (\n            val is not None\n        ), f\"Expect input to have field {name}, but got {input._field_names}!\"\n        assert (\n            other_val is not None\n        ), f\"Expect other to have field {name}, but got {other._field_names}!\"\n        if isinstance(val, Boxes):\n            assert torch.allclose(\n                val.tensor, other_val.tensor, atol=1e-5\n            ), f\"Expect Boxes to match, but got {val} and {other_val}!\"\n        elif isinstance(val, ROIMasks):\n            assert val.tensor.shape == other_val.tensor.shape, (\n                f\"Expect ROIMasks to match, but got {val."}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    # Check if the image sizes are the same\n    if size_as_tensor:\n        assert torch.equal(input.image_size, other.image_size), msg\n    else:\n        assert input.image_size == other.image_size, msg\n\n    # Check if the fields are the same\n    for name in input._field_names:\n        val = getattr(input, \"_\" + name, None)\n        other_val = getattr(other, \"_\" + name, None)\n\n        # If both are None, skip\n        if val is None and other_val is None:\n            continue\n\n        # If one is None, assert False\n        if val is None or other_val is None:\n            assert False, msg\n\n        # If both are Boxes, check if they are equal\n        if isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, other_val.tensor), msg\n\n        # If both are ROIMasks, check if they are equal\n        elif isinstance(val, ROIMasks):\n            assert torch.allclose(val.tensor, other_val.tensor), msg\n\n        # If both are tensors, check if they are equal or close\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol), msg\n\n        # If both are lists, check if they are equal\n        elif isinstance(val, list):\n            assert val == other_val, msg\n\n        # If both are dicts, check if they are equal\n        elif isinstance(val, dict):\n            assert val == other_val, msg\n\n        # If none of the above conditions are met, raise a ValueError\n        else:\n            raise ValueError(f\"Unknown type of field: {type(val)}\")"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances), type(input)\n    assert isinstance(other, Instances), type(other)\n    if size_as_tensor:\n        assert input.image_size == other.image_size, (\n            f\"{msg} image_size not equal: \"\n            f\"{input.image_size} vs {other.image_size}\"\n        )\n    else:\n        assert input.image_size == other.image_size, (\n            f\"{msg} image_size not equal: \"\n            f\"{input.image_size} vs {other.image_size}\"\n        )\n\n    for name in input._field_names:\n        val = getattr(input, name)\n        val_ = getattr(other, name)\n        if isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, val_.tensor, rtol=rtol), (\n                f\"{msg} {name} not equal: \"\n                f\"{val.tensor} vs {val_.tensor}\"\n            )\n        elif isinstance(val, ROIMasks):\n            assert val == val_, (\n                f\"{msg} {name} not equal: \"\n                f\"{val} vs {val_}\"\n            )\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, val_, rtol=rtol), (\n                f\"{msg} {name} not equal: \"\n                f\"{val} vs {val_}\"\n            )\n        elif isinstance(val, Instances):\n            assert_instances_allclose(val, val_, rtol=rtol, msg=msg + f\".{name}\")\n        else:\n            raise ValueError(f\"{msg} {name} has unsupported type {type(val)}\")\n\n"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    assert isinstance(input, Instances) and isinstance(other, Instances), (\n        f\"Expect input and other to be Instances, but got {type(input)} and {type(other)}\"\n    )\n    assert input.image_size == other.image_size, (\n        f\"image_size mismatch: {input.image_size} vs. {other.image_size}\"\n    )\n    if size_as_tensor:\n        assert torch.allclose(\n            torch.as_tensor(input.image_size, dtype=torch.int64),\n            torch.as_tensor(other.image_size, dtype=torch.int64),\n            rtol=0,\n            atol=0,\n        ), f\"image_size mismatch: {input.image_size} vs. {other.image_size}\"\n\n    for name in input._field_names:\n        val = getattr(input, name)\n        other_val = getattr(other, name)\n        assert type(val) == type(\n            other_val\n        ), f\"{msg} {name} has different types: {type(val)} vs. {type(other_val)}\"\n        if isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol, atol=0), (\n                f\"{msg} {name} does not match: {val.tensor} vs. {other_val.tensor}\"\n            )\n        elif isinstance(val, ROIMasks):\n            assert val.tensor.shape == other_val.tensor.shape, (\n                f\"{msg} {name} does not match: {val.tensor.shape} vs. {other_val.tensor.shape}\"\n            )\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol, atol=0), (\n                f\"{msg} {name} does not match: {val} vs. {other_val}\"\n            )\n        else:"}
{"namespace": "detectron2.utils.testing.assert_instances_allclose", "completion": "    if not isinstance(input, Instances) or not isinstance(other, Instances):\n        raise ValueError(\n            \"assert_instances_allclose() requires two inputs of type Instances.\"\n        )\n    assert input.image_size == other.image_size, msg + \"image_size mismatch\"\n    if size_as_tensor:\n        assert torch.allclose(\n            input.image_size_tensor, other.image_size_tensor, rtol=rtol\n        ), msg + \"image_size_tensor mismatch\"\n    for name in input._field_names:\n        val = getattr(input, name, None)\n        other_val = getattr(other, name, None)\n        if val is None:\n            assert other_val is None, msg + f\"{name} mismatch\"\n            continue\n        if isinstance(val, Boxes):\n            assert torch.allclose(val.tensor, other_val.tensor, rtol=rtol), msg + name\n        elif isinstance(val, ROIMasks):\n            assert val == other_val, msg + name\n        elif isinstance(val, torch.Tensor):\n            assert torch.allclose(val, other_val, rtol=rtol), msg + name\n        else:\n            assert val == other_val, msg + name\n\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = (box[:, 2] * box[:, 3]).to(box.dtype)\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        boxes = self.tensor\n        area = (boxes[:, 2] * boxes[:, 3]).to(boxes.dtype)\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = (box[:, 2] * box[:, 3]).to(box.dtype)\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = (box[:, 2] * box[:, 3]).to(box.dtype)\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        boxes = self.tensor\n        return boxes[:, 2] * boxes[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = (box[:, 2] * box[:, 3]).to(box.dtype)\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        boxes = self.tensor\n        return (boxes[:, 2] * boxes[:, 3]).to(boxes.dtype)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        boxes = self.tensor\n        return (boxes[:, 2] * boxes[:, 3]).to(boxes.dtype)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        boxes = self.tensor\n        return (boxes[:, 2] * boxes[:, 3]).to(boxes.dtype)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        boxes = self.tensor\n        return boxes[:, 2] * boxes[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = (box[:, 2] * box[:, 3]).to(box.dtype)\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        boxes = self.tensor\n        area = (boxes[:, 2] * boxes[:, 3]).to(boxes.dtype)\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = (box[:, 2] * box[:, 3]).to(box.dtype)\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = (box[:, 2] * box[:, 3]).to(box.dtype)\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = (box[:, 2] * box[:, 3]).to(box.dtype)\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        boxes = self.tensor\n        return boxes[:, 2] * boxes[:, 3]\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        boxes = self.tensor\n        area = (boxes[:, 2] * boxes[:, 3]).to(boxes.dtype)\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = (box[:, 2] * box[:, 3]).to(box.dtype)\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        box = self.tensor\n        area = (box[:, 2] * box[:, 3]).to(box.dtype)\n        return area\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.area", "completion": "        boxes = self.tensor\n        area = (boxes[:, 2] * boxes[:, 3]).to(boxes.dtype)\n        return area\n"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.proposal_generator.build.build_proposal_generator", "completion": "    \"\"\"\n    name = cfg.MODEL.PROPOSAL_GENERATOR.NAME\n    if name == \"PrecomputedProposals\":\n        return None\n\n    return PROPOSAL_GENERATOR_REGISTRY.get(name)(cfg, input_shape)"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals):\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            assert not proposal_boxes.requires_grad, \"Proposals do not need gradients!\"\n            # If \"gt_boxes\" does not exist, the proposals must be all negative and\n            # should not be included in regression loss computation and proposal_boxes\n            # should be an empty tensor.\n            # Here we just use an all zero tensor in the place of gt_boxes.\n            gt_boxes = cat(\n                [(p.gt_boxes if p.has(\"gt_boxes\") else p.proposal_boxes).tensor for p in proposals],\n                dim=0,\n            )\n        else:\n            proposal_boxes = gt_boxes = torch.empty((0, 4))\n\n        if self.cls_agnostic_bbox_reg:\n            box_dim = proposal_deltas.shape[1] // self.num_classes\n            gt_classes = cat([gt_classes.new_zeros(proposal_deltas.shape[0], box_dim)], dim=1)\n\n        losses = {\n            \"loss_cls\": cross_entropy(scores, gt_classes, reduction=\"mean\"),\n            \"loss_box_reg\": _dense_box_regression_loss(\n                proposal_boxes,\n                gt_boxes,\n                proposal_deltas,\n                self.box2box_transform,\n                smooth_l1_beta=self.smooth_l1_beta,\n                box_reg_loss_type=self.box_reg_loss_type,\n            ),"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = {}\n\n        # parse classification outputs\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals) == 0:\n            losses[\"loss_cls\"] = scores.sum() * 0\n            losses[\"loss_box_reg\"] = proposal_deltas.sum() * 0\n            return losses\n\n        # classification loss\n        loss_cls = cross_entropy(scores, gt_classes, reduction=\"mean\")\n        losses[\"loss_cls\"] = loss_cls * self.loss_weight.get(\"loss_cls\", 1.0)\n\n        # box regression\n        if len(proposal_deltas) == 0:\n            losses[\"loss_box_reg\"] = proposal_deltas.sum() * 0\n            return losses\n\n        # parse classification outputs\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals) == 0:\n            losses[\"loss_cls\"] = scores.sum() * 0\n            losses[\"loss_box_reg\"] = proposal_deltas.sum() * 0\n            return losses\n\n        # classification loss\n        loss_cls = cross_entropy(scores, gt_classes, reduction=\"mean\")\n        losses[\"loss_cls\"] = loss_cls * self.loss_weight.get(\"loss_cls\", 1.0)\n\n        # box regression\n        if len(proposal_deltas) == 0:\n            losses[\"loss_box_reg\"] = proposal_deltas.sum() * 0\n            return losses\n\n        gt_boxes = cat([p.gt_boxes.tensor for p in proposals], dim=0)  # Rx4\n        normalizer = self.box2box_transform.normalizer\n        if len(gt_boxes) == 0:"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        _log_classification_stats(scores, gt_classes)\n\n        # parse box regression outputs\n        if len(proposal_deltas) > 0:\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            assert not proposal_boxes.requires_grad, \"Proposals do not need gradients!\"\n            # If \"gt_boxes\" does not exist, the proposals must be all negative and\n            # should not be included in regression loss computation.\n            # Here we just use proposal_boxes as an arbitrary placeholder because its\n            # value won't be used in self.box_reg_loss().\n            gt_boxes = cat([(p.gt_boxes if p.has(\"gt_boxes\") else p.proposal_boxes).tensor for p in proposals], dim=0)\n        else:\n            proposal_boxes = gt_boxes = torch.empty((0, 4), device=proposal_deltas.device)\n\n        # cls and box loss\n        loss_cls = cross_entropy(scores, gt_classes, reduction=\"mean\")\n        loss_box_reg = _dense_box_regression_loss(\n            proposal_boxes,\n            gt_boxes,\n            proposal_deltas.view(-1, proposal_deltas.shape[-1]),\n            self.box2box_transform,\n            smooth_l1_beta=self.smooth_l1_beta,\n            box_reg_loss_type=self.box_reg_loss_type,\n            reduction=\"mean\",\n        )\n        return {\n            \"loss_cls\": self.loss_weight.get(\"loss_cls\", 1.0) * loss_cls,\n            \"loss_box_reg\": self.loss_weight.get(\"loss_box_reg\", "}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals):\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            assert not proposal_boxes.requires_grad, \"Proposals do not need gradients!\"\n            # If \"gt_boxes\" does not exist, the proposals must be all negative and\n            # should not be included in regression loss computation and proposal_boxes\n            # should be an empty tensor.\n            if len(proposals[0].gt_boxes):\n                gt_boxes = cat([p.gt_boxes.tensor for p in proposals], dim=0)  # Nx4\n            else:\n                gt_boxes = torch.empty((0, 4))\n\n            # box regression\n            if self.box_reg_loss_type == \"smooth_l1\":\n                gt_deltas = self.box2box_transform.get_deltas(proposal_boxes, gt_boxes)\n                loss_box_reg = smooth_l1_loss(\n                    proposal_deltas,\n                    gt_deltas,\n                    proposal_deltas.size(1) // 4,\n                    reduction=\"mean\",\n                    beta=self.smooth_l1_beta,\n                )\n            else:\n                loss_box_reg = _dense_box_regression_loss(\n                    proposal_deltas, gt_deltas, proposal_deltas.size(1) // 4\n                )\n        else:\n            gt_boxes = torch.empty((0, 4))\n            loss_box_reg = proposal_deltas.sum() * 0\n\n        return {\n            \"loss"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        _log_classification_stats(scores, gt_classes)\n\n        # parse box regression outputs\n        if len(proposal_deltas) > 0:\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            box_dim = proposal_deltas.size(1) // self.num_classes\n            cls_agnostic_bbox_reg = self.box2box_transform.weights is None\n            box_deltas = proposal_deltas.view(-1, self.num_classes, box_dim)\n            if cls_agnostic_bbox_reg:\n                box_deltas = box_deltas[:, 0]\n\n            if self.box_reg_loss_type == \"smooth_l1\":\n                gt_proposal_deltas = [\n                    p.gt_boxes.tensor - p.proposal_boxes.tensor if len(p.gt_boxes.tensor) > 0 else torch.zeros_like(p.proposal_boxes.tensor)\n                    for p in proposals\n                ]\n                gt_proposal_deltas = cat(gt_proposal_deltas, dim=0)\n            else:\n                # gt_proposal_deltas = [p.gt_boxes.tensor for p in proposals]\n                gt_proposal_deltas = cat([p.gt_boxes.tensor for p in proposals], dim=0)\n        else:\n            box_deltas = torch.zeros_like(proposal_deltas)\n            gt_proposal_deltas = torch.zeros_like(proposal_deltas)\n\n        losses = {\n            \"loss_cls\": cross_entropy(scores, gt_classes, reduction="}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals):\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            assert not proposal_boxes.requires_grad, \"Proposals do not need gradients!\"\n            # If \"gt_boxes\" does not exist, the proposals must be all negative and\n            # should not be included in loss computation.\n            if \"gt_boxes\" in proposals[0]:\n                gt_boxes = cat([p.gt_boxes.tensor for p in proposals], dim=0)\n            else:\n                log_first_n(\n                    logging.WARN,\n                    \"'gt_boxes' does not exist in proposal predictions, \"\n                    \"therefore any proposal whose gt_classes=0 will not be used \"\n                    \"as ground-truth.  This behavior is not recommended.\",\n                    n=10,\n                )\n                gt_boxes = torch.zeros_like(proposal_boxes)\n        else:\n            gt_boxes = gt_classes.new_zeros((0, 4))\n\n        # parse box regression outputs\n        if len(proposals):\n            box_dim = gt_boxes.shape[1]  # 4 or 5\n            cls_agnostic_bbox_reg = self.box2box_transform.cls_agnostic_bbox_reg\n            box_regression_per_level = self.box2box_transform.apply_deltas(\n                deltas=proposal_deltas, boxes=proposal_boxes\n            )\n            box_regression_flattened = []\n            # for each feature level, permute the outputs to make them be in the\n           "}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        _log_classification_stats(scores, gt_classes)\n\n        # parse box regression outputs\n        if len(proposals):\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            assert not proposal_boxes.requires_grad, \"Proposals do not support gradient computation\"\n            gt_boxes = cat([(p.gt_boxes if p.has(\"gt_boxes\") else p.proposal_boxes).tensor for p in proposals], dim=0)\n        else:\n            proposal_boxes = gt_boxes = torch.empty((0, 4))\n\n        if self.cls_agnostic_bbox_reg:\n            box_dim = gt_boxes.size(1)  # 4 or 5\n            cls_agnostic_bbox_reg = proposal_deltas.size(1) == box_dim\n            if not cls_agnostic_bbox_reg:\n                raise ValueError(\"Class agnostic regression was specified for \" \"box deltas of shape {}.\".format(proposal_deltas.shape))\n        else:\n            box_dim = proposal_deltas.size(1) // self.num_classes\n            if box_dim != 4:\n                raise ValueError(\n                    \"In the non-class specific bbox regression the \"\n                    \"bbox deltas should have shape (N, 4) or (N, 5). Got {}\".format(proposal_deltas.shape)\n                )\n\n        if self.cls_agnostic_bbox_reg:\n            box_deltas = proposal_deltas\n        else:\n            box_deltas = proposal_deltas.view(-1, self.num_classes"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        _log_classification_stats(scores, gt_classes)\n\n        # parse box regression outputs\n        if len(proposal_deltas) > 0:\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            assert not proposal_boxes.requires_grad, \"Proposals do not need gradients!\"\n            # If \"gt_boxes\" does not exist, the proposals must be all negative and\n            # should not be included in regression loss computation.\n            # Here we just use proposal_boxes as an arbitrary placeholder because the\n            # Fast R-CNN network cannot handle the case where there are no visible\n            # ground-truth boxes.\n            gt_boxes = cat([(p.gt_boxes if p.has(\"gt_boxes\") else p.proposal_boxes).tensor for p in proposals], dim=0)\n        else:\n            # get_dummy_proposal_boxes() creates an empty box tensor.\n            proposal_boxes = get_dummy_proposal_boxes()\n            gt_boxes = get_dummy_proposal_boxes()\n\n        # cls_loss = F.cross_entropy(scores, gt_classes)\n        # box_loss = _dense_box_regression_loss(\n        #     proposal_boxes,\n        #     gt_boxes,\n        #     proposal_deltas,\n        #     self.box2box_transform,\n        #     smooth_l1_beta=self.smooth_l1_beta,\n        #     box_reg_loss_type=self.box_reg_loss_type,\n        #     reduction=\"mean\",\n        # )\n\n        # return {\n        #     \"loss_cls\": self.loss_weight.get(\"loss_cls\", 1.0) * cls"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        _log_classification_stats(scores, gt_classes)\n\n        # parse box regression outputs\n        if len(proposal_deltas) > 0:\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            box_dim = proposal_deltas.size(1) // self.num_classes\n            cls_agnostic_bbox_reg = self.box2box_transform.weights is None\n            if cls_agnostic_bbox_reg:\n                proposal_deltas = proposal_deltas.view(-1, box_dim)\n                box_pred = self.box2box_transform.apply_deltas(\n                    proposal_deltas, proposal_boxes\n                )\n            else:\n                box_pred = self.box2box_transform.apply_deltas(\n                    proposal_deltas.view(-1, self.num_classes, box_dim), proposal_boxes\n                )\n\n        losses = {\"loss_cls\": cross_entropy(scores, gt_classes, reduction=\"mean\")}\n\n        if len(proposal_deltas) > 0:\n            losses[\"loss_box_reg\"] = _dense_box_regression_loss(\n                box_pred,\n                cat([p.gt_boxes.tensor for p in proposals], dim=0),\n                cat(\n                    [p.gt_classes for p in proposals],\n                    dim=0,\n                ),\n                self.smooth_l1_beta,\n                self.box_reg_loss_type,\n                weight=self.loss_weight.get(\"loss_box_reg\", None),\n            )\n\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals):\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            assert not proposal_boxes.requires_grad, \"Proposals do not need gradients!\"\n            # If \"gt_boxes\" does not exist, the proposals must be all negative and\n            # should not be included in regression loss computation and proposal_boxes\n            # should be an empty tensor.\n            if proposals[0].has(\"gt_boxes\"):\n                gt_boxes = cat([p.gt_boxes.tensor for p in proposals], dim=0)  # Nx4\n            else:\n                gt_boxes = torch.empty((0, 4))\n\n            # figuring out the prediction and target for the loss\n            # based on which branch of mask head to take\n            if self.box_reg_loss_type == \"smooth_l1\":\n                # smooth l1 loss\n                loss_box_reg = _dense_box_regression_loss(\n                    proposal_boxes,\n                    gt_boxes,\n                    proposal_deltas,\n                    self.box2box_transform,\n                    smooth_l1_beta=self.smooth_l1_beta,\n                )\n            else:\n                raise ValueError(f\"Invalid bbox reg loss type {self.box_reg_loss_type}\")\n\n            losses = {\n                \"loss_cls\": F.cross_entropy(scores, gt_classes),\n                \"loss_box_reg\": loss_box_reg,\n            }\n        else:\n            losses = {\n                \"loss_cls\": F.cross_entropy(scores, gt_classes),\n                \"loss_"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals) == 0:\n            return {\n                \"loss_cls\": scores.sum() * 0,\n                \"loss_box_reg\": proposal_deltas.sum() * 0,\n            }\n\n        proposals = self.box2box_transform.apply_deltas(proposals, proposal_deltas)\n\n        # parse classification label\n        loss_cls = cross_entropy(scores, gt_classes, reduction=\"mean\")\n\n        # parse box regression outputs\n        if self.box_reg_loss_type == \"smooth_l1\":\n            gt_proposal_deltas = [\n                p.proposal_boxes.tensor - p.gt_boxes.tensor for p in proposals\n            ]\n            box_dim = gt_proposal_deltas[0].size(-1)  # 4 or 5\n            gt_proposal_deltas = torch.cat(gt_proposal_deltas, dim=0)\n            if self.smooth_l1_beta < 1e-5:\n                # if smooth_l1_beta == 0, then we use L1 loss instead of smooth L1 loss.\n                loss_box_reg = F.l1_loss(\n                    proposal_deltas, gt_proposal_deltas, reduction=\"none\"\n                )\n            else:\n                loss_box_reg = _dense_box_regression_loss(\n                    proposal_deltas,\n                    gt_proposal_deltas,\n                    self.smooth_l1_beta,\n                )\n            loss_box_reg = loss_box_reg.sum() / box_dim\n        elif self.box_reg_loss_type == \"giou\":\n            loss_box_reg = giou_loss"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = {}\n\n        # parse classification outputs\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals) == 0:\n            losses[\"loss_cls\"] = sum(self.loss_weight.values()) * scores.sum()\n            losses[\"loss_box_reg\"] = sum(self.loss_weight.values()) * proposal_deltas.sum()\n            return losses\n\n        # classification loss\n        loss_cls = cross_entropy(scores, gt_classes, reduction=\"mean\")\n        losses[\"loss_cls\"] = loss_cls * self.loss_weight.get(\"loss_cls\", 1.0)\n\n        # box regression\n        if self.box_reg_loss_type == \"smooth_l1\":\n            gt_proposal_deltas = [\n                p.proposal_boxes.tensor - p.gt_boxes.tensor for p in proposals\n            ]\n            loss_box_reg = _dense_box_regression_loss(\n                proposal_deltas,\n                cat(gt_proposal_deltas, dim=0),\n                self.smooth_l1_beta,\n                reduction=\"mean\",\n            )\n        else:\n            raise ValueError(f\"Invalid bbox reg loss type {self.box_reg_loss_type}\")\n\n        losses[\"loss_box_reg\"] = loss_box_reg * self.loss_weight.get(\"loss_box_reg\", 1.0)\n        return losses\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals):\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            assert not proposal_boxes.requires_grad, \"Proposals do not support gradient computation\"\n            # If \"gt_boxes\" does not exist, the proposals must be all negative and\n            # should not be included in regression loss computation and proposal_boxes\n            # should be None.\n            # Here we just use a dummy box as placeholder and label it as background\n            # (0).\n            gt_boxes = cat([(p.gt_boxes if p.has(\"gt_boxes\") else p.proposal_boxes).tensor for p in proposals], dim=0)\n        else:\n            proposal_boxes = gt_boxes = torch.empty((0, 4), device=proposal_deltas.device)\n\n        # Box regression loss\n        losses = {\n            \"loss_box_reg\": _dense_box_regression_loss(\n                proposal_boxes,\n                gt_boxes,\n                proposal_deltas,\n                self.box2box_transform,\n                box_dim=gt_boxes.shape[-1],\n                smooth_l1_beta=self.smooth_l1_beta,\n                box_reg_loss_type=self.box_reg_loss_type,\n            )\n        }\n\n        # Classification loss\n        if gt_classes.numel() > 0:\n            loss_cls = cross_entropy(scores, gt_classes, reduction=\"mean\")\n            losses[\"loss_cls\"] = loss_cls\n        else:\n            # The network predicts nothing when there are no ground-"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals):\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            assert not proposal_boxes.requires_grad, \"Proposals do not need gradients!\"\n            # If \"gt_boxes\" does not exist, the proposals must be all negative and\n            # should not be included in regression loss computation and proposal_boxes\n            # should be used instead.\n            # TODO this is a hack to handle COCO vs. LVIS sampling\n            if proposals[0].has(\"gt_boxes\"):\n                gt_boxes = cat([p.gt_boxes.tensor for p in proposals], dim=0)\n            else:\n                gt_boxes = proposal_boxes\n            gt_boxes = Boxes(gt_boxes)\n\n            # regression loss\n            if self.box_reg_loss_type == \"smooth_l1\":\n                loss_box_reg = smooth_l1_loss(\n                    proposal_boxes,\n                    gt_boxes,\n                    proposal_deltas,\n                    self.smooth_l1_beta,\n                    reduction=\"none\",\n                )\n            elif self.box_reg_loss_type == \"giou\":\n                loss_box_reg = giou_loss(\n                    proposal_boxes, gt_boxes, reduction=\"none\", loss_type=self.box_reg_loss_type\n                )\n            elif self.box_reg_loss_type == \"diou\":\n                loss_box_reg = giou_loss(\n                    proposal_boxes, gt_boxes, reduction=\"none\", loss_type=self.box_reg_loss_type\n                )"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals):\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            assert not proposal_boxes.requires_grad, \"Proposals do not need gradients!\"\n            # If \"gt_boxes\" does not exist, the proposals must be all negative and\n            # should not be included in regression loss computation and proposal_boxes\n            # should be an empty tensor.\n            if len(proposals) and \"gt_boxes\" in proposals[0]:\n                gt_boxes = cat([p.gt_boxes.tensor for p in proposals], dim=0)  # Nx4\n            else:\n                gt_boxes = torch.empty((0, 4))\n\n            # fig, ax = plt.subplots(1, 1)\n            # ax.imshow(cv2.imread(\"./input.jpg\"))\n            # proposal_boxes = proposal_boxes.cpu().numpy()\n            # gt_boxes = gt_boxes.cpu().numpy()\n            # for box in proposal_boxes:\n            #     x1, y1, x2, y2 = box\n            #     w, h = x2 - x1, y2 - y1\n            #     rect = patches.Rectangle((x1, y1), w, h, linewidth=1, edgecolor='r', facecolor='none')\n            #     ax.add_patch(rect)\n            # for box in gt_boxes:\n            #     x1, y1, x2, y2 = box\n            #     w, h = x2 - x1, y2 - y1\n            #     rect = patches."}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        _log_classification_stats(scores, gt_classes)\n\n        # parse box regression outputs\n        if len(proposal_deltas) > 0:\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n        else:\n            proposal_boxes = proposal_deltas.new_zeros((0, 4))\n\n        if self.cls_agnostic_bbox_reg:\n            box_dim = proposal_deltas.size(1) // self.num_classes\n            gt_proposal_deltas = [\n                cat([p.gt_boxes.tensor for p in proposals], dim=0).view(-1, box_dim)\n                for proposals in proposals\n            ]\n        else:\n            gt_proposal_deltas = [\n                p.gt_boxes.tensor - p.proposal_boxes.tensor\n                for p in proposals\n            ]\n        deltas = self.box2box_transform.get_deltas(proposal_boxes, gt_proposal_deltas)\n\n        losses = {\n            \"loss_cls\": F.cross_entropy(scores, gt_classes, reduction=\"mean\"),\n            \"loss_box_reg\": _dense_box_regression_loss(\n                deltas,\n                gt_proposal_deltas,\n                proposal_boxes,\n                smooth_l1_beta=self.smooth_l1_beta,\n                box_reg_loss_type=self.box_reg_loss_type,\n            ),\n        }\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = {}\n\n        # parse classification outputs\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals) == 0:\n            losses[\"loss_cls\"] = sum(scores.new_tensor(0.0))[None]\n            losses[\"loss_box_reg\"] = sum(proposal_deltas.new_tensor(0.0))[None]\n            return losses\n\n        # classification loss\n        losses[\"loss_cls\"] = cross_entropy(scores, gt_classes, reduction=\"mean\")\n\n        # box regression loss\n        if self.box_reg_loss_type == \"smooth_l1\":\n            gt_proposal_deltas = [\n                p.proposal_boxes.tensor - p.gt_boxes.tensor for p in proposals\n            ]\n            gt_proposal_deltas = cat(gt_proposal_deltas, dim=0)\n            losses[\"loss_box_reg\"] = smooth_l1_loss(\n                proposal_deltas,\n                gt_proposal_deltas,\n                beta=self.smooth_l1_beta,\n                reduction=\"mean\",\n            )\n        else:\n            losses[\"loss_box_reg\"] = _dense_box_regression_loss(\n                proposal_deltas,\n                [p.gt_boxes.tensor for p in proposals],\n                self.box2box_transform,\n                box_reg_loss_type=self.box_reg_loss_type,\n                smooth_l1_beta=self.smooth_l1_beta,\n            )\n\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        _log_classification_stats(scores, gt_classes)\n\n        # parse box regression outputs\n        if len(proposal_deltas) > 0:\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            box_dim = proposal_deltas.size(1) // self.num_classes\n            gt_boxes = cat([p.gt_boxes.tensor for p in proposals], dim=0)\n            if not hasattr(self.box2box_transform, \"weights\"):\n                # Rely on the box list implementation in Boxes\n                # (which supports generalized boxes via a tensor-based implementation)\n                proposal_deltas = proposal_deltas.reshape(-1, self.num_classes, box_dim)\n                losses = {\n                    \"loss_box_reg\": _dense_box_regression_loss(\n                        proposal_boxes,\n                        gt_boxes,\n                        proposal_deltas,\n                        self.box2box_transform,\n                        box_dim,\n                        smooth_l1_beta=self.smooth_l1_beta,\n                        box_reg_loss_type=self.box_reg_loss_type,\n                    )\n                }\n            else:\n                raise NotImplementedError(\n                    \"Hasattr box2box_transform.weights, but dense_box_regression_loss is not implemented for it\"\n                )\n        else:\n            losses = {\"loss_box_reg\": proposal_deltas.sum() * 0}\n\n        return {k: v * self.loss_weight.get(k, 1.0) for k, v in losses.items()}\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n        losses = {}\n\n        # parse classification outputs\n        gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals) == 0:\n            losses[\"loss_cls\"] = sum(self.losses[\"loss_cls\"]) * 0\n            losses[\"loss_box_reg\"] = sum(self.losses[\"loss_box_reg\"]) * 0\n            return losses\n\n        # classification loss\n        loss_cls = cross_entropy(scores, gt_classes, reduction=\"mean\")\n        losses[\"loss_cls\"] = loss_cls * self.loss_weight[\"loss_cls\"]\n\n        # box regression\n        if self.box_reg_loss_type == \"smooth_l1\":\n            gt_proposal_deltas = [\n                p.proposal_boxes.tensor - p.gt_boxes.tensor for p in proposals\n            ]\n            box_deltas = proposal_deltas.view(len(proposals), -1, 4)\n            loss_box_reg = smooth_l1_loss(\n                box_deltas,\n                cat(gt_proposal_deltas, dim=0),\n                beta=self.smooth_l1_beta,\n                reduction=\"mean\",\n            )\n        else:\n            raise ValueError(f\"Invalid bbox reg loss type {self.box_reg_loss_type}\")\n\n        loss_box_reg *= self.loss_weight[\"loss_box_reg\"]\n        losses[\"loss_box_reg\"] = loss_box_reg\n\n        return losses\n"}
{"namespace": "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.losses", "completion": "        scores, proposal_deltas = predictions\n\n        # parse classification outputs\n        gt_classes = (\n            cat([p.gt_classes for p in proposals], dim=0) if len(proposals) else torch.empty(0)\n        )\n        _log_classification_stats(scores, gt_classes)\n\n        if len(proposals):\n            proposal_boxes = cat([p.proposal_boxes.tensor for p in proposals], dim=0)  # Nx4\n            assert not proposal_boxes.requires_grad, \"Proposals do not support gradient computation\"\n            # If \"gt_classes\" does not exist, the proposals must be all negative and\n            # should not be included in regression loss computation and proposal_boxes\n            # should be an empty tensor.\n            if \"gt_classes\" in proposals[0]:\n                gt_classes = cat([p.gt_classes for p in proposals], dim=0)\n                # Positive proposal is defined as proposal with\n                # at least one foreground (non-background) class\n                gt_classes_nonempty = nonzero_tuple(gt_classes)[0]\n                gt_boxes = cat([p.gt_boxes.tensor[p.gt_classes != self.num_classes] for p in proposals], dim=0)\n                proposal_boxes = proposal_boxes[gt_classes_nonempty]\n            else:\n                gt_boxes = torch.empty((0, 4))\n\n            # logits for labels\n            logits_pred = cat([x.pred_logits for x in proposals], dim=0)\n            # Regression loss\n            if len(proposal_boxes):\n                if self.box_reg_loss_type == \"smooth_l1\":\n                    gt_deltas = self.box2box_transform.get_deltas(proposal_boxes, gt_boxes)\n                    box_loss = _dense_box_regression_loss(\n                        proposal_deltas[gt_classes_nonempty],\n                        gt_"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER.NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER.TRACKER_NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER.TRACKER_HEAD\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.TRACKER.TRACKER_HEAD\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER.TRACKER_NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER.NAME\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    name = cfg.MODEL.TRACKER_HEAD.NAME\n    return TRACKER_HEADS_REGISTRY.get(name)(cfg)"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER.TRACKER_HEAD\n    tracker = TRACKER_HEADS_REGISTRY.get(tracker_name)(cfg)\n    return tracker"}
{"namespace": "detectron2.tracking.base_tracker.build_tracker_head", "completion": "    tracker_name = cfg.TRACKER.NAME\n    tracker_class = TRACKER_HEADS_REGISTRY.get(tracker_name)\n    return tracker_class(cfg)"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        if deltas.numel() == 0:\n            return torch.empty_like(deltas)\n\n        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        if deltas.numel() == 0:\n            return torch.empty_like(deltas)\n\n        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        if deltas.numel() == 0:\n            return torch.empty_like(deltas)\n\n        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        if deltas.numel() == 0:\n            return torch.empty_like(deltas)\n\n        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        if deltas.numel() == 0:\n            return torch.empty_like(deltas)\n\n        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        if deltas.numel() == 0:\n            return torch.empty_like(deltas)\n\n        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        if deltas.numel() == 0:\n            return torch.empty_like(deltas)\n\n        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        if deltas.numel() == 0:\n            return torch.empty_like(deltas)\n\n        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w - 1  # x2 (note: -1 is correct; see"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        if deltas.numel() == 0:\n            return torch.empty_like(deltas)\n\n        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w - 1  # x2 (note: -1 is correct;"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w - 1  # x2 (note: -1 is correct)\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h - "}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_box"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        deltas = deltas.float()  # ensure fp32 for decoding precision\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w - 1  # x2 (note: -1 is correct)\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h - "}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        assert torch.isfinite(deltas).all().item()\n        boxes = boxes.to(deltas.dtype)\n\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2\n        pred_boxes[:, 3::4] = pred_ctr_y + 0.5 * pred_h  # y2\n\n        return pred_boxes\n"}
{"namespace": "detectron2.modeling.box_regression.Box2BoxTransform.apply_deltas", "completion": "        # If deltas is empty, return early\n        if deltas.numel() == 0:\n            return deltas\n\n        # Get the dimensions of the boxes tensor\n        boxes = boxes.to(deltas.dtype)\n        widths = boxes[:, 2] - boxes[:, 0]\n        heights = boxes[:, 3] - boxes[:, 1]\n        ctr_x = boxes[:, 0] + 0.5 * widths\n        ctr_y = boxes[:, 1] + 0.5 * heights\n\n        # Apply the transformation deltas to the boxes\n        wx, wy, ww, wh = self.weights\n        dx = deltas[:, 0::4] / wx\n        dy = deltas[:, 1::4] / wy\n        dw = deltas[:, 2::4] / ww\n        dh = deltas[:, 3::4] / wh\n\n        # Prevent sending too large values into torch.exp()\n        dw = torch.clamp(dw, max=self.scale_clamp)\n        dh = torch.clamp(dh, max=self.scale_clamp)\n\n        pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]\n        pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]\n        pred_w = torch.exp(dw) * widths[:, None]\n        pred_h = torch.exp(dh) * heights[:, None]\n\n        # Compute the predicted boxes\n        pred_boxes = torch.zeros_like(deltas)\n        pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w  # x1\n        pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h  # y1\n        pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w  # x2"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            return self.general_ins(image)[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            return {\n                tp: self.general_ins(image)[tp]\n                for tp in anno_type if tp in self.general_ins(image)\n            }\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        output = self.general_ins(image)\n        if anno_type is None:\n            return output\n        else:\n            if len(anno_type) == 1:\n                return output[anno_type[0]]\n            else:\n                return {tp: output[tp] for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        output = self.general_ins(image)\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                return output[anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                return {tp: output[tp] for tp in anno_type}\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins(image)\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {tp: output[tp] for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        output = self.general_ins(image)\n        if anno_type is None:\n            return output\n        if isinstance(anno_type, str):\n            assert anno_type in output.keys()\n            return output[anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in output.keys() for tp in anno_type)\n            return {tp: output[tp] for tp in anno_type}\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.anno_type_map.keys()\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins(image)\n        if len(anno_type) == 1:\n            anno_type = anno_type[0]\n            if anno_type in output.keys():\n                return output[anno_type]\n            else:\n                return None\n        else:\n            return {tp: output[tp] for tp in anno_type if tp in output.keys()}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif anno_type is None:\n            anno_type = []\n\n        output = self.general_ins(image)\n        if len(anno_type) == 0:\n            return output\n        else:\n            if len(anno_type) == 1:\n                return output[anno_type[0]]\n            else:\n                return {tp: output[tp] for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        else:\n            assert isinstance(anno_type, (list, tuple))\n\n        anno_dict = self.general_ins(image)\n        anno_dict = {\n            k: v\n            for k, v in anno_dict.items() if k in anno_type\n        }\n\n        if len(anno_dict) == 1:\n            return list(anno_dict.values())[0]\n        else:\n            return anno_dict"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        image, k = resize_image(image, 512)\n        output = self.general_ins(image)\n\n        if anno_type is None:\n            return output\n        else:\n            output_dict = {}\n            for tp in anno_type:\n                if tp in output.keys():\n                    output_dict[tp] = resize_image_ori(\n                        image.shape[0], image.shape[1], output[tp], k)\n            return output_dict"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                pass\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins(image)\n        if anno_type is not None:\n            anno_dict = {}\n            for tp in anno_type:\n                if tp in output.keys():\n                    anno_dict[tp] = output[tp]\n            return anno_dict\n        else:\n            return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            assert anno_type in self.anno_type_map.keys()\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        anno_dict = self.general_ins(image)\n        anno_dict = {\n            k: v\n            for k, v in anno_dict.items() if k in anno_type\n        }\n        if len(anno_type) == 1:\n            return anno_dict[anno_type[0]]\n        else:\n            return anno_dict"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        else:\n            assert isinstance(anno_type, (list, tuple))\n\n        output = self.general_ins(image)\n        anno_dict = {}\n        for tp in anno_type:\n            if tp in output:\n                anno_dict[tp] = output[tp]\n        if len(anno_dict) == 1:\n            return list(anno_dict.values())[0]\n        return anno_dict"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n\n        input_dict = {'img': image}\n        output_dict = self.general_ins(input_dict)\n        if anno_type is None:\n            return output_dict\n        else:\n            anno_dict = {}\n            for tp in anno_type:\n                if tp in output_dict.keys():\n                    anno_dict[tp] = output_dict[tp]\n            return anno_dict"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            return self.general_ins(image)\n\n        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        anno = self.general_ins(image)\n        anno = {k: v for k, v in anno.items() if k in anno_type}\n        if len(anno) == 1:\n            return anno[anno_type[0]]\n        else:\n            return anno"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        image = image.astype(np.float32) / 255.0\n        image = image[None].transpose(0, 3, 1, 2)\n        image = we.to_device(image)\n        output = self.general_ins(image)\n        if anno_type is None:\n            return output\n        else:\n            if len(anno_type) == 1:\n                return output[anno_type[0]]\n            else:\n                return {tp: output[tp] for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = self.anno_type_map.keys()\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        img, k = resize_image(image, 512)\n        img = img[:, :, ::-1].copy()\n        img = img.transpose(2, 0, 1) / 255.0\n        img = np.expand_dims(img, axis=0).astype('float32')\n        img = we.to_tensor(img)\n        output = self.general_ins(img)\n        output = {\n            k: resize_image_ori(image.shape[0], image.shape[1], v, k)\n            for k, v in output.items()\n        }\n        if len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {tp: output[tp] for tp in anno_type}"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        image = image.astype(np.float32) / 255.0\n        image = image[..., ::-1]\n        image = image.transpose(2, 0, 1)\n        image = np.expand_dims(image, axis=0)\n        image = image.astype(np.float32)\n        image = torch.from_numpy(image).to(we.device_id)\n\n        with torch.no_grad():\n            output = self.general_ins(image)\n\n        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            output = {k: v for k, v in output.items() if k in anno_type}\n        return output"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is None:\n            anno_type = []\n        elif isinstance(anno_type, str):\n            anno_type = [anno_type]\n        elif isinstance(anno_type, (list, tuple)):\n            pass\n        else:\n            raise Exception(f'Error anno_type: {anno_type}')\n\n        output = self.general_ins(image)\n        if len(anno_type) == 0:\n            return output\n        elif len(anno_type) == 1:\n            return output[anno_type[0]]\n        else:\n            return {tp: output[tp] for tp in anno_type}\n"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            elif isinstance(anno_type, (list, tuple)):\n                assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n            else:\n                raise Exception(f'Error anno_type: {anno_type}')\n\n        img, k = resize_image(image, 512)\n        img = img[:, :, ::-1].copy()\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, axis=0)\n        img = img.astype('float32') / 255.0\n        img = (img - 0.5) / 0.5\n        img = we.to_tensor(img)\n        anno_dict = self.general_ins.run(img)\n        if anno_type is not None:\n            anno_dict = {\n                k: resize_image_ori(image.shape[0], image.shape[1], v, k)\n                for k, v in anno_dict.items() if k in anno_type\n            }\n            if len(anno_type) == 1:\n                anno_dict = list(anno_dict.values())[0]\n        else:\n            anno_dict = {\n                k: resize_image_ori(image.shape[0], image.shape[1], v, k)\n                for k, v in anno_dict.items()\n            }\n        return anno_dict"}
{"namespace": "scepter.scepter.modules.annotator.utils.AnnotatorProcessor.run", "completion": "        if anno_type is not None:\n            if isinstance(anno_type, str):\n                anno_type = [anno_type]\n            assert all(tp in self.anno_type_map.keys() for tp in anno_type)\n\n        image = image.astype(np.float32) / 255.0\n        image = image[:, :, ::-1]\n        image = image.transpose(2, 0, 1)\n        image = np.expand_dims(image, axis=0)\n        image = image.astype(np.float32)\n\n        image = we.to_device(image)\n        anno = self.general_ins(image)\n\n        if anno_type is None:\n            return anno\n        else:\n            anno_type = [self.anno_type_map[tp] for tp in anno_type]\n            anno_type = [anno_type] if isinstance(anno_type, str) else anno_type\n            anno = {\n                k: v\n                for k, v in anno.items() if k in anno_type\n            }\n            return anno"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        result = {}\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        scores = defaultdict(float)\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = defaultdict(float)\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = defaultdict(float)\n        for kw in keywords:\n            update_url_scores(scores, self.bm25(kw))\n        return scores"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = defaultdict(float)\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        result = {}\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = defaultdict(float)\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = defaultdict(float)\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = {}\n        for kw in keywords:\n            scores = update_url_scores(scores, self.bm25(kw))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        result = {}\n        for kw in keywords:\n            update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        result = defaultdict(float)\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        normalized_query = normalize_string(query)\n        keywords = normalized_query.split()\n        result = {}\n        for kw in keywords:\n            update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = defaultdict(float)\n        for keyword in keywords:\n            scores = update_url_scores(scores, self.bm25(keyword))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        scores = defaultdict(float)\n        for keyword in keywords:\n            scores = update_url_scores(scores, self.bm25(keyword))\n        return scores\n"}
{"namespace": "microsearch.engine.SearchEngine.search", "completion": "        query = normalize_string(query)\n        keywords = query.split()\n        result = {}\n        for kw in keywords:\n            result = update_url_scores(result, self.bm25(kw))\n        return result\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "microsearch.engine.SearchEngine.bulk_index", "completion": "        for url, content in documents:\n            self.index(url, content)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": ""}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": ""}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": ""}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": ""}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        h, w = box_size\n        x1 = self.tensor[:, 0] - self.tensor[:, 2] / 2.0\n        y1 = self.tensor[:, 1] - self.tensor[:, 3] / 2.0\n        x2 = self.tensor[:, 0] + self.tensor[:, 2] / 2.0\n        y2 = self.tensor[:, 1] + self.tensor[:, 3] / 2.0\n        clip_inds = (self.tensor[:, 4].abs() < clip_angle_threshold).nonzero().squeeze(1)\n        x1[clip_inds] = torch.clamp(x1[clip_inds], min=0, max=w)\n        y1[clip_inds] = torch.clamp(y1[clip_inds], min=0, max=h)\n        x2[clip_inds] = torch.clamp(x2[clip_inds], min=0, max=w)\n        y2[clip_inds] = torch.clamp(y2[clip_inds], min=0, max=h)\n        self.tensor[:, 0] = (x1 + x2) / 2.0\n        self.tensor[:, 1] = (y1 + y2) / 2.0\n        self.tensor[:, 2] = x2 - x1\n        self.tensor[:, 3] = y2 - y1\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        # Identify boxes that are nearly horizontal\n        horizontal_indices = torch.where(torch.abs(self.tensor[:, 4]) < clip_angle_threshold)[0]\n\n        # Convert the boxes to (x1, y1, x2, y2) representation\n        boxes_x1y1x2y2 = self.tensor.clone()\n        boxes_x1y1x2y2[:, 2] = self.tensor[:, 0] - self.tensor[:, 2] / 2\n        boxes_x1y1x2y2[:, 3] = self.tensor[:, 1] - self.tensor[:, 3] / 2\n        boxes_x1y1x2y2[:, 4] = self.tensor[:, 0] + self.tensor[:, 2] / 2\n        boxes_x1y1x2y2[:, 5] = self.tensor[:, 1] + self.tensor[:, 3] / 2\n\n        # Clamp the x and y coordinates\n        boxes_x1y1x2y2[:, [0, 2]] = torch.clamp(boxes_x1y1x2y2[:, [0, 2]], min=0, max=box_size[1])\n        boxes_x1y1x2y2[:, [1, 3]] = torch.clamp(boxes_x1y1x2y2[:, [1, 3]], min=0, max=box_size[0])\n\n        # Convert the boxes back to (center x, center y, width, height, angle) representation\n        self.tensor[:, 0] = (boxes_x1y1x2y2[:, 0] + boxes_x1y1x2y2[:, 2]) / 2\n        self.tensor[:, 1] = (boxes_x1y1x2y2[:, 1] + boxes_x1y1x2y2[:, 3]) / 2\n        self.tensor"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        # Identify boxes that are nearly horizontal\n        indices = torch.where(torch.abs(self.tensor[:, 4]) <= clip_angle_threshold)[0]\n\n        # Convert to (x1, y1, x2, y2) representation\n        boxes = self.tensor[indices]\n        x_ctr, y_ctr, width, height, angle = boxes.unbind(1)\n        x1 = x_ctr - width / 2.0\n        y1 = y_ctr - height / 2.0\n        x2 = x_ctr + width / 2.0\n        y2 = y_ctr + height / 2.0\n\n        # Clamp the x and y coordinates\n        x1 = torch.clamp(x1, min=0, max=box_size[1])\n        y1 = torch.clamp(y1, min=0, max=box_size[0])\n        x2 = torch.clamp(x2, min=0, max=box_size[1])\n        y2 = torch.clamp(y2, min=0, max=box_size[0])\n\n        # Convert back to (center x, center y, width, height, angle) representation\n        self.tensor[indices, 0] = (x1 + x2) / 2.0\n        self.tensor[indices, 1] = (y1 + y2) / 2.0\n        self.tensor[indices, 2] = x2 - x1\n        self.tensor[indices, 3] = y2 - y1\n\n        # Ensure numerical errors do not increase the size of the boxes\n        self.tensor[indices, :4] = torch.round(self.tensor[indices, :4])\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n\n        # Identify boxes that are nearly horizontal\n        indices = torch.where(torch.abs(self.tensor[:, 4]) <= clip_angle_threshold)[0]\n\n        # Convert to (x1, y1, x2, y2) representation\n        boxes = self.tensor[indices]\n        x_ctr, y_ctr, width, height, angle = boxes.unbind(1)\n        x1 = x_ctr - width / 2.0\n        y1 = y_ctr - height / 2.0\n        x2 = x_ctr + width / 2.0\n        y2 = y_ctr + height / 2.0\n\n        # Clamp x and y coordinates\n        x1 = torch.clamp(x1, min=0, max=box_size[1])\n        x2 = torch.clamp(x2, min=0, max=box_size[1])\n        y1 = torch.clamp(y1, min=0, max=box_size[0])\n        y2 = torch.clamp(y2, min=0, max=box_size[0])\n\n        # Convert back to (center x, center y, width, height, angle) representation\n        width = x2 - x1\n        height = y2 - y1\n        x_ctr = (x1 + x2) / 2.0\n        y_ctr = (y1 + y2) / 2.0\n\n        # Update the boxes\n        self.tensor[indices, :] = torch.stack([x_ctr, y_ctr, width, height, angle], dim=1)\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        h, w = box_size\n        boxes = self.tensor\n        x_ctr, y_ctr, width, height, angle = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3], boxes[:, 4]\n        near_horizontal_inds = torch.abs(angle) < clip_angle_threshold\n        boxes[near_horizontal_inds, 0] = torch.clamp(x_ctr, min=0, max=w)\n        boxes[near_horizontal_inds, 1] = torch.clamp(y_ctr, min=0, max=h)\n        boxes[near_horizontal_inds, 2] = torch.clamp(width, min=0, max=w)\n        boxes[near_horizontal_inds, 3] = torch.clamp(height, min=0, max=h)\n        boxes[near_horizontal_inds, 4] = angle\n\n        boxes_for_convert = boxes[~near_horizontal_inds]\n        boxes_for_convert[:, 0] = torch.clamp(boxes_for_convert[:, 0], min=0, max=w)\n        boxes_for_convert[:, 1] = torch.clamp(boxes_for_convert[:, 1], min=0, max=h)\n        boxes_for_convert[:, 2] = torch.clamp(boxes_for_convert[:, 2], min=0, max=w)\n        boxes_for_convert[:, 3] = torch.clamp(boxes_for_convert[:, 3], min=0, max=h)\n        boxes_for_convert[:, 4] = torch.clamp(boxes_for_convert[:, 4], min=-90, max=0)\n        x1, y1, x2, y2, angle = self.box_convert(boxes_for_convert)\n        boxes[~near_horizontal_inds, 0] = x1\n        boxes["}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\n        h, w = box_size\n\n        self.normalize_angles()\n\n        # Find boxes with angles close to 0 or 90 degrees\n        norm_angle = torch.abs(self.tensor[:, 4])\n        idx = torch.where(norm_angle < clip_angle_threshold)[0]\n\n        # Convert boxes to (x1, y1, x2, y2) format\n        boxes_close_to_horizontal = self.tensor[idx]\n        x_ctr, y_ctr, width, height, angle = boxes_close_to_horizontal.unbind(1)\n        x1 = x_ctr - 0.5 * width\n        y1 = y_ctr - 0.5 * height\n        x2 = x_ctr + 0.5 * width\n        y2 = y_ctr + 0.5 * height\n\n        # Clamp coordinates\n        x1 = torch.clamp(x1, min=0, max=w)\n        y1 = torch.clamp(y1, min=0, max=h)\n        x2 = torch.clamp(x2, min=0, max=w)\n        y2 = torch.clamp(y2, min=0, max=h)\n\n        # Convert boxes back to (x_ctr, y_ctr, width, height, angle) format\n        clipped_boxes = torch.stack((x1, y1, x2, y2), dim=1)\n        clipped_boxes = clipped_boxes.view(-1, 2, 2)\n        clipped_width = clipped_boxes[:, 1, 0] - clipped_boxes[:, 0, 0]\n        clipped_height = clipped_boxes[:, 1, 1] - clipped_boxes[:, 0, 1]\n        clipped_x_ctr = x1 + 0.5 * clipped_width\n        clipped_y_ctr = y1 + 0."}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        height, width = box_size\n        clip_inds = torch.where(\n            torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        )[0]\n        boxes_near_horizontal = self.tensor[clip_inds]\n        boxes_near_horizontal[:, 2:] = boxes_near_horizontal[:, 2:].clamp(max=max(width, height))\n        boxes_near_horizontal = Boxes(boxes_near_horizontal).tensor\n        self.tensor[clip_inds] = boxes_near_horizontal\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # Normalize the angles to be within the range (-180, 180] degrees\n        self.normalize_angles()\n\n        # Identify the indices of the boxes that are nearly horizontal\n        horizontal_indices = torch.where(torch.abs(self.tensor[:, 4]) < clip_angle_threshold)[0]\n\n        # Convert the boxes to (x1, y1, x2, y2) representation\n        boxes_xyxy = self.tensor.clone()\n        boxes_xyxy[:, 2:4] /= 2\n        boxes_xyxy[:, :2] -= boxes_xyxy[:, 2:4]\n        boxes_xyxy[:, 2:4] *= 2\n\n        # Clamp the x and y coordinates to ensure they do not exceed the box_size limits\n        boxes_xyxy[:, 0::2].clamp_(min=0, max=box_size[1])\n        boxes_xyxy[:, 1::2].clamp_(min=0, max=box_size[0])\n\n        # Convert the boxes back to (center x, center y, width, height, angle) representation\n        self.tensor[:, :2] = (boxes_xyxy[:, :2] + boxes_xyxy[:, 2:4]) / 2\n        self.tensor[:, 2:4] = boxes_xyxy[:, 2:4] - boxes_xyxy[:, :2]\n\n        # Ensure numerical errors do not increase the size of the boxes\n        self.tensor[:, 2:4].clamp_(min=1e-6)\n\n        # Convert the boxes back to (x1, y1, x2, y2) representation\n        boxes_xyxy[:, :2] = self.tensor[:, :2] - self.tensor[:, 2:4] / 2\n        boxes_xyxy[:, 2:4] = self.tensor[:, :2] + self.tensor[:, 2:4] / 2\n\n        # Clamp the x and y coordinates to ensure they do not exceed the box_size limits\n       "}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        # normalize angles to be within the range (-180, 180] degrees\n        self.normalize_angles()\n\n        # identify the indices of boxes that are nearly horizontal\n        horizontal_indices = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n\n        # convert boxes to (x1, y1, x2, y2) representation\n        boxes_xyxy = self.tensor.clone()\n        boxes_xyxy[:, 2:4] /= 2\n        boxes_xyxy[:, :2] -= boxes_xyxy[:, 2:4]\n        boxes_xyxy[:, 2:4] *= 2\n\n        # clip x and y coordinates\n        boxes_xyxy[:, [0, 2]] = boxes_xyxy[:, [0, 2]].clamp(min=0, max=box_size[1])\n        boxes_xyxy[:, [1, 3]] = boxes_xyxy[:, [1, 3]].clamp(min=0, max=box_size[0])\n\n        # convert boxes back to (center x, center y, width, height, angle) representation\n        self.tensor[:, :2] = (boxes_xyxy[:, :2] + boxes_xyxy[:, 2:4]) / 2\n        self.tensor[:, 2:4] = boxes_xyxy[:, 2:4] - boxes_xyxy[:, :2]\n\n        # ensure numerical errors do not increase box sizes\n        self.tensor[:, 2:4] = self.tensor[:, 2:4].abs()\n\n        # convert boxes to (x1, y1, x2, y2) representation\n        boxes_xyxy = self.tensor.clone()\n        boxes_xyxy[:, 2:4] /= 2\n        boxes_xyxy[:, :2] -= boxes_xyxy[:, 2:4]\n        boxes_xyxy[:, 2:4] *= 2\n\n        # convert boxes back to (center x, center y, width, height, angle) representation\n       "}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        height, width = box_size\n        # convert to (x1, y1, x2, y2) format\n        boxes = self.tensor\n        boxes_xyxy = torch.stack(\n            (\n                boxes[:, 0] - boxes[:, 2] / 2.0,\n                boxes[:, 1] - boxes[:, 3] / 2.0,\n                boxes[:, 0] + boxes[:, 2] / 2.0,\n                boxes[:, 1] + boxes[:, 3] / 2.0,\n            ),\n            dim=1,\n        )\n        # identify boxes that are nearly horizontal\n        nearly_horizontal = torch.abs(boxes[:, 4]) < clip_angle_threshold\n        # convert nearly horizontal boxes to (x1, y1, x2, y2) format\n        boxes_xyxy[nearly_horizontal, 0::2] = 0\n        boxes_xyxy[nearly_horizontal, 1::2] = boxes[nearly_horizontal, 1] - boxes[nearly_horizontal, 3] / 2.0\n        boxes_xyxy[nearly_horizontal, 2::2] = width\n        boxes_xyxy[nearly_horizontal, 3::2] = boxes[nearly_horizontal, 1] + boxes[nearly_horizontal, 3] / 2.0\n        # clip x coordinates\n        boxes_xyxy[:, [0, 2]] = boxes_xyxy[:, [0, 2]].clamp(min=0, max=width)\n        # clip y coordinates\n        boxes_xyxy[:, [1, 3]] = boxes_xyxy[:, [1, 3]].clamp(min=0, max=height)\n        # convert boxes back to (center x, center y, width, height, angle) format\n        self.tensor[:, :4] = torch.stack(\n            (\n                (boxes_xyxy[:, 0] + boxes_xyxy[:, 2]) / 2.0,\n                (box"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        h, w = box_size\n        boxes_horizontal = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        boxes_horizontal_idx = boxes_horizontal.nonzero().squeeze(1)\n        boxes_horizontal = self.tensor[boxes_horizontal_idx]\n        if boxes_horizontal.numel() > 0:\n            x_ctr, y_ctr, width, height, _ = boxes_horizontal.unbind(1)\n            x1 = (x_ctr - width / 2.0).clamp(0, w)\n            y1 = (y_ctr - height / 2.0).clamp(0, h)\n            x2 = (x_ctr + width / 2.0).clamp(0, w)\n            y2 = (y_ctr + height / 2.0).clamp(0, h)\n            self.tensor[boxes_horizontal_idx] = torch.stack((x1, y1, x2, y2, self.tensor[boxes_horizontal_idx][:, 4]), dim=1)\n            self.tensor[boxes_horizontal_idx][:, :4] = torch.min(\n                self.tensor[boxes_horizontal_idx][:, :4], torch.stack((x1, y1, x2, y2), dim=1)\n            )\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        h, w = box_size\n        x1 = self.tensor[:, 0] - self.tensor[:, 2] / 2\n        y1 = self.tensor[:, 1] - self.tensor[:, 3] / 2\n        x2 = self.tensor[:, 0] + self.tensor[:, 2] / 2\n        y2 = self.tensor[:, 1] + self.tensor[:, 3] / 2\n\n        # Clip boxes to image\n        x1 = torch.clamp(x1, min=0, max=w)\n        x2 = torch.clamp(x2, min=0, max=w)\n        y1 = torch.clamp(y1, min=0, max=h)\n        y2 = torch.clamp(y2, min=0, max=h)\n\n        # Clip boxes with nearly horizontal box angles\n        horizontal_boxes = torch.abs(self.tensor[:, 4]) < clip_angle_threshold\n        x1[horizontal_boxes] = 0\n        x2[horizontal_boxes] = w\n        y1[horizontal_boxes] = 0\n        y2[horizontal_boxes] = h\n\n        # Convert boxes back to center x, center y, width, height, angle representation\n        self.tensor[:, 0] = (x1 + x2) / 2\n        self.tensor[:, 1] = (y1 + y2) / 2\n        self.tensor[:, 2] = x2 - x1\n        self.tensor[:, 3] = y2 - y1\n\n        # Ensure numerical errors don't increase box sizes\n        self.tensor[:, 2:] = torch.clamp(self.tensor[:, 2:], min=0.0, max=max(w, h))\n"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        angle_threshold = clip_angle_threshold\n        # Find boxes with horizontal angles close to 0 or 90\n        horizontal_boxes = torch.abs(self.tensor[:, 4]) < angle_threshold\n        horizontal_boxes = torch.logical_or(\n            torch.abs(self.tensor[horizontal_boxes, 4] - 0.0) < angle_threshold,\n            torch.abs(self.tensor[horizontal_boxes, 4] - 90.0) < angle_threshold,\n        )\n\n        # Convert boxes to x1, y1, x2, y2 representation\n        boxes_xyxy = self.tensor.clone()\n        half_width = boxes_xyxy[:, 2] / 2\n        half_height = boxes_xyxy[:, 3] / 2\n        sin_theta = torch.sin(torch.deg2rad(boxes_xyxy[:, 4]))\n        cos_theta = torch.cos(torch.deg2rad(boxes_xyxy[:, 4]))\n        boxes_xyxy[:, 0] -= cos_theta * half_width - sin_theta * half_height\n        boxes_xyxy[:, 1] -= sin_theta * half_width + cos_theta * half_height\n        boxes_xyxy[:, 2] = 2 * half_width\n        boxes_xyxy[:, 3] = 2 * half_height\n\n        # Clamp boxes to image boundaries\n        boxes_xyxy[:, 0] = torch.clamp(boxes_xyxy[:, 0], min=0, max=box_size[1])\n        boxes_xyxy[:, 1] = torch.clamp(boxes_xyxy[:, 1], min=0, max=box_size[0])\n        boxes_xyxy[:, 2] = torch.clamp(boxes_xyxy[:, 2], max=box_size[1] - boxes_xyxy[:, 0])\n        boxes_xyxy"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\n        h, w = box_size\n        self.normalize_angles()\n        boxes = self.tensor\n\n        # Step 1: Convert boxes to format (x1, y1, x2, y2)\n        boxes = self.tensor\n        x_ctr, y_ctr, width, height, angle = boxes.unbind(1)\n        _shape = boxes.shape[:-1] + (1,)\n        x_ctr, y_ctr, width, height, angle = x_ctr.unsqueeze(-1), y_ctr.unsqueeze(-1), width.unsqueeze(-1), height.unsqueeze(-1), angle.unsqueeze(-1)\n        cos, sin = torch.cos(angle), torch.sin(angle)\n        dx = torch.abs(width * cos)\n        dy = torch.abs(height * sin)\n        dxdy = torch.cat((dx, dy), dim=-1)\n        # Get the four corners of the rotated box\n        corners = torch.abs(torch.ger(dxdy, torch.tensor([-1, 1]).to(dxdy.device)) * 0.5)\n        rotated_box = torch.stack([x_ctr - corners[:, 0], y_ctr - corners[:, 1],\n                                   x_ctr + corners[:, 0], y_ctr + corners[:, 1]], dim=-1)\n        # Step 2: Identify boxes that are nearly horizontal\n        horizontal_mask = torch.abs(angle) < clip_angle_threshold\n        # Step 3: Clamp the x and y coordinates\n        x1, y1, x2, y2 = rotated_box.unbind(1)\n        x1 = torch.clamp(x1, min=0, max=w)\n        x2 = torch.clamp(x2, min=0, max=w)\n        y1 = torch.clamp(y1, min=0, max"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\n        h, w = box_size\n\n        self.normalize_angles()\n        boxes = self.tensor\n        xc, yc, w, h, a = boxes.unbind(dim=1)\n\n        # Step 1: Check if the box is nearly horizontal\n        is_nearly_horizontal = (\n            (torch.abs(a) < clip_angle_threshold)\n            | (torch.abs(a - 90.0) < clip_angle_threshold)\n            | (torch.abs(a + 90.0) < clip_angle_threshold)\n        )\n\n        # Step 2: Convert nearly horizontal boxes to x1, y1, x2, y2 representation\n        x1 = xc - w / 2.0\n        x2 = xc + w / 2.0\n        y1 = yc - h / 2.0\n        y2 = yc + h / 2.0\n\n        # Step 3: Clamp x1, y1, x2, y2\n        x1 = torch.clamp(x1, min=0, max=w)\n        x2 = torch.clamp(x2, min=0, max=w)\n        y1 = torch.clamp(y1, min=0, max=h)\n        y2 = torch.clamp(y2, min=0, max=h)\n\n        # Step 4: Convert x1, y1, x2, y2 back to center coordinate and width, height, angle representation\n        xc_new = (x1 + x2) / 2.0\n        yc_new = (y1 + y2) / 2.0\n        w_new = x2 - x1\n        h_new = y2 - y1\n        a_new = torch.zeros_like(a)\n\n        # Step 5: Update the boxes tensor with the clipped values\n        boxes = torch.stack((xc_new, yc_new"}
{"namespace": "detectron2.structures.rotated_boxes.RotatedBoxes.clip", "completion": "        self.normalize_angles()\n        height, width = box_size\n        # Clip boxes with angle close to 0 or 90 to be exactly horizontal or vertical\n        # The original implementation of Boxes.clip() enforces box boundary limits\n        # strictly, which is incompatible with rotated boxes. To address this, we\n        # need to convert them to horizontal or vertical boxes before applying\n        # clipping.\n        # See https://github.com/facebookresearch/detectron2/issues/3775\n        # Note that clipping rotated boxes with +-90 degrees is inaccurate and can\n        # lead to unexpected results.\n        # See https://github.com/facebookresearch/detectron2/issues/7032\n        radian = self.tensor[:, 4] * math.pi / 180.0\n        tan_abs = torch.abs(torch.tan(radian))\n        boxes_horizontal = tan_abs < clip_angle_threshold\n        boxes_vertical = torch.abs(tan_abs - 1.0 / tan_abs) < clip_angle_threshold\n        boxes_near_horizontal = boxes_horizontal | boxes_vertical\n        if boxes_near_horizontal.any():\n            boxes_near_horizontal_idx = boxes_near_horizontal.nonzero().squeeze(1)\n            boxes_near_horizontal = self.tensor[boxes_near_horizontal_idx]\n            boxes_near_horizontal[:, 2:4] = boxes_near_horizontal[:, 2:4] + boxes_near_horizontal[:, :2]\n        # Clip boxes\n        self.tensor[:, 0::2].clamp_(min=0, max=width)\n        self.tensor[:, 1::2].clamp_(min=0, max=height)\n        # Clip boxes with angle close to 0 or 90 to be exactly horizontal or vertical\n        if boxes_near_horizontal.numel():\n            boxes_near_horizontal[:, :2].clamp_(min=0, max=width)\n            boxes_near_horizontal[:, 2:4"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n        for item in self.data:\n            statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n        for item in self.data:\n            statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n        for item in self.data:\n            if item['type'] in statistics:\n                statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for item in self.data:\n            statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if item['type'] in statistics:\n                statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for item in self.data:\n            if item['type'] == 'doc':\n                statistics['doc'] += 1\n            elif item['type'] == 'gen':\n                statistics['gen'] += 1\n            elif item['type'] == 'kno':\n                statistics['kno'] += 1\n            elif item['type'] == 'num':\n                statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n        for item in self.data:\n            if item['type'] == 'doc':\n                statistics['doc'] += 1\n            elif item['type'] == 'gen':\n                statistics['gen'] += 1\n            elif item['type'] == 'kno':\n                statistics['kno'] += 1\n            elif item['type'] == 'num':\n                statistics['num'] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n\n        for item in self.data:\n            if item['type'] in statistics:\n                statistics[item['type']] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            statistics[item['type']] += 1\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n\n        for d in self.data:\n            statistics[d['type']] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for item in self.data:\n            if item['type'] == 'doc':\n                stats['doc'] += 1\n            elif item['type'] == 'gen':\n                stats['gen'] += 1\n            elif item['type'] == 'kno':\n                stats['kno'] += 1\n            elif item['type'] == 'num':\n                stats['num'] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for d in self.data:\n            if d['type'] == 'doc':\n                stats['doc'] += 1\n            elif d['type'] == 'gen':\n                stats['gen'] += 1\n            elif d['type'] == 'kno':\n                stats['kno'] += 1\n            elif d['type'] == 'num':\n                stats['num'] += 1\n        return stats"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n\n        for d in self.data:\n            statistics[d['type']] += 1\n\n        return statistics"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n        for item in self.data:\n            statistics[item['type']] += 1\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            if item['type'] == 'doc':\n                statistics['doc'] += 1\n            elif item['type'] == 'gen':\n                statistics['gen'] += 1\n            elif item['type'] == 'kno':\n                statistics['kno'] += 1\n            elif item['type'] == 'num':\n                statistics['num'] += 1\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0\n        }\n        for item in self.data:\n            if item['type'] in statistics:\n                statistics[item['type']] += 1\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n        for d in self.data:\n            if d['type'] == 'doc':\n                statistics['doc'] += 1\n            elif d['type'] == 'gen':\n                statistics['gen'] += 1\n            elif d['type'] == 'kno':\n                statistics['kno'] += 1\n            elif d['type'] == 'num':\n                statistics['num'] += 1\n        return statistics\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        stats = {'doc': 0, 'gen': 0, 'kno': 0, 'num': 0}\n        for item in self.data:\n            stats[item['type']] += 1\n        return stats\n"}
{"namespace": "xinhua.XinhuaHallucinations.statistics", "completion": "        statistics = {\n            'doc': 0,\n            'gen': 0,\n            'kno': 0,\n            'num': 0,\n        }\n        for item in self.data:\n            if item['type'] == 'doc':\n                statistics['doc'] += 1\n            elif item['type'] == 'gen':\n                statistics['gen'] += 1\n            elif item['type'] == 'kno':\n                statistics['kno'] += 1\n            elif item['type'] == 'num':\n                statistics['num'] += 1\n        return statistics\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_neck", "completion": "    if cfg['type'] in NECKS._module_dict.keys():\n        return NECKS.build(cfg)\n    else:\n        return MMDET_NECKS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        if cfg['type'] in MMDET_LOSSES._module_dict.keys():\n            return MMDET_LOSSES.build(cfg)\n        else:\n            if cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n                return MMSEG_LOSSES.build(cfg)\n            else:\n                raise ValueError(f'{cfg[\"type\"]} is not registered in '\n                                 'any loss registry.')\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        if cfg['type'] in MMDET_LOSSES._module_dict.keys():\n            return MMDET_LOSSES.build(cfg)\n        elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n            return MMSEG_LOSSES.build(cfg)\n        else:\n            raise KeyError(f'{cfg[\"type\"]} is not in the loss registry')"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    else:\n        if cfg['type'] in MMDET_LOSSES._module_dict.keys():\n            return MMDET_LOSSES.build(cfg)\n        else:\n            if cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n                return MMSEG_LOSSES.build(cfg)\n            else:\n                raise ValueError(f'{cfg[\"type\"]} is not registered in '\n                                 'any loss registry.')\n\n"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMDET_LOSSES._module_dict.keys():\n        return MMDET_LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        raise KeyError(f'{cfg[\"type\"]} is not registered in '\n                       'any loss registry.')"}
{"namespace": "mmdet3d.models.builder.build_loss", "completion": "    if cfg['type'] in LOSSES._module_dict.keys():\n        return LOSSES.build(cfg)\n    elif cfg['type'] in MMSEG_LOSSES._module_dict.keys():\n        return MMSEG_LOSSES.build(cfg)\n    else:\n        return MMDET_LOSSES.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_head", "completion": "    if cfg['type'] in HEADS._module_dict.keys():\n        return HEADS.build(cfg)\n    else:\n        return MMDET_HEADS.build(cfg)\n\n"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return SEGMENTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_segmentor", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in SEGMENTORS._module_dict.keys():\n        return SEGMENTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        raise ValueError(f'{cfg[\"type\"]} is not registered in '\n                         'SEGMENTORS')"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if 'train_cfg' in cfg:\n        warnings.warn(\n            'train_cfg is deprecated, please specify them in model',\n            UserWarning)\n        cfg.train_cfg = cfg.pop('train_cfg')\n    if 'test_cfg' in cfg:\n        warnings.warn(\n            'test_cfg is deprecated, please specify them in model',\n            UserWarning)\n        cfg.test_cfg = cfg.pop('test_cfg')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if 'train_cfg' in cfg:\n        warnings.warn(\n            'train_cfg is deprecated, please specify them in model',\n            UserWarning)\n        cfg.train_cfg = cfg.pop('train_cfg')\n    if 'test_cfg' in cfg:\n        warnings.warn(\n            'test_cfg is deprecated, please specify them in model',\n            UserWarning)\n        cfg.test_cfg = cfg.pop('test_cfg')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    return DETECTORS.build(\n        cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn('train_cfg and test_cfg is deprecated, '\n                      'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if 'train_cfg' in cfg:\n        warnings.warn('train_cfg is deprecated, please specify them in model')\n    if 'test_cfg' in cfg:\n        warnings.warn('test_cfg is deprecated, please specify them in model')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if 'train_cfg' in cfg:\n        warnings.warn('train_cfg is deprecated, please move it to model')\n    if 'test_cfg' in cfg:\n        warnings.warn('test_cfg is deprecated, please move it to model')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if 'train_cfg' in cfg:\n        warnings.warn(\n            'train_cfg is deprecated, please specify them in model',\n            UserWarning)\n        train_cfg = cfg.pop('train_cfg')\n    if 'test_cfg' in cfg:\n        warnings.warn(\n            'test_cfg is deprecated, please specify them in model',\n            UserWarning)\n        test_cfg = cfg.pop('test_cfg')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if 'train_cfg' in cfg:\n        warnings.warn('train_cfg is deprecated, please merge your modifications to '\n                      'train_cfg to model.')\n        cfg.update(cfg.pop('train_cfg'))\n    if 'test_cfg' in cfg:\n        warnings.warn('test_cfg is deprecated, please merge your modifications to '\n                      'test_cfg to model.')\n        cfg.update(cfg.pop('test_cfg'))\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if 'train_cfg' in cfg:\n        warnings.warn('train_cfg is deprecated, please merge your modifications '\n                      'to train_cfg in model.')\n    if 'test_cfg' in cfg:\n        warnings.warn('test_cfg is deprecated, please merge your modifications '\n                      'to test_cfg in model.')\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if 'train_cfg' in cfg:\n        warnings.warn(\n            'train_cfg is deprecated, please specify them in model, '\n            'cfg.train_cfg = None; cfg.model.train_cfg = train_cfg')\n    if 'test_cfg' in cfg:\n        warnings.warn(\n            'test_cfg is deprecated, please specify them in model, '\n            'cfg.test_cfg = None; cfg.model.test_cfg = test_cfg')\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if 'train_cfg' in cfg:\n        warnings.warn('train_cfg is deprecated, please merge your modifications '\n                      'to train_cfg in model.')\n        cfg.update(cfg.pop('train_cfg'))\n    if 'test_cfg' in cfg:\n        warnings.warn('test_cfg is deprecated, please merge your modifications '\n                      'to test_cfg in model.')\n        cfg.update(cfg.pop('test_cfg'))\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if 'train_cfg' in cfg:\n        warnings.warn('train_cfg is deprecated, please specify them in model',\n                      UserWarning)\n        cfg.train_cfg = cfg.pop('train_cfg')\n    if 'test_cfg' in cfg:\n        warnings.warn('test_cfg is deprecated, please specify them in model',\n                      UserWarning)\n        cfg.test_cfg = cfg.pop('test_cfg')\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn(\n            'train_cfg and test_cfg is deprecated, '\n            'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if 'train_cfg' in cfg:\n        warnings.warn(\n            'train_cfg is deprecated, please specify them in model. '\n            'For now, they are ignored.', UserWarning)\n    if 'test_cfg' in cfg:\n        warnings.warn(\n            'test_cfg is deprecated, please specify them in model. '\n            'For now, they are ignored.', UserWarning)\n\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))"}
{"namespace": "mmdet3d.models.builder.build_detector", "completion": "    if train_cfg is not None or test_cfg is not None:\n        warnings.warn('train_cfg and test_cfg is deprecated, '\n                      'please specify them in model', UserWarning)\n    assert cfg.get('train_cfg') is None or train_cfg is None, \\\n        'train_cfg specified in both outer field and model field '\n    assert cfg.get('test_cfg') is None or test_cfg is None, \\\n        'test_cfg specified in both outer field and model field '\n    if cfg['type'] in DETECTORS._module_dict.keys():\n        return DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n    else:\n        return MMDET_DETECTORS.build(\n            cfg, default_args=dict(train_cfg=train_cfg, test_cfg=test_cfg))\n\n"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    pred = {}  # map {class_id: pred}\n    gt = {}  # map {class_id: gt}\n    for img_id in range(len(dt_annos)):\n        # parse detected annotations\n        det_anno = dt_annos[img_id]\n        for i in range(len(det_anno['name'])):\n            class_name = det_anno['name'][i]\n            bbox = det_anno['bbox'][i]\n            score = det_anno['score'][i]\n            if class_name not in pred:\n                pred[class_name] = {}\n            if img_id not in pred[class_name]:\n                pred[class_name][img_id] = []\n            xmin, ymin, xmax, ymax = bbox\n            pred[class_name][img_id].append(\n                (bbox, score))  # will be converted to Boxes3D\n        # parse gt annotations\n        gt_anno = gt_annos[img_id]\n        if gt_anno['name'] is not None:\n            for i in range(len(gt_anno['name'])):\n                class_name = gt_anno['name'][i]\n                bbox = gt_anno['bbox'][i]\n                if class_name not in gt:\n                    gt[class_name] = {}\n                if img_id not in gt[class_name]:\n                    gt[class_name][img_id] = []\n                xmin, ymin, xmax, ymax = bbox\n                gt[class_name][img_id].append(\n                    bbox)  # will be converted to Boxes3D\n\n    rec, prec, ap = eval_map_recall(pred, gt, metric)\n    ret_dict = dict()\n    header_map = {0: 'easy', 1: 'moderate', 2: 'hard"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    pred = {}  # map {class_id: pred}\n    gt = {}  # map {class_id: gt}\n    pred_info = {}  # map {class_id: pred_info}\n    gt_info = {}  # map {class_id: gt_info}\n    for i in range(len(gt_annos)):\n        # parse detected annotations\n        det_anno = dt_annos[i]\n        for j in range(len(det_anno['name'])):\n            class_name = det_anno['name'][j]\n            bbox = det_anno['bbox'][j]\n            score = det_anno['score'][j]\n            if class_name not in pred:\n                pred[class_name] = {}\n            if class_name not in gt:\n                gt[class_name] = {}\n\n            if image_id not in pred[class_name]:\n                pred[class_name][image_id] = []\n            if image_id not in gt[class_name]:\n                gt[class_name][image_id] = []\n            pred[class_name][image_id].append((bbox, score))\n\n        # parse gt annotations\n        anno = gt_annos[i]\n        for j in range(len(anno['name'])):\n            class_name = anno['name'][j]\n            bbox = anno['bbox'][j]\n            if class_name not in gt:\n                gt[class_name] = {}\n            if image_id not in gt[class_name]:\n                gt[class_name][image_id] = []\n            gt[class_name][image_id].append(bbox)\n\n    rec, prec, ap = eval_map_recall(pred, gt, metric)\n    ret_dict = dict()\n    header = ['class', 'gts', 'dets', 'recall', 'ap"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    pred = {}  # map {class_id: pred}\n    gt = {}  # map {class_id: gt}\n    pred_no_match = {}  # map {class_id: pred}\n    gt_no_match = {}  # map {class_id: gt}\n    for img_id in range(len(dt_annos)):\n        for i in range(len(dt_annos[img_id]['name'])):\n            if dt_annos[img_id]['name'][i] not in pred:\n                pred[dt_annos[img_id]['name'][i]] = []\n            bbox = dt_annos[img_id]['bbox'][i]\n            if box_type_3d == 'Depth' or box_type_3d == 'Camera':\n                bbox = box_type_3d + 'Box'\n                bbox = eval(bbox)(bbox, box_mode_3d=box_mode_3d)\n            else:\n                raise ValueError('unknown box type')\n            pred[dt_annos[img_id]['name'][i]].append(\n                (bbox, dt_annos[img_id]['score'][i]))\n        for i in range(len(gt_annos[img_id]['name'])):\n            if gt_annos[img_id]['name'][i] not in gt:\n                gt[gt_annos[img_id]['name'][i]] = []\n            bbox = gt_annos[img_id]['bbox'][i]\n            if box_type_3d == 'Depth' or box_type_3d == 'Camera':\n                bbox = box_type_3d + 'Box'\n                bbox = eval(bbox)(bbox, box_mode_3d=box_mode_3d)\n            else:\n                raise ValueError('unknown box type')\n            gt[gt_"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d is None:\n        box_type_3d, box_mode_3d = get_box_type(gt_annos[0]['gt_boxes_upright_depth'])\n\n    pred_bboxes = []\n    pred_labels = []\n    pred_scores = []\n    gt_bboxes = []\n    gt_labels = []\n    gt_difficults = []\n    for i in range(len(gt_annos)):\n        gt_bboxes.append(gt_annos[i]['gt_boxes_upright_depth'])\n        gt_labels.append(gt_annos[i]['gt_names'])\n        gt_difficults.append(gt_annos[i]['difficulty'])\n        pred_bboxes.append(dt_annos[i]['pred_boxes'])\n        pred_labels.append(dt_annos[i]['pred_labels'])\n        pred_scores.append(dt_annos[i]['pred_scores'])\n\n    result_str, result_dict = indoor_eval_core(\n        gt_bboxes,\n        gt_labels,\n        gt_difficults,\n        pred_bboxes,\n        pred_labels,\n        pred_scores,\n        label2cat,\n        metric,\n        box_type_3d=box_type_3d,\n        box_mode_3d=box_mode_3d,\n        logger=logger)\n\n    return result_str, result_dict"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d == 'Depth':\n        gt_annos = ind_eval.depth_box3d_to_bev_box3d(gt_annos)\n        dt_annos = ind_eval.depth_box3d_to_bev_box3d(dt_annos)\n    elif box_type_3d == 'LiDAR':\n        gt_annos = ind_eval.box3d_lidar_to_camera(gt_annos)\n        dt_annos = ind_eval.box3d_lidar_to_camera(dt_annos)\n\n    if box_mode_3d != 'lidar':\n        gt_annos = ind_eval.camera_to_lidar(gt_annos, box_mode_3d)\n        gt_annos = ind_eval.box3d_camera_to_lidar(gt_annos, box_mode_3d)\n        dt_annos = ind_eval.camera_to_lidar(dt_annos, box_mode_3d)\n        dt_annos = ind_eval.box3d_camera_to_lidar(dt_annos, box_mode_3d)\n\n    pred_bboxes = ind_eval.get_official_eval_result(gt_annos, dt_annos, metric)\n\n    ret_dict = ind_eval.eval_det_cls(pred_bboxes, gt_annos, metric, label2cat)\n\n    if logger is not None:\n        result_str, ret_dict = ind_eval.get_eval_result_line(ret_dict, metric)\n        print_log(result_str, logger=logger)\n    return ret_dict\n\n"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    pred = {}  # map {class_id: pred}\n    gt = {}  # map {class_id: gt}\n    for img_id in range(len(dt_annos)):\n        # parse detected annotations\n        det_anno = dt_annos[img_id]\n        for i in range(len(det_anno['name'])):\n            class_name = label2cat[det_anno['name'][i]]\n            bbox = det_anno['bbox'][i]\n            score = det_anno['score'][i]\n            if class_name in pred:\n                pred[class_name].append((bbox, score))\n            else:\n                pred[class_name] = [(bbox, score)]\n        # parse gt annotations\n        gt_anno = gt_annos[img_id]\n        if gt_anno['name'] is not None:\n            for i in range(len(gt_anno['name'])):\n                class_name = label2cat[gt_anno['name'][i]]\n                bbox = gt_anno['bbox'][i]\n                if class_name in gt:\n                    gt[class_name].append(bbox)\n                else:\n                    gt[class_name] = [bbox]\n\n    rec, prec, ap = eval_map_recall(pred, gt, metric)\n    ret_dict = dict()\n    header = ['class', 'gts', 'dets', 'recall', 'ap', 'precision']\n    table_columns = [[\n        np.mean(prec),\n        np.mean(rec)\n    ] + list(np.stack(prec, axis=0).flatten()) +\n                     list(np.stack(rec, axis=0).flatten())]\n\n    if logger is not None:\n        for ci, cname in enumerate(label2cat.values()):\n            # scale recall from 0-1 to 0"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d == 'Depth':\n        gt_boxes = [\n            box_type_3d(anno['gt_boxes_upright_depth'], box_mode_3d,\n                       DepthInstance3DBoxes) for anno in gt_annos\n        ]\n        dt_boxes = [\n            box_type_3d(anno['boxes_upright_depth'], box_mode_3d,\n                       DepthInstance3DBoxes) for anno in dt_annos\n        ]\n    else:\n        gt_boxes = [\n            box_type_3d(anno['gt_boxes'], box_mode_3d, CameraInstance3DBoxes)\n            for anno in gt_annos\n        ]\n        dt_boxes = [\n            box_type_3d(anno['boxes'], box_mode_3d, CameraInstance3DBoxes)\n            for anno in dt_annos\n        ]\n\n    gt_bboxes = []\n    for gt_box in gt_boxes:\n        gt_bboxes.extend(gt_box)\n    gt_labels = []\n    for anno in gt_annos:\n        gt_labels.extend(anno['gt_names'])\n\n    gt_ignore = np.array([False for _ in range(len(gt_labels))], dtype=bool)\n\n    dt_bboxes = []\n    dt_labels = []\n    dt_scores = []\n    for dt_box, dt_label, dt_score in zip(dt_boxes, dt_labels, dt_scores):\n        dt_bboxes.extend(dt_box)\n        dt_labels.extend(dt_label)\n        dt_scores.extend(dt_score)\n\n    result_str, ret_dict = indoor_eval_class(gt_bboxes, gt_labels, gt_ignore,\n                                             dt_bboxes, dt_"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d is None:\n        box_type_3d, box_mode_3d = get_box_type(gt_annos[0]['gt_boxes_upright_depth'])\n\n    cat_info = {}\n    for i in range(len(label2cat)):\n        cat_info[str(i)] = {'name': label2cat[i], 'id': i}\n\n    gt_annos = [\n        remove_dontcare(anno) for anno in gt_annos\n    ] if len(gt_annos) != 0 else []\n    if len(gt_annos) != 0:\n        gt_boxes = [\n            ann['gt_boxes_upright_depth'].convert_box_format_(box_mode_3d=box_mode_3d)\n            for ann in gt_annos\n        ]\n        assert box_type_3d in [\n            Box3DMode.DEPTH, Box3DMode.KITTI, Box3DMode.CAM, Box3DMode.LIDAR\n        ]\n        if box_mode_3d == Box3DMode.LIDAR:\n            gt_boxes = Box3DMode.convert(gt_boxes, Box3DMode.LIDAR,\n                                         Box3DMode.DEPTH)\n        gt_bboxes = box_type_3d.convert_box_format_(gt_boxes, Box3DMode.DEPTH,\n                                                    box_mode_3d)[..., :6]\n        gt_labels = []\n        for anno in gt_annos:\n            gt_labels.append(anno['gt_names'])\n    else:\n        gt_bboxes = np.zeros((0, 6))\n        gt_labels = []\n\n    if box_type_3d == Box3DMode.CAM:\n        dt_annos = camera_to_lidar(dt_annos,"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d == 'Depth' or box_type_3d == 'BEV':\n        gt_annos = indore_eval_common_utils.depth_box3d_to_bev_box3d(gt_annos)\n        dt_annos = indore_eval_common_utils.depth_box3d_to_bev_box3d(dt_annos)\n    elif box_type_3d == 'Camera':\n        gt_annos = indore_eval_common_utils.camera_to_lidar(gt_annos, box_mode_3d)\n        dt_annos = indore_eval_common_utils.camera_to_lidar(dt_annos, box_mode_3d)\n\n    # convert gt and dt details to standard format\n    gt_annos = indore_eval_common_utils.reorganize_annos(gt_annos)\n    dt_annos = indore_eval_common_utils.reorganize_annos(dt_annos)\n\n    # evaluate the DT and GT\n    eval_results = eval_map_recall(\n        gt_annos,\n        dt_annos,\n        metric,\n        label2cat,\n    )\n\n    column_names = ['classes']\n    ret_dict = {}\n    for i, current_class in enumerate(label2cat.values()):\n        ret_dict[current_class] = {}\n        for j, thresh in enumerate(metric):\n            ret_dict[current_class]['recall_%.2f' % thresh] = eval_results[0][j][\n                i]\n            ret_dict[current_class]['precision_%.2f' % thresh] = eval_results[1][j][\n                i]\n            ret_dict[current_class]['AP_%.2f' % thresh] = eval_results[2][j][i]\n\n    # compute"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d == 'Depth':\n        gt_annos = eval_det_depth(gt_annos, metric, box_mode_3d)\n    else:\n        gt_annos = eval_det_bbox(gt_annos, metric, box_type_3d, box_mode_3d)\n    if box_type_3d == 'Depth':\n        dt_annos = eval_det_depth(dt_annos, metric, box_mode_3d)\n    else:\n        dt_annos = eval_det_bbox(dt_annos, metric, box_type_3d, box_mode_3d)\n    rec, prec, ap = eval_map_recall(dt_annos, gt_annos, metric)\n    ret_dict = dict()\n    header_map = [\n        ['classes', 'gts', 'dets', 'recall', 'ap', 'precision']\n    ]\n    table_rows = []\n    for i, cls_name in enumerate(label2cat):\n        row = [\n            cls_name, gt_annos[i]['num_gts'], dt_annos[i]['num_dets'],\n            f'{rec[0][i]:.2f}', f'{ap[0][i]:.2f}', f'{prec[0][i]:.2f}'\n        ]\n        table_rows.append(row)\n        ret_dict[cls_name] = float(f'{ap[0][i]:.2f}')\n    table_data = [header_map] + table_rows\n    table = AsciiTable(table_data)\n    table.inner_footing_row_border = True\n    print_log('\\n' + table.table, logger=logger)\n    print_log(f'mAP: {np.mean(list(ret_dict.values())):.2f}', logger=logger)\n    return ret_dict"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d == 'Depth' and box_mode_3d == 'K':\n        gt_annos = ind_eval.depth_box3d_to_bev_box3d(gt_annos)\n        dt_annos = ind_eval.depth_box3d_to_bev_box3d(dt_annos)\n\n    # obtain gt num for each class\n    pos_nums = [np.zeros(num_classes) for num_classes in ovthresh]\n    for i, cur_gt_annos in enumerate(gt_annos):\n        for cur_gt_anno in cur_gt_annos:\n            gt_boxes = cur_gt_anno['bbox']\n            gt_labels = cur_gt_anno['label']\n            # label str to int\n            for j in range(len(gt_labels)):\n                gt_labels[j] = class2label[gt_labels[j]]\n            if box_type_3d == 'LiDAR':\n                gt_bboxes_3d = box_utils.boxes_to_corners_3d(gt_boxes)\n                loc = gt_annos[i]['location']\n                rots = gt_annos[i]['rotation_y']\n                gt_bboxes_3d = box_utils.boxes3d_kitti_camera_to_lidar(\n                    gt_bboxes_3d, rots, 0, 0)\n                gt_bboxes_3d[:, :, 2] += loc\n                gt_boxes = box_utils.boxes3d_to_bboxes3d(gt_bboxes_3d)\n            for j in range(len(gt_labels)):\n                label = gt_labels[j]\n                pos_nums[label] += 1\n\n    # compute recalls and precisions\n    eval_results_list ="}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d is None:\n        box_type_3d, box_mode_3d = get_box_type(gt_annos[0]['gt_boxes_upright_depth'])\n    if box_mode_3d != 'depth':\n        logger.error('Indoor eval only support depth boxes.')\n        return\n    metric = [0.2, 0.5] if metric is None else metric\n    gts = {}\n    dts = {}\n    for cat in label2cat.keys():\n        gts[cat] = []\n        dts[cat] = []\n    for img_id in range(len(dt_annos)):\n        gt_anno = gt_annos[img_id]\n        dt_anno = dt_annos[img_id]\n        gt_bboxes_3d = gt_anno['gt_boxes_upright_depth']\n        names = gt_anno['name']\n        num_gt = len(gt_bboxes_3d)\n        num_dt = len(dt_anno['name'])\n        for i in range(num_gt):\n            gt_cls = gt_anno['gt_names'][i]\n            gts[gt_cls].append(gt_anno['gt_boxes_upright_depth'][i])\n        for i in range(num_dt):\n            if dt_anno['name'][i] in ['DontCare']:\n                continue\n            bbox = dt_anno['boxes_3d'][i]\n            dt_cls = dt_anno['name'][i]\n            dts[dt_cls].append(bbox)\n\n    rec, prec, ap = eval_map_recall(dts, gts, metric)\n    ret_dict = {}\n    header_map = {}\n    for i, thresh in enumerate(metric):\n        recall = recall[i]\n        precision = precision[i]"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(metric) > 0\n    if box_type_3d is None:\n        box_type_3d, box_mode_3d = LiDARInstance3DBoxes, Box3DMode.LIDAR\n    else:\n        assert isinstance(box_type_3d, type) and issubclass(\n            box_type_3d, BaseInstance3DBoxes)\n    if not isinstance(box_mode_3d, Box3DMode):\n        raise TypeError('box_mode_3d should be a Box3DMode enum')\n    allowed_metrics = ['mAP', 'mAR']\n    if metric == allowed_metrics[0]:\n        iou_thresh = [0.25, 0.5]\n    elif metric == allowed_metrics[1]:\n        iou_thresh = [0.25, 0.5]\n    else:\n        raise NotImplementedError\n\n    gt_boxes = [\n        box_type_3d(\n            annos['gt_boxes_3d'], box_dim=annos['gt_boxes_3d'].shape[-1],\n            with_yaw=False, origin=(0.5, 0.5, 0.5)) for annos in gt_annos\n    ]\n    dt_boxes = [\n        box_type_3d(\n            annos['pred_boxes_3d'], box_dim=annos['pred_boxes_3d'].shape[-1],\n            with_yaw=False, origin=(0.5, 0.5, 0.5)) for annos in dt_annos\n    ]\n\n    result_str, result_dict = indoor_eval_class(\n        gt_boxes,\n        dt_boxes,\n        iou_thresh,\n        label2cat,\n        box_mode_3d=box_mode_3d)\n\n    if logger is None:\n        print_log('\\n' + result_str, logger=logger)\n    else:\n        logger.info('\\n'"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d == 'Depth' and box_mode_3d == 'K':\n        gt_annos = ind_eval_utils.depth_box3d_to_camera_box(gt_annos)\n        dt_annos = ind_eval_utils.depth_box3d_to_camera_box(dt_annos)\n\n    # Get all the classes present in the ground truth and detection annotations\n    class_names = [label2cat[label] for label in label2cat.keys()]\n    class_names = sorted(class_names)\n\n    # Initialize the evaluation results dictionary\n    eval_results = {}\n    for iou in metric:\n        eval_results['recall_rocs{}'.format(iou)] = {}\n        eval_results['precision_rocs{}'.format(iou)] = {}\n        eval_results['ap_rocs{}'.format(iou)] = {}\n\n    # Initialize the total number of ground truth objects and the total number of detected objects\n    total_gt_num = 0\n    total_dt_num = 0\n\n    # Loop through each class and compute the evaluation results\n    for idx, name in enumerate(class_names):\n        # Get the ground truth annotations for the current class\n        gt_class_annos = [anno for anno in gt_annos if anno['name'] == name]\n        # Get the detection annotations for the current class\n        dt_class_annos = [anno for anno in dt_annos if anno['name'] == name]\n        # Compute the evaluation results for the current class\n        eval_ret_dict = ind_eval_utils.class_eval(gt_class_annos, dt_class_annos, metric)\n\n        # Update the evaluation results dictionary with the results for the current class\n        for jdx in range(len(metric)):\n            eval_results['recall_rocs{}'.format(metric[jdx])][name] = eval"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d == 'Depth' or box_type_3d == 'BEV':\n        gt_annos = indoor_eval.convert_valid_bboxes_to_o3d_box(gt_annos)\n        dt_annos = indoor_eval.convert_valid_bboxes_to_o3d_box(dt_annos)\n    else:\n        gt_annos = gt_annos\n        dt_annos = dt_annos\n\n    recalls = [\n        dict() for _ in range(len(metric))\n    ]  # list[dict[label: np.ndarray[num_iou, num_recall_points]].\n    precisions = [\n        dict() for _ in range(len(metric))\n    ]  # list[dict[label: np.ndarray[num_iou, num_precision_points]]].\n    aps = [\n        dict() for _ in range(len(metric))\n    ]  # list[dict[label: float]].\n    for i, thresh in enumerate(metric):\n        # convert detection and ground truth to eval format\n        # TODO: use a single function and pass the\n        # box_type_3d\n        recalls[i], precisions[i], aps[i] = eval_map_recall(\n            gt_annos,\n            dt_annos,\n            iou_thr=thresh,\n            box_type_3d=box_type_3d,\n            box_mode_3d=box_mode_3d)\n\n    # calculate mean AP over all classes\n    all_ap = {}\n    for label in aps[0].keys():\n        label_name = label2cat[label]\n        all_ap[label_name] = np.mean(\n            [ap[label] for ap in aps], axis=0)  # different iou\n\n    ret_dict = {}\n    for label in aps[0].keys():\n        label_name ="}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d == 'Depth':\n        gt_annos = eval_depth_metric(gt_annos)\n        dt_annos = eval_depth_metric(dt_annos)\n    if box_type_3d == 'Camera':\n        gt_annos = eval_camera_metric(gt_annos)\n        dt_annos = eval_camera_metric(dt_annos)\n    if box_type_3d == 'LIDAR':\n        gt_annos = eval_lidar_metric(gt_annos)\n        dt_annos = eval_lidar_metric(dt_annos)\n    if box_type_3d == 'Project':\n        gt_annos = eval_projection_metric(gt_annos)\n        dt_annos = eval_projection_metric(dt_annos)\n    gt_annos = eval_det_metric(gt_annos)\n    dt_annos = eval_det_metric(dt_annos)\n\n    rec, prec, ap = eval_map_recall(\n        dt_annos, gt_annos, metric, label2cat)\n    ret_dict = dict()\n    header = ['classes']\n    for i, iou_thresh in enumerate(metric):\n        header.append(f'AP_{iou_thresh:.2f}')\n        header.append(f'AR_{iou_thresh:.2f}')\n    ret_dict['title'] = 'Indoor metric:'\n    ret_dict['table_header'] = header\n\n    ret_dict['AR@1'] = 0\n    ret_dict['AR@2'] = 0\n    ret_dict['AR@3'] = 0\n    ret_dict['AR@4'] = 0\n    ret_dict['AR@5'] = 0\n    ret_dict['AR@6'] = 0\n    ret_dict['AR@7'] = 0\n    ret_dict['"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d == 'Depth' and box_mode_3d == 'K':\n        gt_annos = indoor_eval_utils.depth_box3d_to_bbox(gt_annos)\n        dt_annos = indoor_eval_utils.depth_box3d_to_bbox(dt_annos)\n\n    # parse detected annotations\n    # dt_annos = indoorscene_eval.get_official_eval_result(gt_annos, dt_annos,\n    #                                                     box_type_3d)\n    dt_annos = indoorscene_eval.get_official_eval_result(gt_annos, dt_annos,\n                                                        box_type_3d)\n\n    # parse gt annotations\n    if box_type_3d == 'Depth' and box_mode_3d == 'K':\n        gt_annos = indoorscene_eval.get_label_annos(gt_annos, box_type_3d)\n    else:\n        gt_annos = indoorscene_eval.get_label_annos(gt_annos, box_type_3d)\n\n    if logger is None:\n        logger = logging.getLogger(__name__)\n    logger.info('*************** INDOOR OFFICIAL EVAL ******************')\n    logger.info('Evaluate by class:')\n    ret_dict = indoorscene_eval.eval_by_class(gt_annos, dt_annos, label2cat,\n                                               box_type_3d, metric)\n    logger.info('Evaluate by difficulty:')\n    ret_dict = indoorscene_eval.eval_by_difficulty(gt_annos, dt_annos, label2cat,\n                                                   box_type_3d, metric,\n                                                   ret_dict)\n    logger.info('Evaluate by distance:')\n    indoorscene_eval.eval"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d is None:\n        box_type_3d = get_box_type(gt_annos[0]['gt_boxes_upright_depth'])\n    if box_mode_3d is None:\n        box_mode_3d = get_box_mode(gt_annos[0]['gt_boxes_upright_depth'])\n    if len(metric) == 0:\n        metric = [0.25]\n    if len(label2cat) == 0:\n        label2cat = {i: i for i in range(10)}\n    ret_dict = {}\n    for iou in metric:\n        print_log(f'Evaluate mAP@{iou:.0%}', logger=logger)\n        iou_th_dict = {}\n        for label, cat in label2cat.items():\n            ret_dict_label = {}\n            for level in range(1, 6):\n                gt_lidar_boxes = []\n                for j in range(len(gt_annos)):\n                    gt_boxes = box_type_3d.convert(\n                        gt_annos[j]['gt_boxes_upright_depth'],\n                        box_mode_3d,\n                        Box3DMode.DEPTH)\n                    gt_lidar_boxes.append(gt_boxes[gt_annos[j]['location'] == level])\n                dt_lidar_boxes = []\n                for j in range(len(dt_annos)):\n                    dt_boxes = box_type_3d.convert(\n                        dt_annos[j]['boxes_3d'],\n                        box_mode_3d,\n                        Box3DMode.LIDAR)\n                    dt_lidar_boxes.append(dt_boxes[dt_annos[j]['location'] == level])\n                annotations = {}\n                annotations['gt'] = gt_lidar_boxes\n                annotations['dt"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d == 'Depth' or box_type_3d == 'BEV':\n        gt_annos = indoor_eval_utils.depth_2_annos_custom(gt_annos)\n        dt_annos = indoor_eval_utils.depth_2_annos_custom(dt_annos)\n    elif box_type_3d == 'Camera':\n        gt_annos = indoor_eval_utils.camera_only_2_annos(gt_annos)\n        dt_annos = indoor_eval_utils.camera_only_2_annos(dt_annos)\n    else:\n        raise NotImplementedError(\n            f'unsupported box_type {box_type_3d} for indoor eval')\n\n    if box_mode_3d != 'wlh_camera':\n        dt_annos = box_mode_3d_to_camera(dt_annos)\n        gt_annos = box_mode_3d_to_camera(gt_annos)\n    else:\n        gt_annos = gt_annos\n        dt_annos = dt_annos\n\n    # convert 3d to depth mode\n    gt_annos = box_mode_3d_to_depth(gt_annos)\n    gt_annos = box_mode_3d_to_depth(gt_annos)\n\n    # convert custom output format to the default output format\n    gt_annos = custom_output_format_to_default_format(gt_annos)\n    dt_annos = custom_output_format_to_default_format(dt_annos)\n\n    # obtain gts\n    class_to_gts = get_class_to_class_gts(gt_annos, label2cat)\n    class_to_gts = group_by_key(class_to_gts, 'name')\n\n    # obtain dets\n    class_to_d"}
{"namespace": "mmdet3d.core.evaluation.indoor_eval.indoor_eval", "completion": "    assert len(dt_annos) == len(gt_annos)\n    if box_type_3d == 'Depth':\n        gt_annos = box_type_3d.remove_dontcare(gt_annos)\n    pred_eval_records = [[] for metric in metric]\n    gt_eval_records = [[] for metric in metric]\n    for i in range(len(gt_annos)):\n        rets = indoor_eval_single_sample(gt_annos[i], dt_annos[i], metric,\n                                         label2cat)\n        for label in range(len(rets)):\n            for k in range(len(metric)):\n                pred_eval_records[k].append(rets[label][k][0])\n                gt_eval_records[k].append(rets[label][k][1])\n    class_names = [label2cat[label] for label in label2cat]\n    ret_dict = indoor_eval_class(pred_eval_records, gt_eval_records,\n                                 class_names, metric, label2cat, logger=logger)\n    return ret_dict\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    from .box_3d_mode import (Box3DMode, CameraInstance3DBoxes, DepthInstance3DBoxes,\n                              LiDARInstance3DBoxes)\n    box_type_lower = box_type.lower()\n    if box_type_lower == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type_lower == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type_lower == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"Lidar\", \"Camera\", \"Depth\" are supported for now')\n\n    return box_type_3d, box_mode_3d"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    from .box_3d_mode import (Box3DMode, CameraInstance3DBoxes,\n                              DepthInstance3DBoxes, LiDARInstance3DBoxes)\n    box_type_lower = box_type.lower()\n    if box_type_lower == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type_lower == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type_lower == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"box_type\" of \"camera\", \"lidar\", \"depth\" are '\n                         f'supported, got {box_type}')\n\n    return box_type_3d, box_mode_3d"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    from .box_3d_mode import (Box3DMode, CameraInstance3DBoxes, DepthInstance3DBoxes,\n                              LiDARInstance3DBoxes)\n    box_type_lower = box_type.lower()\n    if box_type_lower == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type_lower == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type_lower == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"box_type\" of \"camera\", \"lidar\", \"depth\" are '\n                         f'supported, got {box_type}')\n\n    return box_type_3d, box_mode_3d"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    from .box_3d_mode import (Box3DMode, CameraInstance3DBoxes, DepthInstance3DBoxes,\n                              LiDARInstance3DBoxes)\n    box_type_lower = box_type.lower()\n    if box_type_lower == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type_lower == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type_lower == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"Lidar\", \"Camera\", \"Depth\" are supported for now')\n\n    return box_type_3d, box_mode_3d"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    from .box_3d_mode import (Box3DMode, CameraInstance3DBoxes,\n                              DepthInstance3DBoxes, LiDARInstance3DBoxes)\n    box_type_lower = box_type.lower()\n    if box_type_lower == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type_lower == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type_lower == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"Lidar\", \"Camera\", \"Depth\" are supported for '\n                         f'box_type, got {box_type}')\n\n    return box_type_3d, box_mode_3d"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    from .box_3d_mode import (Box3DMode, CameraInstance3DBoxes,\n                              DepthInstance3DBoxes, LiDARInstance3DBoxes)\n    box_type_lower = box_type.lower()\n    if box_type_lower == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type_lower == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type_lower == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"Lidar\", \"Camera\", \"Depth\" are '\n                         f'supported, got {box_type}')\n\n    return box_type_3d, box_mode_3d"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    from .box_3d_mode import (Box3DMode, CameraInstance3DBoxes,\n                              DepthInstance3DBoxes, LiDARInstance3DBoxes)\n    box_type_lower = box_type.lower()\n    if box_type_lower == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type_lower == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type_lower == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError(\n            f'Only \"box_type\" of \"camera\", \"lidar\", \"depth\" are supported, got {box_type}'\n        )\n\n    return box_type_3d, box_mode_3d"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    box_type_lower = box_type.lower()\n    if box_type_lower == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type_lower == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type_lower == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"Lidar\", \"Camera\" and \"Depth\" are supported.')\n\n    return box_type_3d, box_mode_3d"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    from .box_3d_mode import (Box3DMode, CameraInstance3DBoxes,\n                              DepthInstance3DBoxes, LiDARInstance3DBoxes)\n\n    box_type_lower = box_type.lower()\n    if box_type_lower == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type_lower == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type_lower == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"box_type\" of \"camera\", \"lidar\", \"depth\" are '\n                         f'supported, got {box_type}')\n\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"LiDAR\", \"Camera\", and \"Depth\" are supported for now')\n\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"LiDAR\", \"Camera\", and \"Depth\" '\n                         f'are supported, got {box_type}')\n\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    from .box_3d_mode import (Box3DMode, CameraInstance3DBoxes, DepthInstance3DBoxes,\n                              LiDARInstance3DBoxes)\n    box_type_lower = box_type.lower()\n    if box_type_lower == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type_lower == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type_lower == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError(\n            'Only \"box_type\" of \"camera\", \"lidar\", \"depth\" are allowed, '\n            f'got {box_type}')\n\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type == 'LiDAR':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type == 'Camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type == 'Depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"LiDAR\", \"Camera\", \"Depth\" are supported for now')\n\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    from .box_3d_mode import (Box3DMode, CameraInstance3DBoxes, DepthInstance3DBoxes,\n                              LiDARInstance3DBoxes)\n    box_type_lower = box_type.lower()\n    if box_type_lower == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type_lower == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type_lower == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError(\n            f\"Only support 3d box type in ['LiDAR', 'Camera', 'Depth'], \"\n            f'got {box_type}')\n\n    return box_type_3d, box_mode_3d"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    from .box_3d_mode import (Box3DMode, CameraInstance3DBoxes, DepthInstance3DBoxes,\n                              LiDARInstance3DBoxes)\n    box_type_lower = box_type.lower()\n    if box_type_lower == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type_lower == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type_lower == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError(\n            f\"Got unsupported box_type {box_type} with type of {type(box_type)}\")\n\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type.lower() == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type.lower() == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type.lower() == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only accepts 3d box type of lidar, camera or depth')\n\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    if box_type.lower() == 'lidar':\n        box_type_3d = LiDARInstance3DBoxes\n        box_mode_3d = Box3DMode.LIDAR\n    elif box_type.lower() == 'camera':\n        box_type_3d = CameraInstance3DBoxes\n        box_mode_3d = Box3DMode.CAM\n    elif box_type.lower() == 'depth':\n        box_type_3d = DepthInstance3DBoxes\n        box_mode_3d = Box3DMode.DEPTH\n    else:\n        raise ValueError('Only \"box_type\" of \"camera\", \"lidar\", \"depth\" are '\n                         f'supported, got {box_type}')\n\n    return box_type_3d, box_mode_3d\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    # Dictionary mapping box type strings to their corresponding 3D box classes and modes\n    type_to_class_mode = {\n        'LiDAR': (LiDARInstance3DBoxes, 'lidar'),\n        'Camera': (CameraInstance3DBoxes, 'camera'),\n        'Depth': (DepthInstance3DBoxes, 'lidar'),\n    }\n\n    # Check if the input box type is in the dictionary\n    if box_type not in type_to_class_mode:\n        # If not, raise a ValueError with a message indicating the unrecognized box type\n        raise ValueError(f'Unrecognized box type {box_type}')\n\n    # Return the corresponding 3D box class and mode from the dictionary\n    return type_to_class_mode[box_type]\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    # Define a dictionary mapping box type strings to their corresponding 3D box classes and modes\n    type_to_class_mode = {\n        'LiDAR': (LiDARInstance3DBoxes, 'lidar'),\n        'Camera': (CameraInstance3DBoxes, 'camera'),\n        'Depth': (DepthInstance3DBoxes, 'depth')\n    }\n\n    # Check if the input box type is a valid key in the type_to_class_mode dictionary\n    if box_type not in type_to_class_mode:\n        # If not, raise a ValueError with a message indicating that the box type is not recognized\n        raise ValueError(f'Unrecognized box type {box_type}')\n\n    # Return the corresponding 3D box class and mode for the input box type\n    return type_to_class_mode[box_type]\n\n"}
{"namespace": "mmdet3d.core.bbox.structures.utils.get_box_type", "completion": "    # Define a dictionary mapping box type strings to corresponding 3D box classes and modes\n    type_to_class_mode = {\n        'LiDAR': (LiDARInstance3DBoxes, 'lidar'),\n        'Camera': (CameraInstance3DBoxes, 'camera'),\n        'Depth': (DepthInstance3DBoxes, 'depth')\n    }\n\n    # Check if the input box type is in the dictionary\n    if box_type not in type_to_class_mode:\n        # If the box type is not recognized, raise a ValueError with a message indicating the invalid box type\n        raise ValueError(f'Invalid box type: {box_type}')\n\n    # Return the corresponding 3D box class and mode from the dictionary\n    return type_to_class_mode[box_type]\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    for message in messages:\n      if not isinstance(message, (Message, dict)):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message['role'],\n            'content': message['content'],\n            'images': [_encode_image(image) for image in message.get('images', [])],\n          }\n          for message in messages\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide at least one message')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    if not all(isinstance(message, (Message, dict)) for message in messages):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message.get('role'),\n            'content': message.get('content'),\n            'images': [_encode_image(image) for image in message.get('images') or []],\n          }\n          for message in messages\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      messages = []\n\n    for message in messages:\n      if not isinstance(message, Message):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [{\n          'role': message.role,\n          'content': message.content,\n          'images': [_encode_image(image) for image in message.images or []],\n        } for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    for message in messages:\n      if not isinstance(message, Message):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_encode_message(message) for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    if not all(isinstance(message, (Message, dict)) for message in messages):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message.get('role'),\n            'content': message.get('content'),\n            'images': [_encode_image(image) for image in message.get('images', [])],\n          }\n          for message in messages\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    if not all(isinstance(message, (Message, dict)) for message in messages):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message['role'],\n            'content': message['content'],\n            'images': [_encode_image(image) for image in message.get('images', [])],\n          }\n          for message in messages\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is None:\n      messages = []\n\n    if not isinstance(messages, (list, tuple)):\n      raise TypeError('messages must be a list or tuple')\n\n    for message in messages:\n      if not isinstance(message, (Message, dict)):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [{\n          'role': message['role'],\n          'content': message['content'],\n          'images': [_encode_image(image) for image in message.get('images', [])],\n        } for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not all(isinstance(message, (Message, dict)) for message in messages):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [{\n          'role': message['role'],\n          'content': message['content'],\n          'images': [_encode_image(image) for image in message.get('images', [])],\n        } for message in messages or []],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide messages')\n\n    if not isinstance(messages, (list, tuple)):\n      raise TypeError('messages must be a list or tuple')\n\n    if not all(isinstance(message, (Message, dict)) for message in messages):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message['role'],\n            'content': message['content'],\n            'images': [_encode_image(image) for image in message.get('images', [])],\n          }\n          for message in messages\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide at least one message')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    for message in messages:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      if 'role' not in message:\n        raise RequestError('messages must have a role')\n\n      if 'content' not in message:\n        raise RequestError('messages must have content')\n\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide at least one message')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    if not all(isinstance(message, (Message, dict)) for message in messages):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_encode_message(message) for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list')\n\n      for message in messages:\n        if not isinstance(message, (Message, dict)):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n        if images := message.get('images'):\n          message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    for message in messages:\n      if not isinstance(message, (Message, dict)):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message.get('role', ''),\n            'content': message.get('content', ''),\n            'images': [_encode_image(image) for image in message.get('images', [])],\n          }\n          for message in messages\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    for message in messages:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      if not isinstance(message.get('role'), str):\n        raise RequestError('messages must have a role')\n\n      if not isinstance(message.get('content'), str):\n        raise RequestError('messages must have content')\n\n      if images := message.get('images'):\n        if not isinstance(images, list):\n          raise TypeError('images must be a list of str or bytes')\n\n        for image in images:\n          if not isinstance(image, (str, bytes)):\n            raise TypeError('images must be a list of str or bytes')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [\n          {\n            'role': message.get('role'),\n            'content': message.get('content'),\n            'images': [_encode_image(image) for image in message.get('images') or []],\n          }\n          for message in messages\n        ],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    if not all(isinstance(message, (Message, dict)) for message in messages):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    if not all(isinstance(message, Message) for message in messages):\n      messages = [Message(**message) for message in messages]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [message.dict() for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if not messages:\n      raise RequestError('must provide at least one message')\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    for message in messages:\n      if not isinstance(message, Message):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [_encode_message(message) for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is not None:\n      if not isinstance(messages, list):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      for message in messages:\n        if not isinstance(message, dict):\n          raise TypeError('messages must be a list of Message or dict-like objects')\n\n        if 'role' not in message or 'content' not in message:\n          raise RequestError('messages must contain a role and content')\n\n        if images := message.get('images'):\n          message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is None:\n      messages = []\n\n    if not isinstance(messages, list):\n      raise TypeError('messages must be a list')\n\n    if not all(isinstance(message, (Message, dict)) for message in messages):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': [{\n          'role': message.role,\n          'content': message.content,\n          'images': [_encode_image(image) for image in message.images or []],\n        } for message in messages],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages:\n      for message in messages:\n        if not isinstance(message, (Message, dict)):\n          raise TypeError(f'message must be a Message or dict, not {type(message)}')\n\n        if images := message.get('images'):\n          message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages or [],\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    if messages is None:\n      messages = []\n    elif not isinstance(messages, list):\n      raise TypeError('messages must be a list of Message or dict-like objects')\n\n    for i, message in enumerate(messages):\n      if isinstance(message, Message):\n        message = message.dict()\n      elif not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n\n      if not isinstance(message.get('content'), str):\n        raise TypeError(f'message {i} content must be a string')\n\n      if not isinstance(message.get('role'), str):\n        raise TypeError(f'message {i} role must be a string')\n\n      if role := message.get('role'):\n        if role not in ('system', 'user', 'assistant'):\n          raise ValueError(f'message {i} role must be one of \"system\", \"user\", \"assistant\"')\n\n      if images := message.get('images'):\n        if not isinstance(images, list):\n          raise TypeError(f'message {i} images must be a list of images')\n\n        message['images'] = [_encode_image(image) for image in images]\n\n    return self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.pull", "completion": "    return self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'model': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=params, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep-alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=params, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=params, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n    }\n\n    return self._request_stream(\n      'POST',\n      '/generate',\n      json=data,\n      stream=stream,\n      params={'keep-alive': keep_alive} if keep_alive else None,\n    )\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if images is None:\n      images = []\n\n    if context is None:\n      context = []\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'stream': stream,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if images is not None:\n      images = [\n        b64encode(image if isinstance(image, bytes) else Path(image).read_bytes()).decode('ascii')\n        for image in images\n      ]\n\n    if context is None:\n      context = []\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if images is not None:\n      images = [b64encode(i if isinstance(i, bytes) else Path(i).read_bytes()).decode() for i in images]\n\n    if context is None:\n      context = []\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if images:\n      images = [\n        b64encode(image.read() if isinstance(image, PathLike) else image).decode()\n        for image in images\n      ]\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'stream': stream,\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if images is None:\n      images = []\n\n    if context is None:\n      context = []\n\n    if keep_alive is None:\n      keep_alive = '0'\n\n    if isinstance(keep_alive, float):\n      keep_alive = str(keep_alive)\n\n    if options is None:\n      options = {}\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'stream': stream,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep-alive': keep_alive,\n    }\n\n    if raw:\n      params['raw'] = 'true'\n\n    return self._request_stream('POST', '/generate', json=params, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    params = {\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'stream': stream,\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep_alive': keep_alive,\n    }\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n    }\n\n    return self._request_stream('post', '/generate', params=params, json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    params = {}\n    if system:\n      params['system'] = system\n    if template:\n      params['template'] = template\n    if context:\n      params['context'] = context\n    if raw:\n      params['raw'] = True\n    if format:\n      params['format'] = format\n    if images:\n      params['images'] = images\n    if options:\n      params['options'] = options\n    if keep_alive:\n      params['keep_alive'] = keep_alive\n\n    data = {'model': model, 'prompt': prompt, 'params': params}\n\n    return self._request_stream('POST', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if not keep_alive:\n      keep_alive = '0'\n    elif isinstance(keep_alive, float):\n      keep_alive = str(keep_alive)\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep-alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if images:\n      images = [\n        b64encode(image if isinstance(image, bytes) else open(image, 'rb').read()).decode()\n        for image in images\n      ]\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options or {},\n    }\n\n    if keep_alive:\n      data['keep_alive'] = keep_alive\n\n    return self._request_stream('POST', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if keep_alive is not None:\n      if isinstance(keep_alive, str):\n        keep_alive = float(keep_alive)\n      if keep_alive < 0:\n        raise RequestError('keep_alive must be a positive number')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=params, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    if images:\n      images = [\n        {\n          'data': b64encode(image.read() if isinstance(image, io.BufferedIOBase) else image).decode('utf-8'),\n          'sha256': sha256(image.read() if isinstance(image, io.BufferedIOBase) else image).hexdigest(),\n        }\n        for image in images\n      ]\n\n    if context:\n      context = [\n        {\n          'type': 'image',\n          'id': sha256(image.encode('utf-8') if isinstance(image, str) else image).hexdigest(),\n        }\n        for image in context\n      ]\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context,\n      'raw': raw,\n      'format': format,\n      'images': images,\n      'options': options,\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/api/v1/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    data = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n    }\n\n    if keep_alive is not None:\n      if isinstance(keep_alive, str):\n        keep_alive = float(keep_alive)\n      data['keep_alive'] = keep_alive\n\n    return self._request_stream('POST', '/generate', json=data, stream=stream)\n"}
{"namespace": "ollama._client.Client.generate", "completion": "    if not model:\n      raise RequestError('model is required')\n\n    params = {\n      'model': model,\n      'prompt': prompt,\n      'system': system,\n      'template': template,\n      'context': context or [],\n      'stream': stream,\n      'raw': raw,\n      'format': format,\n      'images': images or [],\n      'options': options or {},\n      'keep_alive': keep_alive,\n    }\n\n    return self._request_stream('POST', '/generate', json=params)\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.push", "completion": "    return self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not modelfile:\n      if not path:\n        raise RequestError('must provide a path or modelfile')\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not modelfile and not path:\n      raise RequestError('must provide a path or modelfile')\n\n    if not modelfile:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either a path or modelfile')\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile or Path(path).read_bytes(),\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not modelfile and not path:\n      raise RequestError('must provide either a path or modelfile')\n\n    if not modelfile:\n      with Path(path).open('rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not modelfile:\n      if not path:\n        raise RequestError('must provide a path or modelfile')\n      modelfile = Path(path).read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if path is None and modelfile is None:\n      raise RequestError('must provide a path or modelfile')\n\n    if path is not None:\n      path = Path(path)\n      modelfile = path.read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path and not modelfile:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if not modelfile:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not modelfile:\n      if not path:\n        raise RequestError('must provide either a path or a modelfile')\n      modelfile = Path(path).read_bytes()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either path or modelfile')\n\n    if not modelfile:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either a path or modelfile')\n\n    if path:\n      path = Path(path)\n      if not path.is_file():\n        raise RequestError('path must be a file')\n\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': b64encode(modelfile).decode('ascii'),\n        'stream': stream,\n      },\n      stream=stream,\n    )"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if not modelfile:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path:\n      path = Path(path)\n      if not path.exists():\n        raise RequestError('path does not exist')\n      if not path.is_file():\n        raise RequestError('path is not a file')\n\n      with path.open('rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide a path or modelfile')\n\n    if path and not modelfile:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not modelfile:\n      if not path:\n        raise RequestError('must provide either path or modelfile')\n      modelfile = Path(path).read_bytes()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either path or modelfile')\n\n    if path:\n      path = Path(path)\n      if not path.exists():\n        raise RequestError('path does not exist')\n      if not path.is_file():\n        raise RequestError('path is not a file')\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': b64encode(modelfile).decode(),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either a path or a modelfile')\n\n    if path:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': b64encode(modelfile).decode('utf-8'),\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not path and not modelfile:\n      raise RequestError('must provide either path or modelfile')\n\n    if path and not modelfile:\n      with open(path, 'rb') as f:\n        modelfile = f.read()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'model': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client.create", "completion": "    if not modelfile and not path:\n      raise RequestError('must provide either a path or modelfile')\n\n    if not modelfile:\n      path = Path(path)\n      modelfile = path.read_text()\n\n    return self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    digest = f'sha256:{sha256(path.read_bytes()).hexdigest()}'\n\n    try:\n      self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n      self._request('POST', f'/api/blobs/{digest}', content=path.read_bytes())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise\n      with open(path, 'rb') as f:\n        self._client.post(f'/api/blobs/{digest}', content=f.read())\n\n    return f'sha256:{digest}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    digest = f'sha256:{sha256(path.read_bytes()).hexdigest()}'\n\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise ResponseError(e.response.text, e.response.status_code) from None\n\n      with path.open('rb') as f:\n        self._client.post(\n          '/api/blobs',\n          files={\n            'file': (path.name, f, 'application/octet-stream'),\n          },\n        )\n\n    return digest\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise\n      with open(path, 'rb') as f:\n        self._client.post(f'/api/blobs/{digest}', content=f.read())\n\n    return f'sha256:{digest}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise\n\n      with open(path, 'rb') as f:\n        self._client.post(f'/api/blobs/{digest}', content=f.read())\n\n    return f'sha256:{digest}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    try:\n      self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n      with open(path, 'rb') as f:\n        self._request('POST', '/api/blobs', data=f)\n\n    return f'sha256:{digest}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    digest = f'sha256:{sha256(path.read_bytes()).hexdigest()}'\n\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise ResponseError(e.response.text, e.response.status_code) from None\n\n      self._client.post(\n        '/api/blobs',\n        content=path.read_bytes(),\n        headers={'Content-Type': 'application/octet-stream'},\n      )\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blob/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise ResponseError(e.response.text, e.response.status_code) from None\n\n      with open(path, 'rb') as f:\n        self._client.post(f'/api/blob/{digest}', content=f)\n\n    return f'sha256:{digest}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      data = f.read()\n      digest = 'sha256:' + sha256(data).hexdigest()\n\n    try:\n      self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n      self._request('POST', f'/api/blobs/{digest}', data=data)\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      digest = sha256(f.read()).hexdigest()\n      if self._client.head(f'/api/blobs/{digest}').status_code == 404:\n        self._client.post(f'/api/blobs/{digest}', data=f)\n      return f'sha256:{digest}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n\n    with path.open('rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    try:\n      self._client.head(f'/api/blob/{digest}')\n      return digest\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise\n\n    with path.open('rb') as f:\n      self._client.post(f'/api/blob/{digest}', content=f.read())\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    # Open the file in binary mode and calculate its SHA-256 checksum\n    with open(path, 'rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    # Check if a blob with the same checksum already exists on the server\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise ResponseError(e.response.text, e.response.status_code) from None\n\n      # If the blob does not exist, upload the file as a new blob\n      with open(path, 'rb') as f:\n        self._client.post('/api/blobs', files={'file': f})\n\n    # Return the digest of the file in the format 'sha256:<hexdigest>'\n    return f'sha256:{digest}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    digest = sha256(path.read_bytes()).hexdigest()\n    try:\n      self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n      with path.open('rb') as f:\n        self._request('POST', '/api/blobs', files={'file': (path.name, f)})\n    return f'sha256:{digest}'"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    if not path.exists():\n      raise RequestError(f'{path} does not exist')\n\n    digest = f'sha256:{sha256(path.read_bytes()).hexdigest()}'\n\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code == 404:\n        self._client.post('/api/blobs', files={'file': path.open('rb')})\n\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n    if not path.exists():\n      raise RequestError(f'file {path} does not exist')\n\n    digest = f'sha256:{sha256(path.read_bytes()).hexdigest()}'\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise ResponseError(e.response.text, e.response.status_code) from None\n\n      self._client.post(f'/api/blobs/{digest}', content=path.read_bytes())\n\n    return digest\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n\n    digest = 'sha256:' + sha256(path.read_bytes()).hexdigest()\n    try:\n      self._client.head(f'/api/blob/{digest}')\n      return digest\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise\n\n    self._client.post(\n      '/api/blob',\n      files={\n        'file': (path.name, path.read_bytes()),\n      },\n    )\n    return digest"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      data = f.read()\n\n    digest = 'sha256:' + sha256(data).hexdigest()\n\n    try:\n      self._client.head(f'/api/blobs/{digest}')\n    except httpx.HTTPStatusError as e:\n      if e.response.status_code != 404:\n        raise\n      self._client.post(\n        '/api/blobs',\n        content=data,\n        headers={\n          'Content-Type': 'application/octet-stream',\n          'Digest': digest,\n        },\n      )\n\n    return digest\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    # Calculate the SHA-256 checksum of the file\n    with open(path, 'rb') as f:\n      digest = sha256(f.read()).hexdigest()\n\n    # Check if the blob already exists\n    try:\n      self._request('HEAD', f'/api/blobs/{digest}')\n      return f'sha256:{digest}'\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n    # Upload the file as a new blob\n    with open(path, 'rb') as f:\n      self._request('POST', '/api/blobs', data=f.read())\n\n    return f'sha256:{digest}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    with open(path, 'rb') as f:\n      data = f.read()\n\n    digest = sha256(data).hexdigest()\n    try:\n      self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n      self._request('POST', f'/api/blobs/{digest}', content=data)\n\n    return f'sha256:{digest}'\n\n"}
{"namespace": "ollama._client.Client._create_blob", "completion": "    path = Path(path)\n\n    with open(path, 'rb') as f:\n      data = f.read()\n      digest = f'sha256:{sha256(data).hexdigest()}'\n      if self._client.head(f'/api/blobs/{digest}').status_code == 200:\n        return digest\n\n    return self._client.post(\n      '/api/blobs',\n      files={'file': (path.name, data)},\n    ).json()['digest']\n\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": ""}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.generate", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    return await self._request_stream(\n      'POST',\n      '/api/generate',\n      json={\n        'model': model,\n        'prompt': prompt,\n        'system': system,\n        'template': template,\n        'context': context or [],\n        'stream': stream,\n        'raw': raw,\n        'images': [_encode_image(image) for image in images or []],\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.pull", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/pull',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.chat", "completion": "    if not model:\n      raise RequestError('must provide a model')\n\n    for message in messages or []:\n      if not isinstance(message, dict):\n        raise TypeError('messages must be a list of Message or dict-like objects')\n      if not (role := message.get('role')) or role not in ['system', 'user', 'assistant']:\n        raise RequestError('messages must contain a role and it must be one of \"system\", \"user\", or \"assistant\"')\n      if not message.get('content'):\n        raise RequestError('messages must contain content')\n      if images := message.get('images'):\n        message['images'] = [_encode_image(image) for image in images]\n\n    return await self._request_stream(\n      'POST',\n      '/api/chat',\n      json={\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        'format': format,\n        'options': options or {},\n        'keep_alive': keep_alive,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.push", "completion": "    return await self._request_stream(\n      'POST',\n      '/api/push',\n      json={\n        'name': model,\n        'insecure': insecure,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "ollama._client.AsyncClient._create_blob", "completion": "    sha256sum = sha256()\n    with open(path, 'rb') as r:\n      while True:\n        chunk = r.read(32 * 1024)\n        if not chunk:\n          break\n        sha256sum.update(chunk)\n\n    digest = f'sha256:{sha256sum.hexdigest()}'\n\n    try:\n      await self._request('HEAD', f'/api/blobs/{digest}')\n    except ResponseError as e:\n      if e.status_code != 404:\n        raise\n\n      with open(path, 'rb') as r:\n        await self._request('POST', f'/api/blobs/{digest}', content=r)\n\n    return digest\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the combined code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as temp_file:\n            temp_file_name = temp_file.name\n            temp_file.write(user_code)\n            temp_file.write(test_code)\n\n        # Run Pyright on the combined code and capture the output\n        try:\n            output = subprocess.check_output(\n                [\"pyright\", temp_file_name], stderr=subprocess.STDOUT, text=True\n            )\n        except subprocess.CalledProcessError as e:\n            output = e.output\n\n        # Parse the Pyright output to extract error messages and line numbers\n        error_messages = []\n        line_numbers = []\n        for line in output.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_number = int(match.group(1))\n                error_message = match.group(2)\n                error_messages.append(error_message)\n                line_numbers.append(line_number)\n\n        # Check if the expected type errors are present in the error messages\n        expected_errors = cls.EXPECT_ERROR_COMMENT in user_code\n        if expected_errors:\n            # Check if the expected type errors are present in the error messages\n            expected_error_messages = [\n                message\n                for message in error_messages\n                if cls.EXPECT_ERROR_COMMENT in message\n            ]\n            if not expected_error_messages:\n                return TypeCheckResult(\n                    message=\"Did not find expected type error(s).\",\n                    passed=False,\n                    debug_info={\n                        \"error_messages\": error_messages,\n                        \"line_numbers\": line_numbers,\n                    },\n                )\n\n        # Check if there are any unexpected type errors\n        unexpected_error_messages = [\n            message\n            for message in error_messages\n            if cls.EXPECT_ERROR_COMMENT not in message\n       "}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine the user code and test code into a single string\n        code = user_code + test_code\n\n        # Create a temporary file to store the combined code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as temp_file:\n            temp_file.write(code)\n            temp_file.close()\n\n        # Run Pyright on the temporary file\n        result = subprocess.run(\n            [\"pyright\", temp_file.name], capture_output=True, text=True\n        )\n\n        # Read the output of Pyright\n        output = result.stdout\n\n        # Check if Pyright found any errors\n        if \"error\" not in output:\n            return TypeCheckResult(message=\"Type check passed\", passed=True)\n\n        # Parse the output of Pyright to get the error messages and line numbers\n        error_messages = []\n        line_numbers = []\n        for line in output.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_number = int(match.group(1))\n                error_message = match.group(2)\n                error_messages.append(error_message)\n                line_numbers.append(line_number)\n\n        # Check if any of the expected type errors were found\n        expected_error_messages = []\n        for token in tokenize.generate_tokens(io.StringIO(test_code).readline):\n            if token.type == tokenize.COMMENT and token.string.startswith(\n                cls.EXPECT_ERROR_COMMENT\n            ):\n                expected_error_messages.append(token.string[len(cls.EXPECT_ERROR_COMMENT) :])\n\n        # Check if any of the expected type errors were found\n        for expected_error_message in expected_error_messages:\n            if expected_error_message not in error_messages:\n                return TypeCheckResult(\n                    message=f\"Expected type error: {expected_error_message}\",\n                    passed=False,"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine the user code and test code\n        code = user_code + test_code\n\n        # Create a temporary file to store the combined code\n        with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False) as temp_file:\n            temp_file.write(code.encode())\n            temp_file.flush()\n\n            # Run Pyright on the temporary file\n            pyright_result = subprocess.run(\n                [\"pyright\", temp_file.name], capture_output=True, text=True\n            )\n\n        # Parse the Pyright output to identify lines with expected type errors\n        expected_errors = cls._parse_pyright_output(pyright_result.stdout)\n\n        # Check if the type check passed or failed\n        passed = cls._check_type_check_result(expected_errors, pyright_result.stdout)\n\n        # Create the result object\n        message = \"Type check passed!\" if passed else \"Type check failed.\"\n\n        # Create the result object\n        result = TypeCheckResult(message, passed)\n\n        # Add debug information to the result\n        result.debug_info[\"expected_errors\"] = expected_errors\n        result.debug_info[\"pyright_output\"] = pyright_result.stdout\n\n        return result\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary directory to store the combined code\n        with tempfile.TemporaryDirectory() as temp_dir:\n            temp_dir_path = Path(temp_dir)\n\n            # Write the combined code to a temporary file\n            combined_code_path = temp_dir_path / \"combined_code.py\"\n            with combined_code_path.open(\"w\", encoding=\"utf-8\") as f:\n                f.write(user_code)\n                f.write(test_code)\n\n            # Run Pyright on the combined code\n            pyright_output = subprocess.run(\n                [\"pyright\", str(combined_code_path)],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                encoding=\"utf-8\",\n            )\n\n            # Parse the Pyright output to extract the error messages and line numbers\n            error_messages = []\n            for line in pyright_output.stdout.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no, message = match.groups()\n                    error_messages.append((int(line_no), message))\n\n            # Identify the lines with expected type errors\n            expected_error_lines = set()\n            with io.StringIO(user_code) as f:\n                for token in tokenize.generate_tokens(f.readline):\n                    if token.type == tokenize.COMMENT and token.string.endswith(\n                        cls.EXPECT_ERROR_COMMENT\n                    ):\n                        expected_error_lines.add(token.start[0])\n\n            # Check if the type check passed or failed\n            passed = True\n            for line_no, message in error_messages:\n                if line_no not in expected_error_lines:\n                    passed = False\n                    break\n\n            # Return the result of the type check\n            if passed:\n                return TypeCheckResult(message=\"Passed\", passed=True)\n            else:\n                return TypeCheckResult(\n                    message=\"Failed\","}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the combined code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as temp_file:\n            temp_file.write(user_code)\n            temp_file.write(test_code)\n\n        # Run Pyright on the temporary file\n        result = subprocess.run(\n            [\"pyright\", temp_file.name], capture_output=True, text=True\n        )\n\n        # Delete the temporary file\n        temp_file.close()\n        Path(temp_file.name).unlink()\n\n        # Parse the Pyright output to identify lines with expected type errors\n        expected_error_lines = set()\n        for line in test_code.splitlines():\n            if line.strip().startswith(cls.EXPECT_ERROR_COMMENT):\n                line_no = int(line.strip().split(\":\")[1])\n                expected_error_lines.add(line_no)\n\n        # Check if the type check passed or failed\n        passed = True\n        error_messages = []\n        for line in result.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no = int(match.group(1))\n                message = match.group(2)\n                if line_no in expected_error_lines:\n                    if message.startswith(\"error:\"):\n                        continue\n                    else:\n                        passed = False\n                else:\n                    passed = False\n                error_messages.append(f\"Line {line_no}: {message}\")\n\n        # Generate the result message\n        if passed:\n            message = \"Congratulations, you passed all the type checks!\"\n        else:\n            message = \"Type check failed. Please check the following errors:\"\n\n        # Generate the debug info\n        debug_info = {\n            \"user_code\": user_code,\n            \"test_code\": test_code,\n            \"pyright_output\": result.stdout,\n            \"expected_error_lines\": list(expected_"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine user code and test code\n        code = user_code + test_code\n\n        # Create a temporary file to store the code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n            f.write(code)\n            f.close()\n\n        # Run Pyright on the temporary file\n        process = subprocess.Popen(\n            [\"pyright\", f.name],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            universal_newlines=True,\n        )\n        stdout, stderr = process.communicate()\n\n        # Parse Pyright output to get error messages\n        error_messages = []\n        for line in stdout.split(\"\\n\"):\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, error_message = match.groups()\n                error_messages.append((int(line_no), error_message))\n\n        # Sort error messages by line number\n        error_messages.sort(key=lambda x: x[0])\n\n        # Check if there are any expected type errors\n        expected_error_lines = cls._get_expected_error_lines(test_code)\n        if expected_error_lines:\n            # If there are expected type errors, check if Pyright reported them\n            for line_no, error_message in error_messages:\n                if line_no in expected_error_lines:\n                    # If Pyright reported an expected type error, remove it from the list\n                    expected_error_lines.remove(line_no)\n                else:\n                    # If Pyright reported an unexpected type error, add it to the error messages\n                    error_messages.append((line_no, error_message))\n\n            # If there are any expected type errors that Pyright did not report, add them to the error messages\n            for line_no in expected_error_lines:\n                error_messages.append((line_no, \"Expected type error\"))\n\n        # Sort error messages by line number\n        error_messages"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine user code and test code\n        code = user_code + \"\\n\" + test_code\n\n        # Create a temporary file to store the combined code\n        with tempfile.NamedTemporaryFile(\"w\", delete=False) as f:\n            f.write(code)\n            f.close()\n\n        # Run Pyright on the combined code\n        # We use the `--outputjson` flag to get the output in JSON format\n        # We use the `--non-interactive` flag to suppress any interactive prompts\n        # We use the `--follow-imports` flag to follow imports\n        # We use the `--pythonversion` flag to specify the Python version\n        # We use the `--pythonplatform` flag to specify the Python platform\n        # We use the `--ignoreexternal` flag to ignore external libraries\n        # We use the `--typecheckingmode` flag to specify the type checking mode\n        # We use the `--reportGeneralTypeIssues` flag to report general type issues\n        # We use the `--reportMissingImports` flag to report missing imports\n        # We use the `--reportMissingTypeStubs` flag to report missing type stubs\n        # We use the `--reportUnusedImport` flag to report unused imports\n        # We use the `--reportUnusedVariable` flag to report unused variables\n        # We use the `--reportUnusedCallResult` flag to report unused call results\n        # We use the `--reportUnusedCoroutine` flag to report unused coroutines\n        # We use the `--reportUnusedExpression` flag to report unused expressions\n        # We use the `--reportUnusedOverload` flag to report unused overloads\n        # We use the `--reportUnusedImport` flag to report unused imports\n        # We use the `--reportUnusedVariable` flag to report unused variables\n        # We use the `--reportUnusedCallResult` flag to report unused call results\n        # We use the `--reportUnusedCoroutine` flag to report unused coroutines\n        # We use the `--reportUnusedExpression` flag to report unused expressions\n        # We use the `--reportUnusedOverload` flag"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine the user code and test code into a single string\n        code = user_code + test_code\n\n        # Create a temporary file to store the combined code\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as temp_file:\n            temp_file.write(code)\n            temp_file.close()\n\n        # Run Pyright on the temporary file and capture the output\n        process = subprocess.run(\n            [\"pyright\", temp_file.name],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n        )\n\n        # Remove the temporary file\n        Path(temp_file.name).unlink()\n\n        # Initialize variables to store the expected type errors and their line numbers\n        expected_type_errors = []\n        expected_type_error_lines = set()\n\n        # Tokenize the test code to identify lines with the EXPECT_ERROR_COMMENT\n        test_code_tokens = tokenize.generate_tokens(io.StringIO(test_code).readline)\n        for token_type, token_string, _, _, _ in test_code_tokens:\n            if token_type == tokenize.COMMENT and token_string == cls.EXPECT_ERROR_COMMENT:\n                # Get the line number of the EXPECT_ERROR_COMMENT\n                line_no = token_string.split(\":\")[1]\n                expected_type_error_lines.add(int(line_no))\n\n        # Parse the Pyright output to identify lines with type errors\n        for line in process.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, message = match.groups()\n                line_no = int(line_no)\n                if line_no in expected_type_error_lines:\n                    expected_type_errors.append(message)\n\n        # Check if the expected type errors were found\n        passed = len(expected_type_errors) == len(expected_type_error_"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        with tempfile.NamedTemporaryFile(suffix=\".py\") as f:\n            f.write(user_code.encode(\"utf-8\"))\n            f.write(test_code.encode(\"utf-8\"))\n            f.flush()\n\n            # Run pyright with the temporary file and capture the output\n            process = subprocess.run(\n                [\"pyright\", f.name], capture_output=True, text=True\n            )\n\n            # Check if pyright exited with an error\n            if process.returncode != 0:\n                return TypeCheckResult(\n                    message=\"Pyright encountered an error\",\n                    passed=False,\n                    debug_info={\n                        \"stdout\": process.stdout,\n                        \"stderr\": process.stderr,\n                    },\n                )\n\n            # Parse the pyright output to identify lines with expected type errors\n            expected_errors: dict[int, str] = {}\n            for line in test_code.splitlines():\n                if line.strip().startswith(f\"# {cls.EXPECT_ERROR_COMMENT}\"):\n                    line_no = int(line.split(\":\")[1])\n                    expected_errors[line_no] = line.strip()\n\n            # Parse the pyright output to extract error messages and line numbers\n            error_messages: list[str] = []\n            for line in process.stdout.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_no = int(match.group(1))\n                    message = match.group(2)\n                    if line_no in expected_errors:\n                        # If the line number matches an expected error, remove it from the expected errors dictionary\n                        expected_errors.pop(line_no)\n                    else:\n                        # Otherwise, add the error message to the list of error messages\n                        error_messages.append(message)\n\n            # If there are any expected errors that were not found, add them to the list of error messages\n            for line_no, expected_error in expected_errors.items():\n                error_messages.append("}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Split the user code into lines\n        user_code_lines = user_code.splitlines()\n\n        # Create a temporary file to write the combined code\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as temp_file:\n            temp_file_path = temp_file.name\n\n            # Write the user code to the temporary file\n            temp_file.write(user_code)\n\n            # Write the test code to the temporary file\n            temp_file.write(test_code)\n\n        # Run Pyright on the temporary file\n        try:\n            result = subprocess.run(\n                [\"pyright\", temp_file_path, \"--outputjson\"],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                text=True,\n            )\n        except FileNotFoundError as e:\n            return TypeCheckResult(\n                message=\"Pyright not found. Please install Pyright first.\",\n                passed=False,\n                debug_info={\"exception\": str(e)},\n            )\n\n        # Delete the temporary file\n        Path(temp_file_path).unlink()\n\n        # Check if Pyright returned an error\n        if result.returncode != 0:\n            return TypeCheckResult(\n                message=\"Pyright returned an error. Please check your code.\",\n                passed=False,\n                debug_info={\"stdout\": result.stdout, \"stderr\": result.stderr},\n            )\n\n        # Parse the Pyright output\n        pyright_output = result.stdout\n        pyright_messages = cls._parse_pyright_messages(pyright_output)\n\n        # Check if the user code contains any expected type errors\n        expected_type_error_lines = cls._get_expected_type_error_lines(user_code_lines)\n\n        # Check if any expected type errors were not found\n        if expected_type_error_lines and not pyright_messages:\n            return TypeCheckResult(\n                message=\"Expected type errors not found.\",\n                passed=False,\n                debug_info={\n                    \""}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine user code and test code\n        combined_code = user_code + test_code\n\n        # Create temporary files for user code and test code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\") as user_code_file, tempfile.NamedTemporaryFile(\n            mode=\"w\", suffix=\".py\"\n        ) as test_code_file:\n            user_code_file.write(user_code)\n            user_code_file.flush()\n            test_code_file.write(test_code)\n            test_code_file.flush()\n\n            # Run Pyright on the combined code\n            command = [\"pyright\", \"--outputjson\", user_code_file.name, test_code_file.name]\n            result = subprocess.run(\n                command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding=\"utf-8\"\n            )\n\n            # Parse Pyright output\n            pyright_output = result.stdout\n            pyright_output = pyright_output.replace(\"\\r\\n\", \"\\n\")  # Normalize line endings\n            pyright_output = pyright_output.replace(\"\\r\", \"\\n\")\n            pyright_output = pyright_output.replace(\"\\\\\", \"/\")  # Normalize path separators\n\n            # Parse Pyright output into a dictionary\n            pyright_output_dict = json.loads(pyright_output)\n\n            # Extract error messages and line numbers from Pyright output\n            error_messages = []\n            error_line_numbers = []\n            for message in pyright_output_dict[\"generalDiagnostics\"]:\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, message[\"message\"])\n                if match:\n                    error_message = match.group(2)\n                    error_line_number = int(match.group(1))\n                    error_messages.append(error_message)\n                    error_line_numbers.append(error_line_number)\n\n            # Check if any expected type errors were found\n            expected_"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Create a temporary file to store the combined code\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as temp_file:\n            # Write the user code to the temporary file\n            temp_file.write(user_code)\n            # Write the test code to the temporary file\n            temp_file.write(test_code)\n            # Flush the file contents to disk\n            temp_file.flush()\n\n        # Use pyright to perform type checking on the combined code\n        # The `--outputjson` flag instructs pyright to output the results in JSON format\n        # The `--non-interactive` flag disables interactive output, which is not needed for our purposes\n        # The `--pythonversion` flag specifies the Python version to use for type checking\n        # The `--project` flag specifies the project root directory, which is required for pyright to find the configuration file\n        # The `--typechecking-timeout` flag sets the timeout for type checking, in seconds\n        # The `--pythonversion` flag specifies the Python version to use for type checking\n        # The `--project` flag specifies the project root directory, which is required for pyright to find the configuration file\n        # The `--typechecking-timeout` flag sets the timeout for type checking, in seconds\n        # The `--pythonversion` flag specifies the Python version to use for type checking\n        # The `--project` flag specifies the project root directory, which is required for pyright to find the configuration file\n        # The `--typechecking-timeout` flag sets the timeout for type checking, in seconds\n        # The `--pythonversion` flag specifies the Python version to use for type checking\n        # The `--project` flag specifies the project root directory, which is required for pyright to find the configuration file\n        # The `--typechecking-timeout` flag sets the timeout for type checking, in seconds\n        # The `--pythonversion` flag specifies the Python version to use for type checking\n        # The `--project` flag specifies the project root directory, which is required for pyright to find the configuration file\n        # The `--typechecking-timeout` flag sets the timeout for type checking, in seconds\n        # The `--pythonversion"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine the user code and test code\n        combined_code = user_code + test_code\n\n        # Create a temporary file to store the combined code\n        with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False) as temp_file:\n            temp_file.write(combined_code.encode())\n            temp_file.flush()\n\n        # Run Pyright on the temporary file\n        process = subprocess.run(\n            [\"pyright\", temp_file.name], capture_output=True, text=True\n        )\n\n        # Read the output from Pyright\n        pyright_output = process.stdout\n\n        # Extract the error messages and line numbers from the Pyright output\n        error_messages = []\n        expected_error_lines = set()\n        for line in pyright_output.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, error_message = match.groups()\n                error_messages.append(f\"Line {line_no}: {error_message}\")\n                if cls.EXPECT_ERROR_COMMENT in line:\n                    expected_error_lines.add(int(line_no))\n\n        # Determine if the type check passed or failed\n        passed = not error_messages or all(\n            int(line_no) in expected_error_lines\n            for line_no in error_messages\n            if line_no.isdigit()\n        )\n\n        # Generate the result message\n        if passed:\n            message = \"Type check passed.\"\n        else:\n            message = \"Type check failed.\\n\" + \"\\n\".join(error_messages)\n\n        # Return the result\n        return TypeCheckResult(\n            message=message,\n            passed=passed,\n            debug_info={\n                \"expected_error_lines\": expected_error_lines,\n                \"error_messages\": error_messages,\n            },\n        )\n\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        with tempfile.TemporaryDirectory() as temp_dir:\n            temp_dir = Path(temp_dir)\n            temp_file = temp_dir / \"temp.py\"\n            temp_file.write_text(user_code + test_code)\n\n            # Run Pyright on the combined code\n            result = subprocess.run(\n                [\"pyright\", temp_file, \"--outputjson\"],\n                capture_output=True,\n                text=True,\n            )\n\n            # Parse the Pyright output to extract error messages and line numbers\n            errors = []\n            line_numbers = []\n            for line in result.stdout.splitlines():\n                match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                if match:\n                    line_numbers.append(int(match.group(1)))\n                    errors.append(match.group(2))\n\n            # Identify expected type errors in the test code\n            expected_errors = []\n            expected_line_numbers = []\n            with io.StringIO(test_code) as f:\n                for token in tokenize.generate_tokens(f.readline):\n                    if token.type == tokenize.COMMENT and token.string.strip() == cls.EXPECT_ERROR_COMMENT:\n                        # The previous token is the line number\n                        expected_line_numbers.append(token.start[0] - 1)\n                        # The next token is the error message\n                        expected_errors.append(token.line.split(cls.EXPECT_ERROR_COMMENT)[1].strip())\n\n            # Compare the actual errors with the expected errors\n            passed = True\n            if len(errors) != len(expected_errors):\n                passed = False\n            else:\n                for error, line_number, expected_error, expected_line_number in zip(\n                    errors, line_numbers, expected_errors, expected_line_numbers\n                ):\n                    if error != expected_error or line_number != expected_line_number:\n                        passed = False\n                        break\n\n            # Construct the result message\n            if"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        with tempfile.TemporaryDirectory() as temp_dir:\n            temp_dir_path = Path(temp_dir)\n            test_file_path = temp_dir_path / \"test.py\"\n            test_file_path.write_text(test_code, encoding=\"utf-8\")\n\n            # Write the user code to a temporary file\n            user_code_file_path = temp_dir_path / \"user_code.py\"\n            user_code_file_path.write_text(user_code, encoding=\"utf-8\")\n\n            # Run pyright on the temporary file\n            process = subprocess.run(\n                [\n                    \"pyright\",\n                    \"--outputjson\",\n                    \"--pythonversion\",\n                    \"3.10\",\n                    str(user_code_file_path),\n                    str(test_file_path),\n                ],\n                capture_output=True,\n                text=True,\n            )\n\n            # Check if pyright returned an error\n            if process.returncode != 0:\n                return TypeCheckResult(\n                    message=\"Pyright encountered an error: \" + process.stderr,\n                    passed=False,\n                )\n\n            # Parse the output of pyright\n            output = json.loads(process.stdout)\n\n            # Check if there are any errors or warnings\n            if not output[\"generalDiagnostics\"]:\n                return TypeCheckResult(message=\"No errors or warnings found\", passed=True)\n\n            # Parse the errors and warnings\n            errors = []\n            for diagnostic in output[\"generalDiagnostics\"]:\n                # Check if the error message contains the expected error comment\n                if cls.EXPECT_ERROR_COMMENT in diagnostic[\"message\"]:\n                    # Parse the line number and error message from the error message\n                    match = re.search(cls.PYRIGHT_MESSAGE_REGEX, diagnostic[\"message\"])\n                    if match:\n                        line_number = int(match.group(1))\n                        error_message = match.group(2)\n                        errors.append((line_number, error_message))\n\n            # Check if there"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine user code and test code\n        code = user_code + \"\\n\" + test_code\n\n        # Create a temporary file for the combined code\n        with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False) as tmp_file:\n            tmp_file.write(code.encode(\"utf-8\"))\n            tmp_file.flush()\n            tmp_file_path = tmp_file.name\n\n        # Run Pyright on the combined code\n        result = subprocess.run(\n            [\"pyright\", tmp_file_path],\n            capture_output=True,\n            text=True,\n        )\n\n        # Parse the Pyright output to extract error messages and line numbers\n        error_messages = cls._parse_pyright_output(result.stdout)\n\n        # Determine if the type check passed based on the presence of expected type errors\n        passed = cls._check_type_check_passed(error_messages)\n\n        # Generate a message detailing the outcome of the type check\n        message = cls._generate_type_check_message(passed, error_messages)\n\n        # Create a TypeCheckResult object containing the outcome and error messages\n        type_check_result = TypeCheckResult(\n            message=message,\n            passed=passed,\n            debug_info={\"error_messages\": error_messages},\n        )\n\n        return type_check_result\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine the user code and test code\n        code = user_code + \"\\n\" + test_code\n\n        # Create a temporary file to write the code to\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n            f.write(code)\n            filename = f.name\n\n        # Run Pyright on the temporary file\n        try:\n            result = subprocess.run(\n                [\"pyright\", filename, \"--outputjson\"],\n                capture_output=True,\n                text=True,\n                check=True,\n            )\n        except subprocess.CalledProcessError as e:\n            return TypeCheckResult(\n                message=f\"Pyright error: {e.stderr}\",\n                passed=False,\n                debug_info={\"filename\": filename},\n            )\n\n        # Parse the Pyright output to extract error messages and line numbers\n        error_messages = cls._parse_pyright_output(result.stdout)\n\n        # Check if there are any expected type errors\n        expected_error_messages = cls._find_expected_errors(test_code)\n\n        # Check if the expected errors are present in the Pyright output\n        passed = cls._check_expected_errors(\n            error_messages, expected_error_messages, filename\n        )\n\n        # Construct the message to return\n        message = cls._construct_message(error_messages, passed)\n\n        # Remove the temporary file\n        Path(filename).unlink()\n\n        # Return the result\n        return TypeCheckResult(message=message, passed=passed)\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine the user code and test code into a single file\n        combined_code = user_code + test_code\n\n        # Create a temporary file to store the combined code\n        with tempfile.NamedTemporaryFile(mode=\"w\", delete=False) as temp_file:\n            temp_file.write(combined_code)\n            temp_file.flush()\n\n        # Run Pyright on the temporary file\n        result = subprocess.run(\n            [\"pyright\", temp_file.name],\n            capture_output=True,\n            text=True,\n            encoding=\"utf-8\",\n        )\n\n        # Check if Pyright returned an error\n        if result.returncode != 0:\n            return TypeCheckResult(\n                message=\"Pyright returned an error: \" + result.stderr,\n                passed=False,\n                debug_info={\"stderr\": result.stderr},\n            )\n\n        # Parse the Pyright output to identify expected type errors\n        expected_type_errors = cls._parse_expected_type_errors(user_code)\n\n        # Parse the Pyright output to identify actual type errors\n        actual_type_errors = cls._parse_pyright_output(result.stdout)\n\n        # Check if the expected type errors match the actual type errors\n        passed = expected_type_errors == actual_type_errors\n\n        # Create a message detailing the outcome of the type check\n        message = \"Type check passed!\" if passed else \"Type check failed.\"\n        if not passed:\n            message += \" Expected type errors: \" + str(expected_type_errors)\n            message += \" Actual type errors: \" + str(actual_type_errors)\n\n        # Return the result of the type check\n        return TypeCheckResult(message=message, passed=passed)\n"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        # Combine user code and test code\n        code = user_code + \"\\n\" + test_code\n\n        # Create a temporary file for the combined code\n        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as tmp_file:\n            tmp_file.write(code)\n            tmp_file.flush()\n\n        # Run Pyright on the temporary file\n        try:\n            # Run Pyright on the temporary file and capture the output\n            result = subprocess.run(\n                [\"pyright\", tmp_file.name],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                encoding=\"utf-8\",\n                errors=\"replace\",\n            )\n        except subprocess.CalledProcessError as e:\n            # Handle any errors that occurred while running Pyright\n            return TypeCheckResult(\n                message=\"Pyright failed to run. Please report this issue.\",\n                passed=False,\n                debug_info={\n                    \"returncode\": e.returncode,\n                    \"stdout\": e.stdout,\n                    \"stderr\": e.stderr,\n                },\n            )\n\n        # Parse Pyright output to extract error messages and line numbers\n        errors = []\n        for line in result.stdout.splitlines():\n            match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n            if match:\n                line_no, message = match.groups()\n                errors.append((int(line_no), message))\n\n        # Sort errors by line number\n        errors.sort(key=lambda x: x[0])\n\n        # Check if expected type errors were found\n        expected_errors = cls._find_expected_errors(test_code)\n        if len(expected_errors) != len(errors):\n            return TypeCheckResult(\n                message=\"Incorrect number of type errors found.\",\n                passed=False,\n                debug_info={\"expected_errors\": expected_errors, \"errors\": errors},\n            )\n\n        for (expected_line_no, expected_message), (line"}
{"namespace": "challenge.ChallengeManager._type_check_with_pyright", "completion": "        with tempfile.TemporaryDirectory() as temp_dir:\n            temp_dir = Path(temp_dir)\n            temp_file = temp_dir / \"temp.py\"\n\n            # Write the test code to a temporary file\n            with open(temp_file, \"w\", encoding=\"utf-8\") as f:\n                f.write(test_code)\n\n            # Append the user code to the temporary file\n            with open(temp_file, \"a\", encoding=\"utf-8\") as f:\n                f.write(user_code)\n\n            # Run Pyright on the temporary file and capture the output\n            result = subprocess.run(\n                [\"pyright\", temp_file],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                encoding=\"utf-8\",\n            )\n\n            # Read the output and error messages\n            output = result.stdout\n            error_messages = result.stderr\n\n            # Check if the output contains any unexpected errors\n            if \"error\" in output.lower():\n                return TypeCheckResult(\n                    message=\"Unexpected errors occurred during type checking.\",\n                    passed=False,\n                )\n\n            # Check if the output contains any expected errors\n            if \"error\" in error_messages.lower():\n                # Parse the error messages to extract line numbers and error messages\n                error_lines = []\n                for line in error_messages.splitlines():\n                    match = re.match(cls.PYRIGHT_MESSAGE_REGEX, line)\n                    if match:\n                        line_no = int(match.group(1))\n                        error_message = match.group(2)\n                        error_lines.append((line_no, error_message))\n\n                # Check if the expected errors are present in the output\n                expected_errors = cls._find_expected_errors(test_code)\n                if not expected_errors:\n                    return TypeCheckResult(\n                        message=\"Expected errors were not found.\",\n                        passed=False,\n                        debug_info={\"expected_errors\": expected_errors, \"error_lines\": error_lines},"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = await self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = await self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "ollama._client.AsyncClient.create", "completion": "    if (realpath := _as_path(path)) and realpath.exists():\n      modelfile = self._parse_modelfile(realpath.read_text(), base=realpath.parent)\n    elif modelfile:\n      modelfile = self._parse_modelfile(modelfile)\n    else:\n      raise RequestError('must provide either path or modelfile')\n\n    return await self._request_stream(\n      'POST',\n      '/api/create',\n      json={\n        'name': model,\n        'modelfile': modelfile,\n        'stream': stream,\n      },\n      stream=stream,\n    )\n"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                          bw_compiler=get_compiler_fn(\"Backward\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                            bw_compiler=get_compiler_fn(\"Backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                          bw_compiler=get_compiler_fn(\"Backward\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                            bw_compiler=get_compiler_fn(\"Backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                          bw_compiler=get_compiler_fn(\"Backward\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                            bw_compiler=get_compiler_fn(\"Backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, fw_compiler=get_compiler_fn(\"forward\"),\n                          bw_compiler=get_compiler_fn(\"backward\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"forward\"),\n                            bw_compiler=get_compiler_fn(\"backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, fw_compiler=get_compiler_fn(\"forward\"),\n                          bw_compiler=get_compiler_fn(\"backward\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"forward\"),\n                            bw_compiler=get_compiler_fn(\"backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                          bw_compiler=get_compiler_fn(\"Backward\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                            bw_compiler=get_compiler_fn(\"Backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, fw_compiler=get_compiler_fn(\"Forward Graph\"),\n                          bw_compiler=get_compiler_fn(\"Backward Graph\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"Forward Graph\"),\n                            bw_compiler=get_compiler_fn(\"Backward Graph\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, fw_compiler=get_compiler_fn(\"Forward Graph\"),\n                          bw_compiler=get_compiler_fn(\"Backward Graph\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"Forward Graph\"),\n                            bw_compiler=get_compiler_fn(\"Backward Graph\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            return aot_module(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                              bw_compiler=get_compiler_fn(\"Backward\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                            bw_compiler=get_compiler_fn(\"Backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, fw_compiler=get_compiler_fn(\"forward\"),\n                          bw_compiler=get_compiler_fn(\"backward\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"forward\"),\n                            bw_compiler=get_compiler_fn(\"backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            return aot_module(fn, fw_compiler=get_compiler_fn(\"Forward Graph\"),\n                              bw_compiler=get_compiler_fn(\"Backward Graph\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"Forward Graph\"),\n                            bw_compiler=get_compiler_fn(\"Backward Graph\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, fw_compiler=get_compiler_fn(\"Forward\"), bw_compiler=get_compiler_fn(\"Backward\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"Forward\"), bw_compiler=get_compiler_fn(\"Backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            return aot_module(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                              bw_compiler=get_compiler_fn(\"Backward\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                            bw_compiler=get_compiler_fn(\"Backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        print(\"Compiling module\")\n        return aot_module(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                          bw_compiler=get_compiler_fn(\"Backward\"))\n    else:\n        print(\"Compiling function\")\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"Forward\"),\n                            bw_compiler=get_compiler_fn(\"Backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(fn, fw_compiler=get_compiler_fn(\"Module forward\"),\n                          bw_compiler=get_compiler_fn(\"Module backward\"))\n    else:\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"Function forward\"),\n                            bw_compiler=get_compiler_fn(\"Function backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        return aot_module(\n            fn,\n            fw_compiler=get_compiler_fn(\"Forward graph\"),\n            bw_compiler=get_compiler_fn(\"Backward graph\"),\n        )\n    else:\n        return aot_function(\n            fn,\n            fw_compiler=get_compiler_fn(\"Forward graph\"),\n            bw_compiler=get_compiler_fn(\"Backward graph\"),\n        )"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        with no_fake_tensor():\n            return aot_module(\n                fn,\n                fw_compiler=get_compiler_fn(\"Forward Graph\"),\n                bw_compiler=get_compiler_fn(\"Backward Graph\"),\n            )\n    else:\n        return aot_function(\n            fn, fw_compiler=get_compiler_fn(\"Forward Graph\"), bw_compiler=get_compiler_fn(\"Backward Graph\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        print(\"Module\")\n        return aot_module(\n            fn,\n            fw_compiler=get_compiler_fn(\"Module Forward\"),\n            bw_compiler=get_compiler_fn(\"Module Backward\"))\n    else:\n        print(\"Function\")\n        return aot_function(\n            fn,\n            fw_compiler=get_compiler_fn(\"Function Forward\"),\n            bw_compiler=get_compiler_fn(\"Function Backward\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        # Compile the module using the forward and backward compiler specific for modules\n        return aot_module(\n            fn,\n            fw_compiler=get_compiler_fn(\"Module Forward Graph\"),\n            bw_compiler=get_compiler_fn(\"Module Backward Graph\"))\n    else:\n        # Compile the function using the forward and backward compiler specific for functions\n        return aot_function(\n            fn,\n            fw_compiler=get_compiler_fn(\"Function Forward Graph\"),\n            bw_compiler=get_compiler_fn(\"Function Backward Graph\"))"}
{"namespace": "sfast.utils.aot_printer.aot_printer", "completion": "    if isinstance(fn, torch.nn.Module):\n        # Compile the module using aot_module\n        return aot_module(fn, fw_compiler=get_compiler_fn(\"Forward Graph\"),\n                          bw_compiler=get_compiler_fn(\"Backward Graph\"))\n    else:\n        # Compile the function using aot_function\n        return aot_function(fn, fw_compiler=get_compiler_fn(\"Forward Graph\"),\n                            bw_compiler=get_compiler_fn(\"Backward Graph\"))\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('The output file path must have a .yaml or .yml extension.')\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        assert output_path.endswith('.yaml') or output_path.endswith('.yml'), 'output_path must be .yaml or .yml'\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = load_yaml_file(os.path.join(trial_path, 'config.yaml'))\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(\"Invalid output file extension. Please provide a .yaml or .yml file.\")\n        save_yaml_file(best_config, output_path)\n\n    return best_config"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('Output path must have a .yaml or .yml extension.')\n        with open(output_path, 'w') as f:\n            yaml.safe_dump(best_config, f)\n\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('Output path must have a .yaml or .yml extension.')\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('Output file must be a YAML file with .yaml or .yml extension.')\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('The output file path must have a .yaml or .yml extension.')\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(f\"Invalid output file extension: {output_path}. \"\n                             f\"Output file extension must be either .yaml or .yml.\")\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n\n    config_yaml = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(config_yaml, f)\n\n    return config_yaml\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        assert output_path.endswith('.yaml') or output_path.endswith('.yml'), \\\n            \"Output path must be a .yaml or .yml file.\"\n        yaml.dump(config, open(output_path, 'w'))\n\n    return config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    config = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        assert output_path.endswith('.yaml') or output_path.endswith('.yml'), \\\n            \"output_path must be a .yaml or .yml file\"\n        yaml.safe_dump(config, open(output_path, 'w'))\n    return config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = load_yaml(os.path.join(trial_path, 'config.yaml'))\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(\n                'The output file path must have a .yaml or .yml extension.')\n        save_yaml(output_path, config_dict)\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        assert output_path.endswith('.yaml') or output_path.endswith('.yml'), \\\n            'output_path must be a .yaml or .yml file'\n        yaml.safe_dump(config_dict, open(output_path, 'w'))\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    # Load the summary file\n    summary_df = load_summary_file(trial_path)\n\n    # Load the configuration file\n    config_file = os.path.join(trial_path, 'config.yaml')\n    with open(config_file, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    # Convert the summary dataframe to a config dictionary\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    # Save the config dictionary to a YAML file if output_path is provided\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(\"The output_path must have a .yaml or .yml extension.\")\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml'), 'r'), Loader=yaml.FullLoader)\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(\"Output file must be a YAML file.\")\n        with open(output_path, 'w') as f:\n            yaml.dump(config_dict, f)\n\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('Output path must have a .yaml or .yml extension.')\n        with open(output_path, 'w') as f:\n            yaml.dump(best_config, f)\n\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.load(open(os.path.join(trial_path, 'config.yaml'), 'r'), Loader=yaml.FullLoader)\n    best_config = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError('output_path must be a .yaml or .yml file')\n        yaml.dump(best_config, open(output_path, 'w'), default_flow_style=False)\n    return best_config\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml')))\n    config_dict = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        if not output_path.endswith('.yaml') and not output_path.endswith('.yml'):\n            raise ValueError(\"The output file path must have a '.yaml' or '.yml' extension.\")\n        yaml.safe_dump(config_dict, open(output_path, 'w'))\n    return config_dict\n\n"}
{"namespace": "autorag.deploy.extract_best_config", "completion": "    summary_df = load_summary_file(trial_path)\n    config_dict = yaml.safe_load(open(os.path.join(trial_path, 'config.yaml'), 'r'))\n    config = summary_df_to_yaml(summary_df, config_dict)\n    if output_path is not None:\n        assert output_path.endswith('.yaml') or output_path.endswith('.yml'), \\\n            'output_path must be a .yaml or .yml file'\n        with open(output_path, 'w') as f:\n            yaml.dump(config, f)\n    return config\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    cache = {}\n    lock = threading.Lock()\n\n    def wrapper(*args, **kwargs):\n        nonlocal cache, lock\n        with lock:\n            key = (args, tuple(kwargs.items()))\n            if key not in cache:\n                traced_module, call_helper = trace_with_kwargs(\n                    func, *args, **kwargs_, **kwargs)\n                if ts_compiler is not None:\n                    traced_module = ts_compiler(traced_module)\n                cache[key] = call_helper\n            return cache[key](*args, **kwargs)\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    lock = threading.Lock()\n    cache = {}\n\n    def wrapper(*args, **kwargs):\n        nonlocal cache\n        nonlocal lock\n        with lock:\n            if args in cache:\n                return cache[args]\n            if isinstance(func, torch.nn.Module):\n                module = func\n                func = func.forward\n            else:\n                module = None\n            if ts_compiler is not None:\n                func = ts_compiler(func)\n            traced_module, call_helper = trace_with_kwargs(\n                func,\n                example_inputs=args,\n                example_kwarg_inputs=kwargs,\n                **kwargs_)\n            if module is not None:\n                apply_to_module(traced_module, module)\n            ret = call_helper(traced_module)\n            cache[args] = ret\n            return ret\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if isinstance(func, torch.nn.Module):\n        func = func.forward\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        nonlocal ts_compiler\n        kwargs_ = kwargs_.copy()\n        if ts_compiler is not None:\n            kwargs_['ts_compiler'] = ts_compiler\n        with lock:\n            if func not in cache:\n                cache[func] = trace_with_kwargs(func, *args, **kwargs_)\n            traced_module, call_helper = cache[func]\n        return call_helper(traced_module, *args, **kwargs)\n\n    lock = threading.Lock()\n    cache = {}\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def wrapper(*args, **kwargs):\n        nonlocal ts_compiler\n        if ts_compiler is None:\n            ts_compiler = lambda m: m\n        with lock:\n            if func not in cache:\n                cache[func] = {}\n            key = tuple(flat_tensors.flattern((args, kwargs)))\n            if key not in cache[func]:\n                traced_module, call_helper = trace_with_kwargs(\n                    func, *args, **kwargs_)\n                cache[func][key] = ts_compiler(traced_module)\n            return call_helper(cache[func][key](*args, **kwargs))\n\n    lock = threading.Lock()\n    cache = {}\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    kwargs = kwargs_.copy()\n    if ts_compiler is not None:\n        kwargs['ts_compiler'] = ts_compiler\n\n    def wrapper(*args, **kwargs_):\n        nonlocal wrapper\n        if isinstance(func, torch.nn.Module):\n            forward = func.forward\n        else:\n            forward = func\n        if not hasattr(wrapper, 'cache'):\n            wrapper.cache = {}\n        with wrapper.lock:\n            if forward not in wrapper.cache:\n                wrapper.cache[forward] = trace_with_kwargs(forward,\n                                                           *args,\n                                                           **kwargs,\n                                                           **kwargs_)\n            traced_module, call_helper = wrapper.cache[forward]\n        return call_helper(*args, **kwargs_)\n\n    wrapper.lock = threading.Lock()\n    wrapper.cache = {}\n    wrapper = functools.update_wrapper(wrapper, func)\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    kwargs = dict(kwargs_)\n    kwargs.setdefault('training', getattr(func, 'training', False))\n    if isinstance(func, torch.nn.Module):\n        forward_fn = func.forward\n    else:\n        forward_fn = func\n    if inspect.isfunction(forward_fn):\n        func_name = func.__name__\n    else:\n        func_name = forward_fn.__name__\n    if ts_compiler is not None:\n        kwargs['ts_compiler'] = ts_compiler\n    lock = threading.Lock()\n    cache = {}\n\n    @functools.wraps(forward_fn)\n    def wrapper(*args, **kwargs):\n        nonlocal cache, lock\n        with lock:\n            if func_name not in cache:\n                cache[func_name] = trace_with_kwargs(func, args, kwargs)\n            traced_module, call_helper = cache[func_name]\n        return call_helper(traced_module)(*args, **kwargs)\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n\n        def ts_compiler(m):\n            return m\n\n    kwargs = dict(kwargs_)\n    if 'training' not in kwargs:\n        kwargs['training'] = getattr(func, 'training', False)\n    if 'example_inputs' not in kwargs:\n        kwargs['example_inputs'] = tuple()\n    if 'example_kwarg_inputs' not in kwargs:\n        kwargs['example_kwarg_inputs'] = {}\n    if 'num_inputs' not in kwargs:\n        kwargs['num_inputs'] = None\n    if 'num_kwarg_inputs' not in kwargs:\n        kwargs['num_kwarg_inputs'] = None\n    if 'num_outputs' not in kwargs:\n        kwargs['num_outputs'] = None\n    if 'num_kwarg_outputs' not in kwargs:\n        kwargs['num_kwarg_outputs'] = None\n    if 'num_batches' not in kwargs:\n        kwargs['num_batches'] = 1\n    if 'check_inputs' not in kwargs:\n        kwargs['check_inputs'] = None\n    if 'check_outputs' not in kwargs:\n        kwargs['check_outputs'] = None\n    if 'check_tolerance' not in kwargs:\n        kwargs['check_tolerance'] = None\n    if 'check_all_same_outputs' not in kwargs:\n        kwargs['check_all_same_outputs'] = True\n    if 'check_all_same_grad_outputs' not in kwargs:\n        kwargs['check_all_same_grad_outputs'] = True\n    if 'check_all_same_hessian_outputs' not in kwargs:\n        kwargs['check_all_same_hessian_outputs'] = True\n    if 'check_all_same_inputs'"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda m, **kwargs: m\n    kwargs = dict(kwargs_)\n    kwargs['training'] = getattr(func, 'training', False)\n\n    def wrapper(*args, **kwargs_):\n        nonlocal func\n        nonlocal kwargs\n        if isinstance(func, torch.nn.Module):\n            func = func.forward\n        if not isinstance(args, tuple):\n            args = (args,)\n        args = flat_tensors.flattern(args)\n        kwargs = flat_tensors.flattern(kwargs)\n        key = (args, tuple(kwargs.items()))\n        with lock:\n            if key not in cache:\n                cache[key] = ts_compiler(\n                    better_trace(TraceablePosArgOnlyModuleWrapper(func),\n                                 args, **kwargs), **kwargs)\n            return cache[key](*args, **kwargs)\n\n    cache = {}\n    lock = threading.Lock()\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    kwargs = kwargs_.copy()\n    if 'training' in kwargs:\n        training = kwargs['training']\n        del kwargs['training']\n    else:\n        training = getattr(func, 'training', False) if isinstance(\n            func, torch.nn.Module) else None\n    if ts_compiler is not None:\n        kwargs['ts_compiler'] = ts_compiler\n\n    lock = threading.Lock()\n    cache = {}\n\n    def wrapper(*args, **kwargs_):\n        nonlocal lock, cache\n        kwargs_ = kwargs_.copy()\n        if 'training' in kwargs_:\n            training = kwargs_['training']\n            del kwargs_['training']\n        else:\n            training = getattr(func, 'training', False) if isinstance(\n                func, torch.nn.Module) else None\n        if ts_compiler is not None:\n            kwargs_['ts_compiler'] = ts_compiler\n        with lock:\n            if args not in cache:\n                if isinstance(func, torch.nn.Module):\n                    traced_module, call_helper = trace_with_kwargs(\n                        func, example_inputs=args, example_kwarg_inputs=kwargs_,\n                        **kwargs)\n                else:\n                    traced_module, call_helper = trace_with_kwargs(\n                        func, example_inputs=args, **kwargs)\n                cache[args] = (traced_module, call_helper)\n            traced_module, call_helper = cache[args]\n        return call_helper(traced_module, training=training)\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if isinstance(func, torch.nn.Module):\n        func_forward = func.forward\n    else:\n        func_forward = func\n    func_signature = inspect.signature(func_forward)\n    func_signature = func_signature.replace(\n        parameters=tuple(\n            p for p in func_signature.parameters.values()\n            if p.kind in (p.POSITIONAL_OR_KEYWORD, p.KEYWORD_ONLY)))\n    func_signature = func_signature.replace(return_annotation=torch.Tensor)\n\n    @functools.wraps(func_forward)\n    def wrapper(*args, **kwargs):\n        kwargs_ = func_signature.bind(*args, **kwargs)\n        kwargs_.apply_defaults()\n        args = kwargs_.args\n        kwargs = kwargs_.kwargs\n        args = flat_tensors.flattern(args)\n        kwargs = flat_tensors.flattern(kwargs)\n        key = (args, kwargs)\n        if key in cache:\n            return cache[key]\n        with lock:\n            if key in cache:\n                return cache[key]\n            traced_module, call_helper = trace_with_kwargs(func,\n                                                           example_inputs=args,\n                                                           example_kwarg_inputs=kwargs,\n                                                           **kwargs_)\n            if ts_compiler is not None:\n                traced_module = ts_compiler(traced_module)\n            cache[key] = call_helper\n            return call_helper\n\n    lock = threading.Lock()\n    cache = {}\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if inspect.isclass(func):\n        func = func()\n    kwargs = kwargs_.copy()\n    ts_compiler = ts_compiler or (lambda m, **kwargs: m)\n    lock = threading.Lock()\n    cache = {}\n\n    def trace_func(*args, **kwargs):\n        nonlocal cache\n        nonlocal lock\n        with lock:\n            key = (args, tuple(kwargs.items()))\n            if key not in cache:\n                cache[key] = ts_compiler(\n                    better_trace(func, args, kwargs=kwargs), **kwargs)\n            return cache[key]\n\n    if inspect.isfunction(func):\n        return trace_func\n    elif isinstance(func, torch.nn.Module):\n        return apply_to_module(func, trace_func)\n    else:\n        raise TypeError(\n            f'Expected a function or torch.nn.Module, got {type(func)}.')\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def wrapper(*args, **kwargs):\n        nonlocal cache\n        nonlocal cache_lock\n        nonlocal ts_compiler\n        if len(args) > 0:\n            raise ValueError(\n                \"Lazy tracing only supports kwargs, please check your args\")\n        if len(kwargs) == 0:\n            raise ValueError(\n                \"Lazy tracing requires kwargs, please check your kwargs\")\n        with cache_lock:\n            if func in cache:\n                return cache[func]\n            traced_module, call_helper = trace_with_kwargs(\n                func, **kwargs_)\n            if ts_compiler is not None:\n                traced_module = ts_compiler(traced_module)\n            cache[func] = call_helper\n            return call_helper\n\n    cache = {}\n    cache_lock = threading.Lock()\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if not callable(func):\n        raise TypeError(f\"{func} is not callable\")\n\n    if ts_compiler is not None:\n        if not callable(ts_compiler):\n            raise TypeError(f\"{ts_compiler} is not callable\")\n\n    kwargs = {\n        'training': getattr(func, 'training', False)\n        if isinstance(func, torch.nn.Module) else None,\n        'ts_compiler': ts_compiler\n    }\n    kwargs.update(kwargs_)\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs_):\n        # TODO: add support for kwargs\n        if len(args) > 0:\n            raise NotImplementedError(\"Lazy tracing only supports positional arguments\")\n\n        # TODO: add support for kwargs\n        if len(kwargs_) > 0:\n            raise NotImplementedError(\"Lazy tracing only supports positional arguments\")\n\n        # TODO: add support for kwargs\n        args = flat_tensors.flattern(args)\n\n        # TODO: add support for kwargs\n        args = tuple(tree_copy(args, detach=True))\n\n        # TODO: add support for kwargs\n        args_hash = hash(args)\n\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kwargs\n        # TODO: add support for kw"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda m: m\n    if isinstance(func, torch.nn.Module):\n        forward_func = func.forward\n    else:\n        forward_func = func\n    if not inspect.isfunction(forward_func):\n        raise TypeError(f'{forward_func} is not a function')\n    lock = threading.Lock()\n    cache = {}\n\n    def wrapper(*args, **kwargs):\n        nonlocal cache, lock\n        key = (args, tuple(kwargs.items()))\n        with lock:\n            if key not in cache:\n                traced_module, call_helper = trace_with_kwargs(\n                    forward_func, *args, **kwargs_, **kwargs)\n                cache[key] = ts_compiler(traced_module)\n            return call_helper(cache[key])\n\n    if isinstance(func, torch.nn.Module):\n        return apply_to_module(func, wrapper)\n    else:\n        return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    def wrapper(*args, **kwargs):\n        nonlocal ts_compiler\n        nonlocal kwargs_\n        if inspect.isclass(func):\n            if not isinstance(args[0], func):\n                raise ValueError(\n                    \"The first argument of the wrapped function should be an instance of the class.\"\n                )\n            func_ = args[0].__class__.forward\n        else:\n            func_ = func\n\n        if len(args) > 0 and isinstance(args[0], func_):\n            func_ = args[0]\n\n        if isinstance(func_, torch.nn.Module):\n            func_ = func_.forward\n\n        args = flat_tensors.flattern(args)\n        kwargs = flat_tensors.flattern(kwargs)\n        args = flat_tensors.flattern((args, kwargs))\n\n        with lock:\n            if func_ not in cache:\n                if ts_compiler is not None:\n                    traced_module, call_helper = ts_compiler(\n                        func_, *args, **kwargs_)\n                else:\n                    traced_module, call_helper = trace_with_kwargs(\n                        func_, *args, **kwargs_)\n                cache[func_] = traced_module, call_helper\n            else:\n                traced_module, call_helper = cache[func_]\n\n        return call_helper(traced_module, *args, **kwargs)\n\n    lock = threading.Lock()\n    cache = {}\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    # Check if the function is a PyTorch module\n    if isinstance(func, torch.nn.Module):\n        # If it is a module, get its forward method\n        func = func.forward\n    # Get the signature of the function\n    sig = inspect.signature(func)\n    # Check if the function has a *args parameter\n    has_args = any(p.kind == p.VAR_POSITIONAL for p in sig.parameters.values())\n    # Check if the function has a **kwargs parameter\n    has_kwargs = any(p.kind == p.VAR_KEYWORD for p in sig.parameters.values())\n    # Check if the function has both *args and **kwargs parameters\n    has_both = has_args and has_kwargs\n    # Check if the function has a **kwargs parameter but no *args parameter\n    has_kwargs_only = not has_args and has_kwargs\n    # Check if the function has a *args parameter but no **kwargs parameter\n    has_args_only = has_args and not has_kwargs\n\n    # Define a lock to ensure thread safety\n    lock = threading.Lock()\n    # Define a cache to store the traced modules\n    cache = {}\n\n    # Define a wrapper function that takes *args and **kwargs as input\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        # Get the non-keyword arguments as a tuple\n        args = args\n        # Get the keyword arguments as a dictionary\n        kwargs = kwargs\n        # If the function has both *args and **kwargs parameters\n        if has_both:\n            # Combine the arguments and keyword arguments into a single tuple\n            args = (args, kwargs)\n            # Set the keyword arguments to an empty dictionary\n            kwargs = {}\n        # If the function has only **kwargs parameters\n        elif has_kwargs_only:\n            # Set the arguments to an empty tuple\n            args = ()\n        # If the function has only *args parameters\n        elif has_args_only:\n            # Set the keyword arguments to an empty dictionary\n            kwargs = {}\n        # Get the hashable key for the"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    kwargs = kwargs_.copy()\n    if ts_compiler is not None:\n        kwargs['ts_compiler'] = ts_compiler\n\n    def _lazy_trace(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # If the function is a module, trace its forward method\n            if isinstance(func, torch.nn.Module):\n                return _lazy_trace(func.forward)(*args, **kwargs)\n            # Check if the function is already in the cache\n            if func in _lazy_trace.cache:\n                return _lazy_trace.cache[func](*args, **kwargs)\n            # Otherwise, trace the function and cache the result\n            with _lazy_trace.lock:\n                if func not in _lazy_trace.cache:\n                    traced_func, call_helper = trace_with_kwargs(\n                        func, *args, **kwargs)\n                    _lazy_trace.cache[func] = call_helper\n            return _lazy_trace.cache[func](*args, **kwargs)\n\n        return wrapper\n\n    # Initialize the cache and lock\n    _lazy_trace.cache = {}\n    _lazy_trace.lock = threading.Lock()\n    # Return the wrapped function or module\n    return _lazy_trace(func)\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if inspect.isclass(func) and issubclass(func, torch.nn.Module):\n        forward_fn = func.forward\n    else:\n        forward_fn = func\n\n    @functools.wraps(forward_fn)\n    def wrapper(*args, **kwargs):\n        nonlocal ts_compiler, kwargs_\n        if inspect.isclass(func) and issubclass(func, torch.nn.Module):\n            # forward_fn = func.forward\n            func_key = (id(func), id(forward_fn))\n        else:\n            func_key = id(func)\n        kwargs_key = tuple(kwargs_.items())\n        args_key = (args, kwargs_key)\n\n        if (func_key, args_key) not in _cached_traced_modules:\n            with _cached_traced_modules_lock:\n                if (func_key, args_key) not in _cached_traced_modules:\n                    traced_module, call_helper = trace_with_kwargs(\n                        func, *args, **kwargs_)\n                    if ts_compiler is not None:\n                        traced_module = ts_compiler(traced_module)\n                        call_helper = ts_compiler(call_helper)\n                    _cached_traced_modules[(func_key, args_key)] = (\n                        traced_module, call_helper)\n        return _cached_traced_modules[(func_key, args_key)][1](*args, **kwargs)\n\n    return wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if not callable(func):\n        raise ValueError(f\"func must be callable, got {func}\")\n\n    kwargs = dict(kwargs_)\n    if ts_compiler is not None:\n        kwargs['compiler'] = ts_compiler\n\n    def tracing_wrapper(*args, **kwargs):\n        nonlocal func\n        if isinstance(func, torch.nn.Module):\n            func = func.forward\n\n        if len(args) == 0:\n            args = tuple([torch.randn(1, 1, 1, 1)])\n        args = flat_tensors.flattern(args)\n        kwargs = flat_tensors.flattern(kwargs)\n        # logger.debug(f\"Tracing {func} with args {args} and kwargs {kwargs}\")\n        if func in traced_modules:\n            return traced_modules[func]\n        else:\n            with lock:\n                if func in traced_modules:\n                    return traced_modules[func]\n                traced_module = better_trace(func, args, kwargs)\n                traced_modules[func] = traced_module\n                return traced_module\n\n    return tracing_wrapper\n\n"}
{"namespace": "sfast.jit.trace_helper.lazy_trace", "completion": "    if ts_compiler is None:\n        ts_compiler = lambda m, **kwargs: m\n    kwargs = kwargs_.copy()\n    if 'training' not in kwargs:\n        kwargs['training'] = getattr(func, 'training', False)\n    if isinstance(func, torch.nn.Module):\n        func = func.forward\n    lock = threading.Lock()\n    cache = {}\n    if inspect.isfunction(func):\n        arg_spec = inspect.getfullargspec(func)\n        arg_names = arg_spec.args\n        defaults = arg_spec.defaults\n        if defaults is not None:\n            default_kwargs = dict(zip(arg_names[-len(defaults):], defaults))\n        else:\n            default_kwargs = {}\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            with lock:\n                nonlocal cache\n                kwargs = dict(default_kwargs, **kwargs)\n                args = flat_tensors.flattern(args)\n                key = (args, tuple(kwargs.items()))\n                if key not in cache:\n                    logger.debug(f'Tracing {func.__name__} with args {args}')\n                    cache[key] = ts_compiler(\n                        better_trace(func, args, **kwargs), **kwargs)\n                return cache[key](*args)\n\n        return wrapper\n    else:\n        raise NotImplementedError\n\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        trial_summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(trial_summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(trial_summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        return cls(yaml_dict, project_dir=os.path.dirname(trial_path))"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        if not os.path.exists(trial_path):\n            raise ValueError(f\"{trial_path} does not exist.\")\n        summary_path = os.path.join(trial_path, 'summary.csv')\n        if not os.path.exists(summary_path):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        trial_summary_df = load_summary_file(summary_path, dict_columns=['best_module_params'])\n        config_yaml_path = os.path.join(trial_path, 'config.yaml')\n        with open(config_yaml_path, 'r') as f:\n            config_dict = yaml.safe_load(f)\n        yaml_dict = summary_df_to_yaml(trial_summary_df, config_dict)\n        project_dir = os.path.dirname(trial_path)\n        return cls(yaml_dict, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        yaml_path = os.path.join(trial_path, 'best_config.yaml')\n        if not os.path.exists(yaml_path):\n            raise ValueError(f\"best_config.yaml does not exist in {trial_path}.\")\n        with open(yaml_path, 'r') as f:\n            try:\n                config = yaml.safe_load(f)\n            except yaml.YAMLError as exc:\n                logger.error(exc)\n                raise exc\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        if not os.path.exists(trial_path):\n            raise ValueError(f\"{trial_path} does not exist.\")\n        if not os.path.exists(os.path.join(trial_path, 'summary.csv')):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        config = extract_best_config(trial_path)\n        return cls(config, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        yaml_path = os.path.join(trial_path, 'best_config.yaml')\n        if not os.path.exists(yaml_path):\n            raise ValueError(f\"best_config.yaml does not exist in {trial_path}.\")\n        return cls.from_yaml(yaml_path, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        yaml_path = os.path.join(trial_path, 'best_config.yaml')\n        if not os.path.exists(yaml_path):\n            raise ValueError(f\"best_config.yaml does not exist in {trial_path}.\")\n        return cls.from_yaml(yaml_path, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.abspath(os.path.join(trial_path, os.pardir))\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        yaml_path = os.path.join(trial_path, 'config.yaml')\n        project_dir = os.path.dirname(trial_path)\n        return cls.from_yaml(yaml_path, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        if not os.path.exists(trial_path):\n            raise ValueError(f\"{trial_path} does not exist.\")\n        if not os.path.exists(os.path.join(trial_path, 'summary.csv')):\n            raise ValueError(f\"summary.csv does not exist in {trial_path}.\")\n        project_dir = os.path.dirname(trial_path)\n        config = extract_best_config(trial_path)\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        config = extract_best_config(trial_path)\n        project_dir = os.path.dirname(trial_path)\n        return cls(config, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        yaml_path = os.path.join(trial_path, 'best_config.yaml')\n        if not os.path.exists(yaml_path):\n            raise ValueError(f\"best_config.yaml does not exist in {trial_path}.\")\n        project_dir = os.path.dirname(trial_path)\n        return cls.from_yaml(yaml_path, project_dir=project_dir)\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        yaml_path = os.path.join(trial_path, 'best_config.yaml')\n        if not os.path.exists(yaml_path):\n            raise ValueError(f\"best_config.yaml does not exist in {trial_path}.\")\n        return cls.from_yaml(yaml_path, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.deploy.Runner.from_trial_folder", "completion": "        yaml_path = os.path.join(trial_path, 'config.yaml')\n        return cls.from_yaml(yaml_path, project_dir=os.path.dirname(trial_path))\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize variables\n    best_result = None\n    best_result_summary = None\n    best_result_summary_file = None\n    best_result_summary_file_path = None\n    best_result_summary_file_name = None\n    best_result_summary_file_name_path = None\n    best_result_summary_file_name_path_with_extension = None\n    best_result_summary_file_name_path_with_extension_with_node_line_dir = None\n    best_result_summary_file_name_path_with_extension_with_node_line_dir_with_node_line_dir = None\n    best_result_summary_file_name_path_with_extension_with_node_line_dir_with_node_line_dir_with_node_line_dir = None\n    best_result_summary_file_name_path_with_extension_with_node_line_dir_with_node_line_dir_with_node_line_dir_with_node_line_dir = None\n    best_result_summary_file_name_path_with_extension_with_node_line_dir_with_node_line_dir_with_node_line_dir_with_node_line_dir_with_node_line_dir = None\n    best_result_summary_file_name_path_with_extension_with_node_line_dir_with_node_line_dir_with_node_line_dir_with_node_line_dir_with_node_line_dir_with_node_line_dir = None\n    best_result_summary_file_name_path_with_extension_with_node_line_dir_with_node_line_dir_with_node_line_dir_with_node_line_dir_with_node_line_dir_with_node_line_dir_with_node_line_dir = None\n    best_result_summary_file_name_path_with_extension_with_node_line_dir_with_node_line_dir_with_node_line_dir_with_node_line_dir"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Evaluate each module\n    results = []\n    for module, params in zip(modules, module_params):\n        result = evaluate_retrieval(module, params, previous_result)\n        results.append(result)\n\n    # Measure the execution time of each module\n    execution_times = measure_speed(results)\n\n    # Save the execution times to a summary file\n    summary_file = os.path.join(node_line_dir, \"execution_times.csv\")\n    execution_times.to_csv(summary_file)\n    logger.info(f\"Execution times saved to {summary_file}\")\n\n    # Apply strategies to select the best result\n    best_result = select_best_average(results, strategies)\n\n    # Combine the previous result with the best result\n    best_result = pd.concat([previous_result, best_result], axis=1)\n\n    # Save the best result to a CSV file\n    best_result_file = os.path.join(node_line_dir, \"best_result.csv\")\n    best_result.to_csv(best_result_file)\n    logger.info(f\"Best result saved to {best_result_file}\")\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Create a directory for the node line if it doesn't exist\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Initialize the best result dataframe with the previous result columns\n    best_result = previous_result\n\n    # Initialize the best result summary dictionary\n    best_result_summary = {}\n\n    # Initialize the best result summary file path\n    best_result_summary_file = os.path.join(node_line_dir, \"best_result_summary.json\")\n\n    # Load the previous result summary file if it exists\n    if os.path.exists(best_result_summary_file):\n        best_result_summary = load_summary_file(best_result_summary_file)\n\n    # Iterate over each module, its parameters, and its strategy\n    for module, params, strategy in zip(modules, module_params, strategies):\n\n        # Get the module name\n        module_name = module.__name__\n\n        # Create a directory for the module if it doesn't exist\n        module_dir = os.path.join(node_line_dir, module_name)\n        if not os.path.exists(module_dir):\n            os.makedirs(module_dir)\n\n        # Create a directory for the module's results if it doesn't exist\n        module_results_dir = os.path.join(module_dir, \"results\")\n        if not os.path.exists(module_results_dir):\n            os.makedirs(module_results_dir)\n\n        # Create a directory for the module's summaries if it doesn't exist\n        module_summaries_dir = os.path.join(module_dir, \"summaries\")\n        if not os.path.exists(module_summaries_dir):\n            os.makedirs(module_summaries_dir)\n\n        # Create a file path for the module's summary file\n        module_summary_file = os.path.join(module_summaries_dir, \"summary.json\")\n\n        # Load"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize variables\n    best_result = None\n    best_module_name = None\n    best_module_params = None\n    best_module_result = None\n    best_module_summary = None\n    best_module_speed = None\n\n    # Iterate over each module and its parameters\n    for module, params in zip(modules, module_params):\n        module_name = module.__name__\n        module_dir = os.path.join(node_line_dir, module_name)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Run the module with the given parameters\n        module_result, module_summary = evaluate_retrieval(module, params, previous_result, module_dir)\n\n        # Measure the speed of the module\n        module_speed = measure_speed(module_result)\n\n        # Check if the speed passes the threshold\n        if filter_by_threshold(module_speed, strategies[\"speed_thresholds\"]):\n            # Evaluate the module's result using the specified metrics\n            module_result = evaluate_retrieval(module, params, previous_result, module_dir, strategies[\"metrics\"])\n\n            # Update the best result if the current module's result is better\n            if best_result is None or select_best_average(module_result, best_result, strategies[\"metrics\"]):\n                best_result = module_result\n                best_module_name = module_name\n                best_module_params = params\n                best_module_result = module_result\n                best_module_summary = module_summary\n                best_module_speed = module_speed\n\n    # Save the best result and summary to disk\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n    best_module_summary.to_csv(os.path.join(node_line_dir, \"best_summary.csv\"), index=False)\n\n    # Load the best summary from disk\n    best_summary = load_summary_file(os.path.join(node_line_"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Get the metrics and speed thresholds from the strategies\n    metrics = strategies.get(\"metrics\", [])\n    speed_thresholds = strategies.get(\"speed_thresholds\", {})\n\n    # Initialize the best result dataframe\n    best_result = None\n\n    # Initialize the best result metrics\n    best_result_metrics = None\n\n    # Iterate over the modules and their parameters\n    for module, params in zip(modules, module_params):\n        # Get the module name\n        module_name = module.__name__.split(\".\")[-1]\n\n        # Create a directory for the module\n        module_dir = os.path.join(node_line_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Create a directory for the module's results\n        result_dir = os.path.join(module_dir, \"results\")\n        pathlib.Path(result_dir).mkdir(parents=True, exist_ok=True)\n\n        # Create a directory for the module's summaries\n        summary_dir = os.path.join(module_dir, \"summaries\")\n        pathlib.Path(summary_dir).mkdir(parents=True, exist_ok=True)\n\n        # Run the module with the given parameters\n        result = module(**params)\n\n        # Save the result to disk\n        result.to_csv(os.path.join(result_dir, \"result.csv\"), index=False)\n\n        # Measure the execution time of the module\n        execution_time = measure_speed(module, params)\n\n        # Save the execution time to disk\n        execution_time_df = pd.DataFrame({\"execution_time\": [execution_time]})\n        execution_time_df.to_csv(os.path.join(summary_dir, \"execution_time.csv\"), index=False)\n\n        # Evaluate the module's result\n        result_metrics = evaluate_retrieval(result, previous_result, metrics)\n\n        # Save the result metrics to"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    results_df = pd.DataFrame()\n    summary_df = pd.DataFrame()\n\n    for module, params in zip(modules, module_params):\n        module_name = module.__name__.split('.')[-1]\n        module_dir = os.path.join(node_line_dir, module_name)\n        if not os.path.exists(module_dir):\n            os.makedirs(module_dir)\n\n        module_result, module_summary = evaluate_retrieval(module, params, previous_result)\n\n        results_df[module_name] = module_result\n        summary_df[module_name] = module_summary\n\n        module_result.to_csv(os.path.join(module_dir, \"result.csv\"))\n        module_summary.to_csv(os.path.join(module_dir, \"summary.csv\"))\n\n    # Evaluate the results based on the specified strategies\n    if \"metrics\" in strategies:\n        results_df = evaluate_retrieval_results(results_df, previous_result, strategies[\"metrics\"])\n\n    if \"speed_thresholds\" in strategies:\n        results_df = filter_by_threshold(results_df, previous_result, strategies[\"speed_thresholds\"])\n\n    # Select the best result based on the specified strategies\n    if \"best_average\" in strategies:\n        results_df = select_best_average(results_df, previous_result, strategies[\"best_average\"])\n\n    # Combine the previous result with the best result\n    best_result = pd.concat([previous_result, results_df], axis=1)\n\n    # Save the best result and summary to disk\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"))\n    summary_df.to_csv(os.path.join(node_line_dir, \"summary.csv\"))\n\n    return"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize variables\n    best_result = None\n    best_result_summary = None\n    best_result_summary_path = None\n    best_result_path = None\n    best_module = None\n    best_module_params = None\n    best_module_name = None\n    best_module_summary = None\n    best_module_summary_path = None\n    best_module_result_path = None\n\n    # Create the directory if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Iterate through each module\n    for module, params in zip(modules, module_params):\n\n        # Get the module name\n        module_name = module.__name__\n\n        # Create the directory for the module if it doesn't exist\n        module_dir = os.path.join(node_line_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Get the module result path\n        module_result_path = os.path.join(module_dir, \"result.csv\")\n\n        # Check if the module result already exists\n        if os.path.exists(module_result_path):\n            logger.info(f\"Module result already exists for {module_name}. Loading from disk.\")\n            module_result = pd.read_csv(module_result_path)\n        else:\n            # Execute the module\n            logger.info(f\"Executing module: {module_name}\")\n            module_result = module(**params)\n\n            # Save the module result to disk\n            module_result.to_csv(module_result_path, index=False)\n\n        # Evaluate the module result\n        logger.info(f\"Evaluating module result for {module_name}\")\n        module_result_summary = evaluate_retrieval(module_result, previous_result, node_line_dir, module_name)\n\n        # Save the module result summary to disk\n        module_result_summary_path = os.path.join"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize variables\n    best_result = None\n    best_result_name = None\n    best_result_speed = float('inf')\n    best_result_summary = None\n\n    # Iterate over each module and its parameters\n    for module, params in zip(modules, module_params):\n        module_name = module.__name__\n        logger.info(f\"Running {module_name}\")\n\n        # Create a directory for the module's results\n        module_dir = os.path.join(node_line_dir, module_name)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Execute the module and measure its execution time\n        result, execution_time = measure_speed(module, params, previous_result)\n\n        # Evaluate the result using the provided evaluation context\n        evaluation_context = {\n            'previous_result': previous_result,\n            'result': result,\n            'execution_time': execution_time,\n        }\n        evaluation_result = evaluate_retrieval(evaluation_context, strategies['metrics'])\n\n        # Save the result and evaluation summary to disk\n        result.to_csv(os.path.join(module_dir, 'result.csv'), index=False)\n        evaluation_result.to_csv(os.path.join(module_dir, 'evaluation.csv'), index=False)\n\n        # Check if the result passes the speed threshold and update the best result if necessary\n        if execution_time < strategies['speed_threshold']:\n            if best_result is None or evaluation_result['score'].mean() > best_result_summary['score'].mean():\n                best_result = result\n                best_result_name = module_name\n                best_result_speed = execution_time\n                best_result_summary = evaluation_result\n\n    # Save the best result and its summary to disk\n    best_result.to_csv(os.path.join(node_line_dir, 'best_result.csv'), index=False)\n    best_result_summary.to_csv(os.path.join(node_line_dir, 'best"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Evaluate and select the best result\n    best_result, best_module, best_params = evaluate_retrieval(modules, module_params, previous_result, strategies)\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Save the best module and its parameters\n    with open(os.path.join(node_line_dir, \"best_module.txt\"), \"w\") as f:\n        f.write(f\"{best_module.__name__}\\n\")\n        f.write(str(best_params))\n\n    # Combine the previous result with the best result\n    combined_result = pd.concat([previous_result, best_result], axis=1)\n\n    # Save the combined result\n    combined_result.to_csv(os.path.join(node_line_dir, \"combined_result.csv\"), index=False)\n\n    return combined_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Check if the node_line_dir exists, if not create it\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize the best result dataframe with the previous result columns\n    best_result = previous_result.copy()\n\n    # Initialize the best result summary with the previous result summary\n    best_result_summary = load_summary_file(os.path.join(node_line_dir, \"summary.json\"))\n\n    # Iterate over the modules and their parameters\n    for module, params in zip(modules, module_params):\n        module_name = module.__name__\n        logger.info(f\"Running module: {module_name}\")\n\n        # Get the module's result and execution time\n        result, execution_time = measure_speed(module, params, previous_result)\n\n        # Evaluate the module's result and update the best result and summary if it's better\n        evaluation_result = evaluate_retrieval(result, execution_time, previous_result, best_result_summary, strategies)\n        if evaluation_result:\n            best_result = result\n            best_result_summary = evaluation_result\n\n    # Save the best result and summary to disk\n    best_result.to_csv(os.path.join(node_line_dir, \"result.csv\"), index=False)\n    best_result_summary.to_json(os.path.join(node_line_dir, \"summary.json\"), orient=\"records\", indent=4)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize the best result dataframe with the previous result columns\n    best_result = previous_result.copy()\n\n    # Initialize the best result summary with the previous result summary\n    best_result_summary = load_summary_file(os.path.join(node_line_dir, \"summary.csv\"))\n\n    # Loop through each module, execute it, and evaluate the results\n    for module, params in zip(modules, module_params):\n        # Get the module name\n        module_name = module.__name__.split(\".\")[-1]\n\n        # Create the directory for the module\n        module_dir = os.path.join(node_line_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Execute the module\n        result = module(**params)\n\n        # Evaluate the results\n        eval_result = evaluate_retrieval(result, previous_result)\n\n        # Save the evaluation result to disk\n        eval_result.to_csv(os.path.join(module_dir, \"result.csv\"), index=False)\n\n        # Measure the execution time\n        execution_time = measure_speed(module, params)\n\n        # Save the execution time to disk\n        execution_time.to_csv(os.path.join(module_dir, \"execution_time.csv\"), index=False)\n\n        # Evaluate the execution time\n        eval_execution_time = evaluate_retrieval(execution_time, pd.DataFrame(columns=[\"metric\", \"value\"]))\n\n        # Save the evaluation execution time to disk\n        eval_execution_time.to_csv(os.path.join(module_dir, \"eval_execution_time.csv\"), index=False)\n\n        # Check if the execution time passes the threshold\n        if \"speed_threshold\" in strategies and strategies[\"speed_threshold\"] is not None:\n            if eval_execution_time[\"value\"].iloc[0] > strategies[\"speed_threshold\"]:\n                logger.info(f\"Execution time of {module"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    logger.info(\"Running retrieval node\")\n\n    # Create a directory for this node line if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize the best result dataframe with the previous result\n    best_result = previous_result\n\n    # Initialize a dictionary to store the summary of execution times and evaluation metrics\n    summary = {}\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running module: {module.__name__}\")\n\n        # Run the module with the given parameters\n        result = module(**params)\n\n        # Evaluate the result using the previous result as the evaluation context\n        eval_result = evaluate_retrieval(result, previous_result)\n\n        # Add the evaluation result to the summary dictionary\n        summary[module.__name__] = eval_result\n\n        # Measure the speed of the module\n        speed = measure_speed(module, params)\n\n        # Add the speed to the summary dictionary\n        summary[module.__name__][\"speed\"] = speed\n\n        # If the speed is within the threshold, add the result to the best result dataframe\n        if filter_by_threshold(speed, strategies):\n            best_result = pd.concat([best_result, result], axis=1)\n\n    # Select the best result from the best result dataframe\n    best_result = select_best_average(best_result, strategies)\n\n    # Save the best result to disk\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Save the summary to disk\n    summary_file = os.path.join(node_line_dir, \"summary.json\")\n    load_summary_file(summary_file, summary)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    logger.info(\"Running retrieval node...\")\n\n    # Create a directory for this node line if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize variables for best result and evaluation metrics\n    best_result = None\n    best_result_summary = None\n    best_evaluation_metrics = None\n\n    # Iterate through each module and its parameters\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running module: {module.__name__}\")\n\n        # Run the module with the given parameters and measure the execution time\n        result, execution_time = measure_speed(module, params, previous_result)\n\n        # Evaluate the result using the specified metrics\n        evaluation_metrics = evaluate_retrieval(result, previous_result)\n\n        # Save the result and evaluation metrics to disk\n        result.to_csv(os.path.join(node_line_dir, f\"{module.__name__}.csv\"), index=False)\n        evaluation_metrics.to_csv(os.path.join(node_line_dir, f\"{module.__name__}_evaluation.csv\"), index=False)\n\n        # Check if the current result passes the speed threshold\n        if filter_by_threshold(execution_time, strategies[\"speed_thresholds\"]):\n            logger.info(f\"Module {module.__name__} passed the speed threshold. Evaluation metrics: {evaluation_metrics}\")\n\n            # Update the best result and evaluation metrics if the current result is better\n            best_result, best_result_summary, best_evaluation_metrics = select_best_average(\n                result, evaluation_metrics, best_result, best_result_summary, best_evaluation_metrics\n            )\n        else:\n            logger.info(f\"Module {module.__name__} failed the speed threshold. Evaluation metrics: {evaluation_metrics}\")\n\n    # Save the best result and evaluation metrics summary to disk\n    best_result.to_csv(os.path."}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize the best result dataframe with the previous result columns\n    best_result = previous_result\n\n    # Create a directory for the node line if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize a list to store the execution times for each module\n    execution_times = []\n\n    # Iterate over the modules and their parameters\n    for module, params in zip(modules, module_params):\n        # Get the module name\n        module_name = module.__name__\n\n        # Log the module name\n        logger.info(f\"Running {module_name}\")\n\n        # Run the module with the given parameters\n        result = module(**params)\n\n        # Evaluate the result using the previous result as the evaluation context\n        evaluation_result = evaluate_retrieval(result, previous_result)\n\n        # Save the result to disk\n        result.to_csv(os.path.join(node_line_dir, f\"{module_name}_result.csv\"))\n\n        # Save the evaluation result to disk\n        evaluation_result.to_csv(os.path.join(node_line_dir, f\"{module_name}_evaluation_result.csv\"))\n\n        # Measure the execution time of the module\n        execution_time = measure_speed(module, params)\n\n        # Append the execution time to the list\n        execution_times.append((module_name, execution_time))\n\n        # Log the execution time\n        logger.info(f\"{module_name} execution time: {execution_time}\")\n\n        # Check if the execution time exceeds the threshold\n        if execution_time > strategies.get(\"speed_threshold\", float('inf')):\n            # If the execution time exceeds the threshold, log a warning and skip to the next module\n            logger.warning(f\"{module_name} execution time exceeds the threshold. Skipping...\")\n            continue\n\n        # If the execution time is within the threshold, select the best result using the specified strategy\n        best_result = select_best_average(best_result,"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize variables\n    best_result = None\n    best_module = None\n    best_params = None\n    best_summary = None\n    best_speed = None\n\n    # Loop through each module and its corresponding parameters\n    for module, params in zip(modules, module_params):\n        logger.info(f\"Running {module.__name__} with params {params}\")\n\n        # Create the output directory for this module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Run the module with the given parameters and save the result\n        result = module(**params)\n        result_path = os.path.join(module_dir, \"result.csv\")\n        result.to_csv(result_path, index=False)\n\n        # Evaluate the result using the specified metrics and save the summary\n        summary = evaluate_retrieval(result, previous_result, metrics=strategies[\"metrics\"])\n        summary_path = os.path.join(module_dir, \"summary.csv\")\n        summary.to_csv(summary_path, index=False)\n\n        # Check if speed threshold is specified and if the module meets it\n        if \"speed_threshold\" in strategies and not measure_speed(result, params, strategies[\"speed_threshold\"]):\n            logger.info(f\"{module.__name__} does not meet speed threshold, skipping...\")\n            continue\n\n        # Check if the result is better than the current best result\n        if best_result is None or summary[\"score\"].iloc[0] > best_summary[\"score\"].iloc[0]:\n            best_result = result\n            best_module = module\n            best_params = params\n            best_summary = summary\n            best_speed = summary[\"speed\"].iloc[0]\n\n    # Check if a best result was found\n    if best_result is None:\n        logger.info(\"No retrieval node result meets the criteria.\")\n        return None\n\n    # Save the best result, summary, and speed to disk\n    best"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize the best result dataframe with the previous result columns\n    best_result = previous_result\n\n    # Initialize the best result summary with the previous result summary\n    best_result_summary = load_summary_file(previous_result)\n\n    # Initialize the best result summary with the previous result summary\n    best_result_summary = load_summary_file(previous_result)\n\n    # Initialize the best result module name and parameters\n    best_result_module_name = None\n    best_result_module_params = None\n\n    # Iterate through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Get the module name\n        module_name = module.__name__\n\n        # Log the module name\n        logger.info(f\"Evaluating {module_name}\")\n\n        # Run the module with the given parameters\n        result = module(**params)\n\n        # Measure the execution time of the module\n        execution_time = measure_speed(module, params)\n\n        # Evaluate the result based on the evaluation context\n        evaluation_result = evaluate_retrieval(result, previous_result)\n\n        # Create a dictionary with the evaluation results\n        evaluation_result_dict = {\n            \"module\": module_name,\n            \"execution_time\": execution_time,\n            **evaluation_result,\n        }\n\n        # Append the evaluation result to the best result summary\n        best_result_summary.append(evaluation_result_dict)\n\n        # If the best result is None or the current result is better than the best result\n        if best_result is None or evaluation_result_dict[\"score\"] > best_result_summary[\"score\"].max():\n            # Update the best result\n            best_result = result\n\n            # Update the best result module name and parameters\n            best_result_module_name = module_name\n            best_result_module_params = params\n\n    # Save the best result summary to disk\n    best_result_summary_path = os.path.join(node_line_dir, \"best_result_summary.csv\")\n    best_result"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize variables\n    best_result = None\n    best_result_name = None\n    best_result_speed = None\n    best_result_eval = None\n    best_result_summary = None\n    best_result_time = None\n\n    # Iterate over each module\n    for module, params in zip(modules, module_params):\n        module_name = module.__name__\n        module_params_str = str(params)\n        module_dir = os.path.join(node_line_dir, module_name + module_params_str)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Execute the module with given parameters\n        result = module(**params)\n\n        # Measure the speed of the module\n        speed = measure_speed(module, params)\n\n        # Evaluate the module's result\n        eval_result = evaluate_retrieval(result, previous_result)\n\n        # Check if the speed threshold is exceeded\n        if \"speed_threshold\" in strategies:\n            speed_threshold = strategies[\"speed_threshold\"]\n            if speed > speed_threshold:\n                logger.info(f\"Module {module_name} with parameters {module_params_str} exceeded speed threshold of {speed_threshold} seconds. Skipping...\")\n                continue\n\n        # Save the result to disk\n        result.to_csv(os.path.join(module_dir, \"result.csv\"), index=False)\n\n        # Save the evaluation result to disk\n        eval_result.to_csv(os.path.join(module_dir, \"eval_result.csv\"), index=False)\n\n        # Save the speed and evaluation result to disk\n        with open(os.path.join(module_dir, \"speed_and_eval.txt\"), \"w\") as f:\n            f.write(f\"Speed: {speed}\\n\")\n            f.write(f\"Evaluation Result:\\n{eval_result}\")\n\n        # Load the summary file\n        summary_file = os.path.join(module_dir,"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Evaluate and select best retrieval node result\n    logger.info(\"Evaluating and selecting best retrieval node result...\")\n    metrics = strategies.get(\"metrics\", [])\n    speed_thresholds = strategies.get(\"speed_thresholds\", {})\n\n    # Initialize best result and best module\n    best_result = None\n    best_module = None\n\n    # Initialize summary dataframe\n    summary_df = pd.DataFrame(columns=['Module', 'Speed (s)', 'Metric'])\n\n    # Iterate over modules and evaluate each one\n    for module, params in zip(modules, module_params):\n        module_name = module.__name__\n        logger.info(f\"Evaluating module: {module_name}\")\n\n        # Evaluate module and measure speed\n        result = evaluate_retrieval(module, params, previous_result)\n        speed = measure_speed(module, params, previous_result)\n\n        # Check if speed is below threshold\n        if speed_thresholds.get(module_name, float('inf')) < speed:\n            logger.info(f\"Module {module_name} speed is below threshold, skipping evaluation.\")\n            continue\n\n        # Evaluate result using metrics\n        metric_results = []\n        for metric in metrics:\n            metric_result = metric(result, previous_result)\n            metric_results.append(metric_result)\n\n        # Append module name, speed, and metric results to summary dataframe\n        summary_df = pd.concat([summary_df, pd.DataFrame({\n            'Module': [module_name],\n            'Speed (s)': [speed],\n            'Metric': [metric_results]\n        })], ignore_index=True)\n\n        # Update best result and best module if necessary\n        if best_result is None or all(metric_results[i] > best_metric_results[i] for i, best_metric_results in enumerate(best_result)):\n            best_result = metric_results\n            best_module = module\n\n    # Save summary dataframe to disk\n    summary"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Load the previous result if it exists\n    if previous_result is not None:\n        previous_result = pd.read_csv(previous_result)\n\n    # Create a directory for the node line if it doesn't exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Evaluate each module and measure their execution time\n    results = []\n    for module, params in zip(modules, module_params):\n        module_name = module.__name__.split('.')[-1]\n        module_result, module_time = evaluate_retrieval(module, params, previous_result)\n        results.append((module_result, module_name, module_time))\n\n    # Filter results based on speed thresholds\n    if \"speed_threshold\" in strategies:\n        results = filter_by_threshold(results, strategies[\"speed_threshold\"])\n\n    # Evaluate the results using the specified metrics\n    if \"metrics\" in strategies:\n        results = evaluate_retrieval_results(results, strategies[\"metrics\"])\n\n    # Select the best result based on the specified evaluation metrics\n    best_result = select_best_average(results, strategies[\"metrics\"])\n\n    # Save the results and summary to disk\n    save_retrieval_node_results(results, best_result, node_line_dir)\n\n    # Combine the previous result with the best result\n    best_result = pd.concat([previous_result, best_result], axis=1)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.retrieval.run.run_retrieval_node", "completion": "    # Initialize the best result dataframe with the previous result\n    best_result = previous_result\n\n    # Initialize the best metrics and speed\n    best_metrics = None\n    best_speed = None\n\n    # Iterate through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Get the module name\n        module_name = module.__name__\n\n        # Run the module with the given parameters\n        result = module(**params)\n\n        # Measure the execution speed of the module\n        speed = measure_speed(module, params)\n\n        # Evaluate the result using the previous result as the evaluation context\n        metrics = evaluate_retrieval(result, previous_result)\n\n        # Check if the speed threshold is exceeded\n        if strategies[\"speed_threshold\"] and speed > strategies[\"speed_threshold\"]:\n            # Log a warning message\n            logger.warning(f\"Module {module_name} execution speed exceeded threshold of {strategies['speed_threshold']} seconds. Skipping this module.\")\n            # Continue to the next module\n            continue\n\n        # Check if the best metrics or best speed is None\n        if best_metrics is None or best_speed is None:\n            # Update the best metrics and speed\n            best_metrics = metrics\n            best_speed = speed\n            # Update the best result dataframe\n            best_result = result\n            # Log a message\n            logger.info(f\"Module {module_name} is the best result so far.\")\n        else:\n            # Check if the current metrics are better than the best metrics\n            if strategies[\"metrics\"] == \"accuracy\" and metrics[\"accuracy\"] > best_metrics[\"accuracy\"]:\n                # Update the best metrics\n                best_metrics = metrics\n                # Update the best result dataframe\n                best_result = result\n                # Log a message\n                logger.info(f\"Module {module_name} is the best result so far.\")\n            # Check if the current speed is better than the best speed\n            elif strategies[\"metrics\"] == \"speed\" and speed < best_speed:\n                # Update"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize variables\n    best_result = None\n    best_result_summary = None\n    best_module = None\n    best_module_params = None\n    best_module_name = None\n    best_module_summary = None\n    best_module_summary_path = None\n    best_module_result_path = None\n    best_module_result = None\n    best_module_time = None\n    best_module_metrics = None\n    best_module_speed = None\n    best_module_speed_threshold = None\n    best_module_speed_threshold_name = None\n    best_module_speed_threshold_value = None\n    best_module_speed_threshold_unit = None\n    best_module_speed_threshold_unit_name = None\n    best_module_speed_threshold_unit_value = None\n    best_module_speed_threshold_unit_name = None\n    best_module_speed_threshold_unit_value = None\n    best_module_speed_threshold_unit_name = None\n    best_module_speed_threshold_unit_value = None\n    best_module_speed_threshold_unit_name = None\n    best_module_speed_threshold_unit_value = None\n    best_module_speed_threshold_unit_name = None\n    best_module_speed_threshold_unit_value = None\n    best_module_speed_threshold_unit_name = None\n    best_module_speed_threshold_unit_value = None\n    best_module_speed_threshold_unit_name = None\n    best_module_speed_threshold_unit_value = None\n    best_module_speed_threshold_unit_name = None\n    best_module_speed_threshold_unit_value = None\n    best_module_speed_threshold_unit_name = None\n    best_module_speed_threshold_unit_value = None\n    best_module_speed_threshold_unit_name = None\n    best_module_speed_threshold_unit_value = None\n    best_module_speed_threshold"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a directory for the query expansion node if it doesn't exist\n    node_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the query expansion node results if it doesn't exist\n    node_results_dir = os.path.join(node_dir, \"results\")\n    pathlib.Path(node_results_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the query expansion node summaries if it doesn't exist\n    node_summaries_dir = os.path.join(node_dir, \"summaries\")\n    pathlib.Path(node_summaries_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize a list to store the results of all query expansion modules\n    all_results = []\n\n    # Iterate over each module and its corresponding parameters\n    for module, params in zip(modules, module_params):\n        # Get the name of the module\n        module_name = module.__name__\n\n        # Create a directory for the current module if it doesn't exist\n        module_dir = os.path.join(node_results_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Create a directory for the current module results if it doesn't exist\n        module_results_dir = os.path.join(module_dir, \"results\")\n        pathlib.Path(module_results_dir).mkdir(parents=True, exist_ok=True)\n\n        # Create a directory for the current module summaries if it doesn't exist\n        module_summaries_dir = os.path.join(module_dir, \"summaries\")\n        pathlib.Path(module_summaries_dir).mkdir(parents=True, exist_ok=True)\n\n        # Create a directory for the current module summaries if it doesn't exist\n        module_sum"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a directory for the query expansion node if it doesn't exist\n    node_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the results of each query expansion module if it doesn't exist\n    results_dir = os.path.join(node_dir, \"results\")\n    pathlib.Path(results_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the summaries of each query expansion module if it doesn't exist\n    summaries_dir = os.path.join(node_dir, \"summaries\")\n    pathlib.Path(summaries_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create an empty list to store the results of each query expansion module\n    results = []\n\n    # Iterate over the modules and their corresponding parameters\n    for module, params in zip(modules, module_params):\n\n        # Create a directory for the current query expansion module if it doesn't exist\n        module_dir = os.path.join(node_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Create a directory for the results of the current query expansion module if it doesn't exist\n        module_results_dir = os.path.join(module_dir, \"results\")\n        pathlib.Path(module_results_dir).mkdir(parents=True, exist_ok=True)\n\n        # Create a directory for the summaries of the current query expansion module if it doesn't exist\n        module_summaries_dir = os.path.join(module_dir, \"summaries\")\n        pathlib.Path(module_summaries_dir).mkdir(parents=True, exist_ok=True)\n\n        # Create a deep copy of the previous result to avoid modifying the original data\n        previous_result_copy = deepcopy(previous_result)\n\n        # Evaluate the"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize the best result dataframe\n    best_result = pd.DataFrame()\n\n    # Initialize the best module name\n    best_module_name = \"\"\n\n    # Initialize the best module parameters\n    best_module_params = {}\n\n    # Initialize the best module execution time\n    best_module_execution_time = 0\n\n    # Initialize the best module evaluation metrics\n    best_module_evaluation_metrics = {}\n\n    # Initialize the best module summary\n    best_module_summary = {}\n\n    # Initialize the best module results\n    best_module_results = {}\n\n    # Iterate over each module and its corresponding parameters\n    for module, params in zip(modules, module_params):\n\n        # Get the module name\n        module_name = module.__name__\n\n        # Get the module directory path\n        module_dir = os.path.join(node_line_dir, module_name)\n\n        # Create the module directory if it doesn't exist\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Initialize the module results dataframe\n        module_results = pd.DataFrame()\n\n        # Initialize the module summary dictionary\n        module_summary = {}\n\n        # Initialize the module evaluation metrics dictionary\n        module_evaluation_metrics = {}\n\n        # Initialize the module execution time\n        module_execution_time = 0\n\n        # Iterate over each combination of parameters\n        for combination in make_combinations(params):\n\n            # Get the combination name\n            combination_name = \"_\".join([f\"{key}-{value}\" for key, value in combination.items()])\n\n            # Create the combination directory path\n            combination_dir = os.path.join(module_dir, combination_name)\n\n            # Create the combination directory if it doesn't exist\n            pathlib.Path(combination_dir).mkdir(parents=True, exist_ok=True)\n\n            # Initialize the combination results dataframe\n            combination_results = pd.DataFrame()\n\n            # Initialize the combination"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the directory for the node\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Evaluate each module with its parameters and save the results\n    results = []\n    for module, params in zip(modules, module_params):\n        module_name = module.__name__.split(\".\")[-1]\n        module_dir = os.path.join(node_line_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n        result = evaluate_retrieval_node(module, params, previous_result, module_dir)\n        results.append(result)\n\n    # Measure the execution time for each module\n    execution_times = measure_speed(results)\n\n    # Evaluate the results based on the specified strategies\n    evaluation_results = []\n    for result, execution_time in zip(results, execution_times):\n        evaluation_result = result.copy()\n        evaluation_result[\"execution_time\"] = execution_time\n        evaluation_results.append(evaluation_result)\n\n    # Save the evaluation results and summaries\n    for result, execution_time, module in zip(evaluation_results, execution_times, modules):\n        module_name = module.__name__.split(\".\")[-1]\n        module_dir = os.path.join(node_line_dir, module_name)\n        result.to_csv(os.path.join(module_dir, \"result.csv\"), index=False)\n        with open(os.path.join(module_dir, \"summary.txt\"), \"w\") as f:\n            f.write(f\"Execution time: {execution_time} seconds\\n\")\n            f.write(f\"Result:\\n{result}\")\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(evaluation_results, strategies)\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index="}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a directory for the query expansion node if it doesn't exist\n    node_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the results if it doesn't exist\n    results_dir = os.path.join(node_dir, \"results\")\n    pathlib.Path(results_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the summaries if it doesn't exist\n    summaries_dir = os.path.join(node_dir, \"summaries\")\n    pathlib.Path(summaries_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize a dictionary to store the results\n    results = {}\n\n    # Iterate over each query expansion module\n    for module, params in zip(modules, module_params):\n        # Get the name of the module\n        module_name = module.__name__\n\n        # Create a directory for the current module if it doesn't exist\n        module_dir = os.path.join(results_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Run the module and get the results\n        result = module(**params, previous_result=previous_result)\n\n        # Save the results to a CSV file in the module directory\n        result.to_csv(os.path.join(module_dir, \"result.csv\"), index=False)\n\n        # Measure the speed of the module\n        speed = measure_speed(module, params, previous_result)\n\n        # Add the speed to the results dictionary\n        results[module_name] = {\"speed\": speed}\n\n    # Convert the results dictionary to a dataframe\n    results_df = pd.DataFrame(results).T\n\n    # Save the results dataframe to a CSV file in the results directory\n    results_df.to_csv(os.path.join(results_dir"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the directory for the current node\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get the support modules\n    support_modules = get_support_modules()\n\n    # Create a list to store the results\n    results = []\n\n    # Iterate over the modules and their parameters\n    for module, params in zip(modules, module_params):\n        # Evaluate the module\n        result = evaluate_retrieval_node(module, params, previous_result, node_line_dir, support_modules)\n\n        # Add the result to the list\n        results.append(result)\n\n    # Create a dataframe from the results\n    results_df = pd.DataFrame(results)\n\n    # Save the results to a CSV file\n    results_df.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Measure the speed of each module\n    results_df = measure_speed(results_df)\n\n    # Filter the results based on the speed threshold\n    results_df = filter_by_threshold(results_df, strategies[\"speed_threshold\"])\n\n    # Save the results with the speed measurements to a CSV file\n    results_df.to_csv(os.path.join(node_line_dir, \"results_with_speed.csv\"), index=False)\n\n    # Evaluate the results based on the specified metrics\n    results_df = evaluate_results(results_df, strategies[\"metrics\"])\n\n    # Save the results with the evaluation metrics to a CSV file\n    results_df.to_csv(os.path.join(node_line_dir, \"results_with_metrics.csv\"), index=False)\n\n    # Select the best result based on the specified evaluation criteria\n    best_result = select_best_average(results_df, strategies[\"metrics\"])\n\n    # Save the best result to a CSV file\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result."}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a directory for the query expansion node if it doesn't exist\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Initialize an empty dataframe to store the results\n    results = pd.DataFrame()\n\n    # Initialize a dictionary to store the execution times of each module\n    execution_times = {}\n\n    # Loop over all modules\n    for module, params in zip(modules, module_params):\n        # Get the name of the module\n        module_name = module.__name__.split(\".\")[-1]\n\n        # Initialize a dictionary to store the results of the current module\n        module_results = {}\n\n        # Create a directory for the current module if it doesn't exist\n        module_dir = os.path.join(node_line_dir, module_name)\n        if not os.path.exists(module_dir):\n            os.makedirs(module_dir)\n\n        # Initialize a dictionary to store the execution times of the current module\n        module_execution_times = {}\n\n        # Initialize a dictionary to store the parameters of the current module\n        module_params = {}\n\n        # Loop over all parameters for the current module\n        for param_name, param_values in params.items():\n            # Initialize a dictionary to store the results of the current parameter combination\n            param_results = {}\n\n            # Create a directory for the current parameter combination if it doesn't exist\n            param_dir = os.path.join(module_dir, param_name)\n            if not os.path.exists(param_dir):\n                os.makedirs(param_dir)\n\n            # Loop over all parameter values for the current parameter\n            for param_value in param_values:\n                # Set the parameter for the current module\n                module_params[param_name] = param_value\n\n                # Create a directory for the current parameter value if it doesn't exist\n                param_value_dir = os.path.join(param_dir, str(param_value))\n                if not os.path.exists(param_"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a directory for the query expansion node if it doesn't exist\n    node_line_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize a dictionary to store the results of each query expansion module\n    results = {}\n\n    # Iterate over each query expansion module\n    for module, params in zip(modules, module_params):\n        # Get the name of the module\n        module_name = module.__name__\n\n        # Create a directory for the module if it doesn't exist\n        module_dir = os.path.join(node_line_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Create a copy of the previous result for the module\n        module_previous_result = deepcopy(previous_result)\n\n        # Run the module with the specified parameters and measure its execution time\n        module_result, execution_time = measure_speed(module, module_previous_result, params)\n\n        # Evaluate the module's performance based on the specified strategies\n        module_result = evaluate_retrieval_node(module_result, strategies)\n\n        # Add the execution time to the module's result\n        module_result[\"execution_time\"] = execution_time\n\n        # Save the module's result to the module directory\n        module_result.to_csv(os.path.join(module_dir, \"result.csv\"), index=False)\n\n        # Save the module's result to the results dictionary\n        results[module_name] = module_result\n\n    # Save the results dictionary to a CSV file in the query expansion node directory\n    pd.DataFrame(results).transpose().to_csv(os.path.join(node_line_dir, \"results.csv\"))\n\n    # Select the best result based on the specified strategies\n    best_result = select_best_average(results, strategies)\n\n    # Save the best result to the query expansion node directory"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the directory for the query expansion node\n    node_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize an empty list to store the results\n    results = []\n\n    # Iterate over each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Create the directory for the current module\n        module_dir = os.path.join(node_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Get the module name\n        module_name = module.__name__\n\n        # Initialize an empty list to store the module results\n        module_results = []\n\n        # Iterate over each parameter combination\n        for param_combination in make_combinations(params):\n            # Create the directory for the current parameter combination\n            param_dir = os.path.join(module_dir, str(param_combination))\n            pathlib.Path(param_dir).mkdir(parents=True, exist_ok=True)\n\n            # Evaluate the current module with the current parameter combination\n            result = evaluate_retrieval_node(module, param_combination, previous_result, param_dir)\n\n            # Measure the speed of the current module\n            result = measure_speed(result, strategies[\"speed\"])\n\n            # Append the result to the module results list\n            module_results.append(result)\n\n        # Explode the module results to separate the results for each parameter combination\n        module_results = explode(module_results, \"params\")\n\n        # Filter the module results based on the speed threshold\n        module_results = filter_by_threshold(module_results, \"speed\", strategies[\"speed\"][\"threshold\"])\n\n        # Select the best result based on the evaluation criteria\n        best_result = select_best_average(module_results, strategies[\"evaluation\"])\n\n        # Save the best result to the module directory\n        best"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a directory for the query expansion node\n    node_line_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize an empty list to store the results\n    results = []\n\n    # Iterate over the modules and their corresponding parameters\n    for module, params in zip(modules, module_params):\n        # Get the name of the module\n        module_name = module.__name__.split(\".\")[-1]\n\n        # Create a directory for the current module\n        module_dir = os.path.join(node_line_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Evaluate the current module and get the results\n        result = evaluate_retrieval_node(module, params, previous_result, module_dir)\n\n        # Save the results to the module directory\n        result.to_csv(os.path.join(module_dir, \"results.csv\"))\n\n        # Append the results to the list\n        results.append(result)\n\n    # Concatenate the results into a single dataframe\n    results = pd.concat(results, axis=0)\n\n    # Measure the speed of each module and add the results to the dataframe\n    results = measure_speed(results)\n\n    # Filter the results based on the specified speed thresholds\n    results = filter_by_threshold(results, strategies[\"speed_thresholds\"])\n\n    # Select the best result based on the specified evaluation criteria\n    best_result = select_best_average(results, strategies[\"metrics\"])\n\n    # Save the best result to a CSV file in the query expansion node directory\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"))\n\n    # Save the results to a CSV file in the query expansion node directory\n    results.to_csv(os.path.join(node_line_dir"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the directory for this node\n    node_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Evaluate each module and save the results\n    module_results = []\n    for module, params in zip(modules, module_params):\n        module_result = evaluate_query_expansion_node(module, params, previous_result, node_dir)\n        module_results.append(module_result)\n\n    # Combine the results from all modules\n    combined_results = pd.concat(module_results)\n    combined_results.to_csv(os.path.join(node_dir, \"results.csv\"), index=False)\n\n    # Measure the speed of each module and filter based on the threshold\n    speed_results = measure_speed(combined_results, strategies[\"speed_threshold\"])\n    filtered_results = filter_by_threshold(speed_results, strategies[\"speed_threshold\"])\n\n    # Evaluate the filtered results based on the specified metrics\n    evaluation_results = evaluate_query_expansion_node(filtered_results, strategies[\"metrics\"])\n\n    # Select the best result based on the specified evaluation criteria\n    best_result = select_best_average(evaluation_results, strategies[\"evaluation_criteria\"])\n\n    # Save the best result to a file\n    best_result.to_csv(os.path.join(node_dir, \"best_result.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create the node directory if it does not exist\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize an empty dataframe to store the results\n    results = pd.DataFrame()\n\n    # Iterate over each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Create a new directory for the module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Evaluate the module and save the results\n        result = evaluate_retrieval_node(module, params, previous_result, module_dir)\n        results = pd.concat([results, result])\n\n    # Measure the speed of each module and filter out those that do not meet the speed threshold\n    results = measure_speed(results, strategies[\"speed_threshold\"])\n\n    # Evaluate the results using the specified metrics\n    results = evaluate_retrieval_node(results, strategies[\"metrics\"])\n\n    # Save the results and a summary\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n    results.describe().to_csv(os.path.join(node_line_dir, \"summary.csv\"))\n\n    # Select the best result based on the evaluation criteria\n    best_result = select_best_average(results, strategies[\"evaluation_criteria\"])\n\n    # Save the best result\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a directory for the node's results\n    node_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize a dataframe to store the results\n    results = pd.DataFrame()\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n\n        # Evaluate the module and save the results\n        result = evaluate_retrieval_node(module, params, previous_result, node_dir)\n\n        # Add the module name to the results\n        result[\"module\"] = module.__name__\n\n        # Append the results to the dataframe\n        results = pd.concat([results, result], ignore_index=True)\n\n    # Save the results to a CSV file\n    results.to_csv(os.path.join(node_dir, \"results.csv\"), index=False)\n\n    # Calculate the execution time for each module\n    execution_times = measure_speed(results, \"execution_time\", \"module\")\n\n    # Save the execution times to a CSV file\n    execution_times.to_csv(os.path.join(node_dir, \"execution_times.csv\"), index=False)\n\n    # Evaluate the results based on the specified strategies\n    results = evaluate_results(results, strategies)\n\n    # Save the evaluation results to a CSV file\n    results.to_csv(os.path.join(node_dir, \"evaluation.csv\"), index=False)\n\n    # Select the best result based on the evaluation\n    best_result = select_best_average(results, strategies)\n\n    # Save the best result to a CSV file\n    best_result.to_csv(os.path.join(node_dir, \"best_result.csv\"), index=False)\n\n    # Return the best result\n    return best_result\n\n"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Initialize the best result and the best module\n    best_result = None\n    best_module = None\n\n    # Iterate through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Create a directory for the current module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Evaluate the current module and save the results\n        result = evaluate_retrieval_node(module, params, previous_result, module_dir)\n\n        # Measure the execution time of the current module\n        execution_time = measure_speed(result)\n\n        # Save the execution time to the module directory\n        with open(os.path.join(module_dir, \"execution_time.txt\"), \"w\") as f:\n            f.write(f\"Execution time: {execution_time}\")\n\n        # Evaluate the results based on the specified strategies\n        if strategies[\"evaluation_metrics\"] is not None:\n            result = evaluate_retrieval_node(module, params, previous_result, module_dir)\n\n            # Save the evaluation results to the module directory\n            with open(os.path.join(module_dir, \"evaluation_results.txt\"), \"w\") as f:\n                for metric, value in result.items():\n                    f.write(f\"{metric}: {value}\\n\")\n\n        # Select the best module based on the specified strategies\n        if best_result is None or strategies[\"speed_threshold\"] is not None and execution_time <= strategies[\"speed_threshold\"]:\n            best_result = result\n            best_module = module\n\n    # Save the best result to the node line directory\n    best_result.to_csv(os.path.join(node_line_dir, \"best_result.csv\"), index=False)\n\n    # Save the best module to the node line directory\n    with open(os.path.join(node_line_dir, \"best_module.txt\"), \"w\") as f:"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Check if the node_line_dir exists, if not create it\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize variables\n    best_result = None\n    best_module = None\n    best_params = None\n    best_speed = float('inf')\n    best_metrics = None\n\n    # Initialize a dictionary to store the results for each module\n    results = {}\n\n    # Loop through each module and its corresponding parameters\n    for module, params in zip(modules, module_params):\n        # Get the name of the module\n        module_name = module.__name__\n\n        # Initialize a dictionary to store the results for the current module\n        results[module_name] = {}\n\n        # Initialize a list to store the execution times for the current module\n        execution_times = []\n\n        # Loop through each combination of parameters for the current module\n        for param_combination in make_combinations(params):\n            # Initialize a dictionary to store the results for the current combination of parameters\n            results[module_name][param_combination] = {}\n\n            # Initialize a list to store the execution times for the current combination of parameters\n            execution_times_combination = []\n\n            # Loop through each strategy\n            for strategy in strategies:\n                # Initialize a dictionary to store the results for the current strategy\n                results[module_name][param_combination][strategy] = {}\n\n                # Get the name of the strategy\n                strategy_name = strategy['name']\n\n                # Get the threshold for the strategy\n                threshold = strategy.get('threshold', None)\n\n                # Get the metric for the strategy\n                metric = strategy.get('metric', None)\n\n                # Get the type of the strategy\n                strategy_type = strategy.get('type', None)\n\n                # Get the number of iterations for the strategy\n                n_iter = strategy.get('n_iter', 1)\n\n                # Initialize a list to store the results for the current strategy\n                strategy_results = []\n\n                # Loop through the specified number of"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a directory to save the results and summaries\n    node_line_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a dataframe to store the results of each module\n    results = pd.DataFrame()\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Get the module name and parameters\n        module_name = module.__name__\n        module_params = params\n\n        # Create a directory for the current module\n        module_dir = os.path.join(node_line_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Run the module with the given parameters and get the results\n        result = evaluate_retrieval_node(module, module_params, previous_result, module_dir)\n\n        # Measure the speed of the module\n        speed = measure_speed(result)\n\n        # Filter the results based on the speed threshold\n        result = filter_by_threshold(result, \"speed\", strategies[\"speed_thresholds\"])\n\n        # Save the results and a summary\n        result.to_csv(os.path.join(module_dir, \"results.csv\"), index=False)\n        with open(os.path.join(module_dir, \"summary.txt\"), \"w\") as f:\n            f.write(f\"Speed: {speed}\\n\")\n            f.write(f\"Number of results: {len(result)}\\n\")\n\n        # Add the results and speed to the results dataframe\n        result[\"speed\"] = speed\n        result[\"module\"] = module_name\n        results = pd.concat([results, result], ignore_index=True)\n\n    # Evaluate the results based on the specified metrics\n    results = evaluate_retrieval_node(select_best_average, {}, results, node_line_dir)\n\n    # Select the best result based on"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Check if the module_params list is empty\n    if not module_params:\n        # If it is, create a list of empty dictionaries with the same length as modules\n        module_params = [{} for _ in modules]\n\n    # Check if the length of modules and module_params lists are equal\n    assert len(modules) == len(module_params)\n\n    # Create a directory for the query expansion node if it doesn't exist\n    node_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a list of tuples containing the module and its parameters\n    modules_with_params = list(zip(modules, module_params))\n\n    # Create a list to store the results\n    results = []\n\n    # Iterate over each module and its parameters\n    for module, params in modules_with_params:\n        # Create a dictionary to store the module results\n        module_results = {}\n\n        # Create a directory for the current module\n        module_dir = os.path.join(node_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Create a dictionary to store the module parameters\n        module_params = {}\n\n        # Iterate over each parameter and its value\n        for param, value in params.items():\n            # If the value is a list, create a list of dictionaries with the parameter and each value\n            if isinstance(value, list):\n                module_params[param] = [{param: v} for v in value]\n            # Otherwise, create a dictionary with the parameter and its value\n            else:\n                module_params[param] = {param: value}\n\n        # Create a list of all combinations of the module parameters\n        module_params_combinations = make_combinations(module_params)\n\n        # Iterate over each combination of parameters\n        for params_combination in module_params_combinations:\n            # Create a dictionary to store the combination results\n           "}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Make directory for this node\n    node_line_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(node_line_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get all possible combinations of parameters\n    param_combinations = make_combinations(module_params)\n\n    # Evaluate each module with each parameter combination\n    results = []\n    for module, params in zip(modules, param_combinations):\n        # Get module name and parameters\n        module_name = module.__name__\n        module_params = params\n\n        # Create directory for this module\n        module_dir = os.path.join(node_line_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Run module with given parameters\n        result = evaluate_query_expansion_node(module, module_params, previous_result, module_dir)\n\n        # Save result to list\n        results.append(result)\n\n    # Explode results list\n    results = explode(results)\n\n    # Measure speed of each module\n    results = measure_speed(results, strategies[\"speed_thresholds\"])\n\n    # Evaluate each module based on specified metrics\n    results = evaluate_retrieval_node(results, strategies[\"metrics\"])\n\n    # Save results to file\n    results.to_csv(os.path.join(node_line_dir, \"results.csv\"), index=False)\n\n    # Save summary to file\n    summary = results.groupby(\"module_name\").agg(\n        {\n            \"speed\": [\"mean\", \"std\"],\n            \"score\": [\"mean\", \"std\"],\n        }\n    )\n    summary.to_csv(os.path.join(node_line_dir, \"summary.csv\"))\n\n    # Select best module based on specified criteria\n    best_result = select_best_average(results, strategies[\"best_by\"])\n\n    # Save best result to file\n    best_result.to"}
{"namespace": "autorag.nodes.queryexpansion.run.run_query_expansion_node", "completion": "    # Create a directory for the query expansion node\n    query_expansion_dir = os.path.join(node_line_dir, \"query_expansion\")\n    pathlib.Path(query_expansion_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize an empty list to store the results of all modules\n    all_results = []\n\n    # Iterate over each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Get the name of the module\n        module_name = module.__name__\n\n        # Create a directory for the current module\n        module_dir = os.path.join(query_expansion_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Get the list of supported languages for the current module\n        supported_languages = get_support_modules(module_name, \"languages\")\n\n        # Iterate over each language supported by the current module\n        for language in supported_languages:\n            # Create a directory for the current language\n            language_dir = os.path.join(module_dir, language)\n            pathlib.Path(language_dir).mkdir(parents=True, exist_ok=True)\n\n            # Copy the previous result dataframe to avoid modifying it\n            result_df = deepcopy(previous_result)\n\n            # Run the current module with the given parameters for the current language\n            module_result = evaluate_retrieval_node(module, params, result_df, language, module_dir)\n\n            # If the module result is not empty\n            if module_result is not None:\n                # Add the module name and language to the module result dataframe\n                module_result[\"module_name\"] = module_name\n                module_result[\"language\"] = language\n\n                # Append the module result to the list of all results\n                all_results.append(module_result)\n\n    # If there are no results, return an empty dataframe\n    if len(all_results) == 0:\n        logger.warning(\"No results found."}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create a directory for the node's output\n    node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the node's output\n    node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the node's output\n    node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the node's output\n    node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the node's output\n    node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the node's output\n    node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the node's output\n    node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the node's output\n    node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the node's"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the node directory if it doesn't exist\n    node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create the directory for the best prompt maker module if it doesn't exist\n    best_prompt_maker_dir = os.path.join(node_dir, 'best_prompt_maker')\n    pathlib.Path(best_prompt_maker_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create the directory for the prompt maker module results if it doesn't exist\n    prompt_maker_results_dir = os.path.join(node_dir, 'prompt_maker_results')\n    pathlib.Path(prompt_maker_results_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create the directory for the prompt maker module summaries if it doesn't exist\n    prompt_maker_summaries_dir = os.path.join(node_dir, 'prompt_maker_summaries')\n    pathlib.Path(prompt_maker_summaries_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create the directory for the prompt maker module execution times if it doesn't exist\n    prompt_maker_execution_times_dir = os.path.join(node_dir, 'prompt_maker_execution_times')\n    pathlib.Path(prompt_maker_execution_times_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create the directory for the best prompt maker module execution times if it doesn't exist\n    best_prompt_maker_execution_times_dir = os.path.join(node_dir, 'best_prompt_maker_execution_times')\n    pathlib.Path(best_prompt_maker_execution_times_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create the directory for the best prompt maker module results if it doesn't exist\n    best_prompt_maker"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Initialize the directory for the node\n    node_dir = os.path.join(node_line_dir, \"node\")\n    os.makedirs(node_dir, exist_ok=True)\n\n    # Initialize the directory for the node's output\n    node_output_dir = os.path.join(node_dir, \"output\")\n    os.makedirs(node_output_dir, exist_ok=True)\n\n    # Initialize the directory for the node's summary\n    node_summary_dir = os.path.join(node_dir, \"summary\")\n    os.makedirs(node_summary_dir, exist_ok=True)\n\n    # Initialize the directory for the node's summary\n    node_summary_dir = os.path.join(node_dir, \"summary\")\n    os.makedirs(node_summary_dir, exist_ok=True)\n\n    # Initialize the directory for the node's execution times\n    node_times_dir = os.path.join(node_dir, \"times\")\n    os.makedirs(node_times_dir, exist_ok=True)\n\n    # Initialize the directory for the node's execution times\n    node_times_dir = os.path.join(node_dir, \"times\")\n    os.makedirs(node_times_dir, exist_ok=True)\n\n    # Initialize the directory for the node's evaluation metrics\n    node_metrics_dir = os.path.join(node_dir, \"metrics\")\n    os.makedirs(node_metrics_dir, exist_ok=True)\n\n    # Initialize the directory for the node's evaluation metrics\n    node_metrics_dir = os.path.join(node_dir, \"metrics\")\n    os.makedirs(node_metrics_dir, exist_ok=True)\n\n    # Initialize the directory for the node's evaluation metrics\n    node_metrics_dir = os.path.join(node_dir, \"metrics\")\n    os.makedirs(node_metrics_dir, exist_"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get generator module\n    generator = strategies.get('generator', None)\n    if generator is None:\n        generator = get_support_modules()['generator']\n\n    # Create directory for node's output\n    node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create directory for prompt maker's output\n    prompt_maker_dir = os.path.join(node_dir, 'prompt_maker_output')\n    pathlib.Path(prompt_maker_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create directory for prompt maker's summary\n    prompt_maker_summary_dir = os.path.join(node_dir, 'prompt_maker_summary')\n    pathlib.Path(prompt_maker_summary_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create directory for prompt maker's execution times\n    prompt_maker_time_dir = os.path.join(node_dir, 'prompt_maker_time')\n    pathlib.Path(prompt_maker_time_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create directory for prompt maker's evaluation metrics\n    prompt_maker_metrics_dir = os.path.join(node_dir, 'prompt_maker_metrics')\n    pathlib.Path(prompt_maker_metrics_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create directory for prompt maker's evaluation metrics summary\n    prompt_maker_metrics_summary_dir = os.path.join(node_dir, 'prompt_maker_metrics_summary')\n    pathlib.Path(prompt_maker_metrics_summary_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create directory for prompt maker's evaluation metrics summary\n    prompt_maker_metrics_summary_dir = os.path.join(node_dir, 'prompt_maker_metrics"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Evaluate each prompt maker module\n    results = []\n    for module, params in zip(modules, module_params):\n        # Run the module with the given parameters\n        result = module(**params)\n\n        # Save the result to a CSV file\n        result_path = os.path.join(node_line_dir, f\"{module.__name__}.csv\")\n        result.to_csv(result_path, index=False)\n\n        # Evaluate the result\n        metrics = evaluate_generation(result)\n\n        # Add the result and metrics to the list\n        results.append((result, metrics))\n\n    # Select the best prompt maker module based on the specified strategies\n    best_result, best_metrics = select_best_prompt_maker(results, strategies)\n\n    # Save the best result to a CSV file\n    best_result_path = os.path.join(node_line_dir, \"best_result.csv\")\n    best_result.to_csv(best_result_path, index=False)\n\n    # Save the best metrics to a CSV file\n    best_metrics_path = os.path.join(node_line_dir, \"best_metrics.csv\")\n    best_metrics.to_csv(best_metrics_path, index=False)\n\n    # Combine the previous result with the best result\n    combined_result = pd.concat([previous_result, best_result], ignore_index=True)\n\n    # Save the combined result to a CSV file\n    combined_result_path = os.path.join(node_line_dir, \"combined_result.csv\")\n    combined_result.to_csv(combined_result_path, index=False)\n\n    # Return the combined result\n    return combined_result\n\n"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Get the generator module and its parameters from the strategies dictionary\n    generator_module = strategies.get('generator_module', None)\n    generator_params = strategies.get('generator_params', {})\n\n    # Create a directory for the node's output if it doesn't exist\n    node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the best prompt maker's output if it doesn't exist\n    best_dir = os.path.join(node_dir, 'best')\n    pathlib.Path(best_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the results of all prompt maker modules if it doesn't exist\n    results_dir = os.path.join(node_dir, 'results')\n    pathlib.Path(results_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a directory for the summary of all prompt maker modules if it doesn't exist\n    summary_dir = os.path.join(node_dir, 'summary')\n    pathlib.Path(summary_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize an empty list to store the results of all prompt maker modules\n    results = []\n\n    # Iterate over each prompt maker module and its parameters\n    for module, params in zip(modules, module_params):\n\n        # Create a directory for the current prompt maker module's output if it doesn't exist\n        module_dir = os.path.join(results_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Get the execution time for the current prompt maker module\n        execution_time = measure_speed(module, params, generator_module, generator_params)\n\n        # Get the evaluation metrics for the current prompt maker module\n        metrics = evaluate_generation(module, params, generator_module, generator_params)\n\n        # Cast"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create a directory for the node's output if it doesn't exist\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Initialize the best_result variable\n    best_result = None\n\n    # Initialize the best_module_name variable\n    best_module_name = None\n\n    # Iterate over each prompt maker module and its parameters\n    for module, params in zip(modules, module_params):\n\n        # Get the name of the prompt maker module\n        module_name = module.__name__\n\n        # Create a directory for the current prompt maker module's output\n        module_dir = os.path.join(node_line_dir, module_name)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Run the prompt maker module with the given parameters\n        result = module(**params)\n\n        # Validate the output of the prompt maker module\n        validate_qa_dataset(result)\n\n        # Save the result to a CSV file in the module's directory\n        result.to_csv(os.path.join(module_dir, 'result.csv'), index=False)\n\n        # Measure the execution time of the prompt maker module\n        execution_time = measure_speed(module, params)\n\n        # Save the execution time to a file in the module's directory\n        with open(os.path.join(module_dir, 'execution_time.txt'), 'w') as f:\n            f.write(str(execution_time))\n\n        # If the best_result is None or the current module's execution time is faster than the previous best, update the best_result and best_module_name\n        if best_result is None or execution_time < best_result['execution_time']:\n            best_result = {'result': result, 'execution_time': execution_time}\n            best_module_name = module_name\n\n    # Save the best result to a CSV file in the node's directory\n    best_result['result'].to_csv(os.path.join(node_line_dir, 'best_result."}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Create a list of combinations of modules and parameters\n    combinations = make_combinations(modules, module_params)\n\n    # Initialize a list to store the results\n    results = []\n\n    # Loop through each combination\n    for i, (module, params) in enumerate(combinations):\n        # Create a directory for the current combination\n        combination_dir = os.path.join(node_line_dir, f\"combination_{i}\")\n        os.makedirs(combination_dir, exist_ok=True)\n\n        # Measure the speed of the current module\n        speed = measure_speed(module, params)\n\n        # If the speed is within the specified threshold, execute the module\n        if speed <= strategies[\"speed_threshold\"]:\n            # Execute the module and get the result\n            result = module(**params)\n\n            # Save the result to a file\n            result.to_csv(os.path.join(combination_dir, \"result.csv\"), index=False)\n\n            # Evaluate the result using the specified generator module\n            generator_module = strategies[\"generator_module\"]\n            generator_params = strategies[\"generator_params\"]\n            evaluation_result = evaluate_generation(result, generator_module, **generator_params)\n\n            # Save the evaluation result to a file\n            evaluation_result.to_csv(os.path.join(combination_dir, \"evaluation_result.csv\"), index=False)\n\n            # Add the evaluation result to the results list\n            results.append(evaluation_result)\n\n    # Combine the results from all combinations\n    combined_result = pd.concat(results, ignore_index=True)\n\n    # Filter the results based on the specified metrics\n    filtered_result = filter_by_threshold(combined_result, strategies[\"metrics\"])\n\n    # Select the best combination based on the specified metrics\n    best_combination = select_best_average(filtered_result, strategies[\"metrics\"])\n\n   "}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Initialize variables\n    best_module_name = None\n    best_module_params = None\n    best_module_result = None\n    best_module_time = None\n    best_module_metrics = None\n    best_module_generator_module = None\n    best_module_generator_params = None\n\n    # Iterate over prompt maker modules\n    for module, params in zip(modules, module_params):\n        # Get module name and parameters\n        module_name = module.__name__\n        module_params = params\n\n        # Create module directory\n        module_dir = os.path.join(node_line_dir, module_name)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Run module\n        module_result, module_time = measure_speed(module, params)\n\n        # Evaluate module\n        generator_module = strategies.get('generator_module')\n        generator_params = strategies.get('generator_params')\n        if generator_module is not None:\n            module_result = evaluate_generation(module_result, generator_module, generator_params)\n\n        # Save module result\n        module_result.to_csv(os.path.join(module_dir, 'result.csv'), index=False)\n\n        # Save module execution time\n        with open(os.path.join(module_dir, 'time.txt'), 'w') as f:\n            f.write(str(module_time))\n\n        # Evaluate module performance\n        module_metrics = evaluate_generation(module_result, module, params)\n\n        # Save module metrics\n        module_metrics.to_csv(os.path.join(module_dir, 'metrics.csv'), index=False)\n\n        # Check if module meets speed threshold\n        speed_threshold = strategies.get('speed_threshold')\n        if speed_threshold is not None and module_time > speed_threshold:\n            continue\n\n        # Check if module has better metrics"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    node_dir = os.path.join(node_line_dir, 'prompt_maker')\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Initialize variables\n    best_module_name = None\n    best_module_params = None\n    best_module_result = None\n    best_module_time = None\n    best_module_metrics = None\n\n    # Iterate over prompt maker modules\n    for module, params in zip(modules, module_params):\n        module_name = module.__name__.split('.')[-1]\n        module_dir = os.path.join(node_dir, module_name)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Execute prompt maker module and measure execution time\n        result, time = measure_speed(module, params, previous_result)\n\n        # Evaluate prompt maker module using specified generator module\n        if strategies['generator'] is not None:\n            generator_module = strategies['generator']['module']\n            generator_params = strategies['generator']['params']\n            generator_result = generator_module(result, **generator_params)\n            metrics = evaluate_generation(generator_result, result)\n        else:\n            metrics = evaluate_generation(result, result)\n\n        # Save results and summary\n        result.to_csv(os.path.join(module_dir, 'result.csv'), index=False)\n        pd.DataFrame({'time': [time], 'metrics': [metrics]}).to_csv(os.path.join(module_dir, 'summary.csv'), index=False)\n\n        # Update best prompt maker module if it meets the speed threshold and has the highest evaluation metric\n        if best_module_metrics is None or (time <= strategies['speed_threshold'] and metrics > best_module_metrics):\n            best_module_name = module_name\n            best_module_params = params\n            best_module_result = result\n            best_module_time = time\n            best_module"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'results'), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'summaries'), exist_ok=True)\n\n    # Create a list of combinations of modules and their corresponding parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Initialize variables to track the best result and the corresponding module\n    best_result = None\n    best_module = None\n\n    # Iterate over each module and its parameters\n    for module, params in module_combinations:\n        # Create a new directory for the current module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Run the current module and save the results\n        result = module(**params)\n        result.to_csv(os.path.join(module_dir, 'results.csv'), index=False)\n\n        # Evaluate the module's performance and save the summary\n        summary = evaluate_generation(result, strategies['metrics'])\n        summary.to_csv(os.path.join(module_dir, 'summary.csv'), index=False)\n\n        # Check if the current module's performance is better than the previous best\n        if best_result is None or summary.iloc[0]['accuracy'] > best_result.iloc[0]['accuracy']:\n            best_result = summary\n            best_module = module\n\n    # Save the best result and summary\n    best_result.to_csv(os.path.join(node_line_dir, 'results', 'best_result.csv'), index=False)\n    best_result.to_csv(os.path.join(node_line_dir, 'summaries', 'best_summary.csv'), index=False)\n\n    # Combine the previous result with the best result"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create subdirectories for each module\n    module_dirs = [os.path.join(node_line_dir, module.__name__) for module in modules]\n    for module_dir in module_dirs:\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n    # Create a dictionary to store the results\n    results = {}\n\n    # Iterate over each module and its parameters\n    for module, params in zip(modules, module_params):\n        module_name = module.__name__\n        module_dir = os.path.join(node_line_dir, module_name)\n\n        # Create a directory for the current module\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Run the module with the specified parameters\n        result = module(**params)\n\n        # Validate the result\n        validate_qa_dataset(result)\n\n        # Measure the speed of the module\n        speed = measure_speed(module, params)\n\n        # Add the result, speed, and module name to the results dictionary\n        results[module_name] = {'result': result, 'speed': speed, 'module': module}\n\n    # Check if there are any strategies specified\n    if strategies:\n        # Extract the metrics from the strategies dictionary\n        metrics = strategies.get('metrics', None)\n\n        # Check if there are any metrics specified\n        if metrics:\n            # Evaluate the results using the specified metrics\n            results = evaluate_generation(results, metrics)\n\n        # Extract the speed threshold from the strategies dictionary\n        speed_threshold = strategies.get('speed_threshold', None)\n\n        # Check if there is a speed threshold specified\n        if speed_threshold:\n            # Filter the results based on the speed threshold\n            results = filter_by_threshold(results, speed_threshold)\n\n        # Extract the generator module from the strategies dictionary\n        generator_module = strategies.get('generator_module', None)\n\n        # Check if there is a generator module specified\n        if generator_module:\n           "}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, 'results'), exist_ok=True)\n\n    # Initialize variables\n    best_module = None\n    best_params = None\n    best_result = None\n    best_time = float('inf')\n    best_metrics = {}\n\n    # Iterate over prompt maker modules\n    for module, params in zip(modules, module_params):\n        # Create a new directory for each module\n        module_dir = os.path.join(node_line_dir, module.__name__)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Run the module and measure its speed\n        result, time = measure_speed(module, params, previous_result)\n\n        # Evaluate the module's performance\n        metrics = evaluate_prompt_maker(result, strategies)\n\n        # Update the best module if the current one is better\n        if metrics is not None and metrics['f1'] > best_metrics.get('f1', 0):\n            best_module = module\n            best_params = params\n            best_result = result\n            best_time = time\n            best_metrics = metrics\n\n        # Save the module's results and summary\n        result.to_csv(os.path.join(module_dir, 'result.csv'), index=False)\n        with open(os.path.join(module_dir, 'summary.txt'), 'w') as f:\n            f.write(f\"Execution time: {time:.2f} seconds\\n\")\n            f.write(f\"Metrics: {metrics}\\n\")\n\n    # Create the best module directory\n    best_module_dir = os.path.join(node_line_dir, best_module.__name__)\n    os.makedirs(best_module_dir, exist_ok=True)\n\n    # Save the best module's results and summary\n    best_result.to_csv(os.path.join(best_module_"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create directories for storing node output\n    node_dir = pathlib.Path(node_line_dir) / \"prompt_maker\"\n    node_dir.mkdir(parents=True, exist_ok=True)\n\n    # Create a list of all combinations of modules and their parameters\n    module_combinations = make_combinations(modules, module_params)\n\n    # Initialize a dictionary to store the results of each module combination\n    results = {}\n\n    # Iterate over each module combination\n    for module, params in module_combinations:\n        # Create a directory for the current module combination\n        module_dir = node_dir / module.__name__\n        module_dir.mkdir(parents=True, exist_ok=True)\n\n        # Create a directory for the current module combination's results\n        module_results_dir = module_dir / \"results\"\n        module_results_dir.mkdir(parents=True, exist_ok=True)\n\n        # Run the current module with the given parameters\n        module_result = module(**params)\n\n        # Save the module's result to a CSV file\n        module_result.to_csv(module_results_dir / \"results.csv\", index=False)\n\n        # Add the module's result to the results dictionary\n        results[module.__name__] = module_result\n\n    # Convert the results dictionary to a dataframe\n    results_df = pd.DataFrame(results)\n\n    # Combine the previous result with the best prompt maker's result\n    combined_result = pd.concat([previous_result, results_df.loc[results_df.index[0]]], axis=1)\n\n    # Save the combined result to a CSV file\n    combined_result.to_csv(node_dir / \"combined_result.csv\", index=False)\n\n    # Initialize a dictionary to store the execution times of each module combination\n    execution_times = {}\n\n    # Iterate over each module combination\n    for module, params in module_combinations:\n        # Create a directory for the current module combination\n        module_dir = node_dir"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create subdirectories for the node\n    node_dir = os.path.join(node_line_dir, \"prompt_maker\")\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Get the generator module from the strategies or use the default one\n    generator = strategies.get(\"generator\", \"qa\")\n\n    # Create a list of combinations of modules and their parameters\n    combinations = make_combinations(modules, module_params)\n\n    # Evaluate each combination and store the results\n    results = []\n    for comb in combinations:\n        # Extract the module and parameters from the combination\n        module, params = comb\n\n        # Create a subdirectory for the module\n        module_dir = os.path.join(node_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Run the module and get the result\n        result = module(**params)\n\n        # Evaluate the result using the generator module\n        evaluation_result = evaluate_generation(result, generator)\n\n        # Save the evaluation result to a CSV file\n        evaluation_result.to_csv(os.path.join(module_dir, \"evaluation_result.csv\"), index=False)\n\n        # Append the result to the list of results\n        results.append((comb, result, evaluation_result))\n\n    # Select the best combination based on the specified strategies\n    best_combination, best_result, best_evaluation_result = select_best_average(results, strategies)\n\n    # Save the best result to a CSV file\n    best_result.to_csv(os.path.join(node_dir, \"best_result.csv\"), index=False)\n\n    # Save the best evaluation result to a CSV file\n    best_evaluation_result.to_csv(os.path.join(node_dir, \"best_evaluation_result.csv\"), index=False)\n\n    # Combine the previous result with the best result\n    combined_result = pd.concat([previous"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create directories for the node's output\n    os.makedirs(node_line_dir, exist_ok=True)\n\n    # Initialize the best_result variable\n    best_result = None\n\n    # Initialize the best_module_name variable\n    best_module_name = None\n\n    # Loop through each module and its parameters\n    for module, params in zip(modules, module_params):\n        # Get the module name\n        module_name = module.__name__.split(\".\")[-1]\n\n        # Create a directory for the module's output\n        module_dir = os.path.join(node_line_dir, module_name)\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Create a directory for the module's output files\n        output_files_dir = os.path.join(module_dir, \"output_files\")\n        os.makedirs(output_files_dir, exist_ok=True)\n\n        # Run the module with the specified parameters\n        result = module(**params)\n\n        # Validate the result\n        result = validate_qa_dataset(result)\n\n        # Save the result to a file\n        result.to_csv(os.path.join(module_dir, \"result.csv\"), index=False)\n\n        # Save the result to a file in the output_files directory\n        result.to_csv(os.path.join(output_files_dir, \"result.csv\"), index=False)\n\n        # Measure the speed of the module\n        speed = measure_speed(module, params)\n\n        # Save the speed to a file\n        with open(os.path.join(module_dir, \"speed.txt\"), \"w\") as f:\n            f.write(str(speed))\n\n        # Save the speed to a file in the output_files directory\n        with open(os.path.join(output_files_dir, \"speed.txt\"), \"w\") as f:\n            f.write(str(speed))\n\n        # If the module is the first one to be executed or if it passes the speed threshold"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create directories for the node's output\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"output\"), exist_ok=True)\n    os.makedirs(os.path.join(node_line_dir, \"output\", \"best\"), exist_ok=True)\n\n    # Create a list of all possible combinations of modules and their parameters\n    all_combinations = make_combinations(modules, module_params)\n\n    # Initialize a list to store the results of each combination\n    all_results = []\n\n    # Initialize a list to store the execution times of each combination\n    all_times = []\n\n    # Initialize a list to store the evaluation metrics of each combination\n    all_metrics = []\n\n    # Initialize a variable to store the best result\n    best_result = None\n\n    # Initialize a variable to store the best execution time\n    best_time = None\n\n    # Initialize a variable to store the best evaluation metrics\n    best_metrics = None\n\n    # Iterate over all combinations\n    for i, combination in enumerate(all_combinations):\n        # Initialize a list to store the results of each module in the combination\n        combination_results = []\n\n        # Initialize a list to store the execution times of each module in the combination\n        combination_times = []\n\n        # Initialize a list to store the evaluation metrics of each module in the combination\n        combination_metrics = []\n\n        # Iterate over all modules in the combination\n        for module, params in combination:\n            # Run the module with the specified parameters and get the result\n            result, time = measure_speed(module, params, previous_result)\n\n            # Add the result to the list of results for the combination\n            combination_results.append(result)\n\n            # Add the execution time to the list of execution times for the combination\n            combination_times.append(time)\n\n            # If the module is a generator module, evaluate the result\n            if module.__name__ == \"generator\":\n                # Get the generator"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the directory for the node's output\n    node_dir = os.path.join(node_line_dir, \"prompt_maker\")\n    pathlib.Path(node_dir).mkdir(parents=True, exist_ok=True)\n\n    # Prepare the generator module for evaluation\n    generator_module = get_support_modules(modules, \"generator\")[0]\n    generator_params = module_params[modules.index(generator_module)]\n\n    # Prepare the strategies for selecting the best prompt maker module\n    metrics = strategies.get(\"metrics\", None)\n    speed_thresholds = strategies.get(\"speed_thresholds\", None)\n    generator_module_spec = strategies.get(\"generator_module_spec\", None)\n\n    # Create a list to store the results of each prompt maker module\n    results = []\n\n    # Iterate over each prompt maker module and its parameters\n    for module, params in zip(modules, module_params):\n\n        # Create the directory for the current prompt maker module's output\n        module_dir = os.path.join(node_dir, module.__name__)\n        pathlib.Path(module_dir).mkdir(parents=True, exist_ok=True)\n\n        # Run the current prompt maker module and get the output\n        result = module(**params)\n\n        # Evaluate the performance of the current prompt maker module\n        evaluation_result = evaluate_generation(result,\n                                                generator_module,\n                                                generator_params,\n                                                generator_module_spec,\n                                                metrics,\n                                                speed_thresholds,\n                                                module_dir)\n\n        # Add the evaluation result to the list of results\n        results.append(evaluation_result)\n\n    # Combine the results of all prompt maker modules\n    results = pd.concat(results)\n\n    # Select the best prompt maker module based on the specified strategies\n    best_result = select_best_average(results, strategies)\n\n    # Save the results of the best prompt maker module\n    best_result.to_csv(os.path.join(node_dir, \"best_result.csv\"), index=False"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create necessary directories\n    os.makedirs(node_line_dir, exist_ok=True)\n    os.makedirs(node_line_dir + '/results', exist_ok=True)\n    os.makedirs(node_line_dir + '/summary', exist_ok=True)\n\n    # Initialize the best_result variable\n    best_result = None\n\n    # Iterate over the prompt maker modules\n    for module, params in zip(modules, module_params):\n        # Create a directory for the current module\n        module_dir = node_line_dir + '/results/' + module.__name__.split('.')[-1]\n        os.makedirs(module_dir, exist_ok=True)\n\n        # Run the prompt maker module\n        result = module(**params)\n\n        # Save the prompt maker module's result\n        result.to_csv(module_dir + '/result.csv', index=False)\n\n        # Evaluate the prompt maker module's result\n        if strategies['evaluation']:\n            # Get the generator module from the strategies dictionary\n            generator_module = strategies['evaluation']['generator']\n\n            # Get the evaluation metrics from the strategies dictionary\n            metrics = strategies['evaluation']['metrics']\n\n            # Evaluate the prompt maker module's result using the generator module and evaluation metrics\n            evaluation_result = evaluate_generation(generator_module=generator_module,\n                                                   metrics=metrics,\n                                                   data=result)\n\n            # Save the evaluation result\n            evaluation_result.to_csv(module_dir + '/evaluation_result.csv', index=False)\n\n    # Select the best prompt maker module based on the specified strategies\n    best_result = select_best_prompt_maker(modules=modules,\n                                          node_line_dir=node_line_dir,\n                                          strategies=strategies)\n\n    # Combine the previous result with the best result\n    best_result = pd.concat([previous_result, best_result], axis=0)\n\n    # Save the best result\n    best_result.to_csv(node_line_dir +"}
{"namespace": "autorag.nodes.promptmaker.run.run_prompt_maker_node", "completion": "    # Create the node directory if it doesn't exist\n    if not os.path.exists(node_line_dir):\n        os.makedirs(node_line_dir)\n\n    # Initialize an empty dataframe to store the results\n    df = pd.DataFrame()\n\n    # Iterate through the modules and their corresponding parameters\n    for module, params in zip(modules, module_params):\n        # Get the name of the module\n        module_name = module.__name__.split('.')[-1]\n\n        # Create a directory for the module\n        module_dir = os.path.join(node_line_dir, module_name)\n        if not os.path.exists(module_dir):\n            os.makedirs(module_dir)\n\n        # Generate prompts using the current module\n        prompts = module(**params)\n\n        # Evaluate the generated prompts using the specified generator module\n        generator_module = strategies.get('generator_module', get_support_modules().get('generator').get('default'))\n        generator_module_params = strategies.get('generator_module_params', {})\n        generator_module_params['prompts'] = prompts\n        generator_module_params['save_dir'] = module_dir\n        generator_module(**generator_module_params)\n\n        # Evaluate the prompts using the specified metrics\n        metrics = strategies.get('metrics', {})\n        if metrics:\n            results = evaluate_generation(module_dir, metrics)\n            results['module'] = module_name\n            df = pd.concat([df, results], ignore_index=True)\n\n    # Measure the speed of the prompts\n    df = measure_speed(df)\n\n    # Filter the prompts based on the speed threshold\n    speed_threshold = strategies.get('speed_threshold', None)\n    if speed_threshold:\n        df = filter_by_threshold(df, 'speed', speed_threshold)\n\n    # Select the best prompt based on the specified metrics\n    best_prompt = select_best_average(df, strategies.get"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    values = list(map(lambda x: extract_values(x, key), nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_values_from_node(node: Node):\n        return extract_values(node, key)\n\n    values = list(map(extract_values_from_node, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_module_values(module: Module):\n        if key not in module.module_param:\n            return []\n        value = module.module_param[key]\n        if isinstance(value, str):\n            return [value]\n        elif isinstance(value, list):\n            return value\n        else:\n            raise ValueError(f\"{key} must be str or list, but got {type(value)}\")\n\n    values = list(map(extract_module_values, node.modules))\n    return list(set(list(itertools.chain.from_iterable(values))))\n\n"}
{"namespace": "autorag.schema.node.extract_values_from_nodes", "completion": "    def extract_values(node: Node):\n        if key not in node.node_params:\n            return []\n        value = node.node_params[key]\n        if isinstance(value, str):\n            return [value]\n        elif isinstance(value, list):\n            return value\n        else:\n            raise ValueError(f\"{key} must be str or list, but got {type(value)}\")\n\n    values = list(map(extract_values, nodes))\n    return list(set(list(itertools.chain.from_iterable(values))))"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    pred_embedding = embedding_model.get_query_embedding(pred)\n    gt_embeddings = list(map(lambda x: embedding_model.get_query_embedding(x), generation_gt))\n    return max(list(map(lambda x: calculate_cosine_similarity(pred_embedding, x), gt_embeddings)))"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    gt_embeddings = embedding_model.get_query_embedding(generation_gt)\n    pred_embedding = embedding_model.get_query_embedding([pred])\n    return calculate_cosine_similarity(gt_embeddings, pred_embedding)"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n    pred_embedding = embedding_model.get_text_embedding(pred)\n    gt_embeddings = list(map(embedding_model.get_text_embedding, generation_gt))\n    return max(list(map(lambda x: calculate_cosine_similarity(pred_embedding, x), gt_embeddings)))"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_model()\n\n    pred_embedding = embedding_model.get_text_embedding(pred)\n    gt_embeddings = list(map(embedding_model.get_text_embedding, generation_gt))\n\n    return max(list(map(lambda x: calculate_cosine_similarity(pred_embedding, x), gt_embeddings)))"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    # Convert the ground truth strings into embeddings\n    gt_embeddings = embedding_model.get_query_embedding(generation_gt)\n\n    # Convert the predicted string into an embedding\n    pred_embedding = embedding_model.get_query_embedding(pred)\n\n    # Calculate the cosine similarity between the predicted embedding and each ground truth embedding\n    similarities = calculate_cosine_similarity(pred_embedding, gt_embeddings)\n\n    # Find the maximum similarity score\n    max_similarity = max(similarities)\n\n    return max_similarity"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n    gt_embeddings = embedding_model.get_text_embedding(generation_gt)\n    pred_embedding = embedding_model.get_text_embedding([pred])\n    return calculate_cosine_similarity(pred_embedding, gt_embeddings)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_model()\n    return calculate_cosine_similarity(embedding_model, pred, generation_gt)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n    pred_embedding = embedding_model.get_text_embedding(pred)\n    gt_embeddings = list(map(lambda x: embedding_model.get_text_embedding(x), generation_gt))\n    return max(list(map(lambda x: calculate_cosine_similarity(pred_embedding, x), gt_embeddings)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_model()\n    pred_embedding = embedding_model.get_query_embedding(pred)\n    gt_embedding = embedding_model.get_query_embedding(gt[0])\n    return calculate_cosine_similarity(pred_embedding, gt_embedding)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_model()\n\n    gt_embeddings = embedding_model.get_text_embedding(generation_gt)\n    pred_embeddings = embedding_model.get_text_embedding([pred])\n    return calculate_cosine_similarity(gt_embeddings, pred_embeddings)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    gt_embeddings = embedding_model.get_query_embedding(generation_gt)\n    pred_embedding = embedding_model.get_query_embedding(pred)\n    return calculate_cosine_similarity(pred_embedding, gt_embeddings)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n    gt_embeddings = embedding_model.get_text_embedding(generation_gt)\n    pred_embedding = embedding_model.get_text_embedding([pred])\n    return calculate_cosine_similarity(gt_embeddings, pred_embedding)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    pred_embedding = embedding_model.get_text_embedding(pred)\n    gt_embeddings = list(map(embedding_model.get_text_embedding, generation_gt))\n    return max(list(map(lambda x: calculate_cosine_similarity(x, pred_embedding), gt_embeddings)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    gt_embeddings = embedding_model.get_text_embedding(generation_gt)\n    pred_embedding = embedding_model.get_text_embedding([pred])\n\n    return calculate_cosine_similarity(pred_embedding, gt_embeddings)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    gt_embeddings = embedding_model.get_text_embedding(generation_gt)\n    pred_embedding = embedding_model.get_text_embedding([pred])\n\n    return max(list(map(lambda x: calculate_cosine_similarity(pred_embedding, x), gt_embeddings)))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    gt_embeddings = embedding_model.get_query_embedding(generation_gt)\n    pred_embedding = embedding_model.get_query_embedding([pred])\n\n    return calculate_cosine_similarity(gt_embeddings, pred_embedding)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    gt_embeddings = embedding_model.get_query_embedding(generation_gt)\n    pred_embedding = embedding_model.get_query_embedding([pred])\n    return max(calculate_cosine_similarity(gt_embeddings, pred_embedding))\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n\n    gt_embeddings = embedding_model.get_text_embedding(generation_gt)\n    pred_embedding = embedding_model.get_text_embedding([pred])\n    return calculate_cosine_similarity(pred_embedding, gt_embeddings).max()\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_model_from_huggingface_hub(\n            model_id='sentence-transformers/all-mpnet-base-v2',\n            cache_dir=os.path.join(os.getcwd(), '.cache', 'embedding_model')\n        )\n    gt_embeddings = embedding_model.get_text_embedding(generation_gt)\n    pred_embedding = embedding_model.get_text_embedding([pred])\n    return calculate_cosine_similarity(gt_embeddings, pred_embedding)\n\n"}
{"namespace": "autorag.evaluate.metric.generation.sem_score", "completion": "    if embedding_model is None:\n        embedding_model = embedding_models.get_default_embedding_model()\n    pred_embedding = embedding_model.get_query_embedding(pred)\n    gt_embeddings = list(map(lambda x: embedding_model.get_query_embedding(x), generation_gt))\n    return max(list(map(lambda x: calculate_cosine_similarity(pred_embedding, x), gt_embeddings)))\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Skipping face restoration.\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(f\"GFPGAN face restoration failed: {e}\")\n        return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN is not set up. Skipping face restoration.\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.error(f\"GFPGAN face restoration failed: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if shared.opts.gfpgan_fix_faces:\n        if gfpgan_face_restorer is None:\n            logger.warning(\n                \"GFPGAN not found. Please check your installation. Skipping GFPGAN.\"\n            )\n            return np_image\n\n        try:\n            return gfpgan_face_restorer.restore(np_image)\n        except Exception as e:\n            logger.warning(f\"GFPGAN error: {e}\")\n            return np_image"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN face restorer is not set up. Skipping face restoration.\"\n        )\n        return np_image\n\n    try:\n        restored_img = gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError as e:\n        logger.warning(f\"GFPGAN face restoration failed: {e}\")\n        return np_image\n\n    return restored_img\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN not found. Face restoration is not available. Please install it from https://github.com/TencentARC/GFPGAN\"\n        )\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError as e:\n        logger.error(f\"GFPGAN Error: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN is not set up. Skipping face restoration.\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(f\"GFPGAN face restoration failed: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN face restorer is not set up. Skipping face restoration.\"\n        )\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.error(f\"GFPGAN face restoration failed: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN not loaded, cannot restore faces\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.error(f\"GFPGAN error: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN face restorer is not set up. Please check your configuration.\"\n        )\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError as e:\n        logger.warning(e)\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up. Skipping face restoration.\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError as e:\n        logger.warning(f\"GFPGAN face restorer failed: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN not found. Please download it from https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth and place it in the models folder.\"\n        )\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(f\"GFPGAN error: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN is not set up, so faces are not restored\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError:\n        logger.warning(\"GFPGAN could not restore faces in image\", exc_info=True)\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN not loaded, skipping GFPGAN face restoration\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.warning(f\"GFPGAN failed to restore face: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN face restorer not found. Please check your configuration.\"\n        )\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError as e:\n        logger.error(f\"GFPGAN face restoration failed: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN is not set up. Please set it up in settings to use face restoration.\"\n        )\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.error(f\"GFPGAN restore error: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up, skipping face restoration\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.error(f\"GFPGAN face restoration failed: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    if gfpgan_face_restorer is None:\n        logger.warning(\n            \"GFPGAN face restorer is not set up. Please check your settings and try again.\"\n        )\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except Exception as e:\n        logger.error(f\"GFPGAN face restorer failed to restore image: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN is not set up, cannot restore faces\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError:\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN face restorer is not set up, skipping\")\n        return np_image\n\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.RestorationError as e:\n        logger.warning(f\"GFPGAN face restorer failed: {e}\")\n        return np_image\n\n"}
{"namespace": "gfpgan_model.gfpgan_fix_faces", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        logger.warning(\"GFPGAN not available, skipping face restoration\")\n        return np_image\n    try:\n        return gfpgan_face_restorer.restore(np_image)\n    except errors.NoFaceFound:\n        logger.warning(\"GFPGAN: no face found, skipping face restoration\")\n        return np_image\n    except Exception as e:\n        logger.warning(f\"GFPGAN: face restoration failed: {e}\")\n        return np_image\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        face_restoration.face_restorers.append(codeformer)\n    except Exception as e:\n        errors.report(f\"Error setting up CodeFormer model: {e}\", exc_info=True)"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        face_restoration.face_restorers.append(codeformer)\n    except Exception:\n        errors.report(f\"Failed to set up CodeFormer in directory {dirname}\", exc_info=True)"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        face_restorers.append(FaceRestorerCodeFormer(dirname))\n    except Exception:\n        errors.report(f\"Failed to load CodeFormer in directory {dirname}\", exc_info=True)"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n    except Exception as e:\n        errors.report(f\"Failed to set up CodeFormer: {e}\", exc_info=True)\n        codeformer = None"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        face_restoration.face_restorers.append(codeformer)\n        logger.info(f\"Set up CodeFormer Face Restorer\")\n    except Exception as e:\n        errors.report(f\"Error setting up CodeFormer Face Restorer: {e}\", exc_info=True)"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        face_restoration.face_restorers.append(codeformer)\n    except Exception:\n        errors.report(\"Failed to set up CodeFormer model\", exc_info=True)"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        face_restorer = FaceRestorerCodeFormer(dirname)\n        face_restorer.load_weights()\n        face_restorer.to(face_restorer.get_device())\n        face_restorer.eval()\n        face_restorer.freeze()\n        face_restorers.append(face_restorer)\n    except Exception as e:\n        logger.error(f\"Error setting up model: {e}\")"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        codeformer.load_model()\n        codeformer.to(devices.device_codeformer)\n        face_restoration.face_restorers.append(codeformer)\n    except Exception as e:\n        errors.report(f\"Error setting up CodeFormer: {e}\", exc_info=True)"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n        face_restoration.face_restorers.append(codeformer)\n    except Exception as e:\n        errors.report(\n            f\"Error setting up the CodeFormer face restorer: {e}\",\n            exc_info=True,\n        )"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        face_restoration.face_restorers.append(codeformer)\n    except Exception:\n        errors.report(f\"Failed to load CodeFormer in directory {dirname}\", exc_info=True)\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        codeformer.load_weights()\n        codeformer.to(devices.device_codeformer)\n        face_restoration.face_restorers.append(codeformer)\n        logger.info(f\"CodeFormer: initialized.\")\n    except Exception as e:\n        errors.report(f\"CodeFormer setup error: {e}\", exc_info=True)"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n    try:\n        codeformer = FaceRestorerCodeFormer(dirname)\n        codeformer.net.to(devices.device_codeformer)\n        codeformer.net.eval()\n        face_restoration.face_restorers.append(codeformer)\n    except Exception as e:\n        errors.report(f\"Error setting up CodeFormer model: {e}\", exc_info=True)\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(\n            dirname,\n            model_filename=model_download_name,\n            upscale=1,\n            post_process_mask=True,\n        )\n        codeformer.to(devices.device_codeformer)\n        codeformer.eval()\n        codeformer.freeze()\n    except Exception as e:\n        errors.report(f\"Failed to initialize CodeFormer: {e}\", exc_info=True)"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        restorer = FaceRestorerCodeFormer(dirname)\n        face_restoration.face_restorers.append(restorer)\n    except Exception as e:\n        errors.report(\n            f\"Error setting up CodeFormer model: {e}\",\n            exc_info=True,\n        )\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    global codeformer\n\n    try:\n        codeformer = FaceRestorerCodeFormer(\n            dirname,\n            model_path=shared.cmd_opts.code_former_model_path,\n        )\n        codeformer.load_weights()\n        codeformer.to(codeformer.get_device())\n    except Exception as e:\n        logger.error(f\"Error setting up CodeFormer: {e}\")\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        global codeformer\n        codeformer = FaceRestorerCodeFormer(dirname)\n        face_restoration.face_restorers.append(codeformer)\n    except Exception as e:\n        errors.report(f\"Error setting up CodeFormer: {e}\", exc_info=True)\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        face_restorer = FaceRestorerCodeFormer(dirname)\n        face_restorer.load_weights()\n        face_restorer.to(face_restorer.get_device())\n        face_restorer.set_device(face_restorer.get_device())\n        face_restorer.set_max_batch_size(1)\n        face_restorer.set_max_tile_size(512)\n        face_restorer.set_max_tile_overlap(32)\n        face_restorer.set_pad_mod(0)\n        face_restorer.set_half(True)\n        face_restorer.set_face_size(512)\n        face_restorer.set_face_margin(0)\n        face_restorer.set_face_det_upsample(1)\n        face_restorer.set_face_align_upsample(1)\n        face_restorer.set_face_det_thresh(0.6)\n        face_restorer.set_face_align_thresh(0.6)\n        face_restorer.set_face_det_type('retinaface_resnet50')\n        face_restorer.set_face_align_type('ffhq_512')\n        face_restorer.set_face_align_device('cpu')\n        face_restorer.set_face_det_device('cpu')\n        face_restorer.set_face_det_backend('retinaface')\n        face_restorer.set_face_align_backend('arcface')\n        face_restorer.set_face_det_max_batch_size(1)\n        face_restorer.set_face_align_max_batch_size(1)\n        face_restorer.set_face_det_max_tile_size(512)\n        face_restorer.set_face_align_max_tile_size(512)\n        face_restorer.set_face_det_max_tile_overlap(32)\n       "}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        face_restorer = FaceRestorerCodeFormer(\n            dirname,\n            weight_path=f\"{dirname}/{model_download_name}\",\n            model_path=f\"{dirname}/{model_download_name}\",\n            net_name=\"CodeFormer\",\n        )\n        face_restorer.load_weight()\n        face_restorer.model.to(face_restorer.get_device())\n        face_restorer.model.eval()\n        face_restorer.face_detector = None\n        face_restorer.face_gfpgan = None\n        face_restorer.gfpgan = None\n        face_restorer.upscale = None\n        face_restorer.face_restorer = None\n        face_restorer.inpaint = None\n        face_restorer.device = face_restorer.get_device()\n        face_restorer.half = False\n        face_restorer.model_name = \"CodeFormer\"\n        face_restorer.model_size = \"CodeFormer\"\n        face_restorer.model_steps = 0\n        face_restorer.model_aspect_ratio = 1\n        face_restorer.model_dim = 512\n        face_restorer.model_scale = 1\n        face_restorer.model_type = \"CodeFormer\"\n        face_restorer.model_gfloss = False\n        face_restorer.model_arch = \"CodeFormer\"\n        face_restorer.model_alpha = False\n        face_restorer.model_gfpgan_arch = \"CodeFormer\"\n        face_restorer.model_channel = 3\n        face_restorer.model_gfpgan_channel = 3\n        face_restorer.model_precision = \"fp32\"\n        face_restorer.model_variant = \"CodeFormer\"\n        face_restorer.model_suffix = \"CodeFormer\"\n        face_restorer.model_esrgan_arch = \"CodeFormer\"\n        face_restorer.model_esrgan_channel = 3"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        face_restorer = FaceRestorerCodeFormer(dirname)\n        face_restorer.load_net()\n        face_restorer.to(face_restorer.get_device())\n        face_restorers.append(face_restorer)\n    except Exception as e:\n        errors.report(f\"Error setting up CodeFormer: {e}\", exc_info=True)\n\n"}
{"namespace": "codeformer_model.setup_model", "completion": "    try:\n        face_restorer = FaceRestorerCodeFormer(dirname)\n        face_restorer.load_net()\n        face_restorer.to(face_restorer.get_device())\n        face_restorers.append(face_restorer)\n        logger.info(f\"Face restorer {face_restorer.name()} setup\")\n    except Exception as e:\n        errors.report(f\"Failed to setup face restorer {face_restorer.name()}: {e}\", exc_info=True)\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            dirname,\n            force_cpu=shared.cmd_opts.gfpgan_cpu,\n            force_gpu=shared.cmd_opts.gfpgan_gpu,\n        )\n    except Exception as e:\n        errors.display(e, f\"Error setting up GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        logger.error(f\"GFPGAN setup failed: {e}\")\n        raise errors.InitError(e)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=dirname,\n            upscale=shared.opts.gfpgan_upscale,\n            arch=\"clean\",\n            channel_multiplier=2,\n            bg_upsampler=shared.opts.gfpgan_bg_upsampler,\n        )\n    except Exception:\n        errors.report(\n            \"GFPGAN model failed to initialize\",\n            exc_info=True,\n        )"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        if not gfpgan_face_restorer:\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                dirname,\n                verbose=shared.opts.gfpgan_verbose,\n            )\n    except Exception as e:\n        errors.report(f\"GFPGAN setup failed: {e}\", exc_info=True)\n        gfpgan_face_restorer = None"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        errors.display(e, f\"Error loading GFPGAN model from {dirname}\")\n        logger.warning(\"GFPGAN model not loaded\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=dirname,\n            upscale=shared.opts.gfpgan_upscale,\n            bg_upsampler=shared.opts.gfpgan_bg_upsampler,\n            upscale_order=shared.opts.gfpgan_upscale_order,\n            arch=shared.opts.gfpgan_arch,\n            channel_multiplier=shared.opts.gfpgan_channel_multiplier,\n            bg_tile=shared.opts.gfpgan_bg_tile,\n        )\n        gfpgan_face_restorer.face_restorer = FaceRestorerGFPGAN(\n            model_path=dirname,\n            upscale=shared.opts.gfpgan_upscale,\n            bg_upsampler=shared.opts.gfpgan_bg_upsampler,\n            upscale_order=shared.opts.gfpgan_upscale_order,\n            arch=shared.opts.gfpgan_arch,\n            channel_multiplier=shared.opts.gfpgan_channel_multiplier,\n            bg_tile=shared.opts.gfpgan_bg_tile,\n        )\n        gfpgan_face_restorer.face_restorer.face_restorer = FaceRestorerGFPGAN(\n            model_path=dirname,\n            upscale=shared.opts.gfpgan_upscale,\n            bg_upsampler=shared.opts.gfpgan_bg_upsampler,\n            upscale_order=shared.opts.gfpgan_upscale_order,\n            arch=shared.opts.gfpgan_arch,\n            channel_multiplier=shared.opts.gfpgan_channel_multiplier,\n            bg_tile=shared.opts.gfpgan_bg_tile,\n        )\n        gfpgan_face_restorer.face_restorer.face_restorer.face_restorer = FaceRestorerGFPGAN(\n            model_"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        face_restoration_utils.patch_facexlib(dirname)\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        logger.exception(f\"GFPGAN setup failed: {e}\")\n        errors.display(e, f\"GFPGAN setup failed: {e}\")\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            dirname,\n            model_filename=model_download_name,\n            upscale=1,\n            arch='clean',\n            channel_multiplier=2,\n            bg_upsampler=None,\n        )\n        gfpgan_face_restorer.load_weights(model_download_name)\n        gfpgan_face_restorer.to(devices.device_gfpgan)\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN: {e}\")\n        errors.display(e, f\"Error setting up GFPGAN: {e}\")\n        shared.state.error = e\n        shared.state.error_traceback = traceback.format_exc()\n        shared.state.do_reload_models = True"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        facexlib_path = os.path.join(dirname, \"facexlib\")\n        if os.path.exists(facexlib_path):\n            logger.info(\"Patching facexlib\")\n            face_restoration_utils.patch_facexlib(facexlib_path)\n        else:\n            logger.info(\"Facexlib not found\")\n\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN: {e}\")\n        errors.report(f\"Error setting up GFPGAN: {e}\", exec_info=e)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        face_restoration.facexlib.utils.download_unzip(model_url, dirname)\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(dirname)\n        gfpgan_face_restorer.load_weights(model_download_name)\n        gfpgan_face_restorer.model_name = model_download_name\n        gfpgan_face_restorer.model_path = os.path.join(dirname, model_download_name)\n    except Exception as e:\n        logger.error(f\"GFPGAN setup failed: {e}\")\n        raise errors.InitError(f\"GFPGAN setup failed: {e}\") from e"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            dirname,\n            verbose=False,\n            weight=4,\n            threshold=0.5,\n            margin=32,\n            mask_threshold=0.5,\n            only_center_face=False,\n            paste_back=True,\n            bg_upsampler=None,\n        )\n    except Exception as e:\n        logger.exception(e)\n        errors.display(e, \"Error setting up GFPGAN\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    try:\n        facexlib_model_path = os.path.join(dirname, model_download_name)\n        if not os.path.exists(facexlib_model_path):\n            return\n\n        facexlib_model_path = os.path.abspath(facexlib_model_path)\n        modelloader.patch_facexlib(facexlib_model_path)\n        global gfpgan_face_restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(facexlib_model_path)\n        gfpgan_face_restorer.restore_force_cpu = shared.opts.gfpgan_cpu\n    except Exception as e:\n        errors.report(f\"GFPGAN setup error: {e}\", exc_info=True)"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            facexlib_path = os.path.join(dirname, 'facexlib')\n            if not os.path.exists(facexlib_path):\n                os.makedirs(facexlib_path)\n            facexlib_model_path = os.path.join(facexlib_path, 'model.py')\n            if not os.path.exists(facexlib_model_path):\n                shutil.copy(os.path.join(dirname, 'model.py'), facexlib_model_path)\n            import facexlib\n            facexlib.init(facexlib_path)\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                model_path=os.path.join(dirname, model_download_name),\n                upscale=shared.opts.gfpgan_upscale,\n                arch='clean',\n                channel_multiplier=shared.opts.gfpgan_channel_multiplier,\n                bg_upsampler=shared.opts.gfpgan_bg_upsampler,\n            )\n        except Exception as e:\n            logger.error(f\"GFPGAN setup failed: {e}\")\n            errors.display(e, \"GFPGAN setup failed\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        facexlib_dir = os.path.join(dirname, 'facexlib')\n        if not os.path.exists(facexlib_dir):\n            os.mkdir(facexlib_dir)\n        facexlib_model_dir = os.path.join(facexlib_dir, 'weights')\n        if not os.path.exists(facexlib_model_dir):\n            os.mkdir(facexlib_model_dir)\n        for file in os.listdir(dirname):\n            if file.endswith(\".pth\"):\n                shutil.copy(os.path.join(dirname, file), facexlib_model_dir)\n\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=facexlib_model_dir,\n            upscale=1,\n            arch='clean',\n            channel_multiplier=2,\n            bg_upsampler=None,\n        )\n        gfpgan_face_restorer.net.eval()\n    except Exception as e:\n        logger.exception(e)\n        raise errors.InitError(f\"Error initializing GFPGAN face restorer: {e}\")"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        facexlib_model_path = os.path.join(dirname, \"GFPGANv1.4.pth\")\n        facexlib_model_name = os.path.basename(facexlib_model_path)\n        facexlib_model_dir = os.path.dirname(facexlib_model_path)\n\n        # patch facexlib with the given directory\n        face_restoration_utils.patch_facexlib_with_model_dir(facexlib_model_dir)\n\n        # initialize the GFPGAN face restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            facexlib_model_name,\n            facexlib_model_dir,\n            facexlib_model_path,\n        )\n        gfpgan_face_restorer.load_weights()\n        gfpgan_face_restorer.to(devices.device_gfpgan)\n\n        logger.info(\"GFPGAN face restorer initialized\")\n    except Exception as e:\n        logger.error(f\"GFPGAN face restorer initialization failed: {e}\")\n        raise errors.InitError(\n            f\"GFPGAN face restorer initialization failed: {e}\",\n            extra=dict(model_path=facexlib_model_path),\n        ) from e"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        facexlib_dir = os.path.join(dirname, \"facexlib\")\n        facexlib_model_path = os.path.join(facexlib_dir, \"weights\")\n        facexlib_model_url = \"https://github.com/xinntao/facexlib/releases/download/v0.2.5/facexlib_model.zip\"\n        facexlib_model_download_name = \"facexlib_model.zip\"\n\n        # Patch facexlib\n        if not os.path.exists(facexlib_model_path):\n            os.makedirs(facexlib_model_path)\n\n        modelloader.load_models(\n            model_path=facexlib_model_path,\n            model_url=facexlib_model_url,\n            command_path=dirname,\n            download_name=facexlib_model_download_name,\n            ext_filter=[\".pth\"],\n        )\n\n        # Initialize GFPGAN face restorer\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=dirname,\n            upscale=1,\n            arch=\"clean\",\n            channel_multiplier=2,\n            bg_upsampler=None,\n        )\n\n        logger.info(\"GFPGAN face restorer set up\")\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN face restorer: {e}\")\n        raise errors.InitError(\n            f\"Error setting up GFPGAN face restorer: {e}\",\n            extra_tags={\"exception\": e},\n        ) from e\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        facexlib_dir = os.path.join(dirname, \"facexlib\")\n        if os.path.exists(facexlib_dir):\n            facexlib_dir = os.path.abspath(facexlib_dir)\n            sys.path.append(facexlib_dir)\n        else:\n            logger.error(f\"GFPGAN: facexlib not found in {facexlib_dir}\")\n            return\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=dirname,\n            upscale=shared.opts.gfpgan_upscale,\n            bg_upsampler_name=shared.opts.gfpgan_bg_upsampler,\n            bg_tile=shared.opts.gfpgan_bg_tile,\n            upscale_order=shared.opts.gfpgan_upscale_order,\n            face_size=shared.opts.gfpgan_face_size,\n            crop_expand=shared.opts.gfpgan_crop_expand,\n            strength=shared.opts.gfpgan_strength,\n        )\n        gfpgan_face_restorer.load_weights()\n    except Exception as e:\n        logger.error(f\"GFPGAN: Error setting up model: {e}\")\n        gfpgan_face_restorer = None\n\n"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n\n    try:\n        facexlib_dir = os.path.join(dirname, \"facexlib\")\n        if os.path.exists(facexlib_dir):\n            # patch facexlib\n            facexlib_gfpgan_path = os.path.join(facexlib_dir, \"gfpgan\")\n            if not os.path.exists(facexlib_gfpgan_path):\n                os.makedirs(facexlib_gfpgan_path)\n\n            for file in os.listdir(os.path.join(dirname, \"gfpgan\")):\n                if os.path.isfile(os.path.join(dirname, \"gfpgan\", file)):\n                    shutil.copy(\n                        os.path.join(dirname, \"gfpgan\", file), facexlib_gfpgan_path\n                    )\n\n        if not os.path.exists(os.path.join(dirname, \"GFPGANv1.4.pth\")):\n            # download GFPGANv1.4.pth\n            url = \"https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\"\n            model_path = os.path.join(dirname, \"GFPGANv1.4.pth\")\n            logger.info(f\"Downloading GFPGAN model to: {model_path}\")\n            torch.hub.download_url_to_file(url, model_path)\n\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=model_path,\n            upscale=1,\n            arch=\"clean\",\n            channel_multiplier=2,\n            bg_upsampler=None,\n        )\n        gfpgan_face_restorer.model_name = \"GFPGAN\"\n    except Exception as e:\n        logger.error(f\"Error setting up GFPGAN: {e}\")\n        raise errors.Init"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    if gfpgan_face_restorer is None:\n        try:\n            facexlib_path = shared.cmd_opts.facexlib_path\n            if facexlib_path is None:\n                facexlib_path = os.path.join(\n                    shared.cmd_opts.root_dir, \"facexlib\"\n                )\n            facexlib_path = os.path.abspath(facexlib_path)\n            if not os.path.exists(facexlib_path):\n                raise ValueError(\n                    f\"facexlib_path {facexlib_path} does not exist\"\n                )\n            facexlib_path = os.path.abspath(facexlib_path)\n            if os.path.exists(facexlib_path):\n                from facexlib.utils.face_restoration_helper import (\n                    FaceRestoreHelper,\n                )\n\n                FaceRestoreHelper.face_restore_helper.face_restorers[\n                    \"GFPGAN\"\n                ] = FaceRestoreHelper.FaceRestoreHelper(\n                    name=\"GFPGAN\",\n                    model_dir=dirname,\n                    model_config=None,\n                    model=None,\n                    device=devices.device_gfpgan.type,\n                    face_size=512,\n                    crop_ratio=(1, 1),\n                    paste_back=False,\n                    pre_resize=1,\n                )\n            gfpgan_face_restorer = FaceRestorerGFPGAN(\n                dirname,\n                gfpgan_model_path=os.path.join(\n                    dirname, model_download_name\n                ),\n            )\n        except Exception as e:\n            logger.exception(e)\n            errors.display(\n                e,\n                \"GFPGAN face restorer setup failed. You may need to restart the program.\",\n            )"}
{"namespace": "gfpgan_model.setup_model", "completion": "    global gfpgan_face_restorer\n    try:\n        facexlib_path = os.path.join(dirname, \"GFPGAN\", \"facexlib\")\n        if not os.path.exists(facexlib_path):\n            logger.warning(\n                f\"GFPGAN: facexlib not found at {facexlib_path}, skipping GFPGAN setup\"\n            )\n            return\n        facexlib_path = Path(facexlib_path)\n        face_restoration.facexlib.face_detect.weights_dir = facexlib_path\n        face_restoration.facexlib.model_zoo.weights_dir = facexlib_path\n        face_restoration.facexlib.detection.weights_dir = facexlib_path\n        face_restoration.facexlib.parsing.weights_dir = facexlib_path\n        face_restoration.facexlib.weights_dir = facexlib_path\n        gfpgan_face_restorer = FaceRestorerGFPGAN(\n            model_path=os.path.join(dirname, \"GFPGAN\", \"GFPGANv1.4.pth\"),\n            upscale=1,\n            arch=\"clean\",\n            channel_multiplier=2,\n            bg_upsampler=None,\n        )\n        gfpgan_face_restorer.load_net()\n        gfpgan_face_restorer.to(devices.device_gfpgan)\n    except Exception as e:\n        logger.error(\"GFPGAN setup failed\", exc_info=e)\n        raise errors.Error(\n            f\"GFPGAN setup failed: {e}.\\n\\nYou may try the following to fix this:\\n\\n\"\n            f\"1. Update the graphics drivers for your GPU.\\n\\n\"\n            f\"2. Try running the extension again.\\n\\n\"\n            f\"3. If the problem persists, try installing the extension again.\\n\\n\"\n            f\"4. If the problem persists, try installing the extension in administrator mode.\\n\\"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format with zero real part\n  v_quat = jnp.concatenate([v, jnp.zeros_like(re(q))], axis=-1)\n\n  # Apply the rotation using quaternion multiplication\n  rotated_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Extract the rotated vector from the rotated quaternion\n  rotated_v = im(rotated_quat)\n\n  return rotated_v"}
{"namespace": "quaternion.rotate", "completion": "  v_quat = jnp.concatenate([v, jnp.zeros_like(re(q))], axis=-1)\n  q_inv = inverse(q)\n  rotated_v_quat = multiply(multiply(q, v_quat), q_inv)\n  return im(rotated_v_quat)"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(v[Ellipsis, :1])], axis=-1)\n  q_inv = inverse(q)\n  q_v = multiply(q, v)\n  q_v = multiply(q_v, q_inv)\n  return im(q_v)"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(re(q))], axis=-1)\n  q_inv = inverse(q)\n  return im(multiply(multiply(q, v), q_inv))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(re(v))], axis=-1)\n  return im(multiply(multiply(q, v), conjugate(q)))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(re(v))], axis=-1)\n  return im(multiply(multiply(q, v), conjugate(q)))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(re(v))], axis=-1)\n  return im(multiply(multiply(q, v), conjugate(q)))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(re(v))], axis=-1)\n  return im(multiply(multiply(q, v), conjugate(q)))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(re(q))], axis=-1)\n  return im(multiply(multiply(q, v), conjugate(q)))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion format with zero real part\n  v_quat = jnp.concatenate([v, jnp.zeros_like(re(v))], axis=-1)\n\n  # Apply the quaternion rotation to the vector\n  rotated_v_quat = multiply(q, v_quat)\n  rotated_v_quat = multiply(rotated_v_quat, conjugate(q))\n\n  # Extract the rotated vector from the rotated quaternion\n  rotated_v = im(rotated_v_quat)\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(re(v))], axis=-1)\n  return im(multiply(multiply(q, v), conjugate(q)))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion with zero real part\n  v_quat = jnp.concatenate([v, jnp.zeros_like(v[Ellipsis, :1])], axis=-1)\n\n  # Compute the rotated vector by applying the quaternion rotation\n  rotated_v_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Extract the rotated vector from the rotated quaternion\n  rotated_v = im(rotated_v_quat)\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  # Convert the vector to a quaternion with zero real component\n  v_quat = jnp.concatenate([v, jnp.zeros_like(re(v))], axis=-1)\n\n  # Apply the rotation using quaternion multiplication\n  rotated_quat = multiply(multiply(q, v_quat), conjugate(q))\n\n  # Extract the rotated vector component from the rotated quaternion\n  rotated_v = im(rotated_quat)\n\n  return rotated_v\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(re(q))], axis=-1)\n  v = multiply(q, v)\n  v = multiply(v, conjugate(q))\n  return im(v)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(re(q))], axis=-1)\n  return im(multiply(multiply(q, v), conjugate(q)))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(re(v))], axis=-1)\n  return im(multiply(multiply(q, v), conjugate(q)))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(v[Ellipsis, :1])], axis=-1)\n  return im(multiply(multiply(q, v), conjugate(q)))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(re(v))], axis=-1)\n  q_inv = inverse(q)\n  return im(multiply(multiply(q, v), q_inv))\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(re(q))], axis=-1)\n  v = multiply(multiply(q, v), conjugate(q))\n  return im(v)\n\n"}
{"namespace": "quaternion.rotate", "completion": "  v = jnp.concatenate([v, jnp.zeros_like(re(v))], axis=-1)\n  q_inv = conjugate(q)\n  return im(multiply(multiply(q, v), q_inv))\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis, angle = axis_angle[Ellipsis, :3], axis_angle[Ellipsis, 3:]\n  return jnp.concatenate(\n      [\n          axis\n          * jnp.sin(angle * 0.5)\n          / jnp.maximum(\n              _safe_sqrt(jnp.sum(axis**2, axis=-1, keepdims=True)),\n              eps * jnp.ones_like(angle),\n          ),\n          jnp.cos(angle * 0.5),\n      ],\n      axis=-1,\n  )"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector\n  axis_angle = axis_angle / jnp.linalg.norm(axis_angle)\n\n  # Extract the angle and axis from the axis-angle vector\n  angle = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n\n  # Calculate the quaternion components\n  w = jnp.cos(angle / 2)\n  x, y, z = axis * jnp.sin(angle / 2)\n\n  # Return the quaternion\n  return jnp.array([x, y, z, w])"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle, jnp.float32)\n  axis_angle = axis_angle / jnp.linalg.norm(axis_angle, axis=-1, keepdims=True)\n  axis_angle = axis_angle * jnp.sin(jnp.linalg.norm(axis_angle, axis=-1, keepdims=True) / 2.0)\n  return jnp.concatenate([axis_angle, jnp.cos(jnp.linalg.norm(axis_angle, axis=-1, keepdims=True) / 2.0)], axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle, dtype=jnp.float32)\n  assert axis_angle.shape[-1] == 3\n  theta = linalg.norm(axis_angle, axis=-1, keepdims=True)\n  w = jnp.cos(theta / 2)\n  xyz = jnp.sin(theta / 2) * axis_angle / (theta + eps)\n  return jnp.concatenate([xyz, w], axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.array(axis_angle)\n  axis = axis_angle[Ellipsis, :3]\n  angle = axis_angle[Ellipsis, 3:]\n  squared_norm = jnp.sum(axis * axis, axis=-1, keepdims=True)\n  safe_norm = jnp.sqrt(squared_norm + eps)\n  scale = jnp.sin(0.5 * angle) / safe_norm\n  w = jnp.cos(0.5 * angle)\n  xyz = axis * scale\n  return jnp.concatenate((xyz, w), axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis, angle = axis_angle[Ellipsis, :3], axis_angle[Ellipsis, 3:]\n  axis_norm = jnp.linalg.norm(axis, axis=-1, keepdims=True)\n  half_angle = 0.5 * angle\n  axis_normalized = axis / jnp.maximum(axis_norm, eps * jnp.ones_like(axis_norm))\n  return jnp.concatenate(\n      [\n          axis_normalized * jnp.sin(half_angle),\n          jnp.cos(half_angle),\n      ],\n      axis=-1,\n  )"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector\n  axis_angle_norm = jnp.linalg.norm(axis_angle, axis=-1, keepdims=True)\n  axis_angle_normalized = axis_angle / (axis_angle_norm + eps)\n\n  # Calculate the angle of rotation\n  angle = axis_angle_norm[..., 0]\n\n  # Calculate the quaternion components\n  q_w = jnp.cos(angle / 2)\n  q_xyz = jnp.sin(angle / 2) * axis_angle_normalized\n\n  # Concatenate the quaternion components\n  quaternion = jnp.concatenate((q_xyz, q_w[..., jnp.newaxis]), axis=-1)\n\n  return quaternion"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector to ensure numerical stability\n  axis_angle = axis_angle / jnp.linalg.norm(axis_angle, axis=-1, keepdims=True)\n\n  # Extract the angle and axis from the axis-angle vector\n  angle = jnp.linalg.norm(axis_angle, axis=-1, keepdims=True)\n  axis = axis_angle / (angle + eps)\n\n  # Calculate the quaternion components using the axis-angle formula\n  w = jnp.cos(angle / 2)\n  xyz = jnp.sin(angle / 2) * axis\n\n  # Concatenate the quaternion components into a single array\n  q = jnp.concatenate([xyz, w], axis=-1)\n\n  # Return the quaternion\n  return q"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis of rotation\n  axis = axis_angle / jnp.linalg.norm(axis_angle, axis=-1, keepdims=True)\n\n  # Calculate the angle of rotation\n  angle = jnp.linalg.norm(axis_angle, axis=-1, keepdims=True)\n\n  # Handle small angles using the small epsilon value\n  small_angles = angle < eps\n  sin_half_angle = jnp.sin(0.5 * angle)\n  cos_half_angle = jnp.cos(0.5 * angle)\n  sin_half_angle[small_angles] = jnp.sin(0.5 * eps)\n  cos_half_angle[small_angles] = jnp.cos(0.5 * eps)\n\n  # Construct the quaternion\n  q = jnp.concatenate([\n      axis * sin_half_angle,\n      cos_half_angle\n  ], axis=-1)\n\n  return q"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis, angle = axis_angle[Ellipsis, :3], axis_angle[Ellipsis, 3:]\n  # The quaternion for the zero rotation.\n  q0 = jnp.array([0.0, 0.0, 0.0, 1.0])\n\n  # If the angle is close to zero, return the quaternion for the zero rotation.\n  if jnp.allclose(angle, 0.0, atol=eps):\n    return q0\n\n  # Normalize the axis of rotation.\n  axis = axis / linalg.norm(axis, axis=-1, keepdims=True)\n\n  # Compute the quaternion components.\n  half_angle = 0.5 * angle\n  w = jnp.cos(half_angle)\n  xyz = axis * jnp.sin(half_angle)\n\n  # Concatenate the quaternion components.\n  return jnp.concatenate([xyz, w], axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Extract the axis and angle from the input axis-angle vector\n  axis = axis_angle[Ellipsis, :3]\n  angle = axis_angle[Ellipsis, 3:]\n\n  # Compute the magnitude of the axis\n  axis_norm = linalg.norm(axis, axis=-1, keepdims=True)\n\n  # Compute the rotation angle using the safe_acos function\n  angle = spin_math.safe_acos(angle)\n\n  # Compute the quaternion components using the safe_sin and safe_cos functions\n  w = spin_math.safe_cos(0.5 * angle)\n  xyz = spin_math.safe_sin(0.5 * angle) * axis / (axis_norm + eps)\n\n  # Concatenate the quaternion components and return the quaternion\n  return jnp.concatenate([xyz, w], axis=-1)"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle, jnp.float32)\n  axis_angle_norm = jnp.linalg.norm(axis_angle, axis=-1, keepdims=True)\n  axis = axis_angle / axis_angle_norm\n  angle = axis_angle_norm\n  w = jnp.cos(angle / 2.0)\n  xyz = jnp.sin(angle / 2.0) * axis\n  q = jnp.concatenate([xyz, w], axis=-1)\n  return q / (jnp.linalg.norm(q, axis=-1, keepdims=True) + eps)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis, angle = axis_angle[Ellipsis, :3], axis_angle[Ellipsis, 3:]\n  s = jnp.sin(angle / 2.0)\n  c = jnp.cos(angle / 2.0)\n  axis_norm = linalg.norm(axis, axis=-1, keepdims=True)\n  axis_normalized = axis / jnp.maximum(axis_norm, eps * jnp.ones_like(axis_norm))\n  return jnp.concatenate([axis_normalized * s, c], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  # Normalize the axis-angle vector\n  axis_angle_norm = linalg.norm(axis_angle, axis=-1, keepdims=True)\n  axis = axis_angle / (axis_angle_norm + eps)\n\n  # Compute the angle of rotation\n  angle = axis_angle_norm[..., 0]\n\n  # Compute the quaternion components\n  w = jnp.cos(0.5 * angle)\n  xyz = jnp.sin(0.5 * angle) * axis\n  q = jnp.concatenate([xyz, w[..., None]], axis=-1)\n\n  # Normalize the quaternion\n  return normalize(q)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle, dtype=jnp.float32)\n  axis_angle = axis_angle / jnp.linalg.norm(axis_angle, axis=-1, keepdims=True)\n  axis_angle = axis_angle * jnp.sin(jnp.linalg.norm(axis_angle, axis=-1, keepdims=True) / 2)\n  w = jnp.cos(jnp.linalg.norm(axis_angle, axis=-1, keepdims=True) / 2)\n  q = jnp.concatenate([axis_angle, w], axis=-1)\n  return q / (eps + jnp.linalg.norm(q, axis=-1, keepdims=True))\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle, dtype=jnp.float32)\n  axis_angle = axis_angle / jnp.linalg.norm(axis_angle, axis=-1, keepdims=True)\n  half_angle = jnp.linalg.norm(axis_angle, axis=-1, keepdims=True) / 2.0\n  w = jnp.cos(half_angle)\n  xyz = jnp.sin(half_angle) * axis_angle\n  return jnp.concatenate([xyz, w], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.asarray(axis_angle)\n  if len(axis_angle.shape) == 1:\n    axis_angle = jnp.expand_dims(axis_angle, axis=0)\n  axis_angle_norm = jnp.linalg.norm(axis_angle, axis=-1)\n  axis = axis_angle / jnp.expand_dims(axis_angle_norm, axis=-1)\n  angle = axis_angle_norm\n  w = jnp.cos(angle / 2.0)\n  xyz = jnp.sin(angle / 2.0) * axis\n  wxyz = jnp.concatenate((w[..., jnp.newaxis], xyz), axis=-1)\n  wxyz = jnp.where(\n      jnp.expand_dims(axis_angle_norm < eps, axis=-1),\n      jnp.array([1.0, 0.0, 0.0, 0.0]),\n      wxyz,\n  )\n  return wxyz\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis, angle = axis_angle[Ellipsis, :3], axis_angle[Ellipsis, 3:]\n  n = linalg.norm(axis, axis=-1, keepdims=True)\n  half_angle = angle * 0.5\n  q = jnp.concatenate([axis / (n + eps) * jnp.sin(half_angle), jnp.cos(half_angle)], axis=-1)\n  return q / norm(q)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.array(axis_angle)\n  norm = jnp.linalg.norm(axis_angle)\n  w = jnp.where(norm < eps, 1.0, jnp.cos(norm / 2.0))\n  xyz = jnp.where(norm < eps, axis_angle, axis_angle / norm * jnp.sin(norm / 2.0))\n  return jnp.concatenate([xyz, w[Ellipsis, None]], axis=-1)\n\n"}
{"namespace": "quaternion.from_axis_angle", "completion": "  axis_angle = jnp.array(axis_angle)\n  angle = linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n  q = jnp.concatenate([\n      axis * jnp.sin(angle / 2.0),\n      jnp.cos(angle / 2.0),\n  ], axis=-1)\n  return q\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words = model.topk(prefix, k)\n    if idx in topk_words:\n        return 0, 1\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return -mid, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    topk_words = model.topk(prefix, k=k)\n    topk_idxs = [i for i, _ in topk_words]\n\n    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words = model.topk(prefix, k)\n    if idx in topk_words:\n        return 0, 1\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return -mid, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words = model.topk(prefix, k=k)\n    topk_indices = list(topk_words.keys())\n    topk_logprobs = list(topk_words.values())\n\n    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words = model.topk(prefix, k=k)\n    if idx in topk_words:\n        return 0, 1\n    else:\n        if high == 0:\n            raise TypeError(\n                f\"Token {idx} not in top-k with bias {high}.\"\n                \"Either increase bias or provide top unbiased logprob (top_logprob)\"\n            )\n        success_idxs = list(i for i in idx if i in topk_words)\n        fail_idxs = set(idx) - set(topk_words)\n        biased_top_logprob = max(\n            logprob for i, logprob in topk_words.items() if i not in idx\n        )\n        biased_logprobs = np.array([topk_words[i] for i in success_idxs])\n        logprobs = biased_logprobs - biased_top_logprob + top_logprob - bias\n        return dict(zip(success_idxs, logprobs)), fail_idxs, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    topk_words = model.topk(prefix, k)\n    topk_indices = [model.tokenizer.encode(word)[0] for word in topk_words]\n\n    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words = model.topk(prefix, k)\n    if idx in topk_words:\n        return 0, 1\n    if k > 1:\n        raise ValueError(\"k > 1 not supported yet\")\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n\n    return -mid, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words = model.topk(prefix, k=k)\n    if idx in topk_words:\n        return -topk_words[idx], k\n    else:\n        low = -topk_words[idx]\n        high = high\n        mid = (high + low) / 2\n        while high >= low + 1e-8:\n            logit_bias = {idx: mid}\n            if model.argmax(prefix, logit_bias) == idx:\n                high = mid\n            else:\n                low = mid\n            mid = (high + low) / 2\n        return -mid, k\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    topk_words = model.topk(prefix, k=k)\n    topk_idxs = [i for i, _ in topk_words]\n\n    # check if idx is the argmax\n    num_calls = k\n    if idx in topk_idxs:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while idx not in topk_idxs:\n        logit_bias[idx] *= 2\n        topk_words = model.topk(prefix, logit_bias, k=k)\n        topk_idxs = [i for i, _ in topk_words]\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        topk_words = model.topk(prefix, logit_bias, k=k)\n        topk_idxs = [i for i, _ in topk_words]\n        if idx in topk_idxs:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words, topk_indices, _ = model.topk(prefix, k=k)\n    if idx in topk_indices:\n        return 0, 1\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        k += 1\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return -mid, k\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    logit_bias = {idx: high}\n    topk_words = model.topk(prefix, logit_bias)\n    if idx in topk_words:\n        return 0, k\n\n    # initialize high\n    while idx not in topk_words:\n        logit_bias[idx] *= 2\n        topk_words = model.topk(prefix, logit_bias)\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if idx in topk_words:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n    return -mid, k\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # check if idx is the argmax\n    num_calls = k\n    if model.argmax(prefix) == idx:\n        return 0, num_calls\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n        num_calls += k\n    high = logit_bias[idx]\n\n    # improve estimate\n    mid = (high + low) / 2\n    while high >= low + eps:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n        num_calls += k\n    return -mid, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words = model.topk(prefix, k=k)\n    topk_idxs = [i for i, _ in topk_words]\n    if idx in topk_idxs:\n        return 0, k\n\n    # initialize high\n    logit_bias = {idx: high}\n    while idx not in topk_idxs:\n        logit_bias[idx] *= 2\n        topk_words = model.topk(prefix, logit_bias, k=k)\n        topk_idxs = [i for i, _ in topk_words]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        topk_words = model.topk(prefix, logit_bias, k=k)\n        topk_idxs = [i for i, _ in topk_words]\n        if idx in topk_idxs:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n\n    return -mid, k\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words = model.topk(prefix, k)\n    if idx in topk_words:\n        logprobs = np.array([topk_words[idx]])\n        return logprobs, 1\n    else:\n        if high == 0:\n            raise TypeError(\n                f\"Token {idx} not in top-k with bias {high}. \"\n                \"Either increase bias or provide top unbiased logprob (top_logprob)\"\n            )\n        low = 0\n        mid = (high + low) / 2\n        while high >= low:\n            logit_bias = {idx: mid}\n            if model.argmax(prefix, logit_bias) == idx:\n                high = mid\n            else:\n                low = mid\n            mid = (high + low) / 2\n        logprobs = np.array([topk_words[idx]]) - mid\n        return logprobs, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words = model.topk(prefix, k=k)\n    topk_idxs = [i for i, _ in topk_words]\n    if idx in topk_idxs:\n        logprob = topk_words[idx]\n        return logprob, k\n    else:\n        low = 0\n        num_calls = k\n        while high >= low + 1e-8:\n            mid = (high + low) / 2\n            logit_bias = {idx: mid}\n            topk_words = model.topk(prefix, logit_bias=logit_bias, k=k)\n            topk_idxs = [i for i, _ in topk_words]\n            if idx in topk_idxs:\n                high = mid\n            else:\n                low = mid\n            mid = (high + low) / 2\n            num_calls += k\n        logprob = topk_words[idx]\n        return logprob, num_calls\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words = model.topk(prefix, k=k)\n    if idx in topk_words:\n        return -topk_words[idx], 1\n    else:\n        if high >= model.vocab_size:\n            missing_tokens = set(idx) - set(topk_words)\n            raise TypeError(\n                f\"Tokens {missing_tokens} not in top-k with bias {high}.\"\n                \"Either increase high or provide top unbiased logprob (top_logprob)\"\n            )\n        # initialize high\n        logit_bias = {idx: high}\n        while model.argmax(prefix, logit_bias) != idx:\n            logit_bias[idx] *= 2\n            high = logit_bias[idx]\n        # improve estimate\n        mid = (high + low) / 2\n        while high >= low + eps:\n            logit_bias[idx] = mid\n            if model.argmax(prefix, logit_bias) == idx:\n                high = mid\n            else:\n                low = mid\n            mid = (high + low) / 2\n        return -mid, 1\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words = model.topk(prefix, k=k)\n    topk_idxs = [i for i, _ in topk_words]\n    if idx not in topk_idxs:\n        raise ValueError(f\"{idx} not in topk_idxs\")\n\n    # initialize high\n    logit_bias = {idx: high}\n    while model.argmax(prefix, logit_bias) != idx:\n        logit_bias[idx] *= 2\n    high = logit_bias[idx]\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        if model.argmax(prefix, logit_bias) == idx:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n\n    return -mid, k\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    # get raw topk, could be done outside and passed in\n    topk_words = model.topk(prefix, k)\n    topk_idxs = list(topk_words.keys())\n    topk_logprobs = np.array(list(topk_words.values()))\n\n    # check if idx is the argmax\n    if idx == topk_idxs[0]:\n        return topk_logprobs[0], k\n\n    # initialize high\n    logit_bias = {idx: high}\n    while idx not in topk_idxs:\n        logit_bias[idx] *= 2\n        topk_words = model.topk(prefix, k, logit_bias)\n        topk_idxs = list(topk_words.keys())\n        topk_logprobs = np.array(list(topk_words.values()))\n\n    # improve estimate\n    low = 0\n    mid = (high + low) / 2\n    while high >= low + 1e-8:\n        logit_bias[idx] = mid\n        topk_words = model.topk(prefix, k, logit_bias)\n        topk_idxs = list(topk_words.keys())\n        topk_logprobs = np.array(list(topk_words.values()))\n        if idx in topk_idxs:\n            high = mid\n        else:\n            low = mid\n        mid = (high + low) / 2\n\n    return topk_logprobs[topk_idxs.index(idx)], k\n\n"}
{"namespace": "openlogprobs.extract.topk_search", "completion": "    topk_words = model.topk(prefix, k=k)\n    topk_idxs = list(topk_words.keys())\n    topk_logprobs = list(topk_words.values())\n    topk_idxs.append(idx)\n    topk_logprobs.append(high)\n    topk_idxs, topk_logprobs = zip(*sorted(zip(topk_idxs, topk_logprobs), key=lambda x: x[1]))\n\n    # get topk logprobs\n    topk_logprobs = np.array(topk_logprobs)\n    topk_logprobs = topk_logprobs - logsumexp(topk_logprobs)\n    topk_logprobs = dict(zip(topk_idxs, topk_logprobs))\n\n    # check if idx is the argmax\n    if topk_idxs[0] == idx:\n        return 0, k\n\n    # initialize high\n    logit_bias = {idx: high}\n    while topk_idxs[0] != idx:\n        logit_bias[idx] *= 2\n        topk_words = model.topk(prefix, k=k, logit_bias=logit_bias)\n        topk_idxs = list(topk_words.keys())\n        topk_logprobs = list(topk_words.values())\n        topk_idxs.append(idx)\n        topk_logprobs.append(high)\n        topk_idxs, topk_logprobs = zip(*sorted(zip(topk_idxs, topk_logprobs), key=lambda x: x[1]))\n        topk_logprobs = np.array(topk_logprobs)\n        topk_logprobs = topk_logprobs - logsumexp(topk_logprobs)\n        topk_logprobs = dict(zip(topk_idxs, topk_logprobs))\n\n    # improve estimate\n   "}
{"namespace": "resample.resample_3d", "completion": "  # Check if locations is a tensor.\n  if not jnp.is_tensor(locations):\n    locations = jnp.array(locations)\n\n  # Check if data is a tensor.\n  if not jnp.is_tensor(data):\n    data = jnp.array(data)\n\n  # Check if locations is a tensor.\n  if not jnp.is_tensor(locations):\n    locations = jnp.array(locations)\n\n  # Check if data is a tensor.\n  if not jnp.is_tensor(data):\n    data = jnp.array(data)\n\n  # Check if locations is a tensor.\n  if not jnp.is_tensor(locations):\n    locations = jnp.array(locations)\n\n  # Check if data is a tensor.\n  if not jnp.is_tensor(data):\n    data = jnp.array(data)\n\n  # Check if locations is a tensor.\n  if not jnp.is_tensor(locations):\n    locations = jnp.array(locations)\n\n  # Check if data is a tensor.\n  if not jnp.is_tensor(data):\n    data = jnp.array(data)\n\n  # Check if locations is a tensor.\n  if not jnp.is_tensor(locations):\n    locations = jnp.array(locations)\n\n  # Check if data is a tensor.\n  if not jnp.is_tensor(data):\n    data = jnp.array(data)\n\n  # Check if locations is a tensor.\n  if not jnp.is_tensor(locations):\n    locations = jnp.array(locations)\n\n  # Check if data is a tensor.\n  if not jnp.is_tensor(data):\n    data = jnp.array(data)\n\n  # Check if locations is a tensor.\n  if not jnp.is_tensor(locations):\n    locations = jnp.array(locations)\n\n  # Check if data is a tensor.\n  if not jnp.is_tensor(data):\n    data = jnp."}
{"namespace": "resample.resample_3d", "completion": "  # Check if the input data is a jax array\n  if not isinstance(data, jnp.ndarray):\n    raise ValueError('Input data must be a jax array.')\n\n  # Check if the input locations is a jax array\n  if not isinstance(locations, jnp.ndarray):\n    raise ValueError('Input locations must be a jax array.')\n\n  # Check if the input data has four dimensions\n  if len(data.shape) != 4:\n    raise ValueError('Input data must have four dimensions.')\n\n  # Check if the input locations has at least two dimensions\n  if len(locations.shape) < 2:\n    raise ValueError('Input locations must have at least two dimensions.')\n\n  # Check if the input locations has the same batch dimension as the input data\n  if locations.shape[0] != data.shape[0]:\n    raise ValueError('Input locations must have the same batch dimension as the input data.')\n\n  # Check if the input locations has the same number of dimensions as the input data\n  if len(locations.shape) != len(data.shape):\n    raise ValueError('Input locations must have the same number of dimensions as the input data.')\n\n  # Check if the input locations has the same number of dimensions as the input data\n  if locations.shape[-1] != 3:\n    raise ValueError('Input locations must have three dimensions at the end.')\n\n  # Check if the input locations has the same number of dimensions as the input data\n  if locations.shape[-1] != data.shape[-1]:\n    raise ValueError('Input locations must have the same number of dimensions as the input data.')\n\n  # Check if the input locations has the same number of dimensions as the input data\n  if locations.shape[-1] != data.shape[-1]:\n    raise ValueError('Input locations must have the same number of dimensions as the input data.')\n\n  # Check if the input locations has the same number of dimensions as the input data\n  if locations.shape[-1] != data.shape[-1]:\n    raise ValueError('Input locations must have the same number of dimensions"}
{"namespace": "resample.resample_3d", "completion": "  # Check if the input data is a JAX array, and if not, convert it to a JAX array.\n  if not isinstance(data, jnp.ndarray):\n    data = jnp.array(data)\n\n  # Check if the input locations is a JAX array, and if not, convert it to a JAX array.\n  if not isinstance(locations, jnp.ndarray):\n    locations = jnp.array(locations)\n\n  # Check if the input locations has the correct shape.\n  if len(locations.shape) < 3:\n    raise ValueError(\n        f'locations must have at least 3 dimensions, but got {len(locations.shape)}.'\n    )\n\n  # Check if the input data has the correct shape.\n  if len(data.shape) != 4:\n    raise ValueError(\n        f'data must have 4 dimensions, but got {len(data.shape)}.'\n    )\n\n  # Check if the input data and locations have the same batch size.\n  if data.shape[0] != locations.shape[0]:\n    raise ValueError(\n        f'data and locations must have the same batch size, but got {data.shape[0]} and {locations.shape[0]}.'\n    )\n\n  # Check if the input locations has the correct coordinate order.\n  if coordinate_order not in ('xyz', 'zyx'):\n    raise ValueError(\n        f'coordinate_order must be either \"xyz\" or \"zyx\", but got {coordinate_order}.'\n    )\n\n  # Check if the input method is valid.\n  if method not in ('TRILINEAR', 'NEAREST'):\n    raise ValueError(\n        f'method must be either \"TRILINEAR\" or \"NEAREST\", but got {method}.'\n    )\n\n  # Check if the input data is a JAX array, and if not, convert it to a JAX array.\n  if not isinstance(data, jnp.ndarray):\n    data = jnp.array(data)\n\n  # Check if the input locations is"}
{"namespace": "resample.resample_3d", "completion": "  # Check input shapes\n  if data.ndim != 4:\n    raise ValueError(\n        f'Data must have 4 dimensions, but got {data.ndim}.')\n  if locations.ndim < 2:\n    raise ValueError(\n        f'Locations must have at least 2 dimensions, but got {locations.ndim}.')\n  if locations.shape[-1] != 3:\n    raise ValueError(\n        f'Locations must have 3 values in the last dimension, but got {locations.shape[-1]}.')\n\n  # Check edge behavior\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        f'Edge behavior must be one of \"CONSTANT_OUTSIDE\" or \"CLAMP\", but got {edge_behavior}.')\n\n  # Check coordinate order\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(\n        f'Coordinate order must be one of \"xyz\" or \"zyx\", but got {coordinate_order}.')\n\n  # Check method\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(\n        f'Method must be one of \"TRILINEAR\" or \"NEAREST\", but got {method}.')\n\n  # Check dtype\n  if data.dtype != jnp.float32:\n    raise ValueError(\n        f'Data must have dtype float32, but got {data.dtype}.')\n  if locations.dtype != jnp.float32:\n    raise ValueError(\n        f'Locations must have dtype float32, but got {locations.dtype}.')\n\n  # Pad data\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(data, ((1, 1), (1, 1), (1, 1), (0, 0)),\n                   mode='constant', constant_values=constant_values)\n    locations = locations + 1.0\n\n  # Get"}
{"namespace": "resample.resample_3d", "completion": "  if data.ndim != 4:\n    raise ValueError('Data must be 4D.')\n\n  if locations.ndim < 2:\n    raise ValueError('Locations must have at least 2 dimensions.')\n\n  if locations.shape[-1] != 3:\n    raise ValueError('Locations must have shape [..., 3].')\n\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        'Edge behavior must be one of [\"CONSTANT_OUTSIDE\", \"CLAMP\"].')\n\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Method must be one of [\"TRILINEAR\", \"NEAREST\"].')\n\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('Coordinate order must be one of [\"xyz\", \"zyx\"].')\n\n  if method == 'TRILINEAR':\n    return resample_3d_trilinear(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n  elif method == 'NEAREST':\n    return resample_3d_nearest(\n        data,\n        locations,\n        edge_behavior=edge_behavior,\n        constant_values=constant_values,\n        coordinate_order=coordinate_order,\n        half_pixel_center=half_pixel_center,\n    )\n\n"}
{"namespace": "resample.resample_3d", "completion": "  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Unsupported interpolation method: %s' % method)\n\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('Unsupported edge behavior: %s' % edge_behavior)\n\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('Unsupported coordinate order: %s' % coordinate_order)\n\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Pad the volume with a constant value outside the tensor.\n    pad_width = ((1, 1), (1, 1), (1, 1), (0, 0))\n    data = jnp.pad(\n        data, pad_width, mode='constant', constant_values=constant_values)\n    locations = locations + 1\n\n  # Get the coordinates of the sample points.\n  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  if method == 'TRILINEAR':\n    # Get the coordinates of the neighboring voxels.\n    x_coordinate_floor = jnp.floor(x_coordinate)\n    y_coordinate_floor = jnp.floor(y_coordinate)\n    z_coordinate_floor = jnp.floor(z_coordinate)\n\n    x_coordinate_ceil = jnp.ceil(x_coordinate)\n    y_coordinate_ceil = jnp.ceil(y_coordinate)\n    z_coordinate_ceil = jnp.ceil(z_coordinate)\n\n    # Compute the weights"}
{"namespace": "resample.resample_3d", "completion": "  # Check if the input data is a JAX array and convert it to a NumPy array if it is\n  if isinstance(data, jax.Array):\n    data = np.array(data)\n\n  # Check if the input locations is a JAX array and convert it to a NumPy array if it is\n  if isinstance(locations, jax.Array):\n    locations = np.array(locations)\n\n  # Check if the input data is a NumPy array\n  if not isinstance(data, np.ndarray):\n    raise ValueError('Input data must be a NumPy array or a JAX array.')\n\n  # Check if the input locations is a NumPy array\n  if not isinstance(locations, np.ndarray):\n    raise ValueError('Input locations must be a NumPy array or a JAX array.')\n\n  # Check if the input data has four dimensions\n  if data.ndim != 4:\n    raise ValueError('Input data must have four dimensions.')\n\n  # Check if the input locations has at least two dimensions\n  if locations.ndim < 2:\n    raise ValueError('Input locations must have at least two dimensions.')\n\n  # Check if the input locations has the correct shape\n  if locations.shape[-1] != 3:\n    raise ValueError('The last dimension of input locations must be 3.')\n\n  # Check if the edge behavior is valid\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError('Invalid edge behavior.')\n\n  # Check if the coordinate order is valid\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('Invalid coordinate order.')\n\n  # Check if the interpolation method is valid\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Invalid interpolation method.')\n\n  # Get the input data shape\n  input_shape = data.shape\n\n  # Get the locations shape\n  locations_shape = locations.shape\n\n  # Get the batch size\n  batch_size = locations_shape[0]"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        'Invalid edge behavior: {}. Must be one of {}'.format(\n            edge_behavior, ['CONSTANT_OUTSIDE', 'CLAMP']\n        )\n    )\n\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(\n        'Invalid interpolation method: {}. Must be one of {}'.format(\n            method, ['TRILINEAR', 'NEAREST']\n        )\n    )\n\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(\n        'Invalid coordinate order: {}. Must be one of {}'.format(\n            coordinate_order, ['xyz', 'zyx']\n        )\n    )\n\n  # Pad the data with constant values along the spatial dimensions.\n  pad_width = [(0, 0)] + [(1, 1)] * 3\n  data = np.pad(data, pad_width, mode='constant', constant_values=constant_values)\n\n  # Calculate the sample locations based on the half_pixel_center setting.\n  if half_pixel_center:\n    locations = locations + 0.5\n\n  # Calculate the sample locations based on the coordinate order.\n  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  # Clamp the sample locations to the volume boundaries.\n  if edge_behavior == 'CLAMP':\n    x_coordinate = jnp.clip(x_coordinate, 0, data.shape[2] - 1)\n   "}
{"namespace": "resample.resample_3d", "completion": "  # Initialize output tensor with zeros.\n  output = jnp.zeros(locations.shape[:-1] + (data.shape[-1],), dtype=data.dtype)\n\n  # Pad data with constant values if edge_behavior is set to 'CONSTANT_OUTSIDE'.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(\n        data, ((1, 1), (1, 1), (1, 1), (0, 0)),\n        mode='constant',\n        constant_values=constant_values)\n    locations = locations + 1\n\n  # Clamp sample points to the volume if edge_behavior is set to 'CLAMP'.\n  if edge_behavior == 'CLAMP':\n    locations = jnp.clip(\n        locations, 0,\n        jnp.array(data.shape) - 1).astype(jnp.int32)\n\n  # Calculate sample locations based on half_pixel_center.\n  if half_pixel_center:\n    sample_locations = locations - 0.5\n  else:\n    sample_locations = locations\n\n  # Calculate floor and ceil locations.\n  floor_locations = jnp.floor(sample_locations).astype(jnp.int32)\n  ceil_locations = floor_locations + 1\n\n  # Calculate weights for trilinear interpolation.\n  if method == 'TRILINEAR':\n    weights = sample_locations - floor_locations\n    weights = jnp.stack([\n        weights[Ellipsis, 0] * weights[Ellipsis, 1] * weights[Ellipsis, 2],\n        (1 - weights[Ellipsis, 0]) * weights[Ellipsis, 1] * weights[Ellipsis, 2],\n        weights[Ellipsis, 0] * (1 - weights[Ellipsis, 1]) * weights[Ellipsis, 2],\n        (1 - weights[Ellipsis, "}
{"namespace": "resample.resample_3d", "completion": "  # Extract the shape of the input volume data.\n  input_shape = data.shape\n  num_channels = input_shape[-1]\n\n  # Adjust the locations based on half_pixel_center.\n  if half_pixel_center:\n    locations = locations - 0.5\n\n  # Extract the coordinates from the locations.\n  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  # Compute the lower and upper bounding indices for each location.\n  lower_x_index = jnp.floor(x_coordinate).astype(jnp.int32)\n  lower_y_index = jnp.floor(y_coordinate).astype(jnp.int32)\n  lower_z_index = jnp.floor(z_coordinate).astype(jnp.int32)\n  upper_x_index = lower_x_index + 1\n  upper_y_index = lower_y_index + 1\n  upper_z_index = lower_z_index + 1\n\n  # Compute the distance between the sample location and the lower bounding indices.\n  distance_to_lower_x = x_coordinate - lower_x_index\n  distance_to_lower_y = y_coordinate - lower_y_index\n  distance_to_lower_z = z_coordinate - lower_z_index\n\n  # Compute the distance between the upper bounding indices and the sample location.\n  distance_to_upper_x = 1.0 - distance_to_lower_x\n  distance_to_upper_y = 1.0 - distance_to_lower_y\n  distance_to_"}
{"namespace": "resample.resample_3d", "completion": "  # Check if data and locations have the correct number of dimensions\n  assert data.ndim == 4, f\"data must be a 4D tensor, but got {data.ndim}D tensor\"\n  assert locations.ndim >= 2, f\"locations must be at least 2D tensor, but got {locations.ndim}D tensor\"\n\n  # Check if locations has the correct shape\n  assert locations.shape[-1] == 3, f\"locations must have shape [..., 3], but got {locations.shape[-1]}D tensor\"\n\n  # Check if edge_behavior is valid\n  assert edge_behavior in ['CONSTANT_OUTSIDE', 'CLAMP'], f\"edge_behavior must be either 'CONSTANT_OUTSIDE' or 'CLAMP', but got {edge_behavior}\"\n\n  # Check if coordinate_order is valid\n  assert coordinate_order in ['xyz', 'zyx'], f\"coordinate_order must be either 'xyz' or 'zyx', but got {coordinate_order}\"\n\n  # Check if method is valid\n  assert method in ['TRILINEAR', 'NEAREST'], f\"method must be either 'TRILINEAR' or 'NEAREST', but got {method}\"\n\n  # Check if half_pixel_center is valid\n  assert isinstance(half_pixel_center, bool), f\"half_pixel_center must be a boolean, but got {type(half_pixel_center)}\"\n\n  # Get the shape of the data and locations tensors\n  data_shape = data.shape\n  locations_shape = locations.shape\n\n  # Get the number of dimensions in the locations tensor\n  num_dims = len(locations_shape)\n\n  # Check if the number of dimensions in the locations tensor matches the number of dimensions in the data tensor\n  assert num_dims == len(data_shape), f\"Number of dimensions in locations ({num_dims}) must match the number of dimensions in data ({len(data_shape)})\"\n\n  # Check if the first dimension of the locations tensor matches the first dimension of the data tensor\n "}
{"namespace": "resample.resample_3d", "completion": "  # Check if the input data is a JAX array. If not, convert it to a JAX array.\n  if not isinstance(data, jnp.ndarray):\n    data = jnp.array(data)\n\n  # Check if the locations are a JAX array. If not, convert them to a JAX array.\n  if not isinstance(locations, jnp.ndarray):\n    locations = jnp.array(locations)\n\n  # Check if the input data has four dimensions.\n  assert data.ndim == 4, 'Data must have four dimensions.'\n\n  # Check if the input data has a floating point data type.\n  assert data.dtype in [jnp.float32, jnp.float64], 'Data must be floating point.'\n\n  # Check if the input locations have three dimensions.\n  assert locations.ndim == 3, 'Locations must have three dimensions.'\n\n  # Check if the input locations have a floating point data type.\n  assert locations.dtype in [jnp.float32, jnp.float64], 'Locations must be floating point.'\n\n  # Check if the edge behavior is valid.\n  assert edge_behavior in ['CONSTANT_OUTSIDE', 'CLAMP'], 'Edge behavior must be CONSTANT_OUTSIDE or CLAMP.'\n\n  # Check if the constant values are a scalar.\n  assert jnp.isscalar(constant_values), 'Constant values must be a scalar.'\n\n  # Check if the coordinate order is valid.\n  assert coordinate_order in ['xyz', 'zyx'], 'Coordinate order must be xyz or zyx.'\n\n  # Check if the method is valid.\n  assert method in ['TRILINEAR', 'NEAREST'], 'Method must be TRILINEAR or NEAREST.'\n\n  # Check if half_pixel_center is a boolean.\n  assert isinstance(half_pixel_center, bool), 'half_pixel_center must be a boolean.'\n\n  # Get the shape of the input data.\n  data_shape = data.shape\n\n  # Get the shape of the input locations."}
{"namespace": "resample.resample_3d", "completion": "  # Convert to integer coordinates.\n  locations = jnp.asarray(locations)\n  locations = jnp.floor(locations + 0.5)\n\n  # Pad the volume if necessary.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(\n        data,\n        pad_width=((1, 1), (1, 1), (1, 1), (0, 0)),\n        mode='constant',\n        constant_values=constant_values,\n    )\n    locations = locations + 1\n  elif edge_behavior == 'CLAMP':\n    pass\n  else:\n    raise ValueError(\n        f'Invalid edge_behavior: {edge_behavior}. Options are \"CONSTANT_OUTSIDE\" and \"CLAMP\".'\n    )\n\n  # Get the integer coordinates.\n  if coordinate_order == 'xyz':\n    x_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    z_coordinate = locations[Ellipsis, 2]\n  elif coordinate_order == 'zyx':\n    z_coordinate = locations[Ellipsis, 0]\n    y_coordinate = locations[Ellipsis, 1]\n    x_coordinate = locations[Ellipsis, 2]\n\n  # Compute the offsets for the interpolation.\n  if half_pixel_center:\n    x_offset = x_coordinate - jnp.floor(x_coordinate)\n    y_offset = y_coordinate - jnp.floor(y_coordinate)\n    z_offset = z_coordinate - jnp.floor(z_coordinate)\n  else:\n    x_offset = x_coordinate - jnp.floor(x_coordinate) - 0.5\n    y_offset = y_coordinate - jnp.floor(y_coordinate) - 0.5\n    z_offset = z_coordinate - jnp.floor(z_coordinate) - 0.5\n\n "}
{"namespace": "resample.resample_3d", "completion": "  # Determine the shape of the input data and the number of dimensions.\n  data_shape = data.shape\n  num_dims = len(data_shape)\n\n  # Convert the locations tensor to float32.\n  locations = locations.astype(jnp.float32)\n\n  # Check if the coordinate_order is valid.\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(\n        'coordinate_order must be either \"xyz\" or \"zyx\", got %s' % coordinate_order)\n\n  # Check if the method is valid.\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('method must be either \"TRILINEAR\" or \"NEAREST\", got %s' %\n                     method)\n\n  # Check if the edge_behavior is valid.\n  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        'edge_behavior must be either \"CONSTANT_OUTSIDE\" or \"CLAMP\", got %s' %\n        edge_behavior)\n\n  # Check if the input data is at least 3D.\n  if num_dims < 3:\n    raise ValueError('data must be at least 3D, got %d' % num_dims)\n\n  # Check if the locations tensor is at least 3D.\n  if len(locations.shape) < 3:\n    raise ValueError('locations must be at least 3D, got %d' %\n                     len(locations.shape))\n\n  # Check if the number of dimensions in the input data and the locations tensor match.\n  if num_dims != len(locations.shape):\n    raise ValueError(\n        'data and locations must have the same number of dimensions, got %d and %d'\n        % (num_dims, len(locations.shape)))\n\n  # Check if the number of channels in the input data and the locations tensor match.\n  if data_shape[-1] != locations.shape[-1]:\n   "}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        f'Unknown edge behavior {edge_behavior}. '\n        f'Expected one of {[\"CONSTANT_OUTSIDE\", \"CLAMP\"]}'\n    )\n\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(\n        f'Unknown interpolation method {method}. '\n        f'Expected one of {[\"TRILINEAR\", \"NEAREST\"]}'\n    )\n\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(\n        f'Unknown coordinate order {coordinate_order}. '\n        f'Expected one of {[\"xyz\", \"zyx\"]}'\n    )\n\n  if data.ndim != 4:\n    raise ValueError(\n        f'data must have 4 dimensions, got {data.ndim}'\n    )\n\n  if locations.ndim < 2:\n    raise ValueError(\n        f'locations must have at least 2 dimensions, got {locations.ndim}'\n    )\n\n  if locations.shape[-1] != 3:\n    raise ValueError(\n        f'Last dimension of locations must be 3, got {locations.shape[-1]}'\n    )\n\n  if locations.shape[0] != data.shape[0]:\n    raise ValueError(\n        f'First dimension of locations must be same as first dimension of data, '\n        f'got {locations.shape[0]} and {data.shape[0]}'\n    )\n\n  if locations.dtype != jnp.float32:\n    raise ValueError(\n        f'locations must be of type float32, got {locations.dtype}'\n    )\n\n  if data.dtype != jnp.float32:\n    raise ValueError(\n        f'data must be of type float32, got {data.dtype}'\n    )\n\n  # Pad the volume with zeros to handle sample points outside the volume.\n  if edge_behavior =="}
{"namespace": "resample.resample_3d", "completion": "  if method != 'TRILINEAR' and method != 'NEAREST':\n    raise ValueError('Unsupported interpolation method: %s' % method)\n\n  if edge_behavior != 'CONSTANT_OUTSIDE' and edge_behavior != 'CLAMP':\n    raise ValueError('Unsupported edge behavior: %s' % edge_behavior)\n\n  if coordinate_order != 'xyz' and coordinate_order != 'zyx':\n    raise ValueError('Unsupported coordinate order: %s' % coordinate_order)\n\n  # Get the shape of the input data.\n  data_shape = data.shape\n\n  # Get the shape of the input locations.\n  locations_shape = locations.shape\n\n  # Get the number of dimensions in the input locations.\n  num_dims = locations_shape[-1]\n\n  # Check that the number of dimensions in the input locations is 3.\n  if num_dims != 3:\n    raise ValueError(\n        'Locations must have 3 dimensions in the last axis, but got %d' % num_dims)\n\n  # Get the number of dimensions in the input data.\n  num_data_dims = len(data_shape)\n\n  # Check that the number of dimensions in the input data is 4.\n  if num_data_dims != 4:\n    raise ValueError(\n        'Data must have 4 dimensions in the last axis, but got %d' % num_data_dims)\n\n  # Get the shape of the input data excluding the last dimension.\n  data_spatial_shape = data_shape[:-1]\n\n  # Get the shape of the input locations excluding the last dimension.\n  locations_spatial_shape = locations_shape[:-1]\n\n  # Check that the spatial shapes of the input data and locations are equal.\n  if data_spatial_shape != locations_spatial_shape:\n    raise ValueError(\n        'Data and locations must have equal spatial shapes, but got %s and %s'\n        % (data_spatial_shape, locations_spatial_shape"}
{"namespace": "resample.resample_3d", "completion": "  # Initialize the output tensor with zeros\n  output = jnp.zeros(locations.shape[:-1] + (data.shape[-1],), dtype=data.dtype)\n\n  # If edge_behavior is set to 'CONSTANT_OUTSIDE', pad the input volume with constant values\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(\n        data,\n        ((1, 1), (1, 1), (1, 1), (0, 0)),\n        mode='constant',\n        constant_values=constant_values,\n    )\n    locations = locations + 1\n\n  # If half_pixel_center is set to True, adjust the sample locations\n  if half_pixel_center:\n    locations = locations + 0.5\n\n  # If coordinate_order is set to 'zyx', permute the input volume and locations\n  if coordinate_order == 'zyx':\n    data = jnp.transpose(data, (2, 1, 0, 3))\n    locations = jnp.stack(\n        [locations[Ellipsis, 2], locations[Ellipsis, 1], locations[Ellipsis, 0]],\n        axis=-1,\n    )\n\n  # Get the shape of the input volume\n  depth, height, width, channels = data.shape\n\n  # Get the shape of the locations tensor\n  batch_shape = locations.shape[:-1]\n\n  # Flatten the locations tensor\n  locations = locations.reshape(-1, 3)\n\n  # Get the minimum and maximum x, y, and z coordinates of the locations tensor\n  min_x = jnp.floor(jnp.min(locations[:, 0]))\n  max_x = jnp.ceil(jnp.max(locations[:, 0]))\n  min_y = jnp.floor(jnp.min(locations[:, 1]))\n  max_y = jnp.ceil(jnp.max(locations[:, 1]))\n  min_z = jnp.floor"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        'Edge behavior must be either CONSTANT_OUTSIDE or CLAMP.'\n    )\n\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError('Method must be either TRILINEAR or NEAREST.')\n\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError('Coordinate order must be either xyz or zyx.')\n\n  # Pad the data with constant values along the spatial dimensions.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    data = jnp.pad(\n        data,\n        ((1, 1), (1, 1), (1, 1), (0, 0)),\n        mode='constant',\n        constant_values=constant_values,\n    )\n    locations = locations + 1\n\n  # Clamp the locations to the padded volume.\n  if edge_behavior == 'CLAMP':\n    locations = jnp.clip(\n        locations,\n        a_min=jnp.array([0, 0, 0]),\n        a_max=jnp.array([data.shape[0] - 1, data.shape[1] - 1, data.shape[2] - 1]),\n    )\n\n  # Convert the locations to float32.\n  locations = locations.astype(jnp.float32)\n\n  # Compute the sampling weights.\n  if method == 'NEAREST':\n    z = jnp.round(locations[Ellipsis, 0])\n    y = jnp.round(locations[Ellipsis, 1])\n    x = jnp.round(locations[Ellipsis, 2])\n    z_floor = jnp.floor(z)\n    y_floor = jnp.floor(y)\n    x_floor = jnp.floor(x)\n    z_ceil = jnp.ceil(z)\n    y_ceil = jnp."}
{"namespace": "resample.resample_3d", "completion": "  # Pad the data volume to handle edge behavior.\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    padded_data = jnp.pad(\n        data,\n        jnp.array([(1, 1), (1, 1), (1, 1), (0, 0)]),\n        mode='constant',\n        constant_values=constant_values,\n    )\n  elif edge_behavior == 'CLAMP':\n    padded_data = jnp.pad(\n        data,\n        jnp.array([(1, 1), (1, 1), (1, 1), (0, 0)]),\n        mode='edge',\n    )\n  else:\n    raise ValueError(f'Unknown edge_behavior: {edge_behavior}')\n\n  # Adjust the locations for half-pixel centering.\n  if half_pixel_center:\n    locations = locations + 0.5\n\n  # Compute the integer coordinates of the locations.\n  locations_floor = jnp.floor(locations)\n  locations_ceil = jnp.ceil(locations)\n\n  # Compute the weights for trilinear interpolation.\n  if method == 'TRILINEAR':\n    weights = locations - locations_floor\n    weights = weights.astype(jnp.float32)\n  elif method == 'NEAREST':\n    weights = jnp.zeros_like(locations)\n  else:\n    raise ValueError(f'Unknown method: {method}')\n\n  # Compute the indices for gathering.\n  indices_floor = locations_floor.astype(jnp.int32)\n  indices_ceil = locations_ceil.astype(jnp.int32)\n\n  # Gather the data at the floor and ceil locations.\n  data_floor = gather_volume(padded_data, indices_floor, coordinate_order)\n  data_ceil = gather_volume(padded_data, indices_ceil, coordinate_order)\n\n  # Compute the resampled values using trilinear interpolation.\n  resam"}
{"namespace": "resample.resample_3d", "completion": "  if edge_behavior not in ['CONSTANT_OUTSIDE', 'CLAMP']:\n    raise ValueError(\n        f'Unknown edge behavior {edge_behavior} in resample_3d.')\n\n  if method not in ['TRILINEAR', 'NEAREST']:\n    raise ValueError(f'Unknown interpolation method {method} in resample_3d.')\n\n  if coordinate_order not in ['xyz', 'zyx']:\n    raise ValueError(\n        f'Unknown coordinate order {coordinate_order} in resample_3d.')\n\n  if data.ndim != 4:\n    raise ValueError(\n        f'Input data must have 4 dimensions, but got {data.ndim}')\n\n  if locations.ndim < 2 or locations.shape[-1] != 3:\n    raise ValueError(\n        f'Input locations must have at least 2 dimensions and the last dimension must be of size 3, but got {locations.shape}'\n    )\n\n  if edge_behavior == 'CONSTANT_OUTSIDE':\n    # Pad the volume by 1 voxel on each side\n    padded_data = jnp.pad(\n        data,\n        pad_width=((1, 1), (1, 1), (1, 1), (0, 0)),\n        mode='constant',\n        constant_values=constant_values)\n\n    # Adjust the locations to account for the padding\n    locations = locations + 1\n  else:\n    padded_data = data\n\n  # Get the shape of the input data\n  data_depth, data_height, data_width, data_channels = data.shape\n\n  # Get the shape of the output locations\n  output_shape = locations.shape[:-1]\n\n  # Compute the sample locations\n  if half_pixel_center:\n    sample_locations = locations - 0.5\n  else:\n    sample_locations = locations\n\n  # Compute the floor and ceiling of the sample locations\n  floor_location = jnp.floor(sample_locations)\n "}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(jnp.abs(x) < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.plus_eps", "completion": "  return jnp.where(x < tiny_val, tiny_val, jnp.nextafter(x, jnp.inf))\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), jnp.NINF)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), jnp.NINF)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), jnp.NINF)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), jnp.NINF)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), jnp.NINF)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), -jnp.inf)\n  )\n\n"}
{"namespace": "math.minus_eps", "completion": "  return jnp.where(\n      jnp.abs(x) < tiny_val, -tiny_val, jnp.nextafter(jnp.float32(x), jnp.NINF)\n  )\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, 0),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 0),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, 0),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, 0),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, 0),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda _, y, y_dot: y_dot * y,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda _, y, x_dot: x_dot * y,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 10),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda _, y, x_dot: x_dot * y,\n      (-700, 700),\n  )(x)"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, 0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, 0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: x_dot * y,\n      (min_val, 0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda x, y, x_dot: y * x_dot,\n      (min_val, 0.0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda _, y, x_dot: x_dot * y,\n      (min_val, 0),\n  )(x)\n\n"}
{"namespace": "math.safe_exp", "completion": "  return generate_safe_fn(\n      jnp.exp,\n      lambda _, y, x_dot: y * x_dot,\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / remove_zero(x),\n                          (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / remove_zero(x), (min_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (min_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / remove_zero(x), (tiny_val, max_val))(x)"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / remove_zero(x), (min_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jax.grad(jnp.log), (min_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / remove_zero(x),\n                          (min_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / y, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / y, (min_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jax.grad(jnp.log), (min_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / y, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / remove_zero(x), (min_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / x, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / y, (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / remove_zero(x), (0, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / remove_zero(x),\n                          (-max_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / remove_zero(x),\n                          (-max_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(\n      jnp.log,\n      lambda x, y, x_dot: jnp.clip(x_dot / remove_zero(x), min_val, max_val),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, lambda x, y, x_dot: x_dot / remove_zero(x),\n                          (tiny_val, max_val))(x)\n\n"}
{"namespace": "math.safe_log", "completion": "  return generate_safe_fn(jnp.log, jax.grad(jnp.log), (min_val, max_val))(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: x_dot / (2 * y),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: x_dot / (2 * y),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: x_dot / (2 * y),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0.0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0.0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: x_dot / (2 * y),\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: x_dot / (2 * y),\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: x_dot / (2 * y),\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda _, y, x_dot: x_dot / (2 * y),\n      (0.0, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_sqrt", "completion": "  return generate_safe_fn(\n      jnp.sqrt,\n      lambda x, y, x_dot: 0.5 * x_dot / y,\n      (0, max_val),\n  )(x)\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 2:\n    return 2\n  elif p == 3:\n    return 3\n  elif p == 4:\n    return 4\n  elif p == 5:\n    return 5\n  elif p == 6:\n    return 6\n  elif p == 7:\n    return 7\n  elif p == 8:\n    return 8\n  elif p == 9:\n    return 9\n  elif p == 10:\n    return 10\n  elif p == 11:\n    return 11\n  elif p == 12:\n    return 12\n  elif p == 13:\n    return 13\n  elif p == 14:\n    return 14\n  elif p == 15:\n    return 15\n  elif p == 16:\n    return 16\n  elif p == 17:\n    return 17\n  elif p == 18:\n    return 18\n  elif p == 19:\n    return 19\n  elif p == 20:\n    return 20\n  elif p == 21:\n    return 21\n  elif p == 22:\n    return 22\n  elif p == 23:\n    return 23\n  elif p == 24:\n    return 24\n  elif p == 25:\n    return 25\n  elif p == 26:\n    return 26\n  elif p == 27:\n    return 27\n  elif p == 28:\n    return 28\n  elif p == 29:\n    return 29\n  elif p == 30:\n    return 30\n  elif p == 31:\n    return 31\n  elif p == 32:\n    return 32\n  elif p == 33:\n    return 33\n  elif p == 34:\n    return 34\n  elif p == 35:\n    return 35\n  elif p == 36:\n    return 36\n  elif p == 37:\n    return 37"}
{"namespace": "math.power_ladder_max_output", "completion": "  return select(\n      [\n          (p == 1, 1),\n          (p == 2, 1),\n          (p == 3, 1),\n          (p == 4, 1),\n          (p == 5, 1),\n          (p == 6, 1),\n          (p == 7, 1),\n          (p == 8, 1),\n          (p == 9, 1),\n          (p == 10, 1),\n          (p == 11, 1),\n          (p == 12, 1),\n          (p == 13, 1),\n          (p == 14, 1),\n          (p == 15, 1),\n          (p == 16, 1),\n          (p == 17, 1),\n          (p == 18, 1),\n          (p == 19, 1),\n          (p == 20, 1),\n          (p == 21, 1),\n          (p == 22, 1),\n          (p == 23, 1),\n          (p == 24, 1),\n          (p == 25, 1),\n          (p == 26, 1),\n          (p == 27, 1),\n          (p == 28, 1),\n          (p == 29, 1),\n          (p == 30, 1),\n          (p == 31, 1),\n          (p == 32, 1),\n          (p == 33, 1),\n          (p == 34, 1),\n          (p == 35, 1),\n          (p == 36, 1),\n          (p == 37, 1),\n          (p == 38, 1),\n          (p == 39, 1),\n          (p == 40, 1),\n          (p == 41, 1),\n          (p == 42, 1),\n          (p == 43, 1),\n          (p == 44, 1),\n          (p == 45, 1),\n          (p == 4"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p == 1:\n    return 0\n  elif p == 2:\n    return 1\n  elif p == 3:\n    return 0\n  elif p == 4:\n    return 1\n  elif p == 5:\n    return 0\n  elif p == 6:\n    return 1\n  elif p == 7:\n    return 0\n  elif p == 8:\n    return 1\n  elif p == 9:\n    return 0\n  elif p == 10:\n    return 1\n  elif p == 11:\n    return 0\n  elif p == 12:\n    return 1\n  elif p == 13:\n    return 0\n  elif p == 14:\n    return 1\n  elif p == 15:\n    return 0\n  elif p == 16:\n    return 1\n  elif p == 17:\n    return 0\n  elif p == 18:\n    return 1\n  elif p == 19:\n    return 0\n  elif p == 20:\n    return 1\n  elif p == 21:\n    return 0\n  elif p == 22:\n    return 1\n  elif p == 23:\n    return 0\n  elif p == 24:\n    return 1\n  elif p == 25:\n    return 0\n  elif p == 26:\n    return 1\n  elif p == 27:\n    return 0\n  elif p == 28:\n    return 1\n  elif p == 29:\n    return 0\n  elif p == 30:\n    return 1\n  elif p == 31:\n    return 0\n  elif p == 32:\n    return 1\n  elif p == 33:\n    return 0\n  elif p == 34:\n    return 1\n  elif p == 35:\n    return 0\n  elif p == 36:\n    return 1\n  elif p == 37:\n    return 0\n  elif p == 38:\n    return 1\n  elif"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 0:\n    return 1\n  elif p < 0:\n    return 0\n  elif p > 1:\n    return jnp.inf\n  else:\n    return 1 / (1 - p)"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p > 1:\n    return 1\n  elif p == 1:\n    return 0.5\n  elif p == 0:\n    return 0\n  elif p < 0:\n    return 0\n  else:\n    return 0"}
{"namespace": "math.power_ladder_max_output", "completion": "  return select(\n      [\n          (p == 0, 1),\n          (p > 0, max_val),\n          (p < 0, 0),\n      ],\n      default=jnp.nan,\n  )"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 0:\n    return 1\n  if p == 0:\n    return 2\n  if p > 0:\n    return 0"}
{"namespace": "math.power_ladder_max_output", "completion": "  # If p is less than 0, the output is 0.\n  if p < 0:\n    return 0\n\n  # If p is greater than or equal to 0 and less than 1, the output is 1.\n  elif p >= 0 and p < 1:\n    return 1\n\n  # If p is greater than or equal to 1 and less than 2, the output is 2.\n  elif p >= 1 and p < 2:\n    return 2\n\n  # If p is greater than or equal to 2 and less than 3, the output is 4.\n  elif p >= 2 and p < 3:\n    return 4\n\n  # If p is greater than or equal to 3 and less than 4, the output is 8.\n  elif p >= 3 and p < 4:\n    return 8\n\n  # If p is greater than or equal to 4 and less than 5, the output is 16.\n  elif p >= 4 and p < 5:\n    return 16\n\n  # If p is greater than or equal to 5 and less than 6, the output is 32.\n  elif p >= 5 and p < 6:\n    return 32\n\n  # If p is greater than or equal to 6 and less than 7, the output is 64.\n  elif p >= 6 and p < 7:\n    return 64\n\n  # If p is greater than or equal to 7 and less than 8, the output is 128.\n  elif p >= 7 and p < 8:\n    return 128\n\n  # If p is greater than or equal to 8 and less than 9, the output is 256.\n  elif p >= 8 and p < 9:\n    return 256\n\n  # If p is greater than or equal to 9 and less than 10, the output is 512.\n  elif p >= 9 and p < 10:\n    return 512\n\n  # If p is greater than or equal to 10 and less than 11, the output is 1024."}
{"namespace": "math.power_ladder_max_output", "completion": "  def power_ladder_max_output(p):\n    return select(\n        [\n            (p == 0, 0),\n            (p == 1, 1),\n            (p == 2, 1),\n            (p == jnp.inf, 1),\n            (p == -jnp.inf, 0),\n        ],\n        jnp.nan,\n    )\n\n  return power_ladder_max_output(p)"}
{"namespace": "math.power_ladder_max_output", "completion": "  return select(\n      [\n          (p == 0, 1),\n          (p == 1, jnp.inf),\n          (p == jnp.inf, jnp.inf),\n          (p < 0, 0),\n          (p > 0, jnp.inf),\n      ],\n      default=jnp.nan,\n  )\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 2:\n    return 2\n  elif p == 3:\n    return 3\n  elif p == 4:\n    return 4\n  else:\n    return np.inf\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  return select(\n      [\n          (p > 0, 1),\n          (p < 0, 0),\n          (p == 0, 0.5),\n      ],\n      default=np.nan,\n  )\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p < 1:\n    return 1\n  elif p > 1:\n    return 0\n  else:\n    return 0.5\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p < 1:\n    return jnp.inf\n  else:\n    return 0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  # Calculate the limit of the power_ladder function as x goes to infinity\n  if p > 0:\n    # If p is positive, the limit is infinity\n    return jnp.inf\n  elif p < 0:\n    # If p is negative, the limit is 0\n    return 0.0\n  else:\n    # If p is zero, the limit is 1\n    return 1.0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p > 1:\n    return jnp.inf\n  elif p < 1:\n    return 0\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p < 1:\n    return 0\n  elif p > 1:\n    return jnp.inf\n  else:\n    return jnp.nan\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  if p < 1:\n    return 0\n  if p > 1:\n    return jnp.inf\n  return jnp.nan\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 1\n  elif p == 2:\n    return 2\n  elif p == 3:\n    return 3\n  elif p == 4:\n    return 4\n  else:\n    return 1\n\n"}
{"namespace": "math.power_ladder_max_output", "completion": "  if p == 1:\n    return 0.5\n  elif p > 1:\n    return 0\n  else:\n    return 1\n\n"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [-1, -1, 1],\n            [1, -1, -1],\n            [-1, 1, -1],\n        ]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 2, 1],\n            [0, 3, 2],\n            [0, 4, 3],\n            [0, 1, 4],\n            [1, 2, 5],\n            [2, 3, 5],\n            [3, 4, 5],\n            [4, 1, 5],\n        ]\n    )\n  elif base_shape == 'octahedron':\n    base_verts = np.array(\n        [\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0, 1, 0],\n            [0, -1, 0],\n            [0, 0, 1],\n            [0, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 2, 4],\n            [0, 4, 3],\n            [0, 5, 2],\n            [0, "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 0, -1 / np.sqrt(2)],\n            [-1, 0, -1 / np.sqrt(2)],\n            [0, 1, 1 / np.sqrt(2)],\n            [0, -1, 1 / np.sqrt(2)],\n        ]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, 1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 2, 4],\n            [0, 4, 3],\n            [0, 3, 5],\n            [0, 5, 2],\n            [1, 2, 5],\n            [1, 5, 3],\n            [1, 3, 4],\n            [1, 4, 2],\n        ]\n    )\n  elif base_shape == 'octahedron':\n    base_verts = np.array(\n        [\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0, 1, 0],\n            [0, -1, 0],\n            [0, 0, 1],\n            [0, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 2, 4],"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [-1, -1, 1],\n            [1, -1, -1],\n            [-1, 1, -1],\n        ]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 2, 1],\n            [0, 3, 2],\n            [0, 4, 3],\n            [0, 1, 4],\n            [1, 2, 5],\n            [2, 3, 5],\n            [3, 4, 5],\n            [4, 1, 5],\n        ]\n    )\n  elif base_shape == 'octahedron':\n    base_verts = np.array(\n        [\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0, 1, 0],\n            [0, -1, 0],\n            [0, 0, 1],\n            [0, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 2, 4],\n            [0, 4, 3],\n            [0, 3, 5],\n            [0, 5"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [1, -1, -1],\n            [-1, 1, -1],\n            [-1, -1, 1],\n        ]\n    )\n    base_verts /= np.sqrt(3)\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [0, 1, -phi],\n            [0, -1, -phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [1, -phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, 1],\n            [-phi, 0, -1],\n        ]\n    )\n    base_verts /= np.sqrt(1 + phi**2)\n    base_faces = np.array(\n        [\n            [0, 1, 4],\n            [0, 4, 9],\n            [9, 4, 5],\n            [4, 8, 5],\n            [4, 1, 8],\n            [8, 1, 10],\n            [8, 10, 3],\n            [5, 8, 3],\n            [5, 3, 2],\n            [2, 3, 7],\n            [7, 3, 10],\n            [7, 10, 6],\n            [7, 6, 1"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [-1, -1, 1],\n            [-1, 1, -1],\n            [1, -1, -1],\n        ]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [0, 1, -phi],\n            [0, -1, -phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [1, -phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, 1],\n            [-phi, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 4],\n            [0, 4, 9],\n            [9, 4, 5],\n            [4, 8, 5],\n            [4, 1, 8],\n            [8, 1, 10],\n            [8, 10, 3],\n            [5, 8, 3],\n            [5, 3, 2],\n            [2, 3, 7],\n            [7, 3, 10],\n            [7, 10, 6],\n            [7, 6, 11],\n            [11, 6, 0],\n            [0, 6, 1],\n            [6, 10"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [-1, -1, 1],\n            [1, -1, -1],\n            [-1, 1, -1],\n        ]\n    )\n    base_faces = np.array(\n        [[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]]\n    )\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [0, 1, -phi],\n            [0, -1, -phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [1, -phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 4, 1],\n            [0, 9, 4],\n            [9, 5, 4],\n            [4, 5, 8],\n            [4, 8, 1],\n            [8, 10, 1],\n            [8, 3, 10],\n            [5, 3, 8],\n            [5, 2, 3],\n            [2, 7, 3],\n            [7, 10, 3],\n            [7, 6, 10],\n            [7, 11, 6],\n            [11, 0, 6],\n            [0, 1, 6],\n            [6,"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [-1, -1, 1],\n            [1, -1, -1],\n            [-1, 1, -1],\n        ],\n        dtype=np.float32,\n    )\n    base_faces = np.array(\n        [[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]], dtype=np.int32\n    )\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [0, 1, -phi],\n            [0, -1, -phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [1, -phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, -1],\n        ],\n        dtype=np.float32,\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 4],\n            [0, 4, 9],\n            [9, 4, 5],\n            [4, 8, 5],\n            [4, 1, 8],\n            [8, 1, 10],\n            [8, 10, 3],\n            [5, 8, 3],\n            [5, 3, 2],\n            [2, 3, 7],\n            [7, 3, 10],\n            [7, 10, 6],\n            [7, 6, "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]]).T\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]]).T\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [0, 1, -phi],\n            [0, -1, -phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [1, -phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, -1],\n        ]\n    ).T\n    base_faces = np.array(\n        [\n            [0, 1, 4],\n            [0, 4, 9],\n            [9, 4, 5],\n            [4, 8, 5],\n            [4, 1, 8],\n            [8, 1, 10],\n            [8, 10, 3],\n            [5, 8, 3],\n            [5, 3, 2],\n            [2, 3, 7],\n            [7, 3, 10],\n            [7, 10, 6],\n            [7, 6, 11],\n            [11, 6, 0],\n            [0, 6, 1],\n            [6, 10, 1],\n            [9, 11, "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [-1, -1, 1],\n            [-1, 1, -1],\n            [1, -1, -1],\n        ]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [0, 1, -phi],\n            [0, -1, -phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [1, -phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, 1],\n            [-phi, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 5, 1],\n            [0, 3, 5],\n            [0, 2, 3],\n            [0, 4, 2],\n            [0, 1, 4],\n            [1, 5, 8],\n            [1, 8, 3],\n            [3, 8, 7],\n            [3, 7, 2],\n            [2, 7, 10],\n            [2, 10, 4],\n            [4, 10, 9],\n            [4, 9, 1],\n            [5, 3, 11],\n            [5, 11, 8],\n            [8, 11,"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [-1, -1, 1],\n            [1, -1, -1],\n            [-1, 1, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 2, 3],\n            [0, 3, 1],\n            [1, 3, 2],\n        ]\n    )\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 1, 0.5 * np.sqrt(3)],\n            [0.5, 0.5 * np.sqrt(3), 0],\n            [-0.5, 0.5 * np.sqrt(3), 0],\n            [0, 1, -0.5 * np.sqrt(3)],\n            [0.5, -0.5 * np.sqrt(3), 0],\n            [-0.5, -0.5 * np.sqrt(3), 0],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 2, 3],\n            [0, 3, 4],\n            [0, 4, 1],\n            [1, 5, 2],\n            [2, 5, 3],\n            [3, 5, 4],\n            [4, 5, 1],\n        ]\n    )\n  elif base_shape == 'octahedron':\n    base_verts = np.array(\n        [\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0, 1, 0],\n            [0, -1, 0],\n            [0, 0, 1],\n            [0, 0, -1],"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [-0.5, -0.5, -0.5],\n            [-0.5, 0.5, 0.5],\n            [0.5, -0.5, 0.5],\n            [0.5, 0.5, -0.5],\n        ]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, -1, phi],\n            [0, 1, phi],\n            [0, -1, -phi],\n            [0, 1, -phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [1, -phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 4, 1],\n            [0, 9, 4],\n            [9, 5, 4],\n            [4, 5, 8],\n            [4, 8, 1],\n            [8, 10, 1],\n            [8, 3, 10],\n            [5, 3, 8],\n            [5, 2, 3],\n            [2, 7, 3],\n            [7, 10, 3],\n            [7, 6, 10],\n            [7, 11, 6],\n            [11, 0"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'base_shape {base_shape} not supported')\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [-1, -1, 1],\n            [-1, 1, -1],\n            [1, -1, -1],\n        ]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [0, 1, -phi],\n            [0, -1, -phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [1, -phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 4],\n            [0, 4, 9],\n            [9, 4, 5],\n            [4, 8, 5],\n            [4, 1, 8],\n            [8, 1, 10],\n            [8, 10, 3],\n            [5, 8, 3],\n            [5, 3, 2],\n            [2, 3, 7],\n            [7, 3, 10],\n            [7, 10"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [-1, -1, 1],\n            [-1, 1, -1],\n            [1, -1, -1],\n        ]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    # https://en.wikipedia.org/wiki/Regular_icosahedron\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [0, 1, -phi],\n            [0, -1, -phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [1, -phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, 1],\n            [-phi, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 5, 1],\n            [0, 3, 5],\n            [0, 2, 3],\n            [0, 4, 2],\n            [0, 1, 4],\n            [1, 5, 8],\n            [5, 3, 10],\n            [3, 2, 7],\n            [2, 4, 11],\n            [4, 1, 9],\n            [5, 11, 6],\n            [1, 8, 6],\n            [2, 10, 7],\n            [3, 7, 10"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [1, -1, -1],\n            [-1, 1, -1],\n            [-1, -1, 1],\n        ]\n    )\n    base_verts = base_verts / np.sqrt(3)\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [0, 1, -phi],\n            [0, -1, -phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [1, -phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, 1],\n            [-phi, 0, -1],\n        ]\n    )\n    base_verts = base_verts / np.sqrt(1 + phi**2)\n    base_faces = np.array(\n        [\n            [0, 5, 1],\n            [0, 3, 5],\n            [0, 2, 3],\n            [0, 4, 2],\n            [0, 1, 4],\n            [1, 5, 8],\n            [1, 8, 3],\n            [3, 8, 9],\n            [3, 9, 2],\n            [2, 9, 7],\n            [2, 7, 4],\n            [4, 7, 6],\n            [4, "}
{"namespace": "geopoly.generate_basis", "completion": "  # Define the vertices and faces of the starting polyhedron\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [-1, -1, 1],\n            [-1, 1, -1],\n            [1, -1, -1],\n        ]\n    )\n    base_faces = np.array([[0, 1, 2], [0, 1, 3], [0, 2, 3], [1, 2, 3]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [0, 1, -phi],\n            [0, -1, -phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [1, -phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 4],\n            [0, 4, 6],\n            [0, 6, 2],\n            [0, 2, 1],\n            [1, 4, 7],\n            [1, 7, 9],\n            [1, 9, 2],\n            [2, 9, 10],\n            [2, 10, 6],\n            [2, 6, 1],\n            [3, 5, 8],\n            [3, 8, 11],\n            [3, 11, 7],\n            [3, 7, 5],\n            [4, 5"}
{"namespace": "geopoly.generate_basis", "completion": "  # Define the vertices and faces of the starting polyhedron\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [1, -1, -1],\n            [-1, 1, -1],\n            [-1, -1, 1],\n        ],\n        dtype=np.float32,\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 2, 3],\n            [0, 3, 1],\n            [1, 3, 2],\n        ],\n        dtype=np.int32,\n    )\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [0, 1, -phi],\n            [0, -1, -phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [1, -phi, 0],\n            [-1, -phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, 1],\n            [phi, 0, -1],\n            [-phi, 0, -1],\n        ],\n        dtype=np.float32,\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 4],\n            [0, 4, 6],\n            [0, 6, 1],\n            [0, 1, 8],\n            [0, 8, 4],\n            [0, 4, 9],\n            [0, 9, 1],\n            [0, 1, 10],\n            [0, 10, 8],\n            [0, 8, 9],\n            [0"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(\n        f'base_shape {base_shape} must be one of \"tetrahedron\", \"icosahedron\", or \"octahedron\"'\n    )\n  if not isinstance(angular_tesselation, int):\n    raise ValueError(\n        f'angular_tesselation {angular_tesselation} must be an integer'\n    )\n  if angular_tesselation < 1:\n    raise ValueError(\n        f'angular_tesselation {angular_tesselation} must be greater than 0'\n    )\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [-1, -1, 1],\n            [1, -1, -1],\n            [-1, 1, -1],\n        ],\n        dtype=np.float32,\n    )\n    base_verts /= np.sqrt(3)\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 2, 3],\n            [0, 3, 1],\n            [1, 3, 2],\n        ],\n        dtype=np.int32,\n    )\n  elif base_shape == 'icosahedron':\n    base_verts = np.array(\n        [\n            [0, 1, 0.5],\n            [0.85065080835204, 0, -0.5257311121191336],\n            [0.85065080835204, 0, 0.5257311121191336],\n            [-0.85065080835204, 0, -0.52573111"}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape not in ['tetrahedron', 'icosahedron', 'octahedron']:\n    raise ValueError(f'Unknown base_shape {base_shape}')\n  if not isinstance(angular_tesselation, int):\n    raise ValueError(f'angular_tesselation {angular_tesselation} must be an int')\n  if angular_tesselation < 1:\n    raise ValueError(\n        f'angular_tesselation {angular_tesselation} must be >= 1'\n    )\n\n  if base_shape == 'tetrahedron':\n    base_verts = np.array([[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]])\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 2, 1],\n            [0, 3, 2],\n            [0, 4, 3],\n            [0, 1, 4],\n            [5, 1, 2],\n            [5, 2, 3],\n            [5, 3, 4],\n            [5, 4, 1],\n        ]\n    )\n  elif base_shape == 'octahedron':\n    base_verts = np.array(\n        [[1, 0, 0], [-1, "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [[1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1]]\n    ) / np.sqrt(3)\n    base_faces = np.array([[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]])\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, -1],\n        ]\n    )\n    base_faces = np.array(\n        [\n            [0, 2, 1],\n            [0, 3, 2],\n            [0, 4, 3],\n            [0, 1, 4],\n            [1, 2, 5],\n            [2, 3, 5],\n            [3, 4, 5],\n            [4, 1, 5],\n        ]\n    )\n  elif base_shape == 'octahedron':\n    base_verts = np.array(\n        [[1, 0, 0], [-1, 0, 0], [0, 1, 0], [0, -1, 0], [0, 0, 1], [0, 0, -1]]\n    )\n    base_faces = np.array(\n        [\n            [0, 2, 4],\n            [1, 4, 2],\n            [3, 2, 4],\n            [3, 4, 1],\n            [0, 5, 2],\n            [0, "}
{"namespace": "geopoly.generate_basis", "completion": "  if base_shape == 'tetrahedron':\n    base_verts = np.array(\n        [\n            [1, 1, 1],\n            [-1, -1, 1],\n            [1, -1, -1],\n            [-1, 1, -1],\n        ],\n        dtype=np.float32,\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 2],\n            [0, 2, 3],\n            [0, 3, 1],\n            [1, 3, 2],\n        ],\n        dtype=np.int32,\n    )\n  elif base_shape == 'icosahedron':\n    phi = (1 + np.sqrt(5)) / 2\n    base_verts = np.array(\n        [\n            [0, 1, phi],\n            [0, -1, phi],\n            [1, phi, 0],\n            [-1, phi, 0],\n            [phi, 0, 1],\n            [-phi, 0, -1],\n        ],\n        dtype=np.float32,\n    )\n    base_faces = np.array(\n        [\n            [0, 1, 5],\n            [1, 0, 2],\n            [1, 2, 3],\n            [1, 3, 4],\n            [1, 4, 5],\n            [0, 5, 4],\n            [0, 4, 3],\n            [0, 3, 2],\n            [5, 4, 2],\n            [5, 2, 3],\n        ],\n        dtype=np.int32,\n    )\n  elif base_shape == 'octahedron':\n    base_verts = np.array(\n        [\n            [1, 0, 0],\n            [-1, 0, 0],\n            [0, 1, 0],\n            [0, -1, 0"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + y),\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + y),\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + y),\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + jnp.maximum(tiny_val, x)),\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + x),\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + jnp.maximum(tiny_val, x)),\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + x),\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + jnp.maximum(tiny_val, x)),\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + jnp.maximum(tiny_val, x)),\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + jnp.clip(x, min_val, max_val)),\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + y),\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + jnp.clip(x, -1, 1)),\n      (min_val, 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (tiny_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + jnp.clip(x, min_val, max_val)),\n      (min_val, max_val),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + jnp.clip(x, -1, 1)),\n      (-1, 1),\n  )(x)"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda x, _, x_dot: x_dot / (1 + x),\n      (min_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + jnp.clip(x, -1, 1)),\n      (-1, 1),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + x),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + x),\n      (min_val, max_val),\n  )(x)\n\n"}
{"namespace": "math.safe_log1p", "completion": "  return generate_safe_fn(\n      jnp.log1p,\n      lambda _, y, x_dot: x_dot / (1 + y),\n      (min_val, np.nextafter(np.log(max_val), np.float32(0))),\n  )(x)\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n  if p == 1:\n    y = jnp.sign(x) * jnp.log1p(jnp.abs(x))\n  elif p == 0:\n    y = jnp.log(jnp.abs(x) + 1)\n  elif p == -jnp.inf:\n    y = jnp.sign(x)\n  elif p == jnp.inf:\n    y = jnp.sign(x) * jnp.log(jnp.abs(x))\n  else:\n    y = jnp.sign(x) * jnp.abs(x) ** (p - 1)\n  if postmult is not None:\n    y = y * postmult\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n  if p == 1:\n    y = safe_div(safe_sign(x), power_ladder_max_output(p))\n  elif p == 0:\n    y = safe_div(safe_sign(x), power_ladder_max_output(p))\n  elif p == -jnp.inf:\n    y = safe_div(safe_sign(x), power_ladder_max_output(p))\n  elif p == jnp.inf:\n    y = safe_div(safe_sign(x), power_ladder_max_output(p))\n  else:\n    y = safe_div(safe_sign(x) * safe_abs(x) ** (p - 1), power_ladder_max_output(p))\n  if postmult is not None:\n    y = y * postmult\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = jnp.abs(x)\n  elif p == 0:\n    y = jnp.sign(x)\n  elif p == -jnp.inf:\n    y = jnp.ones_like(x)\n  elif p == jnp.inf:\n    y = jnp.zeros_like(x)\n  else:\n    y = jnp.maximum(0, jnp.abs(x) ** p)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    x = jnp.log1p(x)\n  elif p == 0:\n    x = safe_exp(x)\n  elif p == -jnp.inf:\n    x = safe_log(x)\n  elif p == jnp.inf:\n    x = safe_log1p(x)\n  else:\n    x = safe_pow(x, p)\n\n  if postmult is not None:\n    x = x * postmult\n\n  return x"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = jnp.abs(x)\n  elif p == 0:\n    y = jnp.sign(x)\n  elif p == -jnp.inf:\n    y = jnp.maximum(jnp.abs(x), 1)\n  elif p == jnp.inf:\n    y = jnp.minimum(jnp.abs(x), 1)\n  else:\n    y = jnp.abs(x) ** p\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1\n  if postmult is None:\n    postmult = 1\n  return select(\n      [\n          (p == 1, premult * x * postmult),\n          (p == 0, premult * jnp.sqrt(jnp.abs(x)) * postmult),\n          (p == -jnp.inf, premult * jnp.sign(x) * postmult),\n          (p == jnp.inf, premult * jnp.sign(x) * jnp.abs(x) * postmult),\n      ],\n      premult * jnp.sign(x) * jnp.abs(x) ** (p - 1) * postmult,\n  )"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n  if p == 1:\n    y = safe_div(x, safe_div(1, jnp.abs(x)))\n  elif p == 0:\n    y = safe_div(safe_div(1, jnp.abs(x)), safe_div(1, jnp.abs(x)))\n  elif p == -jnp.inf:\n    y = safe_div(safe_div(1, jnp.abs(x)), safe_div(1, jnp.abs(x)))\n  elif p == jnp.inf:\n    y = safe_div(x, safe_div(1, jnp.abs(x)))\n  else:\n    y = safe_div(safe_div(x, safe_div(1, jnp.abs(x))), safe_div(1, jnp.abs(x)**p))\n  if postmult is not None:\n    y = y * postmult\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n  if p == 1:\n    y = safe_div(x, safe_sign(x))\n  elif p == 0:\n    y = jnp.log(safe_abs(x))\n  elif p == -jnp.inf:\n    y = safe_div(safe_sign(x), x)\n  else:\n    y = safe_div(jnp.power(safe_abs(x), p), p)\n  if postmult is not None:\n    y = y * postmult\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1\n  if postmult is None:\n    postmult = 1\n\n  return select(\n      [\n          (p == 1, x * premult * postmult),\n          (p == 0, jnp.log(x) * premult * postmult),\n          (p == -jnp.inf, jnp.exp(x) * premult * postmult),\n          (p == jnp.inf, safe_div(1, x) * premult * postmult),\n      ],\n      safe_div(jnp.power(x, p) * premult, power_ladder_max_output(p)) * postmult,\n  )"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = safe_log(x)\n  elif p == -jnp.inf:\n    y = jnp.where(x == 0, 0, safe_sign(x))\n  elif p == jnp.inf:\n    y = safe_log(safe_abs(x))\n  else:\n    y = safe_sign(x) * safe_pow(safe_abs(x), p)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n  x = jnp.abs(x)\n  if p == 1:\n    y = x\n  elif p == 0:\n    y = jnp.log(x)\n  elif p == -jnp.inf:\n    y = jnp.where(x >= 1, jnp.inf, jnp.where(x <= 0, -jnp.inf, 0))\n  elif p == jnp.inf:\n    y = jnp.where(x >= 1, 0, jnp.where(x <= 0, -jnp.inf, jnp.inf))\n  else:\n    y = jnp.sign(x) * jnp.abs(x) ** p\n  if postmult is not None:\n    y = y * postmult\n  return y"}
{"namespace": "math.power_ladder", "completion": "  x = jnp.asarray(x)\n  if premult is not None:\n    x = x * premult\n  if p == 1:\n    y = safe_div(x, jnp.abs(x))\n  elif p == 0:\n    y = safe_div(safe_sign(x), jnp.abs(x))\n  elif p == -jnp.inf:\n    y = safe_div(safe_sign(x), jnp.abs(x) + 1)\n  else:\n    y = safe_div(safe_sign(x) * safe_pow(safe_abs(x), p - 1), jnp.abs(x))\n  if postmult is not None:\n    y = y * postmult\n  return y"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n  if p == 1:\n    y = jnp.abs(x)\n  elif p == 0:\n    y = jnp.sign(x)\n  elif p == -jnp.inf:\n    y = jnp.where(x == 0, 1, 0)\n  elif p == jnp.inf:\n    y = jnp.where(jnp.abs(x) == jnp.inf, 1, 0)\n  else:\n    y = jnp.abs(x) ** p\n  if postmult is not None:\n    y = y * postmult\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1\n  if postmult is None:\n    postmult = 1\n  return select(\n      [\n          (p == 1, safe_div(x, premult * power_ladder_max_output(p)) * postmult),\n          (p == 0, safe_div(safe_sign(x) * jnp.log(1 + jnp.abs(x)), premult) * postmult),\n          (p == -jnp.inf, safe_div(safe_sign(x), premult) * postmult),\n          (p == jnp.inf, safe_div(jnp.abs(x), premult) * postmult),\n      ],\n      safe_div(safe_sign(x) * jnp.abs(x) ** (p - 1), premult) * postmult,\n  )"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = jnp.abs(x)\n  elif p == 0:\n    y = jnp.sign(x)\n  elif p == -jnp.inf:\n    y = jnp.sign(x) * jnp.log(1 + jnp.abs(x))\n  elif p == jnp.inf:\n    y = jnp.sign(x) * safe_exp(jnp.abs(x))\n  else:\n    y = jnp.sign(x) * safe_pow(jnp.abs(x), p)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n  if p == 1:\n    x = safe_log1p(x)\n  elif p == 0:\n    x = safe_log(x)\n  elif p == -jnp.inf:\n    x = safe_log(1 / (1 + x))\n  elif p == jnp.inf:\n    x = safe_log(1 + x)\n  else:\n    x = safe_log(safe_pow(1 + x, p)) / p\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n  if p == 1:\n    return x\n  if p == 0:\n    return jnp.log(x)\n  if p == -jnp.inf:\n    return jnp.where(x == 0, 0, safe_div(1, x))\n  if p == jnp.inf:\n    return safe_div(1, x)\n  x = jnp.where(x == 0, 1, x)\n  x = jnp.where(x < 0, -safe_div(jnp.abs(x) + 1, jnp.abs(x)), x)\n  x = jnp.where(x > 1, safe_div(x + 1, x), x)\n  x = jnp.where(x < -1, safe_div(jnp.abs(x) + 1, jnp.abs(x)), x)\n  x = jnp.where(x > 0, jnp.sign(x) * jnp.abs(x)**p, -jnp.sign(x) * jnp.abs(x)**p)\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    x = safe_sqrt(x)\n  elif p == 0:\n    x = safe_log(x)\n  elif p == -jnp.inf:\n    x = safe_exp(x)\n  elif p == jnp.inf:\n    x = safe_log(safe_exp(x))\n  else:\n    x = safe_pow(x, p)\n\n  if postmult is not None:\n    x = x * postmult\n\n  return x\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is not None:\n    x = x * premult\n\n  if p == 1:\n    y = safe_sign(x) * safe_log1p(safe_abs(x))\n  elif p == 0:\n    y = safe_log(safe_abs(x))\n  elif p == -jnp.inf:\n    y = safe_sign(x)\n  elif p == jnp.inf:\n    y = safe_abs(x)\n  else:\n    y = safe_sign(x) * safe_pow(safe_abs(x), p)\n\n  if postmult is not None:\n    y = y * postmult\n\n  return y\n\n"}
{"namespace": "math.power_ladder", "completion": "  if premult is None:\n    premult = 1.0\n  if postmult is None:\n    postmult = 1.0\n\n  if p == 1:\n    return jnp.where(x >= 0, x * premult, -x * postmult)\n  if p == 0:\n    return jnp.where(x >= 0, x * premult, x * postmult)\n  if p == -jnp.inf:\n    return jnp.where(x >= 0, x * premult, jnp.where(x < 0, jnp.inf, 0) * postmult)\n  if p == jnp.inf:\n    return jnp.where(x >= 0, x * premult, jnp.where(x < 0, -jnp.inf, 0) * postmult)\n\n  return jnp.where(\n      x >= 0,\n      jnp.where(\n          jnp.abs(x) < tiny_val,\n          jnp.where(p > 0, x * premult, jnp.where(p < 0, x * postmult, 0)),\n          jnp.where(\n              p > 0,\n              jnp.where(\n                  p < 1,\n                  jnp.where(\n                      p < 0,\n                      jnp.sign(x) * safe_pow(jnp.abs(x), p) * premult,\n                      jnp.where(\n                          p > 1,\n                          jnp.where(\n                              jnp.abs(x) > 1,\n                              jnp.sign(x) * safe_pow(jnp.abs(x), p) * postmult,\n                              x * premult,\n                          ),\n                          x * postmult,\n                      ),\n                  ),\n                  jnp.sign(x) * safe_pow(jnp.abs(x), p) * postmult,\n              ),\n          ),\n      )\n      * jnp.where(p < 0, -1, 1),\n      jnp.where(\n          jnp.abs(x) < tiny_val,\n          jnp.where(p > 0, x * premult, j"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y * postmult\n  if premult is not None:\n    y = y / premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((jnp.abs(y) + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_exp(yp) - 1),\n          (p == -jnp.inf, -safe_log(1 - yp)),\n          (p == jnp.inf, safe_log(1 + yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((yp + 1) ** p_safe - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y * postmult\n  if premult is not None:\n    y = y / premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  return safe_sign(y) * x"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * (safe_exp(jnp.abs(y) * p_safe) - 1)\n      ),\n  )\n  if postmult is not None:\n    y = y * postmult\n  return y"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  if postmult is not None:\n    y = y / postmult\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((jnp.abs(y) + 1) ** (1 / p_safe) - 1)\n      ),\n  )\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y / postmult\n  yp = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((yp + 1) ** p_safe - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  if postmult is not None:\n    y = y / postmult\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      safe_div(\n          jnp.abs(p_safe - 1), p_safe * (y + 1) ** (1 / p_safe) - 1\n      ),\n  )\n  return y"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_expm1(y)),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      clip_finite_nograd(\n          jnp.sign(y) * jnp.abs(p_safe - 1) / p_safe * (jnp.abs(y) + 1) ** (1 / p_safe) - 1\n      ),\n  )\n  if postmult is not None:\n    y = y * postmult\n  return y"}
{"namespace": "math.inv_power_ladder", "completion": "  if postmult is not None:\n    y = y * postmult\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.sign(y)\n          * jnp.abs(p_safe - 1)\n          * (yp ** (1 / p_safe) - 1)\n          * jnp.abs(p_safe - 1)\n          / p_safe\n      ),\n  )\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  if p == 1:\n    x = y\n  elif p == 0:\n    x = safe_expm1(y)\n  elif p == -jnp.inf:\n    x = -safe_expm1(-y)\n  elif p == jnp.inf:\n    x = safe_expm1(y)\n  else:\n    p_safe = clip_finite_nograd(remove_zero(p))\n    x = safe_sign(y) * select(\n        [\n            (p == -1, y),\n            (p == 0, safe_log1p(y)),\n            (p == jnp.inf, safe_expm1(y)),\n            (p == -jnp.inf, -safe_expm1(-y)),\n        ],\n        clip_finite_nograd(\n            jnp.abs(p_safe - 1) / p_safe * ((safe_abs(y) + 1) ** p_safe - 1)\n        ),\n    )\n  if postmult is not None:\n    x = x * postmult\n  return x"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_expm1(yp)),\n          (p == -jnp.inf, -safe_log1p(-yp)),\n          (p == jnp.inf, safe_log1p(yp)),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  # Compute sign(y) * |p - 1|/p * ((|y|/|p-1| + 1)^p - 1)\n  if postmult is not None:\n    y = y * postmult\n  yp = jnp.abs(y)\n  ys = yp / jnp.maximum(tiny_val, jnp.abs(p - 1))\n  p_safe = clip_finite_nograd(remove_zero(p))\n  x = safe_sign(y) * select(\n      [\n          (p == 1, yp),\n          (p == 0, safe_exp(yp) - 1),\n          (p == -jnp.inf, -safe_exp(-yp) + 1),\n          (p == jnp.inf, safe_exp(yp) - 1),\n      ],\n      clip_finite_nograd(\n          jnp.abs(p_safe - 1) / p_safe * ((ys + 1) ** p_safe - 1)\n      ),\n  )\n  if premult is not None:\n    x = x * premult\n  return x\n\n"}
{"namespace": "math.inv_power_ladder", "completion": "  if premult is not None:\n    y = y * premult\n  p_safe = clip_finite_nograd(remove_zero(p))\n  y = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_exp(y) - 1),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      y,\n  )\n  y = jnp.abs(y)\n  x = select(\n      [\n          (p == 1, y),\n          (p == 0, safe_exp(y) - 1),\n          (p == -jnp.inf, -safe_log1p(-y)),\n          (p == jnp.inf, safe_log1p(y)),\n      ],\n      jnp.sign(y) * safe_div(jnp.abs(p_safe - 1), p_safe) * (y**(1 / p_safe) - 1),\n  )\n  if postmult is not None:\n    x = x * postmult\n  return x"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid nan for steps < lr_delay_steps\n    lr_step_ratio = jnp.minimum(step / lr_delay_steps, 1.0)\n    lr_mult = lr_delay_mult + (1.0 - lr_delay_mult) * lr_step_ratio\n  else:\n    lr_mult = 1.0\n  lr_step_ratio = jnp.minimum(step / max_steps, 1.0)\n  lr = lr_mult * lr_init * 0.5 * (\n      1.0 + jnp.cos(jnp.pi * lr_step_ratio)\n  )\n  lr = jnp.maximum(0.0, lr)\n  if lr_final:\n    lr = jnp.maximum(lr, lr_final)\n  return lr"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # A kind of reverse cosine decay.\n    delay_rate = lr_delay_mult + (1 - lr_delay_mult) * jnp.sin(\n        0.5 * jnp.pi * jnp.clip(step / lr_delay_steps, 0, 1)\n    )\n  else:\n    delay_rate = 1.0\n  t = jnp.clip(step / max_steps, 0, 1)\n  log_lerp_t = jnp.clip(5 * (t - 1.0), 0, 1)\n  return jnp.exp(jnp.log(delay_rate) + log_lerp(log_lerp_t, lr_init, lr_final))\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid nan for steps < lr_delay_steps\n    lr_step_ratio = jnp.maximum(\n        0.0, (step - lr_delay_steps) / (max_steps - lr_delay_steps)\n    )\n    lr = lr_multiplier(lr_step_ratio, lr_init, lr_final, lr_delay_mult)\n  else:\n    lr_step_ratio = step / max_steps\n    lr = lr_multiplier(lr_step_ratio, lr_init, lr_final)\n\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid nan for steps < lr_delay_steps\n    lr_step_ratio = jnp.minimum(step / lr_delay_steps, 1.0)\n    lr_mult = (1 - lr_delay_mult) * lr_step_ratio + lr_delay_mult\n  else:\n    lr_mult = 1.0\n  lr_step_ratio = (step - lr_delay_steps) / (max_steps - lr_delay_steps)\n  lr = lr_mult * lr_final + (1 - lr_mult) * lr_init\n  return 0.5 * lr * (1 + jnp.cos(jnp.pi * lr_step_ratio))\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid nan for steps < lr_delay_steps\n    lr_step_ratio = jnp.maximum(\n        min_val, (step - lr_delay_steps) / (max_steps - lr_delay_steps)\n    )\n    lr = lr_multiplier(\n        lr_step_ratio, lr_init * lr_delay_mult, lr_final * lr_delay_mult\n    )\n  else:\n    lr_step_ratio = step / max_steps\n    lr = lr_multiplier(lr_step_ratio, lr_init, lr_final)\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid nan for steps < lr_delay_steps\n    lr_step_ratio = jnp.maximum(\n        jnp.float32(step - lr_delay_steps) / jnp.float32(max_steps - lr_delay_steps),\n        0.0,\n    )\n    lr = lr_multiplier(\n        lr_step_ratio, lr_init * lr_delay_mult, lr_final * lr_delay_mult\n    )\n  else:\n    lr = lr_multiplier(jnp.float32(step) / jnp.float32(max_steps), lr_init, lr_final)\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid nan for steps < lr_delay_steps\n    lr_step_ratio = jnp.maximum(\n        jnp.minimum(1.0, step / lr_delay_steps), 1e-8\n    )\n    lr_mult = lr_delay_mult + (1.0 - lr_delay_mult) * lr_step_ratio\n  else:\n    lr_mult = 1.0\n  lr_step_ratio = jnp.minimum(step / max_steps, 1.0)\n  lr = lr_mult * lr_init * 0.5 * (\n      1.0 + jnp.cos(jnp.pi * lr_step_ratio)\n  )\n  lr = lr_final + (lr_init - lr_final) * lr\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid repeated-if branches.\n    lr_init = lr_init * lr_delay_mult\n    progress = jnp.maximum(0.0, (step - lr_delay_steps) / (max_steps - lr_delay_steps))\n  else:\n    progress = step / max_steps\n  lr_step = lr_init * 0.5 * (1.0 + jnp.cos(jnp.pi * progress))\n  lr = lr_final + (lr_step - lr_final) * (1.0 - progress)\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid nan for steps < lr_delay_steps\n    lr_step_ratio = jnp.minimum(step / lr_delay_steps, 1.0)\n    lr_mult = lr_delay_mult + (1.0 - lr_delay_mult) * lr_step_ratio\n  else:\n    lr_mult = 1.0\n  lr_step_ratio = jnp.minimum(step / max_steps, 1.0)\n  lr = lr_mult * lr_init * 0.5 * (\n      1.0 + jnp.cos(jnp.pi * lr_step_ratio)\n  )\n  lr = jnp.maximum(0.0, lr_final + (lr_init - lr_final) * lr)\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid dividing by 0\n    lr_delay_mult = jnp.where(lr_delay_mult == 0, 0.01, lr_delay_mult)\n    # Avoid negative multiplier\n    lr_delay_mult = jnp.maximum(lr_delay_mult, 0.01)\n    # Avoid negative steps\n    lr_delay_steps = jnp.maximum(lr_delay_steps, 1)\n\n    # Interpolate the initial learning rate\n    lr_init = lr_init * lr_delay_mult\n    # Calculate the progression of steps after the delay\n    progress = (step - lr_delay_steps) / (max_steps - lr_delay_steps)\n    # Clip the progression to the range [0, 1]\n    progress = jnp.clip(progress, 0, 1)\n    # Interpolate the learning rate using a log-linear function\n    lr = lr_init * jnp.exp(progress * jnp.log(lr_final / lr_init))\n  else:\n    # Calculate the progression of steps without the delay\n    progress = step / max_steps\n    # Clip the progression to the range [0, 1]\n    progress = jnp.clip(progress, 0, 1)\n    # Interpolate the learning rate using a log-linear function\n    lr = lr_init * jnp.exp(progress * jnp.log(lr_final / lr_init))\n\n  return jnp.asarray(lr, dtype=jnp.float32)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid nan for steps < lr_delay_steps\n    lr_step_ratio = jnp.maximum(\n        jnp.float32(step - lr_delay_steps) / jnp.float32(max_steps - lr_delay_steps),\n        0.0,\n    )\n    lr = lr_init * (lr_delay_mult + (1.0 - lr_delay_mult) * lr_step_ratio)\n  else:\n    lr_step_ratio = jnp.float32(step) / jnp.float32(max_steps)\n    lr = lr_init * lr_step_ratio\n  # Perform linear interpolation in log space.\n  lr = jnp.clip(lr_init + (lr_final - lr_init) * lr_step_ratio, 0.0, 1.0)\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid nan for steps < lr_delay_steps\n    lr_step_ratio = jnp.maximum(\n        jnp.float32(step - lr_delay_steps) / jnp.float32(max_steps - lr_delay_steps),\n        0.0,\n    )\n    lr = lr_multiplier(\n        lr_step_ratio, lr_init * lr_delay_mult, lr_final * lr_delay_mult\n    )\n  else:\n    lr_step_ratio = jnp.float32(step) / jnp.float32(max_steps)\n    lr = lr_multiplier(lr_step_ratio, lr_init, lr_final)\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid divide-by-zero for steps < lr_delay_steps\n    lr_delay_mult = jnp.where(step >= lr_delay_steps, 1.0, lr_delay_mult)\n    lr_delay_mult = jnp.where(\n        step == 0,\n        jnp.zeros_like(lr_delay_mult),\n        lr_delay_mult,\n    )\n    lr = lr_init * lr_delay_mult\n  else:\n    lr = lr_init\n  lr = jnp.where(step >= max_steps, lr_final, lr)\n  t = (step - lr_delay_steps) / (max_steps - lr_delay_steps)\n  t = jnp.clip(t, 0, 1)\n  return lr * jnp.exp(t * jnp.log(lr_final / lr_init))\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid repeated-if branches.\n    lr_delay_mult = jnp.where(step >= lr_delay_steps, 1.0, lr_delay_mult)\n    progress = jnp.clip(\n        (step - lr_delay_steps) / (max_steps - lr_delay_steps), 0, 1\n    )\n  else:\n    progress = jnp.clip(step / max_steps, 0, 1)\n  return lr_multiplier(lr_init, lr_final, progress) * lr_delay_mult\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid subtracting 1 to max_steps, which gives a negative value in the case\n    # of 0 steps.\n    max_steps = jnp.where(max_steps <= 1, 1, max_steps - 1)\n    # If `step` is smaller than `lr_delay_steps`, use `lr_init * lr_delay_mult`.\n    delay_rate = lr_delay_mult\n  else:\n    # If no delay is specified, use the original learning rate schedule.\n    delay_rate = 1.0\n\n  t = jnp.clip(step / max_steps, 0, 1)\n  log_lerp_t = (1 - delay_rate) * log_lerp(t, lr_init, lr_final) + delay_rate * lr_init\n  return jnp.where(\n      step <= lr_delay_steps,\n      log_lerp_t,\n      log_lerp_t,\n  )\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid repeated-if checks in the loop below during initialization.\n    if step < lr_delay_steps:\n      return lr_init * lr_delay_mult\n    if step == lr_delay_steps:\n      return lr_init\n\n  t = step / max_steps\n  lr_delay_mult = jnp.where(step <= lr_delay_steps, 1.0, lr_delay_mult)\n  lr = lr_delay_mult * (lr_init - lr_final) * 0.5 * jnp.cos(\n      jnp.pi * t\n  ) + lr_delay_mult * (lr_init + lr_final) * 0.5\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid nan for steps < lr_delay_steps\n    lr_step_ratio = jnp.maximum(\n        step / lr_delay_steps, jnp.full_like(step, lr_delay_mult)\n    )\n    lr = lr_init * (lr_delay_mult * lr_step_ratio) / lr_delay_steps\n  else:\n    lr = lr_init\n  lr = jnp.minimum(lr, lr_final * (1 - step / max_steps) ** 2)\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid dividing by 0\n    lr_delay_mult = jnp.where(lr_delay_mult == 0, 0.01, lr_delay_mult)\n    # Avoid negative multiplier\n    lr_delay_mult = jnp.where(lr_delay_mult < 0, -lr_delay_mult, lr_delay_mult)\n    # Delayed learning rate\n    lr_init = lr_init * lr_delay_mult\n    # Avoid 0 steps\n    max_steps = jnp.where(max_steps == 0, 1, max_steps)\n    lr_delay_steps = jnp.minimum(lr_delay_steps, max_steps)\n    # Step ratio for the decay\n    decay_steps = jnp.maximum(step - lr_delay_steps, 0) / (\n        max_steps - lr_delay_steps\n    )\n    # Log-linear decay\n    log_lerp_ratio = jnp.exp(jnp.log(lr_final / lr_init) * decay_steps)\n    # Linear decay\n    lerp_ratio = decay_steps\n    # Final learning rate\n    lr = lr_init * lerp_ratio * log_lerp_ratio\n  else:\n    # Linear decay\n    lr = lr_init * (1 - step / max_steps)\n    # Log-linear decay\n    # lr = lr_init * jnp.exp(jnp.log(lr_final / lr_init) * step / max_steps)\n  # Avoid too small learning rate\n  lr = jnp.maximum(lr, 1e-7 * lr_init)\n  return lr\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # Avoid nan for steps < lr_delay_steps\n    lr_step_ratio = jnp.maximum(\n        jnp.minimum(step / lr_delay_steps, 1.0), 0.0\n    )\n    lr_mult = (1 - lr_delay_mult) * lr_step_ratio + lr_delay_mult\n  else:\n    lr_mult = 1.0\n  lr = lr_mult * lr_init * 0.5 * (\n      1.0 + jnp.cos(jnp.pi * jnp.clip(step / max_steps, 0, 1.0))\n  )\n  if lr_delay_steps > 0:\n    lr *= jnp.sin(\n        (jnp.pi / 2) * jnp.clip(step / lr_delay_steps, 0, 1)\n    ) ** 2\n  return jnp.clip(lr, lr_final, lr_init)\n\n"}
{"namespace": "math.learning_rate_decay", "completion": "  if lr_delay_steps > 0:\n    # A simple linear ramp from the full learning rate to the delayed learning rate.\n    lr_delayed = lr_init * lr_delay_mult\n    lr_ramp = jnp.linspace(lr_delayed, lr_init, lr_delay_steps)\n    lr = jnp.where(step < lr_delay_steps, lr_ramp, lr_init)\n  else:\n    lr = lr_init\n\n  # We then apply the usual log-linear interpolation between the initial and final\n  # learning rates based on the current step.\n  t = jnp.clip(step / max_steps, 0, 1)\n  log_lerp_t = jnp.exp(jnp.clip(5 * (t - 1), -5, 0))\n  lr = jnp.where(t > 0.9995, lr_final, log_lerp_t * lr + (1 - log_lerp_t) * lr_final)\n\n  return lr\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  return generate_random_rays(\n      rng,\n      1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=2.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  return generate_random_rays(\n      rng,\n      n=1,\n      origin_lo=0.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=0.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  random_rays = generate_random_rays(\n      rng,\n      1024,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=2.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n  return random_rays"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  random_rays = generate_random_rays(\n      rng,\n      1,\n      -1.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n  return random_rays"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=0.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=0.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=1.0,\n      far_hi=2.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  random_rays = generate_random_rays(\n      rng,\n      n=1,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0.1,\n      radius_hi=0.1,\n      near_lo=0.0,\n      near_hi=0.0,\n      far_lo=1.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n  return random_rays"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  rays = generate_random_rays(\n      rng,\n      n=1,\n      origin_lo=-1.0,\n      origin_hi=1.0,\n      radius_lo=0.0,\n      radius_hi=1.0,\n      near_lo=0.0,\n      near_hi=1.0,\n      far_lo=0.0,\n      far_hi=1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n  return rays"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=10,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0.01,\n      radius_hi=0.1,\n      near_lo=0.01,\n      near_hi=1,\n      far_lo=1,\n      far_hi=10,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  return generate_random_rays(\n      rng=random.PRNGKey(0),\n      n=10,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0.1,\n      radius_hi=0.2,\n      near_lo=1,\n      near_hi=2,\n      far_lo=3,\n      far_hi=4,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  return generate_random_rays(\n      rng,\n      1024,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0.01,\n      radius_hi=0.1,\n      near_lo=0.0,\n      near_hi=0.1,\n      far_lo=1.0,\n      far_hi=2.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  n = 1\n  origin_lo = -1\n  origin_hi = 1\n  radius_lo = 0.01\n  radius_hi = 1\n  near_lo = 0.01\n  near_hi = 1\n  far_lo = 0.01\n  far_hi = 1\n  return generate_random_rays(\n      rng,\n      n,\n      origin_lo,\n      origin_hi,\n      radius_lo,\n      radius_hi,\n      near_lo,\n      near_hi,\n      far_lo,\n      far_hi,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  return generate_random_rays(\n      rng,\n      1024,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0.001,\n      radius_hi=0.1,\n      near_lo=0.1,\n      near_hi=1,\n      far_lo=1,\n      far_hi=10,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  return generate_random_rays(\n      rng,\n      n=1,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0.1,\n      radius_hi=0.1,\n      near_lo=0,\n      near_hi=0,\n      far_lo=1,\n      far_hi=1,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  return generate_random_rays(\n      rng,\n      1,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0.1,\n      radius_hi=1,\n      near_lo=0.1,\n      near_hi=1,\n      far_lo=1,\n      far_hi=10,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  rays = generate_random_rays(\n      rng,\n      1,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0.1,\n      radius_hi=0.1,\n      near_lo=0.1,\n      near_hi=1,\n      far_lo=1,\n      far_hi=2,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n  return rays\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  random_rays = generate_random_rays(\n      rng,\n      1,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0.1,\n      radius_hi=1,\n      near_lo=0,\n      near_hi=1,\n      far_lo=1,\n      far_hi=2,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n  return random_rays\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  random_rays = generate_random_rays(\n      rng,\n      n=1,\n      origin_lo=-1,\n      origin_hi=1,\n      radius_lo=0.1,\n      radius_hi=0.2,\n      near_lo=0,\n      near_hi=1,\n      far_lo=1,\n      far_hi=2,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n  return random_rays\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  random_rays = generate_random_rays(\n      rng,\n      1,\n      -100,\n      100,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      0.0,\n      1.0,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n  return random_rays\n\n"}
{"namespace": "utils.dummy_rays", "completion": "  rng = random.PRNGKey(0)\n  random_rays = generate_random_rays(\n      rng,\n      n=1,\n      origin_lo=-100,\n      origin_hi=100,\n      radius_lo=0.01,\n      radius_hi=1,\n      near_lo=0,\n      near_hi=1,\n      far_lo=1,\n      far_hi=2,\n      include_exposure_idx=include_exposure_idx,\n      include_exposure_values=include_exposure_values,\n      include_device_idx=include_device_idx,\n  )\n  return random_rays\n\n"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          points,\n          points + xnp.array([1.0, 0.0, 0.0]),\n          points + xnp.array([0.0, 1.0, 0.0]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  point_dirs_stacked = xnp.stack(\n      [\n          points,\n          points + xnp.array([1.0, 0.0, 0.0]),\n          points + xnp.array([0.0, 1.0, 0.0]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, point_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  point_dirs_stacked = xnp.stack(\n      [\n          points,\n          points + xnp.array([1.0, 0.0, 0.0]),\n          points + xnp.array([0.0, 1.0, 0.0]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, point_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def dir_to_pix(x, y):\n    return xnp.stack([x - 0.5, y - 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  point_dirs_stacked = xnp.stack(\n      [\n          dir_to_pix(points[Ellipsis, 0], points[Ellipsis, 1]),\n          dir_to_pix(points[Ellipsis, 0] + 1, points[Ellipsis, 1]),\n          dir_to_pix(points[Ellipsis, 0], points[Ellipsis, 1] + 1),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, point_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def dir_to_pix(x, y):\n    return xnp.stack([x - 0.5, y - 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          dir_to_pix(points[Ellipsis, 0], points[Ellipsis, 1]),\n          dir_to_pix(points[Ellipsis, 0], points[Ellipsis, 1] + 1),\n          dir_to_pix(points[Ellipsis, 0] + 1, points[Ellipsis, 1]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  points_stacked = xnp.stack([points, points, points], axis=0)\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, points_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,\n            camera_dirs_stacked[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANOR"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  points_stacked = xnp.stack(\n      [\n          points,\n          points + xnp.array([1.0, 0.0, 0.0]),\n          points + xnp.array([0.0, 1.0, 0.0]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply camera rotation matrices.\n  camera_dirs_stacked = mat_vec_mul(\n      camtoworlds[Ellipsis, :3, :3], points_stacked\n  )\n  # Extract the offset rays.\n  directions, dx, dy = camera_dirs_stacked\n\n  origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, -1], directions.shape)\n  viewdirs = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, camera_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_distort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  points_stacked = xnp.stack(\n      [\n          points,\n          points + xnp.array([1.0, 0.0, 0.0]),\n          points + xnp.array([0.0, 1.0, 0.0]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply camera rotation matrices.\n  camera_dirs_stacked = mat_vec_mul(\n      camtoworlds[Ellipsis, :3, :3], points_stacked\n  )\n  # Extract the offset rays.\n  directions, dx, dy = camera_dirs_stacked\n\n  origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, -1], directions.shape)\n  viewdirs = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_distort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def point_to_pixel(x, y, z):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  point_dirs_stacked = xnp.stack(\n      [\n          point_to_pixel(points[Ellipsis, 0], points[Ellipsis, 1], points[Ellipsis, 2]),\n          point_to_pixel(points[Ellipsis, 0] + 1, points[Ellipsis, 1], points[Ellipsis, 2]),\n          point_to_pixel(points[Ellipsis, 0], points[Ellipsis, 1] + 1, points[Ellipsis, 2]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, point_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n "}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  points_stacked = xnp.stack(\n      [\n          points,\n          points + xnp.array([1.0, 0.0, 0.0]),\n          points + xnp.array([0.0, 1.0, 0.0]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply camera rotation matrices.\n  camera_dirs_stacked = mat_vec_mul(\n      camtoworlds[Ellipsis, :3, :3], points_stacked\n  )\n  # Extract the offset rays.\n  directions, dx, dy = camera_dirs_stacked\n\n  origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, -1], directions.shape)\n  viewdirs = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, 0]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,\n            camera_dirs_stacked[Ellipsis, 1] * sin_theta_over_theta,"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  point_dirs_stacked = xnp.stack(\n      [\n          points,\n          points + xnp.array([1.0, 0.0, 0.0]),\n          points + xnp.array([0.0, 1.0, 0.0]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, point_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked[Ellipsis, 0] * sin_theta_over_theta,"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  points_stacked = xnp.stack(\n      [\n          points,\n          points + xnp.array([1.0, 0.0, 0.0]),\n          points + xnp.array([0.0, 1.0, 0.0]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply extrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_distort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked[Ellipsis, 0] * sin_theta_"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  # TODO(barron): Add a unit test that this is correct.\n  pixel_dirs_stacked = xnp.stack(\n      [\n          points,\n          points + xnp.array([1.0, 0.0, 0.0]),\n          points + xnp.array([0.0, 1.0, 0.0]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, pixel_dirs_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, :2]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs_stacked = xnp.stack(\n        [\n            camera_dirs_stacked["}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def point_to_pixel(x, y, z):\n    return xnp.stack([x + 0.5, y + 0.5, xnp.ones_like(x)], axis=-1)\n\n  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  points_stacked = xnp.stack(\n      [\n          point_to_pixel(points[Ellipsis, 0], points[Ellipsis, 1], points[Ellipsis, 2]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply inverse intrinsic matrices.\n  camera_dirs_stacked = mat_vec_mul(pixtocams, points_stacked)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_undistort(\n        camera_dirs_stacked[Ellipsis, 0],\n        camera_dirs_stacked[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs_stacked = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs_stacked[Ellipsis, 0]), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta)"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # We need the dx and dy rays to calculate ray radii for mip-NeRF cones.\n  # TODO(barron): Add a unit test that this is correct.\n  points_stacked = xnp.stack(\n      [\n          points,\n          points + xnp.array([1.0, 0.0, 0.0]),\n          points + xnp.array([0.0, 1.0, 0.0]),\n      ],\n      axis=0,\n  )\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply camera rotation matrices.\n  points_cam_stacked = mat_vec_mul(\n      camtoworlds[Ellipsis, :3, :3], points_stacked\n  )\n  # Extract the offset rays.\n  points_cam, dx_cam, dy_cam = points_cam_stacked\n\n  # Flip from OpenCV to OpenGL coordinate system.\n  points_cam = matmul(\n      points_cam, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n  )\n  dx_cam = matmul(dx_cam, xnp.diag(xnp.array([1.0, -1.0, -1.0])))\n  dy_cam = matmul(dy_cam, xnp.diag(xnp.array([1.0, -1.0, -1.0])))\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_distort(\n        points_cam[Ellipsis, 0],\n        points_cam[Ellipsis, 1],\n        **distortion_params,\n        x"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def point_to_dir(p):\n    return xnp.concatenate([p, xnp.ones_like(p[Ellipsis, :1])], axis=-1)\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply extrinsic matrices.\n  camera_dirs = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points)\n  camera_dirs += camtoworlds[Ellipsis, :3, -1]\n\n  # Apply distortion.\n  if distortion_params is not None:\n    x, y = _radial_and_tangential_distort(\n        camera_dirs[Ellipsis, 0],\n        camera_dirs[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_dirs = xnp.stack([x, y, xnp.ones_like(x)], -1)\n\n  if camtype == ProjectionType.FISHEYE:\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_dirs), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    sin_theta_over_theta = xnp.sin(theta) / theta\n    camera_dirs = xnp.stack(\n        [\n            camera_dirs[Ellipsis, 0] * sin_theta_over_theta,\n            camera_dirs[Ellipsis, 1] * sin_theta_over_theta,\n            xnp.cos(theta),\n        ],\n        axis=-1,\n    )\n\n  elif cam"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def dir_to_pix(d):\n    return d[Ellipsis, :2] - 0.5\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply camera rotation matrices.\n  camera_points = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points)\n  # Extract the offset rays.\n  camera_points = camera_points / camera_points[Ellipsis, 2:]\n\n  if camtype == ProjectionType.FISHEYE:\n    r = xnp.linalg.norm(camera_points[Ellipsis, :2], axis=-1)\n    theta = xnp.arctan2(r, camera_points[Ellipsis, 2])\n    camera_points = xnp.stack(\n        [\n            camera_points[Ellipsis, 0] * theta / r,\n            camera_points[Ellipsis, 1] * theta / r,\n            theta,\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = xnp.arctan2(camera_points[Ellipsis, 0], camera_points[Ellipsis, 2])\n    phi = xnp.arctan2(\n        camera_points[Ellipsis, 1],\n        xnp.sqrt(camera_points[Ellipsis, 0] ** 2 + camera_points[Ellipsis, 2] ** 2),\n    )\n    camera_points = xnp.stack([theta, phi, xnp.ones_like(theta)], axis=-1"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def dir_to_pix(d):\n    return d[Ellipsis, :2] - 0.5\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply camera rotation matrices.\n  camera_points = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points)\n\n  if camtype == ProjectionType.FISHEYE:\n    # Calculate the norm of the camera points.\n    norm = xnp.linalg.norm(camera_points, axis=-1)\n    # Calculate the radius of the sphere.\n    theta = xnp.arctan2(norm, camera_points[Ellipsis, -1])\n    # Calculate the new camera points.\n    camera_points = xnp.stack(\n        [\n            camera_points[Ellipsis, 0] * theta / norm,\n            camera_points[Ellipsis, 1] * theta / norm,\n            camera_points[Ellipsis, 2] * theta / norm,\n        ],\n        axis=-1,\n    )\n\n  elif camtype == ProjectionType.PANORAMIC:\n    # Calculate theta and phi.\n    theta = xnp.arctan2(camera_points[Ellipsis, 0], -camera_points[Ellipsis, 2])\n    phi = xnp.arccos(camera_points[Ellipsis, 1] / xnp.linalg.norm(camera_points, axis=-1))\n    # Calculate the new camera points.\n    camera_points = xnp.stack(\n        [\n            theta,\n            phi"}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # Must add half pixel offset to shoot rays through pixel centers.\n  def dir_to_pix(d):\n    return d[Ellipsis, :2] - 0.5\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply camera rotation matrices.\n  camera_points = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points)\n\n  if camtype == ProjectionType.FISHEYE:\n    # Calculate the angle of the ray.\n    theta = xnp.sqrt(xnp.sum(xnp.square(camera_points), axis=-1))\n    theta = xnp.minimum(xnp.pi, theta)\n\n    # Calculate the radius of the ray using the angle and the camera's focal length.\n    r = xnp.tan(0.5 * theta)\n\n    # Calculate the x and y coordinates of the ray in the camera coordinate system.\n    x = camera_points[Ellipsis, 0] * r / theta\n    y = camera_points[Ellipsis, 1] * r / theta\n\n    # Calculate the z coordinate of the ray in the camera coordinate system.\n    z = xnp.cos(0.5 * theta)\n\n    # Combine the x, y, and z coordinates into a single array.\n    camera_points = xnp.stack([x, y, z], axis=-1)\n\n  elif camtype == ProjectionType.PANORAMIC:\n    # Calculate the angle of the ray.\n    theta = xnp.arctan2(camera_points[Ellipsis, 0], camera_points[Ellipsis, 2])\n    phi = xnp.arctan2(\n       "}
{"namespace": "camera_utils.points_to_pixels", "completion": "  # The camera coordinate system is left-handed, so the camera is looking along the\n  # negative z-axis.\n  if camtype != ProjectionType.PERSPECTIVE:\n    raise NotImplementedError('Only perspective camera is supported.')\n\n  # Must add half pixel offset to shoot rays through pixel centers.\n  def dir_to_pix(dirs):\n    return dirs[Ellipsis, :2] - 0.5\n\n  # For jax, need to specify high-precision matmul.\n  matmul = math.matmul if xnp == jnp else xnp.matmul\n  mat_vec_mul = lambda A, b: matmul(A, b[Ellipsis, None])[Ellipsis, 0]\n\n  # Apply camera rotation matrices.\n  points = mat_vec_mul(camtoworlds[Ellipsis, :3, :3], points)\n\n  # Flip from OpenGL to OpenCV coordinate system.\n  points = matmul(\n      points, xnp.diag(xnp.array([1.0, -1.0, -1.0]))\n  )\n\n  # Project into pixel space.\n  camera_points = mat_vec_mul(pixtocams, points)\n\n  if distortion_params is not None:\n    # Correct for distortion.\n    x, y = _radial_and_tangential_distort(\n        camera_points[Ellipsis, 0],\n        camera_points[Ellipsis, 1],\n        **distortion_params,\n        xnp=xnp,\n    )\n    camera_points = xnp.stack([x, y, camera_points[Ellipsis, 2]], axis=-1)\n\n  # Convert from homogeneous coordinates to 2D pixel coordinates.\n  coordinates = dir_to_pix(camera_points)\n  depth = camera_points[Ellipsis, 2]\n\n  return coordinates, depth\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[3:]\n  v = screw_axis[:3]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R = exp_so3(w, eps)\n  p = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta)) * skew(w)\n      + (theta - jnp.sin(theta)) * spin_math.matmul(skew(w), skew(w))\n  ) @ v\n\n  # Prevent bad gradients from propagating back when theta is small.\n  R_taylor = jnp.eye(3) + skew(w)\n  p_taylor = jnp.where(theta > eps, v, 0.0)\n  R = jnp.where(theta > eps, R, R_taylor)\n  p = jnp.where(theta > eps, p, p_taylor)\n\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w, v = screw_axis[:3], screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = exp_so3(w, eps)\n  p_taylor = v\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w_hat = skew(w_safe)\n  w_hat_2 = jnp.matmul(w_hat, w_hat)\n  w_hat_3 = jnp.matmul(w_hat_2, w_hat)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * w_hat\n      + (1.0 - jnp.cos(theta_safe)) * w_hat_2\n  )\n  V = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) * w_hat\n      + (theta_safe - jnp.sin(theta_safe)) * w_hat_2\n  )\n  V_inv = (\n      jnp.eye(3)\n      - 0.5 * w_hat\n      + (1.0 / theta_safe - 0.5 / jnp.tan(theta_safe / 2.0)) * w_hat_2\n  )\n  p = jnp.matmul(V_inv, jnp.expand_dims(v, axis=-1))\n\n  return jnp.where(\n      theta > eps,\n      rp_to_se3(R, p[:, 0]),\n      rp_to_se3(R_taylor, p_taylor),\n  )\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[3:]\n  v = screw_axis[:3]\n  theta_squared = jnp.sum(w**2, axis=-1)\n  theta = _safe_sqrt(theta_squared)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(w)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w_hat = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * w_hat\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(w_hat, w_hat)\n  )\n\n  R_taylor = jnp.where(theta_squared > eps**2, R, R_taylor)\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w_hat = skew(w_safe)\n  V = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) * w_hat\n      + (theta_safe - jnp.sin(theta_safe)) * spin_math.matmul(w_hat, w_hat)\n  )\n\n  V_taylor = jnp.where(theta_squared > eps**2, V, 0.0)\n  p = jnp.matmul(V_taylor, v[..., None])\n  return rp_to_se3(R_taylor, p[..., "}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[3:]\n  v = screw_axis[:3]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = exp_so3(w, eps)\n  p_taylor = v\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w_hat = skew(w_safe)\n  V_inv = jnp.eye(3) - 0.5 * w_hat + (\n      (theta_safe - jnp.sin(theta_safe)) / theta_safe**3\n  ) * spin_math.matmul(w_hat, w_hat)\n  p_safe = jnp.where(theta > eps, v, 0.0)\n  p = jnp.matmul(V_inv, p_safe)\n\n  R = jnp.where(theta > eps, R_taylor, jnp.eye(3))\n  p = jnp.where(theta > eps, p, p_taylor)\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the angular and translational components of the screw axis\n  w = screw_axis[:3]\n  v = screw_axis[3:]\n\n  # Compute the skew-symmetric matrix of the angular component of the screw axis\n  W = skew(w)\n\n  # Compute the magnitude of the angular component of the screw axis\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n\n  # Compute the translation component of the transformation matrix\n  p = (\n      jnp.eye(3)\n      + (1 - jnp.cos(theta)) * W / theta\n      + (theta - jnp.sin(theta)) * W @ W / theta**2\n  ) @ v\n\n  # Compute the rotation component of the transformation matrix\n  R = exp_so3(w, eps)\n\n  # Return the homogeneous transformation matrix\n  return rp_to_se3(R, p)"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[:3]\n  v = screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = exp_so3(w, eps)\n  p_taylor = jnp.where(theta > eps, v * theta, v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  v_safe = jnp.where(theta > eps, v, 0.0)\n  R = jnp.where(theta > eps, R_taylor, jnp.eye(3))\n  p = jnp.where(theta > eps, p_taylor, v)\n\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[3:]\n  v = screw_axis[:3]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = exp_so3(w, eps)\n  p_taylor = jnp.where(theta > eps, v * theta, v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  v_safe = jnp.where(theta > eps, v, 0.0)\n  w_hat = skew(w_safe)\n  w_hat_2 = jnp.matmul(w_hat, w_hat)\n  w_hat_3 = jnp.matmul(w_hat_2, w_hat)\n  w_hat_4 = jnp.matmul(w_hat_3, w_hat)\n\n  # Use the closed form solution.\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) / theta_safe * w_hat\n      + (1.0 - jnp.cos(theta_safe)) / theta_safe**2 * w_hat_2\n  )\n  p = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) / theta_safe**2 * w_hat\n      + (theta_safe - jnp.sin(theta_safe)) / theta_safe**3 * w_hat_2\n  ) @ v_safe\n\n  return jnp.where(\n      theta > eps,\n      rp_to_se3(R, p),\n      rp_to_se3(R_taylor, p_taylor),\n  )\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[:3]\n  v = screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  X_taylor = rp_to_se3(exp_so3(w, eps), v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta > eps, w, 0.0)\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  W = skew(w_safe)\n  W_sq = spin_math.matmul(W, W)\n  R = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) * W / theta_safe\n      + (theta_safe - jnp.sin(theta_safe)) * W_sq / theta_safe**3\n  )\n  V = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) * W / theta_safe**2\n      + (theta_safe - jnp.sin(theta_safe)) * W_sq / theta_safe**4\n  )\n  p = jnp.dot(V, v)\n  X = rp_to_se3(R, p)\n\n  return jnp.where(theta > eps, X, X_taylor)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[3:]\n  v = screw_axis[:3]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R = exp_so3(w, eps)\n  p = jnp.where(theta > eps, v * theta + jnp.dot(R, v) * (1.0 - jnp.cos(theta)), v)\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w, v = screw_axis[:3], screw_axis[3:]\n  theta_squared = jnp.sum(w**2, axis=-1)\n  theta = _safe_sqrt(theta_squared)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R = exp_so3(w, eps)\n  R_taylor = jnp.eye(3) + skew(w)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w_hat = skew(w_safe)\n  R_hat = jnp.eye(3) + w_hat\n  V_inv = jnp.eye(3) - 0.5 * w_hat + (\n      (1.0 / theta_safe**2)\n      - (1.0 + 0.5 * theta_safe / (2.0 * jnp.tan(0.5 * theta_safe)))\n  ) * jnp.outer(w_safe, w_safe)\n\n  p = jnp.where(theta_squared > eps**2, V_inv @ v, v)\n  p_taylor = jnp.where(theta_squared > eps**2, w_hat @ v, v)\n\n  return jnp.where(\n      theta_squared > eps**2,\n      rp_to_se3(R, p),\n      rp_to_se3(R_taylor, p_taylor),\n  )\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w, v = screw_axis[3:], screw_axis[:3]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n  theta_squared = theta**2\n  theta_cubed = theta_squared * theta\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(w)\n  V_taylor = jnp.eye(3) + (1.0 - jnp.cos(theta)) * skew(w) / theta_squared\n  p_taylor = jnp.where(\n      theta_squared > eps**2,\n      (jnp.eye(3) - R_taylor) @ (jnp.expand_dims(v, axis=-1) / theta_squared),\n      jnp.expand_dims(v, axis=-1),\n  )\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w_hat = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * w_hat\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(w_hat, w_hat)\n  )\n  V = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) * w_hat\n      + (theta_safe - jnp.sin(theta_safe))\n      * (1.0 - jnp.cos(theta_safe))\n      * spin_math.matmul(w_hat, w_hat)\n  )\n  p = (\n      jnp.eye(3"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[:3]\n  v = screw_axis[3:]\n  theta_squared = jnp.sum(w**2, axis=-1)\n  theta = _safe_sqrt(theta_squared)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + skew(w)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w_hat = skew(w_safe)\n  R = (\n      jnp.eye(3)\n      + jnp.sin(theta_safe) * w_hat\n      + (1.0 - jnp.cos(theta_safe)) * spin_math.matmul(w_hat, w_hat)\n  )\n  V = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) * w_hat\n      + (theta_safe - jnp.sin(theta_safe)) * spin_math.matmul(w_hat, w_hat)\n  )\n  V_inv = (\n      jnp.eye(3)\n      - 0.5 * w_hat\n      + (1.0 - (theta_safe / 2.0) * jnp.cos(theta_safe / 2.0))\n      / (theta_safe**2)\n      * spin_math.matmul(w_hat, w_hat)\n  )\n  p = V @ v[:, jnp.newaxis]\n  p = jnp.reshape(p, (3))\n  p_hat = V_inv @ p[:, jnp.newaxis]\n  p_hat = jnp.reshape(p_hat, (3))\n  X = rp_to_se3("}
{"namespace": "rigid_body.exp_se3", "completion": "  w, v = screw_axis[:3], screw_axis[3:]\n  theta_squared = jnp.sum(w**2, axis=-1)\n  theta = _safe_sqrt(theta_squared)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  w_hat = skew(w_safe)\n  w_hat_theta = w_hat * theta_safe\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = jnp.eye(3) + w_hat_theta\n  p_taylor = v * theta_safe\n\n  R = jnp.where(theta_squared > eps**2, exp_so3(w_safe), R_taylor)\n  p = jnp.where(theta_squared > eps**2, (jnp.eye(3) - R) @ w_hat @ v, p_taylor)\n  return rp_to_se3(R, p)"}
{"namespace": "rigid_body.exp_se3", "completion": "  theta = _safe_sqrt(jnp.sum(screw_axis[:3]**2, axis=-1))\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = exp_so3(screw_axis[:3], eps)\n  p_taylor = screw_axis[3:]\n\n  # Prevent bad gradients from propagating back when theta is small.\n  theta_safe = jnp.where(theta > eps, theta, 1.0)\n  R = jnp.where(theta > eps, R_taylor, jnp.eye(3))\n  p = jnp.where(theta > eps, p_taylor / theta_safe, screw_axis[3:])\n\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[:3]\n  v = screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n  theta_squared = theta**2\n  theta_cubed = theta**3\n  theta_fourth = theta**4\n  theta_fifth = theta**5\n\n  # Near zero, use first order Taylor expansion.\n  R_taylor = (\n      jnp.eye(3)\n      + (1.0 - theta_squared / 6.0 / theta_cubed) * skew(w)\n      + (0.5 - theta_squared / 24.0 / theta_fourth) * spin_math.matmul(skew(w), skew(w))\n  )\n  V_taylor = (\n      jnp.eye(3)\n      + (0.5 - theta_squared / 24.0 / theta_cubed) * skew(w)\n      + (1.0 / 6.0 - theta_squared / 120.0 / theta_fourth) * spin_math.matmul(skew(w), skew(w))\n  )\n  p_taylor = jnp.reshape(\n      (1.0 - theta_squared / 6.0 / theta_cubed) * v\n      + (0.5 - theta_squared / 24.0 / theta_fourth) * jnp.cross(w, v),\n      (3, 1),\n  )\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w_unit = w_safe / theta_safe\n  w_hat = skew(w_"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[3:]\n  v = screw_axis[:3]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n  theta_squared = theta**2\n\n  # Near zero, use first order Taylor expansion.\n  R_taylor = exp_so3(w, eps)\n  w_taylor = jnp.where(theta_squared > eps**2, w, 0.0)\n  W = skew(w_taylor)\n  V = jnp.eye(3) * theta + (1.0 - jnp.cos(theta)) * W + (\n      theta - jnp.sin(theta)\n  ) * spin_math.matmul(W, W)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  W_safe = jnp.where(theta_squared > eps**2, W, 0.0)\n  V_safe = jnp.where(theta_squared > eps**2, V, 0.0)\n  R_safe = jnp.where(theta_squared > eps**2, R_taylor, 0.0)\n  p_safe = jnp.where(theta_squared > eps**2, v, 0.0)\n\n  # Compute the translation.\n  p = jnp.matmul(V_safe, p_safe)\n\n  # Compute the rotation.\n  R = jnp.matmul(R_safe, W_safe)\n\n  return rp_to_se3(R, p)\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the angular and linear components of the screw axis.\n  w = screw_axis[:3]\n  v = screw_axis[3:]\n\n  # Compute the angular component of the transformation matrix.\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n  w_hat = skew(w)\n  w_hat_squared = spin_math.matmul(w_hat, w_hat)\n  w_hat_cube = spin_math.matmul(w_hat_squared, w_hat)\n  R = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta)) * w_hat / theta\n      + (theta - jnp.sin(theta)) * w_hat_squared / theta**3\n  )\n\n  # Compute the linear component of the transformation matrix.\n  V = (\n      jnp.eye(3)\n      + w_hat / theta\n      + (1.0 - jnp.cos(theta)) * w_hat_squared / theta**2\n      + (theta - jnp.sin(theta)) * w_hat_cube / theta**4\n  )\n  p = spin_math.matmul(V, v)\n\n  # Construct the homogeneous transformation matrix.\n  X = jnp.eye(4)\n  X = X.at[:3, :3].set(R)\n  X = X.at[:3, 3].set(p)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[:3]\n  v = screw_axis[3:]\n  theta = _safe_sqrt(jnp.sum(w**2, axis=-1))\n  theta_squared = theta**2\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = exp_so3(w, eps)\n  p_taylor = jnp.where(theta_squared > eps**2, v * theta + w @ v, v)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w_safe_norm = jnp.where(theta_squared > eps**2, w_safe / theta_safe, 0.0)\n  w_dot_v = jnp.where(theta_squared > eps**2, jnp.sum(w * v, axis=-1), 0.0)\n  p_taylor_safe = jnp.where(\n      theta_squared > eps**2,\n      (theta_safe * v + w_safe_norm * w_dot_v * w_safe_norm) / theta_squared,\n      0.0,\n  )\n\n  return jnp.where(\n      theta_squared > eps**2,\n      rp_to_se3(R_taylor, p_taylor),\n      rp_to_se3(R_taylor, p_taylor_safe),\n  )\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  w = screw_axis[3:]\n  v = screw_axis[:3]\n  theta_squared = jnp.sum(w**2, axis=-1)\n  theta = _safe_sqrt(theta_squared)\n\n  # Near zero, we switch to using the first order Taylor expansion.\n  R_taylor = exp_so3(w)\n\n  # Prevent bad gradients from propagating back when theta is small.\n  w_safe = jnp.where(theta_squared > eps**2, w, 0.0)\n  theta_safe = jnp.where(theta_squared > eps**2, theta, 1.0)\n  w_hat = skew(w_safe)\n  w_hat_2 = jnp.matmul(w_hat, w_hat)\n  R_taylor = jnp.where(theta_squared > eps**2, R_taylor, jnp.eye(3))\n\n  # Compute the translation part of the exponential map.\n  p_taylor = (\n      jnp.eye(3)\n      + (1.0 - jnp.cos(theta_safe)) * w_hat\n      + (theta_safe - jnp.sin(theta_safe)) * w_hat_2\n  ) @ v\n\n  # Compute the full exponential map.\n  R = jnp.eye(4)\n  R = R.at[:3, :3].set(R_taylor)\n  R = R.at[:3, 3].set(p_taylor)\n  return R\n\n"}
{"namespace": "rigid_body.exp_se3", "completion": "  # Extract the rotation and translation components of the screw axis.\n  w = screw_axis[:3]\n  v = screw_axis[3:]\n\n  # Compute the skew-symmetric matrix of the rotation component.\n  W = skew(w)\n\n  # Compute the translation component of the transformation matrix.\n  p = jnp.where(\n      jnp.linalg.norm(w) > eps,\n      jnp.eye(3) * jnp.sin(jnp.linalg.norm(w)) / jnp.linalg.norm(w)\n      + (1 - jnp.cos(jnp.linalg.norm(w)))\n      * (W @ W)\n      / jnp.linalg.norm(w) ** 2,\n      jnp.eye(3) + W,\n  ) @ v\n\n  # Compute the rotation component of the transformation matrix.\n  R = exp_so3(w, eps)\n\n  # Build the homogeneous transformation matrix.\n  X = jnp.eye(4)\n  X = X.at[:3, :3].set(R)\n  X = X.at[:3, 3].set(p)\n\n  return X\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Extract the angle and axis of rotation from the input axis-angle representation\n  angle = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n\n  # Compute the skew-symmetric matrix of the axis\n  skew_axis = skew(axis)\n\n  # Compute the rotation matrix using Rodrigues' formula\n  R = (\n      jnp.eye(3)\n      + jnp.sin(angle) * skew_axis\n      + (1 - jnp.cos(angle)) * skew_axis @ skew_axis\n  )\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  skew_axis_angle = skew(axis_angle)\n  theta_is_nonzero = theta > eps\n  theta_is_zero = theta <= eps\n  safe_theta = jnp.where(theta_is_nonzero, theta, 1.0)\n  theta_n = jnp.where(theta_is_nonzero, safe_theta, 1.0)\n  theta_n_minus_x_over_theta_n = jnp.where(\n      theta_is_nonzero,\n      jnp.eye(3) + ((1 - jnp.cos(theta_n)) / (theta_n**2)) * skew_axis_angle\n      + ((theta_n - jnp.sin(theta_n)) / (theta_n**3))\n      * (skew_axis_angle @ skew_axis_angle),\n      jnp.zeros((3, 3)),\n  )\n  theta_is_zero = theta <= eps\n  safe_theta = jnp.where(theta_is_nonzero, theta, 1.0)\n  theta_n = jnp.where(theta_is_nonzero, safe_theta, 1.0)\n  theta_n_minus_x_over_theta_n = jnp.where(\n      theta_is_nonzero,\n      jnp.eye(3) + ((1 - jnp.cos(theta_n)) / (theta_n**2)) * skew_axis_angle\n      + ((theta_n - jnp.sin(theta_n)) / (theta_n**3))\n      * (skew_axis_angle @ skew_axis_angle),\n      jnp.zeros((3, 3)),\n  )\n  R = jnp.where(theta_is_zero, jnp.eye(3), theta_n_minus_x_over_theta_n)\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  eps_factor = jnp.where(theta < eps, 1.0 - theta**2 / 6.0, jnp.cos(theta))\n  skew_axis_angle = skew(axis_angle)\n  return jnp.eye(3) + eps_factor * skew_axis_angle + (\n      1.0 - eps_factor\n  ) * jnp.matmul(skew_axis_angle, skew_axis_angle)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  skew_axis_angle = skew(axis_angle)\n\n  # If the angle is small, use the first-order Taylor approximation\n  theta_sq = theta * theta\n  theta_po4 = theta_sq * theta_sq\n  theta_po6 = theta_po4 * theta_sq\n  theta_po8 = theta_po4 * theta_po4\n  safe_theta = jnp.where(theta_sq < eps, 1 - theta_sq / 6 + theta_po4 / 120, theta)\n  c = jnp.where(theta_sq < eps, 1 - theta_sq / 2 + theta_po4 / 24 - theta_po6 / 720 + theta_po8 / 40320, jnp.cos(safe_theta))\n  s = jnp.where(theta_sq < eps, 1 / 2 - theta_sq / 24 + theta_po4 / 720 - theta_po6 / 40320, jnp.sin(safe_theta) / safe_theta)\n\n  return jnp.eye(3) + s * skew_axis_angle + (1 - c) * (skew_axis_angle @ skew_axis_angle)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n  k = skew(axis)\n  return jnp.eye(3) + jnp.sin(theta) * k + (1 - jnp.cos(theta)) * k @ k\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  skew_axis_angle = skew(axis_angle)\n  return jnp.where(\n      theta < eps,\n      jnp.eye(3) + skew_axis_angle,\n      jnp.eye(3)\n      + jnp.sin(theta) / theta * skew_axis_angle\n      + (1 - jnp.cos(theta)) / theta**2 * (skew_axis_angle @ skew_axis_angle),\n  )\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n  return jnp.cos(theta) * jnp.eye(3) + (\n      1 - jnp.cos(theta)\n  ) * (axis @ axis.T) + jnp.sin(theta) * skew(axis)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Extract the axis of rotation and the angle of rotation from the input axis-angle representation\n  theta = jnp.linalg.norm(axis_angle)\n  w = axis_angle / (theta + eps)\n\n  # Compute the skew-symmetric matrix of the axis of rotation\n  W = skew(w)\n\n  # Compute the exponential map using Rodrigues' formula\n  R = jnp.eye(3) + jnp.sin(theta) * W + (1 - jnp.cos(theta)) * W @ W\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  axis_angle = jnp.reshape(axis_angle, (3))\n  angle = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (angle + eps)\n  skew_axis = skew(axis)\n\n  # Rodrigues' formula for the exponential map\n  # R = I + sin(angle) * skew_axis + (1 - cos(angle)) * skew_axis^2\n  R = (\n      jnp.eye(3)\n      + jnp.sin(angle) * skew_axis\n      + (1 - jnp.cos(angle)) * jnp.linalg.matrix_power(skew_axis, 2)\n  )\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n  k = skew(axis)\n\n  return jnp.eye(3) + jnp.sin(theta) * k + (1 - jnp.cos(theta)) * k @ k\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Extract the angle of rotation from the axis-angle representation\n  angle = jnp.linalg.norm(axis_angle)\n\n  # If the angle is small, use a Taylor series expansion to avoid numerical instability\n  if angle < eps:\n    skew_axis_angle = skew(axis_angle)\n    return jnp.eye(3) + skew_axis_angle + 0.5 * skew_axis_angle @ skew_axis_angle\n\n  # Otherwise, use Rodrigues' formula to compute the rotation matrix\n  axis_angle_normalized = axis_angle / angle\n  skew_axis_angle_normalized = skew(axis_angle_normalized)\n  return (\n      jnp.eye(3)\n      + jnp.sin(angle) * skew_axis_angle_normalized\n      + (1 - jnp.cos(angle)) * (skew_axis_angle_normalized @ skew_axis_angle_normalized)\n  )\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Extract the magnitude of the rotation from the input axis-angle representation\n  theta = jnp.linalg.norm(axis_angle)\n\n  # If the magnitude of the rotation is very small, use a small epsilon value instead\n  theta = jnp.where(theta < eps, eps, theta)\n\n  # Compute the skew-symmetric matrix of the axis-angle representation\n  W = skew(axis_angle / theta)\n\n  # Compute the rotation matrix using Rodrigues' formula\n  R = jnp.eye(3) + jnp.sin(theta) * W + (1 - jnp.cos(theta)) * W @ W\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Extract the magnitude of rotation from the axis-angle representation\n  angle = jnp.linalg.norm(axis_angle)\n\n  # Compute the skew-symmetric matrix of the axis of rotation\n  skew_axis = skew(axis_angle)\n\n  # Compute the rotation matrix using Rodrigues' formula\n  R = (\n      jnp.eye(3)\n      + jnp.sin(angle) / (angle + eps) * skew_axis\n      + (1 - jnp.cos(angle)) / (angle + eps) * (skew_axis @ skew_axis)\n  )\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Extract the magnitude of the rotation from the axis-angle representation\n  theta = jnp.linalg.norm(axis_angle)\n\n  # If the magnitude of the rotation is less than the numerical stability threshold, return the identity matrix\n  if theta < eps:\n    return jnp.eye(3)\n\n  # Normalize the axis of rotation\n  axis = axis_angle / theta\n\n  # Compute the cross product matrix of the axis\n  axis_skew = skew(axis)\n\n  # Compute the rotation matrix using Rodrigues' formula\n  R = jnp.eye(3) + jnp.sin(theta) * axis_skew + (1 - jnp.cos(theta)) * (axis_skew @ axis_skew)\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  theta_sq = theta**2\n  theta_cubed = theta_sq * theta\n  theta_pow_5 = theta_sq * theta_cubed\n  theta_pow_7 = theta_sq * theta_cubed * theta_pow_5\n\n  # Compute the terms for the numerator and denominator of Rodrigues' formula\n  numerator = (\n      jnp.eye(3)\n      + (1 - jnp.cos(theta)) * skew(axis_angle)\n      + (theta - jnp.sin(theta)) * skew(axis_angle) @ skew(axis_angle)\n  )\n  denominator = (\n      jnp.where(theta < eps, 1.0 - theta_sq / 6.0 + theta_pow_5 / 120.0, theta)\n      * theta_cubed\n  )\n\n  # Compute the rotation matrix using Rodrigues' formula\n  R = jnp.where(theta < eps, jnp.eye(3) + skew(axis_angle), numerator / denominator)\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / (theta + eps)\n  cross_prod_mat = skew(axis)\n  return (\n      jnp.eye(3)\n      + jnp.sin(theta) * cross_prod_mat\n      + (1 - jnp.cos(theta)) * cross_prod_mat @ cross_prod_mat\n  )\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Extract the magnitude of the axis-angle representation\n  theta = jnp.linalg.norm(axis_angle)\n\n  # Compute the skew-symmetric matrix corresponding to the axis of rotation\n  W = skew(axis_angle)\n\n  # Compute the rotation matrix using Rodrigues' formula\n  R = jnp.eye(3) + jnp.sin(theta) * W + (1 - jnp.cos(theta)) * (W @ W)\n\n  # Check if the angle of rotation is small\n  theta_sq = theta * theta\n  theta_po4 = theta_sq * theta_sq\n\n  # If the angle is small, use a Taylor expansion to approximate the rotation matrix\n  R = jnp.where(\n      theta_sq > eps * eps,\n      R,\n      jnp.eye(3) + (1 - theta_sq / 6.0) * W + (0.5 - theta_sq / 24.0) * (W @ W),\n  )\n\n  # If the angle is very small, use a Taylor expansion to approximate the rotation matrix\n  R = jnp.where(\n      theta_po4 > eps * eps,\n      R,\n      jnp.eye(3)\n      + (1 / 12.0 - theta_sq / 1800.0) * W\n      + (1 / 20.0 - theta_sq / 1260.0) * (W @ W),\n  )\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  axis = axis_angle / theta\n  s = jnp.sin(theta)\n  c = jnp.cos(theta)\n  k_hat = skew(axis)\n\n  # Numerical stability for small angles\n  theta = jnp.where(theta < eps, 1.0, theta)\n  s = jnp.where(theta < eps, 1.0, s)\n  c = jnp.where(theta < eps, 1.0, c)\n\n  return jnp.eye(3) + s * k_hat + (1 - c) * (k_hat @ k_hat)\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  theta = jnp.linalg.norm(axis_angle)\n  theta_squared = theta**2\n  theta_cubed = theta**3\n  theta_fourth = theta**4\n  theta_fifth = theta**5\n  theta_sixth = theta**6\n\n  # Compute the rotation matrix using Rodrigues' formula\n  # If the angle is very small, use the first-order Taylor approximation\n  if theta_squared < eps:\n    R = jnp.eye(3) + skew(axis_angle)\n  else:\n    R = (\n        jnp.eye(3)\n        + jnp.sin(theta) / theta * skew(axis_angle)\n        + (1 - jnp.cos(theta)) / theta_squared * skew(axis_angle) @ skew(axis_angle)\n    )\n\n  return R\n\n"}
{"namespace": "rigid_body.exp_so3", "completion": "  # Compute the norm of the axis-angle vector\n  norm = jnp.linalg.norm(axis_angle)\n\n  # If the norm is small, use the Taylor series expansion to avoid numerical instability\n  if norm < eps:\n    return jnp.eye(3) + skew(axis_angle) + (1 / 2) * (\n        1 - (norm / 6) * (1 - (norm / 20) * (1 - (norm / 42)))\n    )\n\n  # Otherwise, use the Rodrigues' formula\n  else:\n    axis = axis_angle / norm\n    return (\n        jnp.eye(3)\n        + jnp.sin(norm) * skew(axis)\n        + (1 - jnp.cos(norm)) * skew(axis) @ skew(axis)\n    )\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  mu = (t0 + t1) / 2\n  hw = (t1 - t0) / 2\n  t_mean = mu + (2 * mu * hw**2) / (3 * mu**2 + hw**2)\n  t_var = (hw**2) / 3 - (4 / 15) * ((hw**4 * (12 * mu**2 - hw**2)) /\n                                    (3 * mu**2 + hw**2)**2)\n  r_var = base_radius**2 * ((mu**2) / 4 + (5 / 12) * hw**2 - 4 / 15 *\n                            (hw**4) / (3 * mu**2 + hw**2))\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  mu = (t0 + t1) / 2\n  hw = (t1 - t0) / 2\n  t_mean = mu + (2 * mu * hw**2) / (3 * mu**2 + hw**2)\n  t_var = (hw**2) / 3 - (4 / 15) * ((hw**4 * (12 * mu**2 - hw**2)) /\n                                    (3 * mu**2 + hw**2)**2)\n  r_var = base_radius**2 * ((mu**2) / 4 + (5 / 12) * hw**2 - 4 / 15 *\n                            (hw**4) / (3 * mu**2 + hw**2))\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  mu = (t0 + t1) / 2\n  hw = (t1 - t0) / 2\n  t_mean = mu + (2 * mu * hw**2) / (3 * mu**2 + hw**2)\n  t_var = (hw**2) / 3 - (4 / 15) * ((hw**4 * (12 * mu**2 - hw**2)) /\n                                    (3 * mu**2 + hw**2)**2)\n  r_var = base_radius**2 * ((mu**2) / 4 + (5 / 12) * hw**2 - 4 / 15 *\n                            (hw**4) / (3 * mu**2 + hw**2))\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  mu = (t0 + t1) / 2\n  hw = (t1 - t0) / 2\n  t_mean = mu + (2 * mu * hw**2) / (3 * mu**2 + hw**2)\n  t_var = (hw**2) / 3 - (4 / 15) * ((hw**4 * (12 * mu**2 - hw**2)) /\n                                   (3 * mu**2 + hw**2)**2)\n  r_var = base_radius**2 * ((mu**2) / 4 + (5 / 12) * hw**2 - 4 / 15 *\n                            (hw**4) / (3 * mu**2 + hw**2))\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  mu = (t0 + t1) / 2\n  hw = (t1 - t0) / 2\n  t_mean = mu + (2 * mu * hw**2) / (3 * mu**2 + hw**2)\n  t_var = (hw**2) / 3 - (4 / 15) * ((hw**4 * (12 * mu**2 - hw**2)) /\n                                    (3 * mu**2 + hw**2)**2)\n  r_var = base_radius**2 * ((mu**2) / 4 + (5 / 12) * hw**2 - 4 / 15 *\n                            (hw**4) / (3 * mu**2 + hw**2))\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  mu = (t0 + t1) / 2\n  hw = (t1 - t0) / 2\n  t_mean = mu + (2 * mu * hw**2) / (3 * mu**2 + hw**2)\n  t_var = (hw**2) / 3 - (4 / 15) * ((hw**4 * (12 * mu**2 - hw**2)) /\n                                    (3 * mu**2 + hw**2)**2)\n  r_var = base_radius**2 * ((mu**2) / 4 + (5 / 12) * hw**2 - 4 / 15 *\n                            (hw**4) / (3 * mu**2 + hw**2))\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= base_radius**2\n  t0_orig, t1_orig = t0, t1\n  if base_radius != 1:\n    t0 = t0_orig * base_radius\n    t1 = t1_orig * base_radius\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= base_radius**2\n  t0_orig = t0\n  t1_orig = t1\n  if base_radius != 1:\n    t0 = t0_orig * base_radius\n    t1 = t1_orig * base_radius\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  mu = (t0 + t1) / 2\n  hw = (t1 - t0) / 2\n  t_mean = mu + (2 * mu * hw**2) / (3 * mu**2 + hw**2)\n  t_var = (hw**2) / 3 - (4 / 15) * ((hw**4 * (12 * mu**2 - hw**2)) /\n                                    (3 * mu**2 + hw**2)**2)\n  r_var = base_radius**2 * ((mu**2) / 4 + (5 / 12) * hw**2 - 4 / 15 *\n                            (hw**4) / (3 * mu**2 + hw**2))\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  mu = (t0 + t1) / 2\n  hw = (t1 - t0) / 2\n  t_mean = mu + (2 * mu * hw**2) / (3 * mu**2 + hw**2)\n  t_var = (hw**2) / 3 - (4 / 15) * ((hw**4 * (12 * mu**2 - hw**2)) /\n                                   (3 * mu**2 + hw**2)**2)\n  r_var = base_radius**2 * ((mu**2) / 4 + (5 / 12) * hw**2 - 4 / 15 *\n                            (hw**4) / (3 * mu**2 + hw**2))\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= base_radius**2\n  t0_orig, t1_orig = t0, t1\n  if base_radius != 1:\n    t0 *= base_radius\n    t1 *= base_radius\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # A more stable version of Equation 7 from https://arxiv.org/abs/2103.13415.\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= base_radius**2\n  t0_mean, t0_var, r0_var = gaussianize_frustum(t0, jnp.zeros_like(t0))\n  r0_var *= base_radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag), lift_gaussian(\n      d, t0_mean, t0_var, r0_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= base_radius**2\n  t0_mean, t0_var = gaussianize_frustum(t0, jnp.zeros_like(t0))\n  t1_mean, t1_var = gaussianize_frustum(t1, jnp.zeros_like(t1))\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Calculate the mean and variance of the Gaussian distribution.\n  mu = (t0 + t1) / 2\n  hw = (t1 - t0) / 2\n  t_mean = mu + (2 * mu * hw**2) / (3 * mu**2 + hw**2)\n  t_var = (hw**2) / 3 - (4 / 15) * ((hw**4 * (12 * mu**2 - hw**2)) /\n                                    (3 * mu**2 + hw**2)**2)\n  r_var = base_radius**2 * ((mu**2) / 4 + (5 / 12) * hw**2 - 4 / 15 *\n                            (hw**4) / (3 * mu**2 + hw**2))\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  mu = (t0 + t1) / 2\n  hw = (t1 - t0) / 2\n  t_mean, t_var, r_var = gaussianize_frustum(mu, hw)\n  t_mean = t_mean[Ellipsis, None]\n  t_var = t_var[Ellipsis, None]\n  r_var = r_var[Ellipsis, None]\n  r_var *= base_radius**2\n  t0 = distance_to_depth(t0, math.clamp(1e-10, base_radius / 2))\n  t1 = distance_to_depth(t1, math.clamp(1e-10, base_radius / 2))\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  mu = ((t0 + t1) / 2) * d\n  hw = (t1 - t0) / 2\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  rad_t0 = jnp.linalg.norm(mu - t0 * d)\n  rad_t1 = jnp.linalg.norm(mu - t1 * d)\n  r_var *= (1 + (rad_t0 / base_radius)**2) * (1 + (rad_t1 / base_radius)**2)\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= base_radius**2\n  t0_mean, t0_var = gaussianize_frustum(t0, jnp.zeros_like(t0))\n  p_mean = jnp.concatenate([t0_mean, r_var], axis=-1)\n  p_var = jnp.concatenate(\n      [\n          t0_var,\n          jnp.concatenate(\n              [\n                  jnp.zeros_like(r_var),\n                  jnp.zeros_like(r_var),\n                  jnp.zeros_like(r_var),\n                  jnp.zeros_like(r_var),\n                  r_var,\n                  jnp.zeros_like(r_var),\n                  jnp.zeros_like(r_var),\n                  jnp.zeros_like(r_var),\n                  r_var,\n              ],\n              axis=-1,\n          ),\n      ],\n      axis=-1,\n  )\n  mean, cov = lift_gaussian(d, p_mean, p_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= base_radius**2\n  t0_orig, t1_orig = t0, t1\n  if base_radius != 1:\n    t0 /= base_radius\n    t1 /= base_radius\n  fun = lambda t_in: base_radius**2 * jnp.piecewise(\n      t_in,\n      [t_in == 0, (t_in > 0) * (t_in < 1), t_in == 1],\n      [\n          lambda t: jnp.ones_like(t),\n          lambda t: 1 / jnp.sqrt(1 - t**2),\n          lambda t: 0 * t,\n      ],\n  )\n  t_mean = fun(t_mean) / base_radius\n  t_var = fun(t_var) / base_radius**2\n  r_var *= fun(t0_orig) / fun(t1_orig)\n  r_var /= base_radius**2\n  return lift_gaussian(d, t_mean, t_var, r_var, diag)\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  # Calculate the mean and variance of the Gaussian distribution along the ray\n  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n\n  # Scale the radius of the frustum based on the distance from the origin\n  m = math.safe_sqrt(1 - t_mean**2)\n  m_inv = math.safe_cdiv(1, m)\n  r_var *= m_inv**2\n  t_var *= m_inv**2\n\n  # Scale the radius of the frustum by the base radius\n  r_var *= base_radius**2\n  t_var *= base_radius**2\n\n  # Lift the Gaussian distribution along the ray\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.conical_frustum_to_gaussian", "completion": "  t_mean, t_var, r_var = gaussianize_frustum(t0, t1)\n  r_var *= base_radius**2\n  t0_orig, t1_orig = t0, t1\n  if base_radius != 1:\n    t0 /= base_radius\n    t1 /= base_radius\n  t_mean += (t1 + t0) / 2\n  t_var += (t1**2 + t0**2) / 2\n  fun = lambda x: jnp.exp(-x * t0) - jnp.exp(-x * t1)\n  integral, _ = math.integrate(fun, 0, 1, 1 / 512, 1 / 512)\n  t_var -= integral**2\n  t_var = jnp.clip(t_var, 1e-10)\n  r_var *= 4 / 3 - (t1 - t0) / t_mean**2\n  t_mean = jnp.clip(t_mean, t0_orig)\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  mean, cov = lift_gaussian(d, (t0 + t1) / 2, (t1 - t0) / 2, radius**2, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  mean, cov = lift_gaussian(d, (t0 + t1) / 2, (t1 - t0) / 2, radius**2, diag)\n  return mean, cov"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  mean, cov = lift_gaussian(d, (t0 + t1) / 2, (t1 - t0) / 2, radius**2, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  t_mean = (t0 + t1) / 2\n  r_var = radius**2 / 4\n  t_var = (t1 - t0)**2 / 12\n  mean, cov = lift_gaussian(d, t_mean, t_var, r_var, diag)\n  return mean, cov\n\n"}
{"namespace": "render.cylinder_to_gaussian", "completion": "  mean, cov = lift_gaussian(d, (t0 + t1) / 2, t1 - t0, radius**2, diag)\n  return mean, cov\n\n"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  \"\"\"\n  This function calculates 3D camera rays given 2D pixel coordinates, camera inverse intrinsics, and extrinsics. It supports optional distortion correction, different camera projection types (e.g., fisheye, panoramic), and can work with either numpy or jax.numpy for computations. The function is vectorized to handle arrays of pixel coordinates and camera parameters, and it computes ray origins, directions, normalized view directions, ray differential radii, and image plane coordinates.\n\n  Input-Output Arguments\n  :param pix_x_int: int array, shape SH, the x coordinates of image pixels, used as part of the input to compute ray directions.\n  :param pix_y_int: int array, shape SH, the y coordinates of image pixels, used alongside pix_x_int to compute ray directions.\n  :param pixtocams: float array, broadcastable to SH + [3, 3], the inverse intrinsics of the cameras, used to transform pixel coordinates to camera coordinates.\n  :param camtoworlds: float array, broadcastable to SH + [3, 4], the extrinsics of the cameras, used to transform camera coordinates to world coordinates.\n  :param distortion_params: dict of floats, optional, camera distortion parameters for correcting lens distortion in the computed rays.\n  :param pixtocam_ndc: float array, [3, 3], optional, inverse intrinsics for Normalized Device Coordinates (NDC) projection, used when converting ray origins and directions into NDC space.\n  :param camtype: camera_utils.ProjectionType, the type of camera projection (e.g., fisheye or perspective), affects how rays are computed based on the camera model.\n  :param xnp: module, either numpy or jax.numpy, the numerical library used for computations, allowing the function to be used with different backends.\n\n  :return: A tuple containing:\n           - origins: float array, shape SH + [3], the origin points of the rays in world coordinates.\n           - directions: float array, shape SH + [3], the direction vectors of the rays in world coordinates.\n           - viewdirs"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shape of the pixel coordinates.\n  sh = pix_x_int.shape\n\n  # Convert pixel coordinates to NDC space.\n  if pixtocam_ndc is not None:\n    pix_x_int, pix_y_int = xnp.split(\n        pixtocam_ndc @ xnp.stack(\n            [pix_x_int.ravel(), pix_y_int.ravel(), xnp.ones_like(pix_x_int).ravel()],\n            axis=0,\n        ),\n        2,\n    )\n    pix_x_int = pix_x_int.reshape(sh)\n    pix_y_int = pix_y_int.reshape(sh)\n\n  # Apply distortion to pixel coordinates if distortion parameters are provided.\n  if distortion_params is not None:\n    pix_x_int, pix_y_int = _radial_and_tangential_undistort(\n        xd=pix_x_int,\n        yd=pix_y_int,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n        xnp=xnp,\n    )\n\n  # Convert pixel coordinates to camera coordinates.\n  x, y = xnp.meshgrid(\n      xnp.arange(xnp.prod(sh[-1]), dtype=xnp.float32),\n      xnp.arange(xnp.prod(sh[:-1]), dtype=xnp.float32),\n      indexing='xy',\n  )\n  x = x.reshape(sh)\n  y = y.reshape(sh)\n  cam_x = (pix_x_int - x) / pixtocams[Ellipsis, 0, 2]\n  cam_y = (p"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # TODO(jaxnerf): Add support for jax.lax.map.\n\n  # SH for shape.\n  if distortion_params is None:\n    distortion_params = {}\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  # Total ops: 18 flops per ray.\n  #"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Calculate the xy coordinates of the pixel centers (in the OpenCV coordinate system).\n  pix_x = pix_x_int + 0.5\n  pix_y = pix_y_int + 0.5\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params is not None:\n    pix_x, pix_y = _radial_and_tangential_undistort(\n        xd=pix_x,\n        yd=pix_y,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n        xnp=xnp,\n    )\n\n  # Convert the pixel centers to NDC coordinates.\n  if pixtocam_ndc is not None:\n    pix_x, pix_y = xnp.split(\n        pixtocam_ndc @ xnp.stack([pix_x, pix_y, xnp.ones_like(pix_x)], axis=-1),\n        [-1],\n        axis=-1,\n    )\n    pix_x = pix_x[Ellipsis, 0]\n    pix_y = pix_y[Ellipsis, 0]\n\n  # Convert the pixel centers to camera coordinates.\n  pix_x, pix_y = xnp.split(\n      pixtocams @ xnp.stack([pix_x, pix_y, xnp.ones_like(pix_x)], axis=-1),\n      [-1],\n      axis=-1,\n  )\n  pix_x = pix_x[Ellipsis, 0]\n  pix_y = pix_y[Ellipsis, 0]\n\n  # Compute the ray directions in camera coordinates.\n  if camtype == ProjectionType.PERSPECTIVE:\n    directions = xnp.stack(["}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  if distortion_params is None:\n    distortion_params = {}\n  if pixtocam_ndc is None:\n    pixtocam_ndc = xnp.eye(3)\n\n  # Shape abbreviations.\n  B = xnp.broadcast\n  S = pix_x_int.shape\n  SH = S + (3,)\n\n  # Pixel in NDC.\n  pix_ndc = xnp.stack([pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)], axis=-1)\n  pix_ndc = pix_ndc @ xnp.moveaxis(pixtocam_ndc, -1, 0)\n  pix_ndc = xnp.moveaxis(pix_ndc, -1, 0)\n  # Pixel in camera space.\n  pix_cam = pix_ndc[Ellipsis, :2] / pix_ndc[Ellipsis, 2:3]\n  # Pixel in world space.\n  pix_world = pix_cam[Ellipsis, None, :] @ camtoworlds[Ellipsis, :3, :3]\n  pix_world = xnp.moveaxis(pix_world, -1, 0)\n  # Ray direction in camera space.\n  dirs_cam = pix_cam[Ellipsis, None, :] @ xnp.moveaxis(pixtocams, -1, 0)\n  dirs_cam = xnp.moveaxis(dirs_cam, -1, 0)\n  dirs_cam = dirs_cam / xnp.linalg.norm(dirs_cam, axis=-1, keepdims=True)\n\n  # Ray origin in camera space.\n  origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, -1], SH)\n\n  # Correct distortion\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Perspective distortion\n    if 'k1'"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Cast to float32 to ensure precision.\n  pix_x_int = xnp.array(pix_x_int).astype(np.float32)\n  pix_y_int = xnp.array(pix_y_int).astype(np.float32)\n  pixtocams = xnp.array(pixtocams).astype(np.float32)\n  camtoworlds = xnp.array(camtoworlds).astype(np.float32)\n\n  if distortion_params is not None:\n    # Correct distortion.\n    # Note: this step is slow (60% of total time for a 800x800 image) so avoid if\n    # not necessary.\n    pix_x_corrected, pix_y_corrected = _radial_and_tangential_undistort(\n        xd=pix_x_int,\n        yd=pix_y_int,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n        xnp=xnp,\n    )\n  else:\n    pix_x_corrected, pix_y_corrected = pix_x_int, pix_y_int\n\n  if camtype in (ProjectionType.PERSPECTIVE, ProjectionType.FISHEYE):\n    # Convert from pixel coordinates in the image to NDC space, where the\n    # camera-space y-axis is up.\n    x, y = pix_x_corrected, pix_y_corrected\n    x, y = x / pixtocams[Ellipsis, 0, 2] - 1, y / pixtocams[Ellipsis, 1, 2] - 1\n    x, y = x * pixtocams[Ellipsis, 0, "}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Cast to float32 for numerical stability.\n  pix_x_int = xnp.array(pix_x_int, dtype=xnp.float32)\n  pix_y_int = xnp.array(pix_y_int, dtype=xnp.float32)\n\n  # Shape of the input dimensions.\n  sh = pix_x_int.shape\n\n  # The ray directions are the inverse camera rotation multiplied with the\n  # pixel-to-camera rays.\n  x, y = xnp.meshgrid(pix_x_int, pix_y_int, indexing='xy')\n  x = x.reshape((-1,))\n  y = y.reshape((-1,))\n\n  # Apply inverse intrinsic matrix.\n  camx = (x - pixtocams[Ellipsis, 0, 2]) / pixtocams[Ellipsis, 0, 0]\n  camy = (y - pixtocams[Ellipsis, 1, 2]) / pixtocams[Ellipsis, 1, 1]\n  directions = xnp.stack([camx, camy, xnp.ones_like(x)], axis=-1)\n  directions = xnp.einsum('hwij,hj->hwi', camtoworlds[Ellipsis, :3, :3], directions)\n  directions = xnp.reshape(directions, list(sh) + [3])\n\n  # Optionally apply distortion.\n  if distortion_params is not None:\n    fx = pixtocams[Ellipsis, 0, 0]\n    fy = pixtocams[Ellipsis, 1, 1]\n    cx = pixtocams[Ellipsis, 0, 2]\n    cy = pixtocams[Ellipsis, 1, 2]\n    k1 = distortion_params['k1']\n    k2 = distortion_params['k2']\n    k3 = distortion_"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute the inverse intrinsics if not provided.\n  if pixtocam_ndc is None:\n    pixtocam_ndc = xnp.linalg.inv(pixtocams)\n\n  # Convert pixel coordinates to NDC space.\n  pix_x = (pix_x_int + 0.5) / pixtocams[0, 0] - 1.0\n  pix_y = (pix_y_int + 0.5) / pixtocams[1, 1] - 1.0\n  directions = xnp.stack([pix_x, pix_y, xnp.ones_like(pix_x)], axis=-1)\n  directions = directions @ pixtocam_ndc.T\n  directions = directions[Ellipsis, :2] / directions[Ellipsis, 2:]\n\n  # Correct distortion if distortion_params are provided.\n  if distortion_params is not None:\n    directions = _radial_and_tangential_undistort(\n        directions[Ellipsis, 0],\n        directions[Ellipsis, 1],\n        **distortion_params,\n    )\n    directions = xnp.stack([directions[0], directions[1], xnp.ones_like(pix_x)], -1)\n\n  # Convert pixel coordinates to camera space.\n  if camtype in (ProjectionType.PERSPECTIVE, ProjectionType.FISHEYE):\n    directions = directions @ pixtocams.T\n    directions = directions[Ellipsis, :2] / directions[Ellipsis, 2:]\n  elif camtype == ProjectionType.PANORAMIC:\n    theta = xnp.pi * directions[Ellipsis, 0]\n    phi = xnp.pi * directions[Ellipsis, 1]\n    directions = xnp.stack(\n        [\n            xnp.sin(phi) * xnp.sin(theta),\n            -xnp.cos(phi),\n            xnp.sin(phi"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # The coordinate convention for the camera is to align with the OpenCV coordinate\n  # system. This only affects the `fisheye` and `pano` projections, which are\n  # defined in the OpenCV coordinate system.\n  if camtype in [ProjectionType.FISHEYE, ProjectionType.PANORAMIC]:\n    # Flip the y-axis by inverting the intrinsic matrix. Only affects intrinsic\n    # matrix. Extrinsics are unchanged.\n    pixtocams = xnp.copy(pixtocams)\n    pixtocams[1, 1] *= -1\n\n  # Calculate the inverse camera rotation.\n  camrot = camtoworlds[Ellipsis, :3, :3]\n  camrot_inv = xnp.swapaxes(xnp.linalg.inv(camrot), -1, -2)\n\n  # Broadcast to the shape of pix_x_int and pix_y_int.\n  pixtocams = xnp.broadcast_to(pixtocams, pix_x_int.shape + (3, 3))\n  camrot_inv = xnp.broadcast_to(camrot_inv, pix_x_int.shape + (3, 3))\n\n  # Calculate the undistorted pixel coordinates.\n  if distortion_params is not None:\n    pix_x_corr, pix_y_corr = _radial_and_tangential_undistort(\n        xd=pix_x_int,\n        yd=pix_y_int,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n        xnp=xnp,\n    )\n  else:\n    pix_x_corr, pix_y_corr = pix_x_int, pix_y_int"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Check if the input pixel coordinates are integer-valued.\n  chex.assert_shape(pix_x_int, ())\n  chex.assert_shape(pix_y_int, ())\n  chex.assert_type([pix_x_int, pix_y_int], xnp.int32)\n\n  # Check if the input camera parameters are valid.\n  chex.assert_shape(pixtocams, (3, 3))\n  chex.assert_shape(camtoworlds, (3, 4))\n  chex.assert_type([pixtocams, camtoworlds], xnp.float32)\n\n  # Check if the input distortion parameters are valid.\n  if distortion_params is not None:\n    chex.assert_shape(distortion_params, ())\n    chex.assert_type(distortion_params, xnp.float32)\n\n  # Check if the input NDC parameters are valid.\n  if pixtocam_ndc is not None:\n    chex.assert_shape(pixtocam_ndc, (3, 3))\n    chex.assert_type(pixtocam_ndc, xnp.float32)\n\n  # Check if the input camera type is valid.\n  chex.assert_type(camtype, ProjectionType)\n\n  # Compute the inverse intrinsics for the camera.\n  pixtocam = pixtocams\n  if pixtocam_ndc is not None:\n    # If NDC parameters are provided, compute the inverse intrinsics for NDC.\n    pixtocam = pixtocam_ndc @ pixtocam\n\n  # Convert pixel coordinates to camera coordinates.\n  cam_x, cam_y, _ = xnp.linalg.inv(pixtocam) @ xnp.stack(\n      [pix_x_int, pix_y_int, xnp.ones_like(pix_x_int)]\n  )\n\n  # Apply distortion correction if necessary.\n  if distortion_params is not None"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shape of pixtocam_ndc is [3, 3], so we need to add two dimensions to it.\n  if pixtocam_ndc is not None:\n    pixtocam_ndc = xnp.reshape(pixtocam_ndc, [1, 1, 3, 3])\n\n  # Shape of pixtocams is [3, 3], so we need to add two dimensions to it.\n  pixtocams = xnp.reshape(pixtocams, [-1, 1, 1, 3, 3])\n\n  # Shape of camtoworlds is [3, 4], so we need to add two dimensions to it.\n  camtoworlds = xnp.reshape(camtoworlds, [-1] + [1, 1] + [3, 4])\n\n  # Convert to float32, since we assume the function is used for rendering.\n  pix_x_int = xnp.array(pix_x_int, dtype=xnp.float32)\n  pix_y_int = xnp.array(pix_y_int, dtype=xnp.float32)\n\n  # The coordinate transformation looks like:\n  #\n  #  +-----------------+\n  #  |                 |\n  #  | \uff21ffine         |\n  #  |  transformation |\n  #  |                 |\n  #  +--------+--------+\n  #           |\n  #  +--------v--------+             +-------------------+\n  #  |                 |             |                   |\n  #  |   Perspective   |             |      Lens        |\n  #  |   projection    |------------->+   distortion     |\n  #  |                 |             |                   |\n  #  +--------+--------+             +--------+---------+\n  #           |                              |\n  #           |                              |\n  #           |                              |\n  #           |                              |\n  #           |                              |\n  #           |                              |\n  #           |                              |\n  #           |                              |\n  #           |                              |\n  #           |                              |\n  #           |                              |"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Cast to float32 to avoid numerical issues with jax.\n  pix_x_int = xnp.array(pix_x_int, dtype=xnp.float32)\n  pix_y_int = xnp.array(pix_y_int, dtype=xnp.float32)\n  pixtocams = xnp.array(pixtocams, dtype=xnp.float32)\n  camtoworlds = xnp.array(camtoworlds, dtype=xnp.float32)\n\n  # Undistort.\n  if distortion_params is not None:\n    x, y = _radial_and_tangential_undistort(\n        xd=pix_x_int,\n        yd=pix_y_int,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n        xnp=xnp,\n    )\n  else:\n    x, y = pix_x_int, pix_y_int\n\n  # Convert to normalized coordinates in the range [-1, 1].\n  x = (2 * x / pixtocams[Ellipsis, 0, 2] - 1)\n  y = (2 * y / pixtocams[Ellipsis, 1, 2] - 1)\n\n  # OpenCV convention:\n  # +x is right, +y is down, +z is into the image, which is -z in the NeRF convention.\n  x, y, z = xnp.moveaxis(xnp.stack([x, y, xnp.ones_like(x)]), 0, -1)\n\n  # Camera coordinate system is 3D: +x is right, +y is down, +z is look-at direction.\n  # The coordinate system is assumed to be the same as the"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Cast to float32 to ensure precision is sufficient for the different numerical operations.\n  pix_x_int = xnp.array(pix_x_int, dtype=xnp.float32)\n  pix_y_int = xnp.array(pix_y_int, dtype=xnp.float32)\n  pixtocams = xnp.array(pixtocams, dtype=xnp.float32)\n  camtoworlds = xnp.array(camtoworlds, dtype=xnp.float32)\n\n  # Undistort the pixel coordinates if distortion parameters are provided.\n  if distortion_params is not None:\n    pix_x_int, pix_y_int = _radial_and_tangential_undistort(\n        pix_x_int, pix_y_int, **distortion_params\n    )\n\n  # Convert the pixel coordinates to camera coordinates.\n  pix_x_cam = (pix_x_int - pixtocams[..., 0, 2]) / pixtocams[..., 0, 0]\n  pix_y_cam = (pix_y_int - pixtocams[..., 1, 2]) / pixtocams[..., 1, 1]\n  primes = xnp.stack([pix_x_cam, pix_y_cam, xnp.ones_like(pix_x_int)], axis=-1)\n\n  # Compute the ray directions in camera coordinates.\n  if camtype == ProjectionType.PERSPECTIVE:\n    directions = xnp.squeeze(xnp.matmul(primes, pixtocams.T), axis=-1)\n  elif camtype in [ProjectionType.FISHEYE, ProjectionType.PANORAMIC]:\n    directions = xnp.squeeze(xnp.matmul(primes, pixtocams.T), axis=-1)\n    directions = directions / xnp.linalg.norm(directions, axis=-1, keepdim"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shape of the input pixel coordinates.\n  sh = pix_x_int.shape\n\n  # The inverse intrinsics for the NDC projection.\n  if pixtocam_ndc is None:\n    pixtocam_ndc = xnp.eye(3)\n\n  # The xy coordinates on the image plane, used to compute ray directions.\n  x, y = xnp.meshgrid(\n      xnp.arange(xnp.max(sh)), xnp.arange(xnp.min(sh)), indexing='xy'\n  )\n  x = x[None, Ellipsis]\n  y = y[None, Ellipsis]\n\n  # The pixel coordinates in camera coordinates, used to compute ray directions.\n  xcam = (x - pixtocams[Ellipsis, 0, 2]) / pixtocams[Ellipsis, 0, 0]\n  ycam = (y - pixtocams[Ellipsis, 1, 2]) / pixtocams[Ellipsis, 1, 1]\n  xcam = xcam[Ellipsis, None]\n  ycam = ycam[Ellipsis, None]\n\n  # The ray directions in camera coordinates, used to compute ray origins.\n  if camtype == ProjectionType.PERSPECTIVE:\n    directions = xnp.concatenate([xcam, ycam, xnp.ones_like(xcam)], axis=-1)\n  elif camtype == ProjectionType.FISHEYE:\n    r = xnp.sqrt(xcam * xcam + ycam * ycam)\n    theta = xnp.arctan2(r, xnp.ones_like(r))\n    sintheta = xnp.sin(theta)\n    tantheta = xnp.tan(theta)\n    rsintheta = r * sintheta\n    rcostheta = r * xnp.cos(theta)\n    directions = xnp.concatenate(\n        [\n            xcam * tantheta / rsinthe"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Compute pixel positions.\n  pix_x = pix_x_int + 0.5\n  pix_y = pix_y_int + 0.5\n\n  # Apply distortion to the pixel positions.\n  if distortion_params is not None:\n    # Compute the distortion parameters.\n    k1 = distortion_params.get('k1', 0.0)\n    k2 = distortion_params.get('k2', 0.0)\n    k3 = distortion_params.get('k3', 0.0)\n    k4 = distortion_params.get('k4', 0.0)\n    p1 = distortion_params.get('p1', 0.0)\n    p2 = distortion_params.get('p2', 0.0)\n    # Apply distortion correction.\n    pix_x, pix_y = _radial_and_tangential_undistort(\n        xd=pix_x, yd=pix_y, k1=k1, k2=k2, k3=k3, k4=k4, p1=p1, p2=p2\n    )\n\n  # Grab the camera intrinsics.\n  fx, fy, cx, cy = pixtocams[Ellipsis, 0, 0], pixtocams[Ellipsis, 1, 1], pixtocams[\n      Ellipsis, 0, 2\n  ], pixtocams[Ellipsis, 1, 2]\n\n  # Calculate the directions in camera space.\n  dirs = xnp.stack(\n      [(pix_x - cx) / fx, (pix_y - cy) / fy, xnp.ones_like(pix_x)], axis=-1\n  )\n  if camtype == ProjectionType.PANORAMIC:\n    # Rays through the center of the image are mapped to rays through the \"zenith\"\n    # of the sphere at the center of the image plane.\n    dirs /= x"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # TODO(keunhong): Add a reference to the paper describing the algorithm.\n  # TODO(keunhong): Add a reference to the paper describing the NDC space.\n  # TODO(keunhong): Add a reference to the paper describing the mip-NeRF cones.\n\n  # If the camera projection type is perspective, use the perspective projection formula.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # Apply the inverse intrinsic matrix to the pixel coordinates.\n    xcam = pixtocams[Ellipsis, 0, 0] * pix_x_int + pixtocams[Ellipsis, 0, 1] * pix_y_int + pixtocams[Ellipsis, 0, 2]\n    ycam = pixtocams[Ellipsis, 1, 0] * pix_x_int + pixtocams[Ellipsis, 1, 1] * pix_y_int + pixtocams[Ellipsis, 1, 2]\n    zcam = pixtocams[Ellipsis, 2, 0] * pix_x_int + pixtocams[Ellipsis, 2, 1] * pix_y_int + pixtocams[Ellipsis, 2, 2]\n    # Apply the inverse extrinsic matrix to the camera coordinates.\n    xcam = xcam - camtoworlds[Ellipsis, 0, 3]\n    ycam = ycam - camtoworlds[Ellipsis, 1, 3]\n    zcam = zcam - camtoworlds[Ellipsis, 2, 3]\n    # Compute the ray directions.\n    directions = xnp.stack([xcam, ycam, zcam], axis=-1)\n    # Compute the ray origins.\n    origins = xnp.broadcast_to(camtoworlds[Ellipsis, :3, -1], directions.shape)\n    # Normalize the ray directions.\n    viewdirs = directions / xnp.linal"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shape abbreviations.\n  sh = pix_x_int.shape\n  sh_prefix = sh[:-1]\n\n  # The coordinate transformation looks like:\n  #\n  #      image plane   p'      extrinsic      intrinsic     p\n  #            +---------->|------------>+------------>+---------->\n  #   camera   |          |   world      |   camera     |   image\n  #   frame  X |          |              |              |  frame\n  #            +<----------+<------------+<------------+----------+\n  #\n  # For perspective camera projection, the intrinsic matrix is typically the\n  # identity matrix, so here we omit it.\n  #\n  # First, convert from pixel coordinates p to normalized coordinates p'.\n  # Multiply with intrinsic inverse to get to camera frame.\n  if camtype == ProjectionType.PERSPECTIVE:\n    # No inverse intrinsic matrix.\n    px = pix_x_int\n    py = pix_y_int\n  elif camtype == ProjectionType.FISHEYE:\n    # Invert pixtocams.\n    pixtocam_inv = xnp.linalg.inv(pixtocams)\n    px, py = _radial_and_tangential_undistort(\n        xd=pix_x_int,\n        yd=pix_y_int,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n    )\n    px = px[Ellipsis, None]\n    py = py[Ellipsis, None]\n    # Apply inverse intrinsic matrix.\n    tmp = xnp.concatenate([px, py, xnp.ones_like(px)], axis=-1)\n    tmp = tmp[Ellipsis, None]\n    tmp = xnp.matmul(pixtocam_inv, tmp)"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # SH for shape.\n  if distortion_params is None:\n    distortion_params = {}\n\n  # Normalize directions between -1 and 1.\n  x = (pix_x_int + 0.5) / xnp.array(pixtocams)[..., 0, 2] - 1.0\n  y = (pix_y_int + 0.5) / xnp.array(pixtocams)[..., 1, 2] - 1.0\n\n  if camtype in [ProjectionType.PANORAMIC, ProjectionType.FISHEYE]:\n    # Calculate undistortion.\n    x, y = _radial_and_tangential_undistort(\n        x, y, **distortion_params, xnp=xnp\n    )\n\n  # Directions.\n  directions = xnp.stack([x, y, xnp.ones_like(x)], axis=-1)\n  if camtype == ProjectionType.PERSPECTIVE:\n    # The case of perspective camera is straight forward: pixel in NDC space.\n    directions = directions @ xnp.array(pixtocams)\n    directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n  elif camtype in [ProjectionType.PANORAMIC, ProjectionType.FISHEYE]:\n    # First transform to camera coordinates.\n    directions = directions @ xnp.array(pixtocams)\n    # Then project onto unit sphere.\n    directions = directions / xnp.linalg.norm(directions, axis=-1, keepdims=True)\n    # Calculate angular \"radius\" of the ray on the unit sphere.\n    radii = xnp.linalg.norm(directions[..., :2], axis=-1, keepdims=True)\n    # Calculate the z coordinate assuming the unit sphere is at z=1.\n    directions[..., 2:] = xnp.sqrt(\n        xnp.clip(1.0 - radii"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Shape abbreviations:\n  #    SH: shape of input arrays.\n  #    C: number of cameras.\n  #    H: height of image.\n  #    W: width of image.\n\n  # Determine the shape of the input arrays.\n  if isinstance(pix_x_int, int) and isinstance(pix_y_int, int):\n    # If pix_x_int and pix_y_int are integers, assume they are scalars.\n    # Convert them to arrays of shape [1].\n    pix_x_int = xnp.array([pix_x_int])\n    pix_y_int = xnp.array([pix_y_int])\n  else:\n    # If pix_x_int and pix_y_int are arrays, determine their shape.\n    # The shape is the broadcasted shape of the arrays.\n    shape = xnp.broadcast_shapes(pix_x_int.shape, pix_y_int.shape)\n\n  # Determine the number of cameras (C) and the height and width of the image (H, W).\n  # If pixtocams is a 3D array, its shape is [C, 3, 3].\n  # The number of cameras (C) is the first dimension of pixtocams.\n  # The height (H) and width (W) are determined by the shape of pix_x_int and pix_y_int.\n  C, H, W = pixtocams.shape[0], pix_x_int.shape[0], pix_x_int.shape[1]\n\n  # Reshape pix_x_int and pix_y_int to [H, W].\n  pix_x_int = pix_x_int.reshape([H, W])\n  pix_y_int = pix_y_int.reshape([H, W])\n\n  # Create an array of pixel coordinates of shape [H, W, 2].\n  # The array is filled with the pixel coordinates in the x and y directions.\n  pix_int = xnp.stack([pix_x_int"}
{"namespace": "camera_utils.pixels_to_rays", "completion": "  # Get the shape of the pixel coordinates, and broadcast the camera parameters.\n  # SH is the broadcasted shape of the pixel coordinates.\n  # SH is the shape of the pixel coordinates if they are already broadcasted, or the broadcasted shape of the camera parameters if they are not broadcasted.\n  SH = pix_x_int.shape\n  pixtocams = xnp.broadcast_to(pixtocams, SH + (3, 3))\n  camtoworlds = xnp.broadcast_to(camtoworlds, SH + (3, 4))\n\n  # Calculate the camera coordinates from the pixel coordinates.\n  # x and y are the camera coordinates, z is the depth of the camera.\n  # The camera coordinates are in the OpenCV coordinate system.\n  x, y = pix_x_int, pix_y_int\n  z = xnp.ones_like(x)\n\n  # Apply distortion correction if distortion parameters are provided.\n  if distortion_params is not None:\n    x, y = _radial_and_tangential_undistort(\n        x,\n        y,\n        k1=distortion_params['k1'],\n        k2=distortion_params['k2'],\n        k3=distortion_params['k3'],\n        k4=distortion_params['k4'],\n        p1=distortion_params['p1'],\n        p2=distortion_params['p2'],\n        xnp=xnp,\n    )\n\n  # Apply the inverse intrinsic matrix to get the camera coordinates.\n  camcoords = xnp.stack([x, y, z], axis=-1)\n  camcoords = camcoords @ xnp.moveaxis(pixtocams, -1, 0)\n\n  # Convert the camera coordinates to world coordinates.\n  camcoords = camcoords[Ellipsis, :3]\n  camcoords = camcoords / camcoords[Ellipsis, 2:]\n  camcoords = xnp.concatenate(\n      [camcoords, xnp.ones_like(camco"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density[Ellipsis, 1:] * jnp.linalg.norm(dirs[Ellipsis, 1:], axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  adjusted_density = density * tdist\n  return compute_alpha_weights_helper(adjusted_density, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density[Ellipsis, 1:] * jnp.linalg.norm(dirs[Ellipsis, 1:], axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density[Ellipsis, 1:] * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  adjusted_density = density * jnp.linalg.norm(dirs[Ellipsis, None, :], axis=-1)\n  density_delta = adjusted_density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * jnp.linalg.norm(dirs[Ellipsis, 1:, :], axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)"}
{"namespace": "render.compute_alpha_weights", "completion": "  adjusted_density = density * jnp.linalg.norm(dirs[Ellipsis, None, :], axis=-1)\n  alpha_weights = compute_alpha_weights_helper(adjusted_density * tdist, **kwargs)\n\n  return alpha_weights"}
{"namespace": "render.compute_alpha_weights", "completion": "  adjusted_density = density * jnp.linalg.norm(dirs[Ellipsis, None, :], axis=-1)\n  adjusted_tdist = tdist * adjusted_density\n  alpha_weights = compute_alpha_weights_helper(adjusted_tdist, **kwargs)\n  return alpha_weights"}
{"namespace": "render.compute_alpha_weights", "completion": "  adjusted_density = density * jnp.linalg.norm(dirs[Ellipsis, None, :], axis=-1)\n  density_delta = adjusted_density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density[Ellipsis, 1:] * jnp.linalg.norm(dirs[Ellipsis, 1:], axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  adjusted_density = density * jnp.linalg.norm(dirs[Ellipsis, 1:, :], axis=-1)\n  density_delta = adjusted_density * tdist\n\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  adjusted_density = density * jnp.linalg.norm(dirs[Ellipsis, None, :], axis=-1)\n  density_delta = adjusted_density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density * math.l2_norm(dirs[Ellipsis, 1:, :], axis=-1)\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  adjusted_density = density * math.safe_norm(dirs, axis=-1, keepdims=True)\n  adjusted_density = jnp.concatenate([adjusted_density, jnp.zeros_like(adjusted_density[Ellipsis, :1])], axis=-1)\n  density_delta = adjusted_density[Ellipsis, 1:] - adjusted_density[Ellipsis, :-1]\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  adjusted_density = density * tdist\n  return compute_alpha_weights_helper(adjusted_density, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  density_delta = density[Ellipsis, 1:] * tdist\n  alpha_weights = compute_alpha_weights_helper(density_delta, **kwargs)\n  return alpha_weights\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  adjusted_density = density * jnp.linalg.norm(dirs[Ellipsis, None, :], axis=-1)\n  density_delta = adjusted_density * tdist\n  return compute_alpha_weights_helper(density_delta, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  adjusted_density = density * tdist[Ellipsis, :-1]\n  return compute_alpha_weights_helper(adjusted_density, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  adjusted_density = density * tdist\n  return compute_alpha_weights_helper(adjusted_density, **kwargs)\n\n"}
{"namespace": "render.compute_alpha_weights", "completion": "  adjusted_density = density * (jnp.linalg.norm(dirs[Ellipsis, 1:], axis=-1) / tdist)\n  alpha_weights = compute_alpha_weights_helper(adjusted_density, **kwargs)\n  return alpha_weights\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Sample around the center of the step function.\n      u = jnp.linspace(0.5 / num_samples, 1.0 - 0.5 / num_samples, num_samples)\n      u = jnp.broadcast_to(u, w.shape[:-1] + (num_samples,))\n    else:\n      # Sample across the entire step function.\n      u = jnp.linspace(0.0, 1.0, num_samples)\n      u = jnp.broadcast_to(u, w.shape[:-1] + (num_samples,))\n    u = jnp.moveaxis(u, -1, 0)\n  else:\n    # Random sampling, from the inverse CDF.\n    if single_jitter:\n      # Apply the same jitter u to all samples.\n      u_jitter = jax.random.uniform(rng, w.shape[:-1] + (1,))\n      u = u_jitter + jnp.linspace(\n          0.0, 1.0 - eps, num_samples, dtype=w.dtype\n      )\n      u = jnp.broadcast_to(u, w.shape[:-1] + (num_samples,))\n    else:\n      # Apply a different jitter u to each sample.\n      u = jax.random.uniform(rng, w.shape[:-1] + (num_samples,))\n    u = jnp.sort(u)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_t"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Sample around the center of each bin.\n      u = (jnp.linspace(0.0 + eps, 1.0 - eps, num_samples) +\n           jnp.linspace(0.0, 1.0, num_samples)[:, None]) / 2\n    else:\n      # Sample across the entire PDF.\n      u = jnp.linspace(0.0 + eps, 1.0 - eps, num_samples)\n    return invert_cdf(u, t, w_logits)\n  else:\n    # Random sampling.\n    if single_jitter:\n      # Apply the same jitter to all samples.\n      shape = t.shape[:-1] + (num_samples,)\n      u = jax.random.uniform(rng, shape)\n    else:\n      # Apply a unique jitter to each sample.\n      u_max = jnp.broadcast_to(1 - eps, t.shape[:-1] + (num_samples,))\n      u_min = jnp.broadcast_to(0.0 + eps, t.shape[:-1] + (num_samples,))\n      u = jax.random.uniform(rng, t.shape[:-1] + (num_samples,)) * (\n          u_max - u_min) + u_min\n    return invert_cdf(u, t, w_logits)"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Sample from the center of the step function.\n      u = (jnp.linspace(0.0 + eps, 1.0 - eps, num_samples) + jnp.linspace(\n          0.0, 1.0, num_samples + 2)[1:-1]) / 2\n    else:\n      # Sample across the entire step function.\n      u = jnp.linspace(0.0 + eps, 1.0 - eps, num_samples)\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  else:\n    # Random sampling.\n    if single_jitter:\n      # Apply the same jitter to all samples.\n      shape = t.shape[:-1] + (num_samples,)\n      u = jax.random.uniform(rng, shape)\n    else:\n      # Apply a different jitter to each sample.\n      u_max = jnp.broadcast_to(cw[Ellipsis, -2:-1], cw[Ellipsis, :-1].shape)\n      u_min = jnp.broadcast_to(cw[Ellipsis, :1], cw[Ellipsis, :-1].shape)\n      u = jax.random.uniform(rng, cw[Ellipsis, :-1].shape) * (u_max - u_min) + u_min\n    t_new = invert_cdf(u, t, w_logits)\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Sample from the center of the step function.\n      u = (cw[Ellipsis, 1:] + cw[Ellipsis, :-1]) / 2\n    else:\n      # Sample from the entire step function.\n      u = jnp.linspace(0. + 0.5 * eps, 1. - 0.5 * eps, num_samples)\n      u = jnp.broadcast_to(u, cw.shape[:-1] + (num_samples,))\n  else:\n    # Random sampling, with optional jitter.\n    if single_jitter:\n      # If 'single_jitter' is True, the same jitter is applied to all samples.\n      # This results in no correlation between the samples.\n      u = jax.random.uniform(rng, cw.shape[:-1] + (1,))\n      u = u + jnp.arange(0, num_samples, dtype=cw.dtype) / num_samples\n      u = u - u.min()\n      u = u / (u.max() + eps)\n      u = jnp.broadcast_to(u, cw.shape[:-1] + (num_samples,))\n    else:\n      # If 'single_jitter' is False, each sample is jittered independently.\n      # This results in correlation between the samples.\n      u = jax.random.uniform(rng, cw.shape[:-1] + (num_samples,))\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Generate samples.\n  if rng is None:\n    # Deterministic sample along the step function.\n    if deterministic_center:\n      # Sample from the center of the step function.\n      u = (jnp.linspace(0.0, 1.0, num_samples) + jnp.linspace(\n          1.0 / num_samples, 1 - 1.0 / num_samples, num_samples)[:, None]) / 2\n    else:\n      # Sample from the entire step function.\n      u = jnp.linspace(0.0, 1.0, num_samples)\n    u = jnp.clip(u, eps, 1.0 - eps)\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  else:\n    # Randomly sample the step function.\n    if single_jitter:\n      # Apply the same jitter to all samples.\n      shape = w.shape[:-1] + (num_samples,)\n      u = jax.random.uniform(rng, shape)\n    else:\n      # Apply a different jitter to each sample.\n      u = jax.random.uniform(rng, (num_samples,))\n    t_new = invert_cdf(u, t, w_logits)\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Draw uniform samples.\n  if rng is None:\n    # Produce deterministic samples and wrap them.\n    if deterministic_center:\n      u = (jnp.linspace(0.0 + eps, 1.0 - eps, num_samples) + jnp.linspace(\n          0.0, 1.0, num_samples)[:, None]) / 2\n    else:\n      u = jnp.linspace(0.0 + eps, 1.0 - eps, num_samples)\n    u = math.pseudo_wrap(u)\n  else:\n    # Produce random samples.\n    # Note: we don't use random.uniform() because it's not supported by TPU.\n    u = jax.random.uniform(rng, list(w.shape[:-1]) + [num_samples])\n    if single_jitter:\n      # Match the behavior of jax.random.uniform() + linspace() above.\n      u += jax.random.uniform(rng, list(w.shape[:-1]) + [1])\n    u = math.pseudo_wrap(u)\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  return t_new"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  if rng is None:\n    # Produce samples through interpolation.\n    if deterministic_center:\n      # Sample from the center of the step function.\n      u = (jnp.linspace(0.0 + eps, 1.0 - eps, num_samples) + jnp.linspace(\n          0.0 + 0.5 / num_samples, 1.0 - 0.5 / num_samples, num_samples)) / 2\n    else:\n      # Sample from the entire step function.\n      u = jnp.linspace(0.0 + eps, 1.0 - eps, num_samples)\n    u = jnp.expand_dims(u, axis=-2)\n    return invert_cdf(u, t, w_logits)\n\n  else:\n    # Produce random samples.\n    if single_jitter:\n      # Apply the same jitter to all samples.\n      shape = (w_logits.shape[:-1] + (num_samples,))\n      u = jax.random.uniform(rng, shape=shape)\n    else:\n      # Apply a different jitter to each sample.\n      u_max = jnp.broadcast_to(cw[Ellipsis, -2:-1], cw.shape[:-1] + (num_samples,))\n      u_min = jnp.broadcast_to(cw[Ellipsis, 1:2], cw.shape[:-1] + (num_samples,))\n      u = jax.random.uniform(rng, shape=cw.shape[:-1] + (num_samples,), minval=u_min, maxval=u_max)\n\n    if deterministic_center:\n      #"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Invert the CDF.\n  if rng is None:\n    # Match MipNeRF-360 sampling, which does linspace then inverse transform.\n    u = jnp.linspace(0. + 0.5 / num_samples, 1. - 0.5 / num_samples, num_samples)\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  else:\n    # Pick random points.\n    if single_jitter:\n      # Match the behavior of jax.random.uniform() by only jittering the first sample.\n      # The difference is only noticeable when the number of samples is small.\n      u = jax.random.uniform(rng, t.shape[:-1] + (1,), dtype=t.dtype)\n      u = u + jnp.arange(num_samples, dtype=t.dtype) / num_samples / (num_samples + 1)\n      u = (u % 1.0)[:, 0]\n    else:\n      u = jax.random.uniform(rng, t.shape[:-1] + (num_samples,), dtype=t.dtype)\n    t_new = invert_cdf(u, t, w_logits)\n\n  # Postprocess to get continuous samples.\n  if deterministic_center and rng is not None:\n    # Match the behavior of NeRF-360 sampling, which samples the center of each bin.\n    bin_size = jnp.diff(t, axis=-1, append=jnp.inf)\n    t_new = jnp.clip(t_new, t[Ellipsis, :-1] + bin_size / 2, t["}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Invert the CDF.\n  if rng is None:\n    # Match Mip-NeRF 360's sampling, which does argmax sampling along the bins.\n    # This amounts to the CDF of a step function.\n    # TODO(jiawen): Replace with inverse transform sampling.\n    u = jnp.linspace(0.0 + eps, 1.0 - eps, num_samples)\n    u = jnp.broadcast_to(u, cw.shape[:-1] + (num_samples,))\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  else:\n    # Take a uniformly distributed sample.\n    u = jax.random.uniform(rng, cw.shape[:-1] + (num_samples,))\n    t_new = invert_cdf(u, t, w_logits)\n\n  # Perturb within each bin.\n  if not single_jitter:\n    # Apply the same jitter to all samples.\n    u = jax.random.uniform(rng, t_new.shape)\n  else:\n    # Apply a different jitter to each sample.\n    u = jax.random.uniform(rng, t_new.shape[:-1] + (1,))\n    u = jnp.broadcast_to(u, t_new.shape)\n  t_new = t_new + u * jnp.diff(t, axis=-1, keepdims=True)\n\n  # Truncate to the desired samples.\n  if deterministic_center:\n    t_new = jnp.clip(t_new, t[Ellipsis, :-1], t[Ellipsis, 1:"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Invert the CDF.\n  if rng is None:\n    # Match Mip-NeRF's sampling by using linspace instead of random uniform.\n    u = jnp.linspace(0. + 0.5 / num_samples, 1. - 0.5 / num_samples, num_samples)\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  else:\n    # Pick random points.\n    if single_jitter:\n      # Match the original NeRF sampling by jittering all samples by the same amount.\n      shape = w.shape[:-1] + (num_samples,)\n      u = jax.random.uniform(rng, shape)\n      jitter = jax.random.uniform(rng, shape)\n      u = u + jitter / num_samples\n      u = jnp.clip(u, 0, 1 - 1 / num_samples)\n    else:\n      # Sample one random number per sample.\n      u = jax.random.uniform(rng, w.shape[:-1] + (num_samples,))\n    t_new = invert_cdf(u, t, w_logits)\n\n  # Post-process to get the samples.\n  if deterministic_center:\n    # Match the original NeRF sampling---keep only the center point in each bin.\n    t_new = (t_new[Ellipsis, 1:] + t_new[Ellipsis, :-1]) / 2\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Determine the bin size for each interval.\n  bin_size = jnp.diff(t, axis=-1)\n\n  # Generate random values for each bin.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Sample around the center of each bin.\n      u = jnp.linspace(0.5 / num_samples, 1.0 - 0.5 / num_samples, num_samples)\n      u = jnp.broadcast_to(u, w_logits.shape[:-1] + (num_samples,))\n    else:\n      # Sample over the entire bin.\n      u = jnp.linspace(0.0, 1.0, num_samples)\n      u = jnp.broadcast_to(u, w_logits.shape[:-1] + (num_samples,))\n  else:\n    # Random sampling.\n    if single_jitter:\n      # Apply the same jitter to all samples.\n      u = jax.random.uniform(rng, w_logits.shape[:-1] + (num_samples,))\n    else:\n      # Apply a different jitter to each sample.\n      u = jax.random.uniform(rng, w_logits.shape[:-1] + (num_samples,))\n      # Add a random offset to each jitter to reduce correlation.\n      jitter_offset = jax.random.uniform(rng, w_logits.shape[:-1] + (1,))\n      u = (u + jitter_offset) % 1.0\n\n  # Compute the CDF and invert it to sample the step function.\n  t_new = invert_cdf(u, t, w_logits)\n\n  # Apply jitter to the samples.\n  if rng is not None:\n    t_new = t_new + jnp.expand_dims(bin_size, axis=-1) *"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Determine the bin into which each sample falls.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Sample around the center of each bin.\n      u = (jnp.linspace(0.0, 1.0, num_samples) + jnp.linspace(\n          0.5 / num_samples, (num_samples - 0.5) / num_samples, num_samples))\n    else:\n      # Sample across the entire PDF.\n      u = jnp.linspace(0.0, 1.0, num_samples)\n    u = jnp.clip(u, 0.0, 1.0 - eps)\n  else:\n    # Random sampling, from the inverse CDF.\n    if single_jitter:\n      # Apply the same jitter u to all samples.\n      u = jax.random.uniform(rng, (num_samples,))\n    else:\n      # Apply a different jitter u to each sample.\n      u = jax.random.uniform(rng, (num_samples,))\n  u = jnp.clip(u, eps, 1.0 - eps)\n\n  # Invert the CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Because we are sampling the CDF, we need to make sure the last value is 1.\n  cw = jnp.clip(cw, 0, 1)\n\n  # Get the coordinates for the ticks along the x-axis where the sampling will happen.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Sample around the center of each bin.\n      u = (cw[Ellipsis, 1:] + cw[Ellipsis, :-1]) / 2\n    else:\n      # Sample over the full range of the CDF.\n      u = jnp.linspace(0. + 0.5 * eps, 1. - 0.5 * eps, num_samples)\n      u = jnp.broadcast_to(u, cw.shape[:-1] + (num_samples,))\n  else:\n    # Random sampling.\n    if single_jitter:\n      # Apply the same jitter to all samples.\n      u = jax.random.uniform(rng, cw.shape[:-1] + (num_samples,))\n    else:\n      # Apply a different jitter to each sample.\n      u = jax.random.uniform(rng, (cw.shape[0], num_samples))\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  return t_new\n\n"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Invert the CDF.\n  if rng is None:\n    # Match the behavior of jax.random.uniform and np.random.uniform.\n    u = jnp.linspace(0.0 + eps, 1.0 - eps, num_samples)\n    if not single_jitter:\n      u = u[None, ...]  # [num_samples] -> [batch_size, num_samples]\n    u = u.astype(t.dtype)\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  else:\n    # Generate random samples.\n    if single_jitter:\n      # Don't jitter -- this makes the sampling pattern (and average)\n      # visually the same across all channels.\n      delta = jnp.zeros_like(w[Ellipsis, 0])\n    else:\n      # Apply jitter -- this makes the sampling pattern (and average)\n      # different across the channels.\n      delta = jax.random.uniform(rng, w[Ellipsis, 0].shape, dtype=w.dtype)\n      delta = (delta - 0.5) * (\n          jnp.diff(cw, axis=-1) / jnp.diff(t, axis=-1)\n      )\n    if deterministic_center:\n      # Match the behavior of jax.random.uniform and np.random.uniform.\n      u = cw[Ellipsis, :-1] + delta[Ellipsis, None] + 0.5 * jnp.diff(cw, axis=-1)\n      u = jnp.clip(u, eps, 1.0 - eps)\n    else:\n      #"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  # Invert the CDF.\n  if rng is None:\n    # Match Mip-NeRF's sampling, which uses a simple linear spacing on [0, 1).\n    # This results in samples that are always nicely placed in the center of each\n    # bin.\n    u = jnp.linspace(0.0, 1.0 - eps, num_samples)\n    t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n  else:\n    # Draw uniform samples.\n    min_u = jnp.maximum(0, cw[Ellipsis, :-1])  # eps\n    max_u = jnp.minimum(1, cw[Ellipsis, 1:])  # 1 - eps\n    u = jax.random.uniform(rng, cw.shape[:-1] + (num_samples,))\n    if not single_jitter:\n      min_u = min_u[Ellipsis, jnp.newaxis]\n      max_u = max_u[Ellipsis, jnp.newaxis]\n      u = min_u + u * (max_u - min_u)\n    else:\n      u = min_u + u * (max_u - min_u)\n    t_new = invert_cdf(u, t, w_logits)\n\n  if deterministic_center:\n    # Match the behavior of jax.random.uniform, which returns samples from\n    # [0, 1) * size. This means that half the samples will be centered in the\n    # bin interval.\n    t_new = (t_new[Ellipsis, 1:] + t_new[Ellipsis, :-1]) /"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  if rng is None:\n    # Produce samples through inverse transform sampling.\n    # Get the coordinates of the step function segments' centerpoints.\n    if deterministic_center:\n      # Deterministically sample around the centerpoint of each step.\n      # Find the centerpoint of each step.\n      t_mid = (t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2\n      # Pad with the first and last endpoints.\n      t_mid = jnp.concatenate([t[Ellipsis, :1], t_mid, t[Ellipsis, -1:]], axis=-1)\n    else:\n      # Deterministically sample from the entire step function.\n      # Pad with the first and last endpoints.\n      t_mid = jnp.concatenate([t[Ellipsis, :1], t_mid, t[Ellipsis, -1:]], axis=-1)\n\n    # Draw uniform samples.\n    u = jnp.linspace(0., 1., num_samples)\n    # Interpolate into the inverse CDF.\n    t_new = math.sorted_interp(u, cw, t_mid, utils.device_is_tpu())\n\n  else:\n    # Produce samples through inverse transform sampling.\n    # Draw uniform samples.\n    if single_jitter:\n      # If `single_jitter` is True, the same jitter is applied to all samples.\n      # This avoids the numerical issues related to maintaining density in the\n      # tails of the histograms.\n      shape = w.shape[:-1] + (num_samples,)\n      u = jax.random.uniform(rng, shape)\n    else:\n      # If `single_jitter` is False, a new jitter is applied to each sample.\n     "}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Pad CDFs to ensure we can always sample from the endpoints.\n  cw0 = jnp.concatenate([jnp.zeros_like(cw[Ellipsis, :1]), cw, jnp.ones_like(cw[Ellipsis, :1])], axis=-1)\n  # Draw uniform samples.\n  if rng is None:\n    # Produce deterministic samples by sampling linearly in the interval.\n    # We use linspace instead of random uniform sampling because this\n    # gives us better numerical precision when we use these samples\n    # to query a continuous random variable.\n    # The default behavior is to sample uniformly from the PDF.\n    u = jnp.linspace(0. + 0.5 / num_samples, 1 - 0.5 / num_samples, num_samples)\n    u = jnp.broadcast_to(u, cw.shape[:-1] + (num_samples,))\n  else:\n    # Produce random samples.\n    if single_jitter:\n      # Apply the same jitter to every sample.\n      shape = cw.shape[:-1] + (num_samples,)\n      u = jax.random.uniform(rng, shape, minval=1e-5)\n    else:\n      # Apply a different jitter to each sample.\n      u_max = 1 - 1e-5\n      u = jax.random.uniform(rng, cw.shape[:-1] + (num_samples,), maxval=u_max)\n  # Identify the location in `cw` that corresponds to a random sample.\n  # The final `True` index implies the samples are discretized.\n  index = jnp.argmax(u[Ellipsis, None, :] >= cw0["}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Because we are using the CDF, the last value must be strictly less than 1.\n  cw = cw[Ellipsis, :-1]\n\n  # Get the coordinates of the center of each interval.\n  t_mid = (t[Ellipsis, :-1] + t[Ellipsis, 1:]) / 2\n  # Get the size of each interval.\n  t_delta = (t[Ellipsis, 1:] - t[Ellipsis, :-1]) / 2\n\n  # Sample uniformly for each weight vector.\n  if rng is None:\n    # Deterministic sampling.\n    if deterministic_center:\n      # Sample around the center of the step function.\n      u = t_mid\n    else:\n      # Sample around the whole step function.\n      u = jnp.linspace(0. + 0.5 * eps, 1. - 0.5 * eps, num_samples)\n      u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # Random sampling, with optional jitter.\n    if single_jitter:\n      # Apply the same jitter u to all samples.\n      u = jax.random.uniform(rng, t.shape[:-1] + (num_samples,))\n    else:\n      # Apply a different jitter u to each sample.\n      u = jax.random.uniform(rng, t.shape[:-1] + (num_samples,))\n\n  # Interpolate each sample independently.\n  t_new = math.sorted_interp(u, cw, t, utils.device_is_tpu())\n\n  # Apply jitter.\n  if rng is not"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n\n  if rng is None:\n    # Deterministic sample along each interval.\n    pad = 0.1 if deterministic_center else 0.0\n    t_pad = jnp.pad(t[Ellipsis, 1:-1], (*t.shape[:-1], 1), mode=\"constant\", constant_values=pad)\n    # Draw uniform samples in [0, 1).\n    u = jnp.linspace(pad, 1 - pad, num_samples)\n    u = utils.expand_to(u, t.shape[:-1])\n    # Identify the corresponding bin for each uniform sample.\n    # Note `(u[Ellipsis, None] > cw[Ellipsis, None, :])` has shape [..., num_samples, n+1].\n    index = jnp.argmax(u[Ellipsis, None] > cw[Ellipsis, None, :], axis=-1)\n    # Identify the interval for each uniform sample.\n    # Note `t_pad` has shape [..., n+1], so `t_pad[index]` has shape [..., num_samples].\n    t0, t1 = t_pad[index], t_pad[index + 1]\n    # Jitter within the interval.\n    u = jnp.maximum(u, eps)\n    u = jnp.minimum(u, 1 - eps)\n    t_sample = (t1 - t0) * u + t0\n  else:\n    # Randomly sample across all bins.\n    if single_jitter:\n      # If single_jitter is True, we can jitter all samples together, which\n      # improves efficiency. In this case, we draw a single, shared sample in\n      # [0, 1), identify the"}
{"namespace": "stepfun.sample", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w_logits, axis=-1)\n  cw = integrate_weights(w)\n  # Pad cw with the value 0 at the beginning and 1 at the end.\n  cw = jnp.pad(cw, [(0, 0)] * (cw.ndim - 1) + [(1, 1)], mode=\"constant\", constant_values=(0, 1))\n  # Draw uniform samples.\n  if rng is None:\n    # Match MATLAB's linspace.\n    # https://github.com/google/mipnerf/issues/54.\n    # https://github.com/google/mipnerf/issues/104.\n    u = jnp.linspace(0.0, 1.0, num_samples + 2)[1:-1]\n    if deterministic_center:\n      u = 0.5 * (u + 1.0 / num_samples + jnp.arange(num_samples) / num_samples)\n      u = jnp.where(u > 1.0, u - 1.0, u)\n  else:\n    # Note: we're out of bounds of [0, 1) here because of the padding above.\n    u_shape = (t.shape[:-1] + (num_samples,))\n    if single_jitter:\n      # If single_jitter is True, we add the same jitter to all samples.\n      u = jax.random.uniform(rng, shape=u_shape)\n    else:\n      # Otherwise, we add a different jitter to each sample.\n      u_delta = jax.random.uniform(rng, shape=u_shape)\n      u = jnp.linspace(0.0, 1.0, num_samples + 2)[1:-1]\n      u = u + u_delta / num_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_samples_mid = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to fit within the domain\n  t_samples_mid = jnp.concatenate(\n      [\n          jnp.full(t_samples.shape[:-1] + (1,), domain[0]),\n          t_samples_mid,\n          jnp.full(t_samples.shape[:-1] + (1,), domain[1]),\n      ],\n      axis=-1,\n  )\n\n  return t_samples_mid"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples + 1)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples + 1,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jax.random.uniform(rng, t.shape[:-1] + (num_samples + 1,))\n\n  # Invert the CDF.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_mid = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Adjust the first and last intervals to fit within the domain.\n  t_samples = jnp.concatenate([t_samples[Ellipsis, :1], t_mid, t_samples[Ellipsis, -1:]], axis=-1)\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1 - jnp.finfo(jnp.float32).eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = jnp.finfo(jnp.float32).eps + (1 - jnp.finfo(jnp.float32).eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - jnp.finfo(jnp.float32).eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Compute the midpoints between adjacent samples.\n  t_samples = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain.\n  t_samples = jnp.concatenate(\n      [\n          jnp.full(t.shape[:-1] + (1,), domain[0]),\n          t_samples,\n          jnp.full(t.shape[:-1] + (1,), domain[1]),\n      ],\n      axis=-1,\n  )\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = jnp.finfo(jnp.float32).eps + (1 - jnp.finfo(jnp.float32).eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - jnp.finfo(jnp.float32).eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_samples = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Adjust the first and last intervals to fit within the domain.\n  t_samples = jnp.concatenate(\n      [\n          jnp.full(t.shape[:-1] + (1,), domain[0]),\n          t_samples,\n          jnp.full(t.shape[:-1] + (1,), domain[1]),\n      ],\n      axis=-1,\n  )"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_mids = (t_samples[..., :-1] + t_samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the domain\n  t_first = jnp.full(t_mids[..., :1].shape, domain[0])\n  t_last = jnp.full(t_mids[..., -1:].shape, domain[1])\n  t_mids = jnp.concatenate([t_first, t_mids, t_last], axis=-1)\n\n  return t_mids"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1 - jnp.finfo(jnp.float32).eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = jnp.finfo(jnp.float32).eps + (1 - jnp.finfo(jnp.float32).eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - jnp.finfo(jnp.float32).eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Compute the midpoints between adjacent samples.\n  t_mid = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Include the first and last sample points in the midpoint calculation.\n  t_mid = jnp.concatenate([t_samples[Ellipsis, :1], t_mid, t_samples[Ellipsis, -1:]], axis=-1)\n\n  # Clamp the intervals to the domain.\n  t_samples = jnp.clip(t_samples, domain[0], domain[1"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples + 1)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples + 1,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = jnp.finfo(jnp.float32).eps + (1 - jnp.finfo(jnp.float32).eps) / num_samples\n    max_jitter = (1 - u_max) / num_samples - jnp.finfo(jnp.float32).eps\n    u = jnp.linspace(0, 1 - u_max, num_samples + 1) + jax.random.uniform(\n        rng, t.shape[:-1] + (num_samples + 1,), maxval=max_jitter\n    )\n\n  # Invert the CDF.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_samples = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Adjust the first and last intervals to fit within the domain.\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n  t_samples = jnp.concatenate(\n      [\n          jnp.full(t.shape[:-1] + (1,), domain[0]),\n          t_samples,\n          jnp.full(t.shape[:-1] + (1,), domain["}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1 - jnp.finfo(jnp.float32).eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jax.random.uniform(rng, t.shape[:-1] + (num_samples,))\n\n  # Invert the CDF.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Calculate midpoints between adjacent samples.\n  t_samples = (t_samples[..., 1:, :] + t_samples[..., :-1, :]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the domain.\n  t_samples = jnp.concatenate(\n      [\n          jnp.full(t_samples[..., :1, :].shape, domain[0]),\n          t_samples,\n          jnp.full(t_samples[..., -1:, :].shape, domain[1]),\n      ],\n      axis=-2,\n  )\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples + 1)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples + 1,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = jnp.finfo(jnp.float32).eps + (1 - jnp.finfo(jnp.float32).eps) / num_samples\n    max_jitter = (1 - u_max) / num_samples - jnp.finfo(jnp.float32).eps\n    u = jnp.linspace(0, 1 - u_max, num_samples + 1) + jax.random.uniform(\n        rng, t.shape[:-1] + (num_samples + 1,), maxval=max_jitter\n    )\n\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Compute the midpoints between adjacent samples.\n  midpoints = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain.\n  t_samples = jnp.concatenate(\n      [\n          jnp.broadcast_to(domain[0], t_samples.shape[:-1] + (1,)),\n          midpoints,\n          jnp.broadcast_to(domain[1], t_samples.shape[:-1] + (1,)),\n      ],\n      axis=-1,\n  )\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1 - jnp.finfo(jnp.float32).eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = jnp.finfo(jnp.float32).eps + (1 - jnp.finfo(jnp.float32).eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - jnp.finfo(jnp.float32).eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Compute the midpoints between adjacent samples.\n  t_samples_mid = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Ensure that the first and last intervals are within the valid domain.\n  t_samples_mid = jnp.concatenate(\n      [\n          t_samples[Ellipsis, :1],\n          t_samples_mid,\n          t_samples[Ellipsis, -1:],\n      ],\n      axis=-1,\n  )\n  t_samples_mid = jnp.clip(t_samples_mid"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    pad = 1 / (2 * num_samples)\n    u = jnp.linspace(pad, 1.0 - pad, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jax.random.uniform(rng, t.shape[:-1] + (num_samples,))\n\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Compute the midpoints between adjacent samples.\n  t_mid = (t_samples[..., 1:, :] + t_samples[..., :-1, :]) / 2\n\n  # Ensure that the first and last intervals are within the valid range.\n  t_samples = jnp.concatenate([t_samples[..., :1, :], t_mid, t_samples[..., -1:, :]], axis=-2)\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples + 1)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples + 1,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples + 1)\n    if not single_jitter:\n      max_jitter = (1 - u[Ellipsis, -1]) / num_samples\n      u = u + jax.random.uniform(rng, t.shape[:-1] + (num_samples + 1,), maxval=max_jitter)\n\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Piecewise-Constant PDF sampling from a step function.\n  t_mid = (t_samples[Ellipsis, 1:, :] + t_samples[Ellipsis, :-1, :]) / 2\n  t_samples = jnp.concatenate([t_samples[Ellipsis, :1, :], t_mid, t_samples[Ellipsis, -1:, :]], axis=-2)\n\n  # Clip to the desired domain.\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_mid = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Adjust the first and last intervals to fit within the domain\n  t_first = jnp.full_like(t_samples[Ellipsis, :1], domain[0])\n  t_last = jnp.full_like(t_samples[Ellipsis, :1], domain[1])\n  t_samples = jnp.concatenate([t_first, t_mid, t_last], axis=-1)\n\n  # Clamp the intervals to the domain\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    pad = 1 / (2 * num_samples)\n    u = jnp.linspace(pad, 1.0 - pad - jnp.finfo(jnp.float32).eps, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u_max = jnp.finfo(jnp.float32).eps + (1 - jnp.finfo(jnp.float32).eps) / num_samples\n    max_jitter = (1 - u_max) / (num_samples - 1) - jnp.finfo(jnp.float32).eps\n    d = 1 if single_jitter else num_samples\n    u = jnp.linspace(0, 1 - u_max, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (d,), maxval=max_jitter\n    )\n\n  # Invert the CDF.\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Piecewise-Constant PDF sampling from a step function.\n  # This function samples intervals from a step function based on provided bin endpoint coordinates, bin weights (logits), and other parameters.\n  # It generates a set of interval samples by first sampling points from the step function, then calculating midpoints between adjacent samples, and finally adjusting the first and last intervals to ensure they are within the specified domain.\n\n  # Input-Output Arguments\n  # :param rng: Random number generator or None. Used for generating random samples. If None, 'linspace' sampling is implied.\n  # :param t:"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  midpoints = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to fit within the domain\n  first_interval = jnp.concatenate([t[..., :1], midpoints[..., :1]], axis=-1)\n  last_interval = jnp.concatenate([midpoints[..., -1:], t[..., -1:]], axis=-1)\n  t_samples = jnp.concatenate([first_interval, midpoints, last_interval], axis=-1)\n\n  # Clip the intervals to fit within the domain\n  t_samples = jnp.clip(t_samples, domain[0], domain[1])\n\n  return t_samples\n\n"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    pad = 1 / (2 * num_samples)\n    u = jnp.linspace(pad, 1.0 - pad, num_samples)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jnp.linspace(0, 1.0, num_samples) + jax.random.uniform(\n        rng, t.shape[:-1] + (num_samples,), maxval=1 / num_samples\n    )\n\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Compute the midpoints between adjacent samples.\n  t_mid = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Include a sample that is exactly at the left endpoint.\n  t_first = t[Ellipsis, :1]\n  t_mid = jnp.concatenate([t_first, t_mid], axis=-1)\n\n  # Include a sample that is exactly at the right endpoint.\n  t_last = t[Ellipsis, -1:]\n  t_mid = jnp.concatenate([t_mid, t_last], axis=-1)\n\n  # Clip the left endpoint to the domain's lower bound.\n  t_mid = jnp.where(t_mid < domain[0], domain[0], t_mid)\n\n  # Clip the right endpoint to the domain's upper bound.\n  t_mid = jnp.where(t_mid > domain[1], domain[1], t_mid)"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Generate samples from the step function\n  samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  midpoints = (samples[..., :-1] + samples[..., 1:]) / 2\n\n  # Adjust the first and last intervals to fit within the domain\n  minval, maxval = domain\n  first_interval = jnp.minimum(samples[..., :1], midpoints[..., :1])\n  last_interval = jnp.maximum(samples[..., -1:], midpoints[..., -1:])\n  midpoints = jnp.concatenate([first_interval, midpoints, last_interval], axis=-1)\n\n  # Clip the midpoints to the valid range\n  midpoints = jnp.clip(midpoints, minval, maxval)\n\n  # Return the midpoints as the sampled intervals\n  return midpoints"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    # Match the behavior of jax.random.uniform() by spanning [0, 1-eps].\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples + 1)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples + 1,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jnp.linspace(0, 1.0 - jnp.finfo(jnp.float32).eps, num_samples + 1)\n    if single_jitter:\n      jitter = jax.random.uniform(rng, t.shape[:-1] + (1,)) / num_samples\n      u += jitter\n    else:\n      u += jax.random.uniform(rng, t.shape[:-1] + (num_samples + 1,)) / num_samples\n\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Compute the midpoints between adjacent samples.\n  t_samples = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Ensure that the first and last samples are within the valid range.\n  t_samples = jnp.concatenate(\n      [\n          jnp.full(t.shape[:-1] + (1,), domain[0]),\n          t_samples,\n          jnp.full(t.shape[:-1] + (1,), domain[1]),\n      ],\n      axis=-1,\n  )\n\n  return t_samples"}
{"namespace": "stepfun.sample_intervals", "completion": "  utils.assert_valid_stepfun(t, w_logits)\n\n  # Draw uniform samples.\n  if rng is None:\n    u = jnp.linspace(0, 1, num_samples + 1)\n    u = jnp.broadcast_to(u, t.shape[:-1] + (num_samples + 1,))\n  else:\n    # `u` is in [0, 1) --- it can be zero, but it can never be 1.\n    u = jnp.linspace(0, 1, num_samples + 1)\n    if not single_jitter:\n      jitter_size = (1 - u[Ellipsis, 1:]) / num_samples\n      jitter = jax.random.uniform(rng, t.shape[:-1] + (num_samples,), maxval=jitter_size)\n      u = u[Ellipsis, :-1] + jitter\n\n  t_samples = invert_cdf(u, t, w_logits)\n\n  # Compute the midpoints between adjacent samples.\n  t_mid = (t_samples[Ellipsis, 1:] + t_samples[Ellipsis, :-1]) / 2\n\n  # Adjust the first and last intervals to fit within the specified domain.\n  t_samples = t_samples.at[Ellipsis, 0].set(domain[0])\n  t_samples = t_samples.at[Ellipsis, -1].set(domain[1])\n  t_mid = t_mid.at[Ellipsis, 0].set(domain[0])\n  t_mid = t_mid.at[Ellipsis, -1].set(domain[1])\n\n  return t_mid"}
{"namespace": "stepfun.sample_intervals", "completion": "  # Sample points from the step function\n  t_samples = sample(rng, t, w_logits, num_samples, single_jitter)\n\n  # Calculate midpoints between adjacent samples\n  t_samples_mid = (t_samples[..., 1:] + t_samples[..., :-1]) / 2\n\n  # Adjust the first and last intervals to ensure they are within the specified domain\n  t_samples_mid = jnp.concatenate([\n      jnp.full(t_samples_mid[..., :1].shape, domain[0]),\n      t_samples_mid,\n      jnp.full(t_samples_mid[..., :1].shape, domain[1])\n  ], axis=-1)\n\n  # Return the sampled intervals\n  return t_samples_mid\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return linspline.interpolate(cw, t, ps)"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  w = weight_to_pdf(t, w)\n  cw = integrate_weights(w)\n  return linspline.interpolate(ps, cw, t)"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_new"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the integrated weights at the given percentiles.\n  return linspline.interpolate(cw, t, ps / 100)"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the integrated weights at the given percentiles.\n  return linspline.interpolate(cw, t, ps / 100)"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the integrated weights at the given percentiles.\n  return linspline.interpolate(cw, t, ps / 100)"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the integrated weights at the given percentiles.\n  p = jnp.array(ps) / 100\n  t_p = math.sorted_interp(p, cw, t, utils.device_is_tpu())\n\n  return t_p"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  cw = integrate_weights(w)\n  return jax.vmap(linspline.interpolate, in_axes=(0, 0, 0))(cw, t, ps / 100)"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Ensure that the weights sum to 1.\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the integrated weights at the given percentiles.\n  cw_interp = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return cw_interp"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the CDF and normalize the weights.\n  cw = integrate_weights(w)\n  cw /= cw[Ellipsis, -1:]\n  # Interpolate each percentile.\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n  return t_percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Ensure that the weights sum to 1\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n\n  # Integrate the weights to get the cumulative distribution function (CDF)\n  cw = jnp.cumsum(w, axis=-1)\n\n  # Interpolate the CDF to find the x-values corresponding to the given percentiles\n  t_new = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_new"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the CDF and normalize it.\n  cw = integrate_weights(w)\n  cw /= cw[Ellipsis, -1:]\n  cw = jnp.clip(cw, 0, 1)\n  # Interpolate into the inverse CDF.\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n  return t_percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the CDF\n  cw = integrate_weights(w)\n\n  # Interpolate the CDF to the given percentiles\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the CDF.\n  cw = integrate_weights(w)\n\n  # Interpolate the desired percentiles.\n  return math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the integrated weights\n  cw = integrate_weights(w)\n\n  # Interpolate the integrated weights to find the x-coordinates corresponding to the given percentiles\n  t_new = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_new"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Compute the integrated weights\n  w_int = integrate_weights(w)\n\n  # Interpolate the integrated weights at the given percentiles\n  w_int_at_ps = linspline.interpolate(w_int, ps / 100, t)\n\n  # Compute the weighted percentiles\n  w_percentiles = w_int_at_ps / w_int_at_ps[..., -1:]\n\n  return w_percentiles"}
{"namespace": "stepfun.weighted_percentile", "completion": "  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the integrated weights at the given percentiles.\n  cw_interp = linspline.interpolate(cw, ps / 100)\n\n  # Compute the weighted percentiles.\n  t_interp = linspline.interpolate(t, cw_interp)\n\n  return t_interp"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n  w = jnp.where(w == jnp.inf, 0, w)\n  w = jnp.where(jnp.isnan(w), 0, w)\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n  cw = integrate_weights(w)\n  return jnp.interp(ps / 100.0, cw, t)\n\n"}
{"namespace": "stepfun.weighted_percentile", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the integrated weights.\n  cw = integrate_weights(w)\n\n  # Interpolate the integrated weights at the given percentiles.\n  # This returns the x-coordinates of the weighted percentiles.\n  t_percentiles = math.sorted_interp(ps / 100, cw, t, utils.device_is_tpu())\n\n  return t_percentiles\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF.\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  blurred_pdf = linspline.blur(t, pdf, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points.\n  resampled_weights = resample(tq, t, blurred_pdf, use_avg=False)\n\n  return resampled_weights"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert weights to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF using a Gaussian kernel\n  p_blurred = linspline.blur(t, p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  p_resampled = resample(tq, t, p_blurred)\n\n  # Convert the resampled PDF back to weights\n  w_resampled = pdf_to_weight(tq, p_resampled)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a probability density function (PDF)\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF using a Gaussian filter\n  blurred_pdf = linspline.gaussian_filter(pdf, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  resampled_pdf = resample(tq, t, blurred_pdf, use_avg=True)\n\n  # Convert the resampled PDF back to weights\n  resampled_weights = pdf_to_weight(tq, resampled_pdf)\n\n  return resampled_weights"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Convert the weights to a PDF.\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  p_blurred = linspline.blur(p, blur_halfwidth)\n\n  # Resample the blurred PDF.\n  p_resampled = resample(tq, t, p_blurred, use_avg=False)\n\n  # Convert the resampled PDF back to weights.\n  w_resampled = pdf_to_weight(tq, p_resampled)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a probability density function (PDF)\n  pdf = weight_to_pdf(t, w)\n\n  # Blur the PDF using a Gaussian filter\n  blurred_pdf = linspline.gaussian_filter(pdf, blur_halfwidth, t)\n\n  # Resample the blurred PDF to match the new time points `tq`\n  resampled_blurred_pdf = resample(tq, t, blurred_pdf, use_avg=False)\n\n  # Convert the resampled blurred PDF back to weights\n  resampled_blurred_weights = pdf_to_weight(tq, resampled_blurred_pdf)\n\n  return resampled_blurred_weights"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  w = linspline.resample(tq, t, w, use_avg=False)\n  w = linspline.blur(w, blur_halfwidth)\n  w = jnp.maximum(w, 0)\n  w = w / jnp.sum(w, axis=-1, keepdims=True)\n  return w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a probability density function (PDF)\n  p = weight_to_pdf(t, w)\n\n  # Apply Gaussian blur to the PDF\n  p_blurred = linspline.blur(p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points\n  p_resampled = resample(tq, t, p_blurred, use_avg=False)\n\n  # Convert the resampled PDF back to weights\n  w_resampled = pdf_to_weight(tq, p_resampled)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  if blur_halfwidth == 0:\n    return resample(tq, t, w)\n\n  # Convert to a PDF.\n  w = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  w = blur(t, w, blur_halfwidth)\n\n  # Resample the PDF.\n  w = resample(tq, t, w)\n\n  # Convert back to weights.\n  w = pdf_to_weight(tq, w)\n\n  return w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  # Convert the histogram to a PDF.\n  p = weight_to_pdf(t, w)\n\n  # Blur the PDF.\n  p = linspline.blur(t, p, blur_halfwidth)\n\n  # Resample the blurred PDF to match the new time points.\n  p_resampled = resample(tq, t, p, use_avg=False)\n\n  # Convert the resampled PDF back to weights.\n  w_resampled = pdf_to_weight(tq, p_resampled)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Convert the weights into a PDF.\n  p = weight_to_pdf(t, w)\n  # Blur the PDF.\n  p_blurred = linspline.blur(t, p, blur_halfwidth)\n  # Resample the PDF to match the new time points.\n  p_resampled = resample(tq, t, p_blurred, use_avg=False)\n  # Convert the resampled PDF back to weights.\n  w_resampled = pdf_to_weight(tq, p_resampled)\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w, axis=-1)\n  cw = integrate_weights(w)\n  # Compute the blurred PDF.\n  cw_blur = linspline.blur(cw, blur_halfwidth, t)\n  # Interpolate into the inverse CDF.\n  w_blur = math.sorted_interp(cw_blur, t, w, utils.device_is_tpu())\n  # Resample the blurred PDF.\n  w_blur_resampled = resample(tq, t, w_blur, use_avg=False)\n  return w_blur_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w, axis=-1)\n  cw = integrate_weights(w)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(tq, cw, t, utils.device_is_tpu())\n\n  # Blur the PDF.\n  t_blur, w_blur = linspline.blur(t_new, w, blur_halfwidth)\n\n  # Resample the blurred PDF.\n  w_blur_resampled = resample(tq, t_blur, w_blur, use_avg=False)\n\n  return w_blur_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  t_blur, w_blur = linspline.convolve_with_filter1d(\n      t, w, blur_halfwidth, padding='SYMMETRIC'\n  )\n  w_blur_resampled = resample(tq, t_blur, w_blur)\n  return w_blur_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  tp = jnp.concatenate([t[Ellipsis, :1], (t[Ellipsis, 1:] + t[Ellipsis, :-1]) / 2], axis=-1)\n  wp = jnp.concatenate([jnp.zeros(w.shape[:-1] + (1,)), w], axis=-1)\n  wp = linspline.blur(tp, wp, blur_halfwidth)\n  w = resample(tq, tp, wp, use_avg=False)\n  return w"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n\n  # Blur the weights with a Gaussian kernel.\n  w_blurred = linspline.gaussian_convolution(t, w, blur_halfwidth)\n\n  # Resample the blurred weights to the new time points.\n  w_resampled = resample(tq, t, w_blurred, use_avg=False)\n\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  if blur_halfwidth == 0:\n    return resample(tq, t, w)\n  # Compute the PDF.\n  pdf = weight_to_pdf(t, w)\n  # Blur the PDF.\n  pdf_blurred = linspline.blur(pdf, blur_halfwidth)\n  # Resample the PDF.\n  pdf_resampled = resample(tq, t, pdf_blurred)\n  # Convert the resampled PDF back to weights.\n  w_resampled = pdf_to_weight(tq, pdf_resampled)\n  return w_resampled\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w, axis=-1)\n  cw = integrate_weights(w)\n  # Blur the PDF.\n  t_blur, p_blur = linspline.convolve_with_filter1d(\n      t, cw, t, blur_halfwidth, padding='SYMMETRIC'\n  )\n  # Interpolate into the PDF.\n  p_resampled = jnp.vectorize(jnp.interp, signature='(n),(m),(m)->(n)')(tq, t_blur, p_blur)\n  # Convert the PDF back to weights.\n  w_resampled = math.safe_div(p_resampled, jnp.diff(t_blur, axis=-1))\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF and CDF for each weight vector.\n  w = jax.nn.softmax(w, axis=-1)\n  cw = integrate_weights(w)\n\n  # Blur the CDF.\n  cw_blur = linspline.blur(t, cw, blur_halfwidth)\n\n  # Interpolate into the inverse CDF.\n  t_new = math.sorted_interp(cw_blur, t, tq, utils.device_is_tpu())\n\n  # Resample the weights.\n  w_new = resample(t_new, t, w)\n\n  return w_new\n\n"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  tp = t[Ellipsis, :-1]\n  vp = w\n  tqp = tq[Ellipsis, :-1]\n  vqp = jnp.concatenate([jnp.zeros(tq.shape[:-1] + (1,)), tq[Ellipsis, 1:]], axis=-1)\n  # Compute the PDF.\n  wp = pdf_to_weight(tp, vp)\n  # Blur the PDF.\n  wp_blur = linspline.blur(wp, blur_halfwidth, tp, tqp, vqp)\n  # Resample the PDF.\n  w_resampled = resample(tq, tp, wp_blur, use_avg=False)\n  return w_resampled"}
{"namespace": "stepfun.blur_and_resample_weights", "completion": "  utils.assert_valid_stepfun(t, w)\n  # Compute the PDF.\n  p = weight_to_pdf(t, w)\n  # Blur the PDF.\n  p_blurred = linspline.blur(t, p, blur_halfwidth)\n  # Resample the PDF.\n  p_resampled = resample(tq, t, p_blurred, use_avg=False)\n  # Convert the resampled PDF back to weights.\n  w_resampled = pdf_to_weight(tq, p_resampled)\n  return w_resampled\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input vectors to homogeneous coordinates\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the homogeneous transformation to the homogeneous vectors\n  transformed_vectors = matmul(transform, homogeneous_vectors.T).T\n\n  # Convert the transformed vectors back to non-homogeneous coordinates\n  return from_homogeneous(transformed_vectors)"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input vectors to homogeneous coordinates\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the homogeneous transformation to the homogeneous vectors\n  transformed_homogeneous_vectors = matmul(transform, homogeneous_vectors)\n\n  # Convert the transformed homogeneous vectors back to non-homogeneous coordinates\n  transformed_vectors = from_homogeneous(transformed_homogeneous_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(vectors, transform))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input vectors to homogeneous coordinates\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the transformation to the homogeneous vectors\n  transformed_homogeneous_vectors = matmul(transform, homogeneous_vectors.T).T\n\n  # Convert the transformed homogeneous vectors back to non-homogeneous coordinates\n  transformed_vectors = from_homogeneous(transformed_homogeneous_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Apply the homogeneous transformation to each vector in the collection\n  vectors_h = to_homogeneous(vectors)\n  transformed_vectors_h = matmul(transform, vectors_h)\n  transformed_vectors = from_homogeneous(transformed_vectors_h)\n\n  # Return the transformed vectors\n  return transformed_vectors\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(transform, to_homogeneous(vectors)))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  return from_homogeneous(matmul(to_homogeneous(vectors), transform))\n\n"}
{"namespace": "spin_math.apply_homogeneous_transform", "completion": "  # Convert the input vectors to homogeneous coordinates\n  homogeneous_vectors = to_homogeneous(vectors)\n\n  # Apply the homogeneous transformation to the homogeneous vectors\n  transformed_homogeneous_vectors = matmul(transform, homogeneous_vectors)\n\n  # Convert the transformed homogeneous vectors back to non-homogeneous coordinates\n  transformed_vectors = from_homogeneous(transformed_homogeneous_vectors)\n\n  return transformed_vectors\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  if use_avg:\n    v = linspline.resample(t, tp, vp, linspline.ResampleMethod.AVG)\n  else:\n    v = linspline.resample(t, tp, vp, linspline.ResampleMethod.SUM)\n  return v"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of each interval in the original step function.\n  w = jnp.diff(tp, axis=-1)\n\n  # Compute the width of each interval in the new step function.\n  wp = jnp.diff(t, axis=-1)\n\n  # Compute the indices of the original time points that are within each interval in the new step function.\n  inds = jnp.searchsorted(tp, t[Ellipsis, :-1])\n\n  # Compute the indices of the original time points that are within each interval in the new step function.\n  inds = jnp.searchsorted(tp, t[Ellipsis, :-1])\n\n  # Compute the width of each interval in the original step function.\n  w = jnp.diff(tp, axis=-1)\n\n  # Compute the width of each interval in the new step function.\n  wp = jnp.diff(t, axis=-1)\n\n  # Compute the indices of the original time points that are within each interval in the new step function.\n  inds = jnp.searchsorted(tp, t[Ellipsis, :-1])\n\n  # Compute the indices of the original time points that are within each interval in the new step function.\n  inds = jnp.searchsorted(tp, t[Ellipsis, :-1])\n\n  # Compute the width of each interval in the original step function.\n  w = jnp.diff(tp, axis=-1)\n\n  # Compute the width of each interval in the new step function.\n  wp = jnp.diff(t, axis=-1)\n\n  # Compute the indices of the original time points that are within each interval in the new step function.\n  inds = jnp.searchsorted(tp, t[Ellipsis, :-1])\n\n  # Compute the indices of the original time points that are within each interval in the new step function.\n  inds = jnp.searchsorted(tp"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # Compute the weights for resampling.\n  w = jnp.diff(t, axis=-1)\n  wp = jnp.diff(tp, axis=-1)\n  # Resample the values.\n  v = jnp.where(\n      use_avg,\n      linspline.resample_linear(t, tp, vp * wp, w),\n      linspline.resample_linear(t, tp, vp, w),\n  )\n  return v"}
{"namespace": "stepfun.resample", "completion": "  # Assert that the input tensors have the correct shapes\n  assert t.shape[-1] == tp.shape[-1] + 1, \"t must have one more element than tp\"\n  assert t.shape == vp.shape, \"t and vp must have the same shape\"\n\n  # Compute the width of each interval in t\n  dt = t[..., 1:] - t[..., :-1]\n\n  # Compute the width of each interval in tp\n  dtp = tp[..., 1:] - tp[..., :-1]\n\n  # Compute the overlap between each interval in t and tp\n  overlap = jnp.maximum(0, jnp.minimum(dtp[..., :, None], dt[..., None, :]) - jnp.maximum(t[..., :-1, None], tp[..., None, :-1]))\n\n  # Compute the weight for each interval in tp\n  if use_avg:\n    weight = overlap / dtp[..., None]\n  else:\n    weight = overlap\n\n  # Compute the resampled values\n  v = jnp.sum(weight * vp[..., None, :], axis=-1)\n  if use_avg:\n    v /= dt\n\n  return v"}
{"namespace": "stepfun.resample", "completion": "  # Compute the width of each interval in `t`\n  t_widths = t[..., 1:] - t[..., :-1]\n\n  # Compute the width of each interval in `tp`\n  tp_widths = tp[..., 1:] - tp[..., :-1]\n\n  # Compute the intersection between each interval in `t` and `tp`\n  t_start = jnp.maximum(t[..., :, None], tp[..., None, :])\n  t_end = jnp.minimum(t[..., 1:, None], tp[..., None, 1:])\n  t_intersect_widths = jnp.maximum(0, t_end - t_start)\n\n  # Compute the weight for each interval in `t`\n  if use_avg:\n    t_weights = t_intersect_widths / t_widths[..., None]\n  else:\n    t_weights = t_intersect_widths\n\n  # Compute the weight for each interval in `tp`\n  if use_avg:\n    tp_weights = t_intersect_widths / tp_widths[..., None]\n  else:\n    tp_weights = t_intersect_widths\n\n  # Compute the resampled values\n  v = jnp.sum(vp[..., None, :] * tp_weights, axis=-1)\n  if use_avg:\n    v = v / jnp.sum(t_weights, axis=-1)\n\n  return v"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of each interval in `t`.\n  dt = jnp.diff(t, axis=-1)\n\n  # Compute the width of each interval in `tp`.\n  dtp = jnp.diff(tp, axis=-1)\n\n  # Compute the midpoint of each interval in `t`.\n  tmid = (t[..., 1:] + t[..., :-1]) / 2\n\n  # Compute the midpoint of each interval in `tp`.\n  tpmid = (tp[..., 1:] + tp[..., :-1]) / 2\n\n  # Compute the distance between each midpoint in `t` and each midpoint in `tp`.\n  dist = jnp.abs(tmid[..., :, None] - tpmid[..., None, :])\n\n  # Compute the weight of each interval in `tp` for each interval in `t`.\n  wt = jnp.clip(1 - jnp.abs(dist / (dt[..., :, None] / 2)), 0, 1)\n\n  # Compute the weighted sum of the values in `vp` for each interval in `t`.\n  if use_avg:\n    v = jnp.sum(wt * vp[..., None, :] * dtp[..., None, :], axis=-1) / dt\n  else:\n    v = jnp.sum(wt * vp[..., None, :], axis=-1)\n\n  return v"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of each interval in tp.\n  tp_width = jnp.diff(tp, axis=-1)\n\n  # Compute the width of each interval in t.\n  t_width = jnp.diff(t, axis=-1)\n\n  # Compute the width of each interval in tp, resampled to t.\n  tp_width_resampled = jnp.interp(t, tp, tp_width, left=0, right=0)\n\n  # Compute the width of each interval in t, resampled to tp.\n  t_width_resampled = jnp.interp(tp, t, t_width, left=0, right=0)\n\n  # Compute the weight for each interval in tp, resampled to t.\n  weight = tp_width_resampled / t_width_resampled\n\n  # Compute the resampled values of the step function.\n  if use_avg:\n    v = jnp.interp(t, tp, vp, left=0, right=0) * weight\n  else:\n    v = jnp.interp(t, tp, vp, left=0, right=0)\n\n  # Compute the sum of the resampled values for each interval in t.\n  v_sum = jnp.cumsum(v, axis=-1)\n\n  # Compute the sum of the weights for each interval in t.\n  weight_sum = jnp.cumsum(weight, axis=-1)\n\n  # Compute the resampled values of the step function.\n  v_resampled = jnp.where(weight_sum > 0, v_sum / weight_sum, 0)\n\n  return v_resampled\n\n"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of each interval in `t`.\n  t_widths = jnp.diff(t)\n\n  # Compute the indices of the original time points (tp) that are within each interval in `t`.\n  tp_indices = jnp.searchsorted(tp, t)\n\n  # Compute the width of each interval in `tp`.\n  tp_widths = jnp.diff(tp)\n\n  # Compute the width of each interval in `t`, weighted by the width of the corresponding interval in `tp`.\n  t_weighted_widths = t_widths / tp_widths[tp_indices]\n\n  # Compute the values of the resampled step function at the new intervals defined by t.\n  if use_avg:\n    # Compute the average value, weighted by the width of each interval in `t`.\n    v = jnp.sum(vp * t_weighted_widths, axis=-1)\n  else:\n    # Sum the values of the step function for each interval in `t`.\n    v = jnp.sum(vp * t_widths, axis=-1)\n\n  return v"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  if use_avg:\n    # Compute the width of each interval in tp.\n    tp_diff = jnp.diff(tp, axis=-1)\n\n    # Compute the width of each interval in t.\n    t_diff = jnp.diff(t, axis=-1)\n\n    # Compute the overlap between each interval in t and tp.\n    overlap = jnp.minimum(tp[Ellipsis, 1:], t[Ellipsis, 1:, None]) - jnp.maximum(\n        tp[Ellipsis, :-1], t[Ellipsis, :-1, None]\n    )\n\n    # Compute the weight of each interval in tp for each interval in t.\n    weight = math.safe_div(overlap, tp_diff[Ellipsis, :, None])\n\n    # Compute the weighted sum of the values in vp for each interval in t.\n    v = jnp.sum(weight * vp[Ellipsis, None, :], axis=-1)\n\n    # Compute the sum of the weights for each interval in t.\n    w = jnp.sum(weight, axis=-1)\n\n    # Compute the weighted average of the values in vp for each interval in t.\n    v = math.safe_div(v, w)\n  else:\n    # Compute the overlap between each interval in t and tp.\n    overlap = jnp.minimum(tp[Ellipsis, 1:], t[Ellipsis, 1:, None]) - jnp.maximum(\n        tp[Ellipsis, :-1], t[Ellipsis, :-1, None]\n    )\n\n    # Compute the sum of the overlapping values in vp for each interval in t.\n    v = jnp.sum(math.safe_div(overlap, jnp.diff(tp, axis=-1)) * vp[Ellipsis, None, :], axis="}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  if tp.shape[-1] != vp.shape[-1]:\n    raise ValueError(\n        f'tp and vp must have the same number of steps, but got {tp.shape} and {vp.shape}'\n    )\n  if t.shape[-1] != tp.shape[-1] + 1:\n    raise ValueError(\n        f't must have one more step than tp and vp, but got {t.shape} and {tp.shape}'\n    )\n\n  # Compute the width of each interval in tp.\n  tp_widths = jnp.diff(tp, axis=-1)\n\n  # Compute the width of each interval in t.\n  t_widths = jnp.diff(t, axis=-1)\n\n  # Compute the width of each interval in tp, weighted by the width of the corresponding interval in t.\n  tp_widths_weighted = tp_widths * t_widths[..., None]\n\n  # Compute the width of each interval in t, weighted by the width of the corresponding interval in tp.\n  t_widths_weighted = t_widths * tp_widths[..., None]\n\n  # Compute the sum of the values of vp for each interval in tp, weighted by the width of the corresponding interval in t.\n  vp_sum_weighted = jnp.sum(vp * tp_widths_weighted, axis=-1)\n\n  # Compute the sum of the values of vp for each interval in t, weighted by the width of the corresponding interval in tp.\n  vp_sum_weighted_transpose = jnp.sum(vp * t_widths_weighted, axis=-1)\n\n  # Compute the resampled values of vp.\n  if use_avg:\n    vp_resampled = vp_sum_weighted_transpose / t_widths\n  else:\n    vp_resampled = vp_"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # Compute the weights for the resampling.\n  tp_diff = jnp.diff(tp, axis=-1)\n  tp_diff = jnp.where(tp_diff < np.finfo(np.float32).tiny, 0, tp_diff)\n  tp_diff = jnp.concatenate([tp_diff, jnp.ones_like(tp_diff[Ellipsis, :1])], -1)\n  w = tp_diff / jnp.sum(tp_diff, axis=-1, keepdims=True)\n\n  # Resample the values.\n  v = jnp.concatenate([vp[Ellipsis, :1], vp[Ellipsis, 1:]], -1)\n  v = v * w\n  if use_avg:\n    v = v / tp_diff\n  v = jnp.cumsum(v, axis=-1)\n\n  # Interpolate the resampled values.\n  v = math.sorted_interp(t, tp, v, utils.device_is_tpu())\n  return v"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of each interval in `t`.\n  t_widths = jnp.diff(t, axis=-1)\n\n  # Compute the width of each interval in `tp`.\n  tp_widths = jnp.diff(tp, axis=-1)\n\n  # Compute the total width of all intervals in `tp`.\n  tp_total_width = jnp.sum(tp_widths, axis=-1)\n\n  # Compute the total width of all intervals in `t`.\n  t_total_width = jnp.sum(t_widths, axis=-1)\n\n  # Compute the ratio of the total widths of `t` and `tp`.\n  ratio = t_total_width / tp_total_width\n\n  # Compute the width of each interval in `tp` scaled by the ratio of the total widths.\n  tp_scaled_widths = tp_widths * ratio\n\n  # Compute the cumulative sum of the scaled widths of `tp`.\n  tp_cum_scaled_widths = jnp.cumsum(tp_scaled_widths, axis=-1)\n\n  # Compute the cumulative sum of the widths of `t`.\n  t_cum_widths = jnp.cumsum(t_widths, axis=-1)\n\n  # Compute the ratio of the cumulative sum of the widths of `t` and `tp`.\n  ratio_cum = t_cum_widths / tp_cum_scaled_widths\n\n  # Compute the ratio of the widths of `t` and `tp`.\n  ratio = t_widths / tp_scaled_widths\n\n  # Compute the index of the first interval in `tp` that overlaps with each interval in `t`.\n  idx = jnp.searchsorted(tp_cum_scaled_widths, t_cum_widths, side='"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # Compute the weights of each bin.\n  w = pdf_to_weight(tp, vp)\n  # Compute the CDF of each bin.\n  cw = integrate_weights(w)\n  # Compute the percentiles of each bin.\n  cw = (cw[Ellipsis, 1:] + cw[Ellipsis, :-1]) / 2\n  # Compute the inverse CDF of the percentiles.\n  tp_new = invert_cdf(cw, tp, w)\n  # Compute the values of the resampled step function at the new time points.\n  if use_avg:\n    vp_new = (tp_new[Ellipsis, 1:] - tp_new[Ellipsis, :-1]) * (\n        vp[Ellipsis, 1:] + vp[Ellipsis, :-1]\n    ) / 2\n  else:\n    vp_new = jnp.interp(t, tp_new, vp)\n  return vp_new"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the width of each interval in tp.\n  dt = tp[Ellipsis, 1:] - tp[Ellipsis, :-1]\n\n  # Compute the width of each interval in t.\n  dt_new = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n\n  # Compute the intersection between each interval in t and each interval in tp.\n  # The intersection is the amount of overlap between the two intervals.\n  # The intersection is computed by taking the minimum of the right endpoint of each interval in t and the right endpoint of each interval in tp,\n  # minus the maximum of the left endpoint of each interval in t and the left endpoint of each interval in tp.\n  # The resulting tensor has shape (..., num_intervals_t, num_intervals_tp).\n  intersection = jnp.minimum(t[Ellipsis, :, None], tp[Ellipsis, None, :]) - jnp.maximum(\n      t[Ellipsis, :, None], tp[Ellipsis, None, :]\n  )\n\n  # Clip the intersection to be non-negative.\n  intersection = jnp.clip(intersection, 0, None)\n\n  # Compute the weight of each interval in tp for each interval in t.\n  # The weight is the ratio of the intersection of the two intervals to the width of the interval in tp.\n  # The resulting tensor has shape (..., num_intervals_t, num_intervals_tp).\n  weight = intersection / dt_new[Ellipsis, :, None]\n\n  # Compute the value of the resampled step function at each interval in t.\n  # If use_avg is True, the value is the weighted average of the values of the step function at each interval in tp.\n  # If use_avg is False, the value is the sum of the values of the step function at each interval in tp, weighted by the width of each interval in tp."}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  utils.assert_valid_stepfun(t, jnp.zeros_like(vp))\n\n  # Compute the width of each interval in tp.\n  wp = jnp.diff(tp, axis=-1)\n\n  # Compute the width of each interval in t.\n  w = jnp.diff(t, axis=-1)\n\n  # Compute the width of each interval in tp, weighted by the width of the corresponding interval in t.\n  wp_weighted = wp * w / jnp.sum(w)\n\n  # Compute the indices of the intervals in tp that overlap with each interval in t.\n  tp_idx = jnp.searchsorted(tp[..., 1:], t[..., :, None], side='left')\n\n  # Compute the indices of the intervals in t that overlap with each interval in tp.\n  t_idx = jnp.searchsorted(t[..., 1:], tp[..., :, None], side='left')\n\n  # Compute the width of each interval in tp that overlaps with each interval in t.\n  wp_intersect = jnp.maximum(0, jnp.minimum(tp[..., 1:], t[..., 1:, None]) - jnp.maximum(tp[..., :-1], t[..., :-1, None]))\n\n  # Compute the width of each interval in t that overlaps with each interval in tp.\n  w_intersect = jnp.maximum(0, jnp.minimum(t[..., 1:], tp[..., 1:, None]) - jnp.maximum(t[..., :-1], tp[..., :-1, None]))\n\n  # Compute the values of the resampled step function at the new intervals defined by t.\n  v = jnp.zeros_like(t)\n  v = v.at[..., :-1].add(jnp.sum(vp["}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Compute the widths of each interval in tp.\n  tp_widths = jnp.diff(tp)\n\n  # Compute the cumulative sum of tp_widths.\n  tp_cumsum = jnp.cumsum(tp_widths, axis=-1)\n\n  # Compute the total width of the step function.\n  total_width = tp_cumsum[Ellipsis, -1:]\n\n  # Compute the normalized cumulative sum of tp_widths.\n  tp_cumsum_norm = tp_cumsum / total_width\n\n  # Compute the normalized t values.\n  t_norm = (t - tp[Ellipsis, :1]) / total_width\n\n  # Find the indices of the t values that are less than the normalized tp values.\n  indices = jnp.searchsorted(tp_cumsum_norm, t_norm, side='left')\n\n  # Compute the tp values corresponding to the indices.\n  tp_indices = tp[Ellipsis, indices]\n\n  # Compute the tp widths corresponding to the indices.\n  tp_widths_indices = tp_widths[Ellipsis, indices]\n\n  # Compute the tp values for the next index.\n  tp_indices_next = tp[Ellipsis, indices + 1]\n\n  # Compute the normalized t values for the next index.\n  t_norm_next = (t - tp[Ellipsis, :1]) / total_width\n\n  # Compute the tp widths for the next index.\n  tp_widths_indices_next = tp_widths[Ellipsis, indices + 1]\n\n  # Compute the normalized t values for the current index.\n  t_norm_curr = t_norm[Ellipsis, indices]\n\n  # Compute the normalized t values for the next index.\n  t_norm_"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  tp = jnp.concatenate([tp[Ellipsis, :1], tp, tp[Ellipsis, -1:]], axis=-1)\n  vp = jnp.concatenate([vp[Ellipsis, :1], vp, vp[Ellipsis, -1:]], axis=-1)\n  tp_size = tp.shape[-1]\n  vp_size = vp.shape[-1]\n  if tp_size != vp_size:\n    raise ValueError(\n        f'tp and vp must have the same size, but got {tp_size} and {vp_size}.'\n    )\n\n  # Compute the width of each interval in the original step function.\n  tp_widths = tp[Ellipsis, 1:] - tp[Ellipsis, :-1]\n\n  # Compute the indices of the intervals in the new time points where the original step function is resampled.\n  indices = jnp.searchsorted(tp, t, side='right') - 1\n\n  # Compute the width of each interval in the new time points.\n  t_widths = t[Ellipsis, 1:] - t[Ellipsis, :-1]\n\n  # Compute the width of each interval in the new time points, clipped to the original time points.\n  t_widths_clipped = jnp.minimum(\n      t_widths, tp[Ellipsis, 1:] - t[Ellipsis, :-1]\n  )\n\n  # Compute the width of each interval in the original step function, clipped to the new time points.\n  tp_widths_clipped = jnp.minimum(\n      tp_widths, t[Ellipsis, 1:] - tp[Ellipsis, :-1]\n  )\n\n  # Compute the values of the resampled step function for each interval in the new time points.\n "}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # Compute the width of each interval.\n  tp_diff = jnp.diff(tp, axis=-1)\n\n  # Compute the midpoint of each interval.\n  tp_mid = (tp[..., 1:] + tp[..., :-1]) / 2\n\n  # Compute the width of each interval in the new time points.\n  t_diff = jnp.diff(t, axis=-1)\n\n  # Compute the midpoint of each interval in the new time points.\n  t_mid = (t[..., 1:] + t[..., :-1]) / 2\n\n  # Compute the intersection of the intervals.\n  intersection = jnp.minimum(tp[..., 1:], t[..., 1:, None]) - jnp.maximum(\n      tp[..., :-1], t[..., :-1, None]\n  )\n\n  # Compute the width of the intersection.\n  intersection_width = jnp.maximum(0, intersection)\n\n  # Compute the width of the intersection between the intervals in the new time points.\n  intersection_width_t = jnp.maximum(0, jnp.minimum(t_diff, tp_diff[..., None]))\n\n  # Compute the width of the intersection between the intervals in the original time points.\n  intersection_width_tp = jnp.maximum(\n      0, jnp.minimum(tp_diff, t_diff[..., None])\n  )\n\n  # Compute the weight of each interval in the original time points.\n  weight_tp = intersection_width_tp / tp_diff\n\n  # Compute the weight of each interval in the new time points.\n  weight_t = intersection_width_t / t_diff\n\n  # Compute the weight of each interval in the intersection.\n  weight_intersection = intersection_width / t_diff\n\n  # Compute the values of the resampled step function at the new intervals.\n  v = jnp.where"}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n  # Compute the mask of which intervals in tp are in each interval in t.\n  # We assume that t is sorted.\n  tp_intervals = jnp.concatenate([tp[Ellipsis, :-1], tp[Ellipsis, -2:-1]], axis=-1)\n  tp_intervals = jnp.concatenate([tp_intervals, tp[Ellipsis, -1:]], axis=-1)\n  mask = jnp.logical_and(tp_intervals[Ellipsis, :, None] >= t[Ellipsis, None, :],\n                         tp_intervals[Ellipsis, :, None] < t[Ellipsis, None, 1:])\n  # Compute the width of each interval in t.\n  t_widths = jnp.diff(t, axis=-1)\n  # Compute the width of each interval in tp.\n  tp_widths = jnp.diff(tp, axis=-1)\n  # Compute the weight of each interval in tp in each interval in t.\n  tp_weights = jnp.clip(\n      jnp.minimum(tp_intervals[Ellipsis, :, 1:], t[Ellipsis, 1:, None]) -\n      jnp.maximum(tp_intervals[Ellipsis, :, :-1], t[Ellipsis, :-1, None]),\n      0,\n      tp_widths[Ellipsis, :, None],\n  )\n  # Compute the weight of each interval in t in each interval in tp.\n  t_weights = tp_weights / tp_widths[Ellipsis, :, None]\n  # Compute the resampled values.\n  if use_avg:\n    v = jnp.sum(mask * t_weights * vp[Ellipsis, :, None], axis=-2)\n  else:\n   "}
{"namespace": "stepfun.resample", "completion": "  utils.assert_valid_stepfun(tp, vp)\n\n  # Determine the size of the output.\n  batch_shape = t.shape[:-1]\n  num_samples = t.shape[-1]\n\n  # Compute the integral of the step function.\n  cw = integrate_weights(vp)\n\n  # Compute the average value of the step function within each interval.\n  cw_mean = (cw[Ellipsis, 1:] + cw[Ellipsis, :-1]) / 2\n\n  # Compute the width of each interval.\n  t_width = jnp.diff(t, axis=-1)\n\n  # Compute the total width of the step function.\n  cw_width = jnp.sum(t_width, axis=-1)\n\n  # Compute the width of each interval within the step function.\n  cw_width_int = jnp.diff(cw, axis=-1)\n\n  # Compute the total width of the step function.\n  cw_width_total = cw[Ellipsis, -1] - cw[Ellipsis, 0]\n\n  # Compute the width of each interval within the step function, normalized by the total width.\n  cw_width_int_norm = cw_width_int / cw_width_total\n\n  # Compute the total width of each interval, normalized by the total width.\n  t_width_norm = t_width / cw_width_total\n\n  # Compute the total width of each interval, normalized by the total width.\n  cw_width_total_norm = cw_width / cw_width_total\n\n  # Compute the width of each interval within the step function, normalized by the total width of each interval.\n  cw_width_int_norm_int = cw_width_int / cw_width\n\n  # Compute the total width of each interval, normalized by the total width of each interval.\n  t_width_norm_int = t_width / cw_width\n\n  #"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scaling the mean and variance by powers of 2\n  scaled_mean = mean[..., None] * 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_var = var[..., None] * 2.0 ** jnp.arange(min_deg, max_deg)\n\n  # Concatenating the scaled mean and variance\n  encoded_vars = jnp.concatenate([jnp.sin(scaled_mean), jnp.cos(scaled_var)], axis=-1)\n\n  return encoded_vars"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # This is the scaling factor for the encoding.\n  scale = 2 ** jnp.linspace(min_deg, max_deg, max_deg - min_deg)\n  # This scales the mean and variance of the coordinates.\n  x = mean[..., None] * scale[:, None]\n  x_var = var[..., None] * scale[:, None] ** 2\n  # This concatenates the scaled mean and variance along the last axis.\n  x_var = jnp.concatenate([x, x_var], axis=-1)\n  # This applies the sinusoidal encoding to the scaled mean and variance.\n  x_var = jnp.sin(jnp.concatenate([x, x_var], axis=-1))\n  return x_var"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scaling the mean and variance of the coordinates.\n  scaled_mean = mean[..., None] * 2**jnp.linspace(min_deg, max_deg, max_deg - min_deg)\n  scaled_var = var[..., None] * 2**jnp.linspace(min_deg, max_deg, max_deg - min_deg)\n\n  # Concatenating the scaled mean and variance.\n  x = jnp.concatenate([jnp.sin(scaled_mean), jnp.cos(scaled_mean)], axis=-1)\n  x = jnp.concatenate([x, jnp.sin(scaled_var), jnp.cos(scaled_var)], axis=-1)\n  return x"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scaled mean and variance.\n  scaled_mean = mean[..., None] * 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_var = var[..., None] * 2.0 ** jnp.arange(min_deg, max_deg)\n\n  # Concatenate the scaled mean and variance.\n  scaled_mean_var = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Apply the sinusoidal encoding.\n  encoded = jnp.sin(\n      jnp.concatenate(\n          [scaled_mean_var, scaled_mean_var + 0.5 * jnp.pi], axis=-1\n      )\n  )\n\n  return encoded"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance by the encoding scale.\n  scale = 2**jnp.linspace(min_deg, max_deg, max_deg - min_deg)\n  scaled_mean = mean[..., None] * scale[None, :]\n  scaled_var = var[..., None] * scale[None, :]**2\n\n  # Concatenate the scaled mean and variance for the encoding.\n  encoded_vars = jnp.concatenate([jnp.sin(scaled_mean), jnp.cos(scaled_mean)], axis=-1)\n  encoded_vars *= jnp.exp(-0.5 * scaled_var)\n  return encoded_vars"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scaling the mean and variance of the coordinates\n  scaled_mean = mean[..., None] * 2**jnp.arange(min_deg, max_deg)\n  scaled_var = var[..., None] * 2**jnp.arange(min_deg, max_deg)\n\n  # Concatenating the scaled mean and variance\n  scaled_mean_var = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Applying the sinusoidal encoding to the scaled mean and variance\n  sin_encoded = jnp.sin(math.pi * scaled_mean_var)\n\n  return sin_encoded"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scales the mean and variance of the coordinates by powers of 2 within the specified range of degrees.\n  scaled_mean = mean[..., None] * 2.0**jnp.arange(min_deg, max_deg)\n  scaled_var = var[..., None] * 2.0**jnp.arange(min_deg, max_deg)\n\n  # Concatenates the scaled mean and variance along the last axis.\n  scaled_mean_var = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Applies a sinusoidal encoding to the concatenated scaled mean and variance.\n  return jnp.sin(math.safe_sin(scaled_mean_var))\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  x = mean[Ellipsis, None] * 2**jnp.arange(min_deg, max_deg)\n  x = jnp.concatenate([jnp.sin(x), jnp.cos(x)], axis=-1)\n  var = var[Ellipsis, None] * 2**jnp.arange(min_deg, max_deg)\n  var = jnp.concatenate([jnp.sin(var), jnp.cos(var)], axis=-1)\n  return jnp.concatenate([x, var], axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # This is the scale factor used to scale the coordinates before encoding.\n  # It is determined by the minimum and maximum degrees specified in the input arguments.\n  scale = 2**jnp.linspace(min_deg, max_deg, max_deg - min_deg)\n  # Scale the mean and variance of the coordinates using the scale factor.\n  scaled_mean = mean[..., None, :] * scale[:, None]\n  scaled_var = var[..., None, :] * scale[:, None]**2\n  # Concatenate the scaled mean and variance to form the input for the encoding.\n  x = jnp.concatenate([jnp.sin(scaled_mean), jnp.cos(scaled_mean)], axis=-1)\n  return x"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # The scale of the encoding is 2**[min_deg, max_deg)\n  degs = jnp.arange(min_deg, max_deg)\n  # This scales the mean and variance of the coordinates by the encoding scale\n  scale = 2 ** (degs[..., None] / math.nint(jnp.log(1024) / jnp.log(2)))\n  # This concatenates the scaled mean and variance along the last axis\n  x = jnp.concatenate([scale * mean[..., None, :], scale * var[..., None, :]], axis=-2)\n  # This applies the sinusoidal encoding to the concatenated mean and variance\n  x = jnp.sin(jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-3))\n  # This flattens the encoded variables along the last axis\n  return x.reshape(*x.shape[:-2], -1)"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance to be in [0, 1].\n  mean = (mean + 1) / 2\n  var = (var + 1) / 2\n\n  # Compute the encoding scale.\n  scale = 2**jnp.linspace(min_deg, max_deg, max_deg - min_deg)\n\n  # Concatenate the scaled mean and variance along the last axis.\n  x = jnp.concatenate([mean[..., None, :] * scale[:, None],\n                       var[..., None, :] * scale[:, None]], axis=-2)\n\n  # Apply the sinusoidal encoding to the concatenated mean and variance.\n  x = jnp.sin(jnp.concatenate([2**jnp.arange(min_deg, max_deg)[:, None],\n                              2**jnp.arange(min_deg, max_deg)[:, None]],\n                              axis=-1) * x)\n\n  # Return the encoded variables.\n  return x"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Compute the scaling factor for the encoding\n  scale = 2 ** jnp.linspace(min_deg, max_deg, max_deg - min_deg)\n  # Scale the mean and variance\n  scaled_mean = mean[..., None] * scale[None, :]\n  scaled_var = var[..., None] * scale[None, :] ** 2\n  # Concatenate the scaled mean and variance\n  encoded = jnp.concatenate([jnp.sin(scaled_mean), jnp.cos(scaled_mean)], axis=-1)\n  # Compute the expected sinusoidal value\n  expected_sin_val = expected_sin(scaled_mean, scaled_var)\n  # Concatenate the encoded values and expected sinusoidal value\n  return jnp.concatenate([encoded, expected_sin_val], axis=-1)"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # The scale of the encoding is determined by the number of degrees between min_deg and max_deg.\n  scale = 2 ** jnp.linspace(min_deg, max_deg, max_deg - min_deg)\n  # The mean and variance are scaled by the scale factor.\n  x = mean[..., None] * scale\n  x_var = var[..., None] * scale**2\n  # The encoded variables are the concatenation of the sinusoidal encoding of the scaled mean and variance.\n  return jnp.concatenate([jnp.sin(jnp.concatenate([x, x + 0.5 * jnp.pi], axis=-1)),\n                          jnp.sin(jnp.concatenate([x_var, x_var + 0.5 * jnp.pi], axis=-1))],\n                         axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scaling the mean and variance by powers of 2.\n  scaled_mean = mean[Ellipsis, None] / 2**jnp.arange(min_deg, max_deg)\n  scaled_var = var[Ellipsis, None] / 2**(jnp.arange(min_deg, max_deg) * 2)\n  # Concatenating the scaled mean and variance.\n  x = jnp.concatenate([jnp.sin(scaled_mean), jnp.cos(scaled_mean)], axis=-1)\n  # Applying the sinusoidal encoding to the scaled mean and variance.\n  return jnp.concatenate([x, x * jnp.sin(jnp.clip(scaled_var, 0, 1))], axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scaling the mean and variance using the scale factor\n  scaled_mean = mean[..., None, :] * 2.0 ** jnp.arange(min_deg, max_deg)\n  scaled_var = var[..., None, :] * 2.0 ** jnp.arange(min_deg, max_deg)\n\n  # Concatenating the scaled mean and variance\n  scaled_mean_var = jnp.concatenate([scaled_mean, scaled_var], axis=-1)\n\n  # Applying the sinusoidal encoding to the scaled mean and variance\n  encoded_vars = jnp.sin(jnp.concatenate([scaled_mean_var, scaled_mean_var + 0.5 * jnp.pi], axis=-1))\n\n  # Returning the encoded variables\n  return encoded_vars\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # This scales the mean and variance of the coordinates to be within a range of [-1, 1].\n  # This is done to make the encoding process more efficient and stable.\n  mean = mean * (2**max_deg)\n  var = var * (2**max_deg)\n\n  # This creates a sequence of powers of 2 from min_deg to max_deg-1, inclusive.\n  degs = jnp.arange(min_deg, max_deg)\n\n  # This computes the encoding by scaling the mean and variance by powers of 2 and concatenating them.\n  # The resulting tensor is then passed through a sinusoidal encoding function.\n  # The final result is a tensor of encoded variables.\n  return jnp.concatenate([\n      jnp.sin(2**i * mean) * 2**i * jnp.exp(-0.5 * i * var) for i in degs\n  ],\n                         axis=-1)"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scale the mean and variance of the coordinates.\n  scaled_mean = mean[Ellipsis, None] * 2**jnp.arange(min_deg, max_deg)\n  scaled_var = var[Ellipsis, None] * 2**jnp.arange(min_deg, max_deg)\n\n  # Concatenate the scaled mean and variance.\n  x = jnp.concatenate([jnp.sin(scaled_mean), jnp.cos(scaled_mean)], axis=-1)\n\n  # Apply the sinusoidal encoding to the scaled mean and variance.\n  m_sin = expected_sin(\n      jnp.concatenate([scaled_mean, scaled_mean + 0.5 * jnp.pi], axis=-1),\n      jnp.concatenate([scaled_var, scaled_var], axis=-1),\n  )\n  return jnp.concatenate([x, m_sin, x * m_sin], axis=-1)\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # Scaling the mean and variance using a power of 2.\n  scaled_mean = 2**mean\n  scaled_var = 2**var\n\n  # Concatenating the scaled mean and variance.\n  scaled_mean_var = jnp.concatenate([scaled_mean[..., None], scaled_var[..., None]], axis=-1)\n\n  # Applying the sinusoidal encoding.\n  encoded_vars = math.safe_sin(\n      math.integrated_pos_enc(scaled_mean_var, min_deg, max_deg)\n  )\n\n  return encoded_vars\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # The magic number 10 is used to scale the mean and variance before encoding.\n  # This scaling factor is chosen empirically to ensure that the encoded values lie within the range [-1, 1].\n  mean = 10 * mean\n  var = 10 * var\n  # The magic number 0.1 is used to scale the encoded values before concatenation.\n  # This scaling factor is chosen empirically to ensure that the encoded values lie within the range [-1, 1].\n  x = 0.1 * mean[..., None]\n  for i in range(min_deg, max_deg):\n    x = jnp.concatenate([x, 2**i * jnp.sin(2**i * var[..., None])], axis=-1)\n  return x\n\n"}
{"namespace": "coord.integrated_pos_enc", "completion": "  # The scale factors are powers of 2, so we use a bitshift to compute them.\n  scale_factors = jnp.array([2**i for i in range(min_deg, max_deg)])\n\n  # Scale the mean and variance using the scale factors.\n  mean_scaled = mean[..., None] * scale_factors\n  var_scaled = var[..., None] * scale_factors**2\n\n  # Concatenate the scaled mean and variance.\n  mean_var_scaled = jnp.concatenate([mean_scaled, var_scaled], axis=-1)\n\n  # Apply a sinusoidal encoding to the scaled mean and variance.\n  encoded = jnp.sin(jnp.concatenate([mean_var_scaled,\n                                     jnp.zeros_like(mean_var_scaled[..., :1])],\n                                    axis=-1))\n\n  # Return the encoded variables.\n  return encoded\n\n"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"Function returning integrated directional encoding (IDE).\n\n    Args:\n      xyz: [..., 3] array of Cartesian coordinates of directions to evaluate at.\n      kappa_inv: [..., 1] reciprocal of the concentration parameter of the von\n        Mises-Fisher distribution.\n\n    Returns:\n      An array with the resulting IDE.\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vmxy * math_lib.matmul(vmz, mat)\n\n    # Apply"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the integrated directional encoding (IDE) for the given inputs.\n\n    Input-Output Arguments\n    :param xyz: Float array. The 3D point (or points) at which to evaluate the IDE.\n    :param kappa_inv: Float array. The reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Float array. The evaluated IDE at the given point(s).\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph_harms = vm"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the integrated directional encoding (IDE) for a given set of 3D points and inverse concentration parameter.\n\n    Input-Output Arguments\n    :param xyz: Array. A 3D point (or points) represented as an array of shape (..., 3).\n    :param kappa_inv: Array. The inverse concentration parameter of the von Mises-Fisher distribution.\n    :return: Array. The evaluated integrated directional encoding for the given inputs.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the integrated directional encoding (IDE) for a given set of 3D points and inverse concentration parameter.\n\n    Input-Output Arguments\n    :param xyz: Float array. The 3D points for which the IDE is to be computed.\n    :param kappa_inv: Float array. The inverse concentration parameter of the von Mises-Fisher distribution.\n    :return: Float array. The computed IDE for the given points and inverse concentration parameter.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get spherical harmonics.\n    sph"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the integrated directional encoding (IDE) for a given set of 3D points.\n\n    Input-Output Arguments\n    :param xyz: Float[..., 3]. The 3D points for which the IDE is to be evaluated.\n    :param kappa_inv: Float[..., 1]. The reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Float[..., 2 * l_max + 1]. The computed IDE values for the given points.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the integrated directional encoding (IDE) for a given set of 3D points (xyz) and inverse concentration parameter (kappa_inv).\n\n    Input-Output Arguments\n    :param xyz: Float array. The 3D points for which to compute the directional encoding.\n    :param kappa_inv: Float array. The inverse concentration parameter of the von Mises-Fisher distribution.\n    :return: Float array. The directional encoding for the given 3D points.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the integrated directional encoding (IDE) for the given inputs.\n\n    Input-Output Arguments\n    :param xyz: Float array of shape [..., 3]. The Cartesian coordinates of the points for which the IDE is to be evaluated.\n    :param kappa_inv: Float array of shape [..., 1]. The reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Float array of shape [..., l_max * l_max]. The computed IDE values.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the integrated directional encoding (IDE) for the given input points and concentration parameter.\n\n    Input-Output Arguments\n    :param xyz: Float32 array. A 3D point (or points) to evaluate the directional encoding at.\n    :param kappa_inv: Float32 array. The reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Float32 array. The evaluated IDE for the given input points and concentration parameter.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Get"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the integrated directional encoding (IDE) for the given input points and concentration parameter.\n\n    Input-Output Arguments\n    :param xyz: Tensor. A tensor of shape (..., 3) containing the input points for which to compute the IDE.\n    :param kappa_inv: Tensor. A tensor of shape (..., 1) containing the inverse of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Tensor. A tensor of shape (..., 2 * (l_max + 1)^2) representing the IDE for the input points.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Computes the integrated directional encoding (IDE) for the given input points and concentration parameter.\n\n    Input-Output Arguments\n    :param xyz: Array. The input points for which to compute the IDE. It should have shape (..., 3), where '...' represents any number of additional dimensions.\n    :param kappa_inv: Array. The reciprocal of the concentration parameter of the von Mises-Fisher distribution. It should have shape (..., 1), where '...' represents any number of additional dimensions.\n    :return: Array. The computed IDE values for the input points. It has shape (..., 2 * l_max + 1), where '...' represents any number of additional dimensions.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function that evaluates the directional encoding for a given input point (or points) using the integrated directional encoding function.\n\n    Input-Output Arguments\n    :param xyz: Float array of shape (..., 3). The 3D point (or points) to evaluate the directional encoding for.\n    :param kappa_inv: Float array of shape (..., 1). The reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Float array of shape (..., l_max + 1). The resulting directional encoding for the input point (or points).\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y)"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Function that computes the integrated directional encoding for a given input point or points.\n\n    Input-Output Arguments\n    :param xyz: Float array of shape (..., 3). The Cartesian coordinates of the input point(s) for which to compute the directional encoding.\n    :param kappa_inv: Float array of shape (..., 1). The reciprocal of the concentration parameter of the von Mises-Fisher distribution. This parameter controls the shape and spread of the distribution.\n    :return: Float array of shape (..., 2 * l_max + 1). The computed directional encoding for the input point(s).\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([("}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the integrated directional encoding (IDE) for a given set of 3D points.\n\n    Input-Output Arguments\n    :param xyz: Array. A 3D point (or points) to evaluate the IDE at. The shape of xyz should be (..., 3), where ... represents any number of additional dimensions.\n    :param kappa_inv: Array. The reciprocal of the concentration parameter of the von Mises-Fisher distribution. The shape of kappa_inv should be (..., 1), where ... represents any number of additional dimensions.\n    :return: Array. The evaluated IDE. The shape of the output will be (..., 2 * l_max + 1), where ... represents the same number of additional dimensions as in the input xyz, and l_max is the maximum spherical harmonic degree used in the encoding.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the integrated directional encoding (IDE) for the given input points and inverse concentration parameter.\n\n    Input-Output Arguments\n    :param xyz: Array. The input points for which to compute the IDE. The shape of the array should be [..., 3].\n    :param kappa_inv: Array. The inverse concentration parameter of the von Mises-Fisher distribution. The shape of this array should be [..., 1].\n    :return: Array. The computed IDE values for the input points. The shape of the returned array is [..., 2 * (deg_view + 1)^2].\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the integrated directional encoding (IDE) for the given input point(s) and inverse concentration parameter.\n\n    Input-Output Arguments\n    :param xyz: Float array. The input point(s) for which to compute the directional encoding. It should be a 3D point or an array of 3D points.\n    :param kappa_inv: Float array. The inverse concentration parameter of the von Mises-Fisher distribution. It determines the shape and spread of the encoding.\n    :return: Float array. The computed directional encoding for the input point(s). The output shape will be the same as the input shape, but with an additional dimension for the encoding values.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde matrix.\n    vmxy"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Check if the degree of view is within the acceptable range.\n  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  # Get the matrix of spherical harmonics coefficients.\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the integrated directional encoding (IDE) for the given inputs.\n\n    Input-Output Arguments\n    :param xyz: A 3D point (or points) for which the IDE is to be computed.\n    :param kappa_inv: The reciprocal of the concentration parameter of the von Mises-Fisher distribution.\n    :return: The computed IDE.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute the z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute the x+iy Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    #"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  ml_array = get_ml_array(deg_view)\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix corresponding to ml_array holding all coefficients, which,\n  # when multiplied (from the right) by the z coordinate Vandermonde matrix,\n  # results in the z component of the encoding.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Evaluates the integrated directional encoding (IDE) for the given input points and concentration parameter.\n\n    Input-Output Arguments\n    :param xyz: Float array. The input 3D points for which the IDE is to be computed. The shape should be (..., 3), where the first dimensions can be arbitrary.\n    :param kappa_inv: Float array. The reciprocal of the concentration parameter of the von Mises-Fisher distribution. The shape should be (..., 1).\n    :return: Float array. The computed IDE values for the input points. The shape will be (..., 2 * l_max + 1), where the first dimensions are the same as those of the input points.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute x+iy Vandermonde"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  # Get the matrix of (m, l) pairs for the specified degree of spherical harmonics.\n  ml_array = get_ml_array(deg_view)\n\n  # Compute the maximum spherical harmonic degree (l_max) based on the degree of view.\n  l_max = 2 ** (deg_view - 1)\n\n  # Create a matrix holding all coefficients corresponding to the (m, l) pairs.\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n  for i, (m, l) in enumerate(ml_array.T):\n    for k in range(l - m + 1):\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Computes the integrated directional encoding (IDE) for a given set of 3D points.\n\n    Input-Output Arguments\n    :param xyz: Array. The input 3D points for which the IDE is computed.\n    :param kappa_inv: Array. The inverse of the concentration parameter of the von Mises-Fisher distribution.\n    :return: Array. The computed IDE values for the input points.\n\n    \"\"\"\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis, 1:2]\n    z = xyz[Ellipsis, 2:3]\n\n    # Compute the Z Vandermonde matrix.\n    vmz = jnp.concatenate([z**i for i in range(mat.shape[0])], axis=-1)\n\n    # Compute the X+iY Vandermonde matrix.\n    vmxy = jnp.concatenate([(x + 1j * y) ** m for m in ml_array[0, :]], axis=-1)\n\n    # Compute the spherical harmonics"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Check if the number of spherical harmonics degrees is valid\n  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  # Get the array of (m, l) pairs for the specified number of spherical harmonics degrees\n  ml_array = get_ml_array(deg_view)\n\n  # Compute the maximum spherical harmonic degree (l_max) based on the number of spherical harmonics degrees\n  l_max = 2 ** (deg_view - 1)\n\n  # Initialize a matrix with zeros to hold the coefficients for the spherical harmonics\n  mat = np.zeros((l_max + 1, ml_array.shape[1]))\n\n  # Loop over each (m, l) pair in the ml_array\n  for i, (m, l) in enumerate(ml_array.T):\n    # Loop over all possible values of k from 0 to l-m\n    for k in range(l - m + 1):\n      # Compute the coefficient for the current (m, l, k) combination and store it in the matrix\n      mat[k, i] = sph_harm_coeff(l, m, k)\n\n  # Define a function that computes the integrated directional encoding (IDE)\n  def integrated_dir_enc_fn(xyz, kappa_inv):\n    \"\"\"\n    Computes the integrated directional encoding (IDE) for a given set of 3D points and inverse concentration parameter.\n\n    Input-Output Arguments\n    :param xyz: 3D points for which the IDE is computed. Shape: [..., 3]\n    :param kappa_inv: Inverse concentration parameter of the von Mises-Fisher distribution. Shape: [..., 1]\n    :return: IDE values for the given points. Shape: [..., 2 * l_max + 1]\n\n    \"\"\"\n    # Extract the x, y, and z coordinates from the input points\n    x = xyz[Ellipsis, 0:1]\n    y = xyz[Ellipsis"}
{"namespace": "ref_utils.generate_dir_enc_fn", "completion": "  # Check if the input degree of view is within the valid range (1 to 5).\n  if deg_view > 5:\n    raise ValueError('Only deg_view of at most 5 is numerically stable.')\n\n  # Generate the integrated directional encoding function with the specified degree of view.\n  integrated_dir_enc_fn = generate_ide_fn(deg_view)\n\n  def dir_enc_fn(xyz, kappa_inv):\n\n    \"\"\"\n    Computes the directional encoding for a given 3D point or points.\n\n    Input-Output Arguments\n    :param xyz: Float tensor of shape [..., 3]. The 3D point(s) for which to compute the directional encoding.\n    :param kappa_inv: Float tensor of shape [..., 1]. The inverse concentration parameter of the von Mises-Fisher distribution.\n    :return: Float tensor of shape [..., m]. The computed directional encoding(s) for the input point(s).\n\n    \"\"\"\n\n    # Compute the integrated directional encoding using the generated function.\n    ide = integrated_dir_enc_fn(xyz, kappa_inv)\n\n    # Compute the directional encoding by dividing the integrated encoding by the norm of xyz.\n    # This normalization ensures that the directional encoding is unit-length for each point.\n    return ide / jnp.linalg.norm(xyz, axis=-1, keepdims=True)\n\n  # Return the directional encoding function.\n  return dir_enc_fn"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    # print(lines)\n    if not lines:\n        return result\n    lines = [line.strip() for line in lines]\n    lines = [line for line in lines if not should_skip(line, xml)]\n    lines = [line for line in lines if not find_floating_chars(line)]\n    lines = [line for line in lines if not is_table_row(line)]\n    lines = [line for line in lines if check_parentheses(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_2.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_3.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_4.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_5.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_6.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_7.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_8.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_9.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_10.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_11.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_12.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_13.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_14.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_15.search(line)]\n    lines = [line for line in lines if not patterns.num_unit_1"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    # remove duplicate lines\n    lines = list(set(lines))\n    # remove empty lines\n    lines = [line for line in lines if line.strip()]\n    # remove lines with less than 2 characters\n    lines = [line for line in lines if not find_floating_chars(line)]\n    # remove lines with more than 100 characters\n    lines = [line for line in lines if len(line) < 100]\n    # remove lines with more than 100 words\n    lines = [line for line in lines if len(line.split()) < 100]\n    # remove lines with more than 100 characters\n    lines = [line for line in lines if len(line) < 100]\n    # remove lines with more than 100 words\n    lines = [line for line in lines if len(line.split()) < 100]\n    # remove lines with more than 100 characters\n    lines = [line for line in lines if len(line) < 100]\n    # remove lines with more than 100 words\n    lines = [line for line in lines if len(line.split()) < 100]\n    # remove lines with more than 100 characters\n    lines = [line for line in lines if len(line) < 100]\n    # remove lines with more than 100 words\n    lines = [line for line in lines if len(line.split()) < 100]\n    # remove lines with more than 100 characters\n    lines = [line for line in lines if len(line) < 100]\n    # remove lines with more than 100 words\n    lines = [line for line in lines if len(line.split()) < 100]\n    # remove lines with more than 100 characters\n    lines = [line for line in lines if len(line) < 100]\n    # remove lines with more than 100 words\n    lines = [line for line in lines if len(line.split()) < 100]\n    # remove lines with more than 100 characters\n    lines"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    logger.info(\"Cleaning lines...\")\n    result = []\n    lines = [line.strip() for line in lines]\n    lines = [line for line in lines if not should_skip(line, xml=xml)]\n    lines = [line for line in lines if not find_floating_chars(line)]\n    lines = [line for line in lines if not is_table_row(line)]\n    lines = [line for line in lines if not check_parentheses(line)]\n    lines = [line for line in lines if not line.isdigit()]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num_unit.search(line)]\n    lines = [line for line in lines if not patterns.num"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    block_index = 0\n    header_index = 0\n    header_block = None\n    header_block_index = 0\n    header_block_level = 0\n    list_block = None\n    list_block_index = 0\n    list_block_level = 0\n    list_block_type = None\n    list_block_count = 0\n    list_block_count_level = 0\n    list_block_count_type = None\n    list_block_count_index = 0\n    list_block_count_level_type = None\n    list_block_count_level_index = 0\n    list_block_count_type_index = 0\n    list_block_count_level_type_index = 0\n    list_block_count_level_type_level = 0\n    list_block_count_level_type_level_index = 0\n    list_block_count_level_type_level_type = None\n    list_block_count_level_type_level_type_index = 0\n    list_block_count_level_type_level_type_level = 0\n    list_block_count_level_type_level_type_level_index = 0\n    list_block_count_level_type_level_type_level_type = None\n    list_block_count_level_type_level_type_level_type_index = 0\n    list_block_count_level_type_level_type_level_type_level = 0\n    list_block_count_level_type_level_type_level_type_level_index = 0\n    list_block_count_level_type_level_type_level_type_level_type = None\n    list_block_count_level_type_level_type_level_type_level_type_index = 0\n    list_block_count_level_type_level_type_level_type_level_type_level = 0\n    list_block_count_level_type_level_type_level_type_level_type_level_index = 0\n    list_block_count_level_type_level_type_level"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    current_block = []\n    current_block_type = None\n    current_block_index = None\n    current_block_start_index = None\n    current_block_header_index = None\n    current_block_list_index = None\n    current_block_list_level = None\n    current_block_list_type = None\n    current_block_list_text = None\n    current_block_list_items = []\n    current_block_list_item_index = None\n    current_block_list_item_level = None\n    current_block_list_item_type = None\n    current_block_list_item_text = None\n    current_block_list_item_list_index = None\n    current_block_list_item_list_level = None\n    current_block_list_item_list_type = None\n    current_block_list_item_list_text = None\n    current_block_list_item_list_items = []\n    current_block_list_item_list_item_index = None\n    current_block_list_item_list_item_level = None\n    current_block_list_item_list_item_type = None\n    current_block_list_item_list_item_text = None\n    current_block_list_item_list_item_list_index = None\n    current_block_list_item_list_item_list_level = None\n    current_block_list_item_list_item_list_type = None\n    current_block_list_item_list_item_list_text = None\n    current_block_list_item_list_item_list_items = []\n    current_block_list_item_list_item_list_item_index = None\n    current_block_list_item_list_item_list_item_level = None\n    current_block_list_item_list_item_list_item_type = None\n    current_block_list_item_list_item_list_item_text = None\n    current_block_list_item_list_item_list_item_"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    if not lines:\n        return []\n\n    # Remove duplicate lines\n    lines = [line for line in lines if line.strip()]\n    lines = list(set(lines))\n    lines = [line for line in lines if not find_floating_chars(line)]\n\n    # Fix spaced characters\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\u2022\", \"-\") for line in lines]\n    lines = [line.replace(\"\uf0b7\", \"-\") for line in lines]\n    lines = [line.replace(\"\u2013\", \"-\") for line in lines]\n    lines = [line.replace(\"*\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\\", \"\") for line in lines]\n    lines = [line.replace(\"\\\\"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    lines = [line.strip() for line in lines]\n    lines = [line for line in lines if not should_skip(line, xml)]\n    lines = [line for line in lines if not find_floating_chars(line)]\n    lines = [line for line in lines if not line.startswith(\"$\")]\n    lines = [line for line in lines if not line.startswith(\"*\")]\n    lines = [line for line in lines if not line.startswith(\"^\")]\n    lines = [line for line in lines if not line.startswith(\"_\")]\n    lines = [line for line in lines if not line.startswith(\"-\")]\n    lines = [line for line in lines if not line.startswith(\"+\")]\n    lines = [line for line in lines if not line.startswith(\"=\")]\n    lines = [line for line in lines if not line.startswith(\"~\")]\n    lines = [line for line in lines if not line.startswith(\"`\")]\n    lines = [line for line in lines if not line.startswith(\":\")]\n    lines = [line for line in lines if not line.startswith(\";\")]\n    lines = [line for line in lines if not line.startswith(\"<\")]\n    lines = [line for line in lines if not line.startswith(\">\")]\n    lines = [line for line in lines if not line.startswith(\"{\")]\n    lines = [line for line in lines if not line.startswith(\"}\")]\n    lines = [line for line in lines if not line.startswith(\"|\")]\n    lines = [line for line in lines if not line.startswith(\"[\")]\n    lines = [line for line in lines if not line.startswith(\"]\")]\n    lines = [line for line in lines if not line.startswith(\"(\")]\n    lines = [line for line in lines if not line.startswith(\")\")]\n    lines = [line for line in lines if not line.startswith(\"@\")]\n    lines = [line for line in lines if not line.startswith(\""}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    lines = [line.strip() for line in lines]\n    lines = [line for line in lines if not should_skip(line, xml)]\n    lines = [line for line in lines if not find_floating_chars(line)]\n    lines = [line for line in lines if not is_table_row(line)]\n    lines = [line for line in lines if not line.startswith(\"\\\\\")]\n    lines = [line for line in lines if not line.startswith(\".\")]\n    lines = [line for line in lines if not line.startswith(\"-\")]\n    lines = [line for line in lines if not line.startswith(\"_\")]\n    lines = [line for line in lines if not line.startswith(\"+\")]\n    lines = [line for line in lines if not line.startswith(\"*\")]\n    lines = [line for line in lines if not line.startswith(\"^\")]\n    lines = [line for line in lines if not line.startswith(\"~\")]\n    lines = [line for line in lines if not line.startswith(\"`\")]\n    lines = [line for line in lines if not line.startswith(\"=\")]\n    lines = [line for line in lines if not line.startswith(\"|\")]\n    lines = [line for line in lines if not line.startswith(\":\")]\n    lines = [line for line in lines if not line.startswith(\";\")]\n    lines = [line for line in lines if not line.startswith(\"<\")]\n    lines = [line for line in lines if not line.startswith(\">\")]\n    lines = [line for line in lines if not line.startswith(\"[\")]\n    lines = [line for line in lines if not line.startswith(\"]\")]\n    lines = [line for line in lines if not line.startswith(\"{\")]\n    lines = [line for line in lines if not line.startswith(\"}\")]\n    lines = [line for line in lines if not line.startswith(\"(\")]\n    lines = [line for line in lines if not line.startswith(\")"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    blocks = []\n    block_index = 0\n    header_index = 0\n    header_block_index = 0\n    indentation = 0\n    list_index = 0\n    list_block_index = 0\n    list_item_index = 0\n    is_list = False\n    is_list_item = False\n    is_header = False\n    is_paragraph = False\n    is_table = False\n    is_table_row = False\n    is_table_header = False\n    is_table_body = False\n    is_table_footer = False\n    is_table_caption = False\n    is_table_header_row = False\n    is_table_body_row = False\n    is_table_footer_row = False\n    is_table_caption_row = False\n    is_table_header_cell = False\n    is_table_body_cell = False\n    is_table_footer_cell = False\n    is_table_caption_cell = False\n    is_table_header_cell_text = False\n    is_table_body_cell_text = False\n    is_table_footer_cell_text = False\n    is_table_caption_cell_text = False\n    is_table_header_cell_text_bold = False\n    is_table_body_cell_text_bold = False\n    is_table_footer_cell_text_bold = False\n    is_table_caption_cell_text_bold = False\n    is_table_header_cell_text_italic = False\n    is_table_body_cell_text_italic = False\n    is_table_footer_cell_text_italic = False\n    is_table_caption_cell_text_italic = False\n    is_table_header_cell_text_underline = False\n    is_table_body_cell_text_underline = False\n    is_table_footer_cell_text_underline = False\n    is_table_caption_cell_text_underline = False\n    is_table_header_cell_text_strikethrough = False\n    is_table_body_cell_"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Initialize variables\n    result = []\n    index = 0\n    paragraph_index = 0\n    header_index = 0\n    list_index = 0\n    list_level = 0\n    paragraph = []\n    header = []\n    list_item = []\n    list_items = []\n    list_item_index = 0\n    list_items_index = 0\n    header_block_index = 0\n    header_block_index_dict = defaultdict(int)\n    header_block_index_dict[0] = 0\n    header_block_index_dict[1] = 0\n    header_block_index_dict[2] = 0\n    header_block_index_dict[3] = 0\n    header_block_index_dict[4] = 0\n    header_block_index_dict[5] = 0\n    header_block_index_dict[6] = 0\n    header_block_index_dict[7] = 0\n    header_block_index_dict[8] = 0\n    header_block_index_dict[9] = 0\n    header_block_index_dict[10] = 0\n    header_block_index_dict[11] = 0\n    header_block_index_dict[12] = 0\n    header_block_index_dict[13] = 0\n    header_block_index_dict[14] = 0\n    header_block_index_dict[15] = 0\n    header_block_index_dict[16] = 0\n    header_block_index_dict[17] = 0\n    header_block_index_dict[18] = 0\n    header_block_index_dict[19] = 0\n    header_block_index_dict[20] = 0\n    header_block_index_dict[21] = 0\n    header_block_index_dict[22] = 0\n    header_block_index_dict[23] = 0\n    header_block_index_dict[24] = 0\n    header_block_index_dict[25] = 0\n    header_block_index_dict"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    header_blocks = []\n    list_blocks = []\n    paragraph_blocks = []\n    current_header_block = None\n    current_list_block = None\n    current_paragraph_block = None\n    current_list_index = 0\n    current_paragraph_index = 0\n    current_header_index = 0\n    current_header_level = 0\n    current_list_level = 0\n    current_paragraph_level = 0\n    current_list_block_index = 0\n    current_paragraph_block_index = 0\n    current_header_block_index = 0\n    current_list_block_level = 0\n    current_paragraph_block_level = 0\n    current_header_block_level = 0\n    current_list_block_type = None\n    current_paragraph_block_type = None\n    current_header_block_type = None\n    current_list_block_text = \"\"\n    current_paragraph_block_text = \"\"\n    current_header_block_text = \"\"\n    current_list_block_list_items = []\n    current_paragraph_block_list_items = []\n    current_header_block_list_items = []\n    current_list_block_header_block_index = None\n    current_paragraph_block_header_block_index = None\n    current_header_block_header_block_index = None\n    current_list_block_header_block_level = None\n    current_paragraph_block_header_block_level = None\n    current_header_block_header_block_level = None\n    current_list_block_header_block_type = None\n    current_paragraph_block_header_block_type = None\n    current_header_block_header_block_type = None\n    current_list_block_header_block_text = None\n    current_paragraph_block_header_block_text = None\n    current_header_block_header_block_text = None\n    current_list_block_header_block_list_items = None\n    current_paragraph_block_header_block_list_items = None\n    current_header_block_"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    block_index = 0\n    header_index = 0\n    header_block_index = 0\n    header_block_level = 0\n    header_block_index_stack = []\n    block_type = \"paragraph\"\n    block_text = \"\"\n    block_start_index = 0\n    block_list = []\n    block_indentation_level = 0\n    block_list_item = False\n    block_list_item_index = 0\n    block_list_item_level = 0\n    block_list_item_index_stack = []\n    block_list_item_level_stack = []\n    block_list_item_stack = []\n    block_list_item_stack_index = 0\n    block_list_item_stack_level = 0\n    block_list_item_stack_index_stack = []\n    block_list_item_stack_level_stack = []\n    block_list_item_stack_stack = []\n    block_list_item_stack_stack_index = 0\n    block_list_item_stack_stack_level = 0\n    block_list_item_stack_stack_index_stack = []\n    block_list_item_stack_stack_level_stack = []\n    block_list_item_stack_stack_stack = []\n    block_list_item_stack_stack_stack_index = 0\n    block_list_item_stack_stack_stack_level = 0\n    block_list_item_stack_stack_stack_index_stack = []\n    block_list_item_stack_stack_stack_level_stack = []\n    block_list_item_stack_stack_stack_stack = []\n    block_list_item_stack_stack_stack_stack_index = 0\n    block_list_item_stack_stack_stack_stack_level = 0\n    block_list_item_stack_stack_stack_stack_index_stack = []\n    block_list_item_stack_stack_stack_stack_level_stack = []\n    block_list_item_stack_stack_stack_stack_stack = []\n    block_list"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    block_index = 0\n    block_type = \"paragraph\"\n    block_start_index = 0\n    block_list = []\n    block_header_index = None\n    block_level = 0\n    block_text = \"\"\n    block_is_table = False\n    block_is_list = False\n    block_is_header = False\n    block_is_figure = False\n    block_is_footer = False\n    block_is_footnote = False\n    block_is_caption = False\n    block_is_table_row = False\n    block_is_table_header = False\n    block_is_table_footer = False\n    block_is_table_caption = False\n    block_is_table_body = False\n    block_is_table_footnote = False\n    block_is_table_footnote_header = False\n    block_is_table_footnote_body = False\n    block_is_table_footnote_footer = False\n    block_is_table_footnote_list = False\n    block_is_table_footnote_list_header = False\n    block_is_table_footnote_list_body = False\n    block_is_table_footnote_list_footer = False\n    block_is_table_footnote_list_item = False\n    block_is_table_footnote_list_item_header = False\n    block_is_table_footnote_list_item_body = False\n    block_is_table_footnote_list_item_footer = False\n    block_is_table_footnote_list_item_list = False\n    block_is_table_footnote_list_item_list_header = False\n    block_is_table_footnote_list_item_list_body = False\n    block_is_table_footnote_list_item_list_footer = False\n    block_is_table_footnote_list_item_list_item = False\n    block_is_table_footnote_list_item_list_item_header = False\n    block_is_table_footnote_list_item_list_item_body = False\n    block_is_table_footnote_list_"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    block_index = 0\n    header_index = 0\n    block_type = \"paragraph\"\n    text_group_index = 0\n    blocks = []\n    indentation = 0\n    list_items = []\n    for i, line in enumerate(lines):\n        if should_skip(line, xml):\n            continue\n        if xml:\n            line = line.replace(\"</p>\", \"\")\n            line = line.replace(\"<p>\", \"\")\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        line = line.replace(\"<p>\", \"\")\n        line = line.replace(\"</p>\", \"\")\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\"<\"):\n            continue\n        if line.startswith(\""}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # logger.info(f\"cleaning {len(lines)} lines\")\n    result = []\n    text_group_index = 0\n    text_group_start = 0\n    text_group_type = None\n    text_group_blocks = []\n    header_index = None\n    text_group_indent = 0\n    text_group_list_index = None\n    text_group_list_type = None\n    text_group_list_level = 0\n    text_group_list_parent = None\n    text_group_list_parent_type = None\n    text_group_list_parent_level = None\n    text_group_list_parent_index = None\n    text_group_list_parent_blocks = []\n    text_group_list_parent_indent = 0\n    text_group_list_parent_list_index = None\n    text_group_list_parent_list_type = None\n    text_group_list_parent_list_level = None\n    text_group_list_parent_list_parent = None\n    text_group_list_parent_list_parent_type = None\n    text_group_list_parent_list_parent_level = None\n    text_group_list_parent_list_parent_index = None\n    text_group_list_parent_list_parent_blocks = []\n    text_group_list_parent_list_parent_indent = 0\n    text_group_list_parent_list_parent_list_index = None\n    text_group_list_parent_list_parent_list_type = None\n    text_group_list_parent_list_parent_list_level = None\n    text_group_list_parent_list_parent_list_parent = None\n    text_group_list_parent_list_parent_list_parent_type = None\n    text_group_list_parent_list_parent_list_parent_level = None\n    text_group_list_parent_list_parent_list_parent_index = None\n    text_group_list_parent_list_parent_list_parent_blocks = []\n    text_group_list_parent_"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Clean lines\n    lines = [line_parser.Line(line) for line in lines]\n    lines = [line for line in lines if not line.is_empty]\n    lines = [line for line in lines if not line.is_table_row]\n\n    # Remove duplicate lines\n    lines = remove_duplicate_lines(lines)\n\n    # Fix spaced characters\n    lines = fix_spaced_characters(lines)\n\n    # Connect incomplete lines\n    lines = connect_incomplete_lines(lines)\n\n    # Categorize lines into paragraphs, headers, or list items\n    paragraphs = categorize_lines(lines)\n\n    # Create result list with metadata\n    result = []\n    for i, paragraph in enumerate(paragraphs):\n        if paragraph.is_header:\n            result.append(\n                {\n                    \"index\": i,\n                    \"text\": paragraph.text,\n                    \"type\": \"header\",\n                    \"start\": paragraph.start,\n                    \"list\": [],\n                    \"header_index\": None,\n                    \"level\": paragraph.level,\n                }\n            )\n        elif paragraph.is_list_item:\n            result.append(\n                {\n                    \"index\": i,\n                    \"text\": paragraph.text,\n                    \"type\": \"list_item\",\n                    \"start\": paragraph.start,\n                    \"list\": [],\n                    \"header_index\": None,\n                    \"level\": paragraph.level,\n                }\n            )\n        else:\n            result.append(\n                {\n                    \"index\": i,\n                    \"text\": paragraph.text,\n                    \"type\": \"paragraph\",\n                    \"start\": paragraph.start,\n                    \"list\": [],\n                    \"header_index\": None,\n                    \"level\": paragraph.level,\n                }\n            )\n\n    # Add list blocks to the result list\n    result = add_list_blocks(result)\n\n    # Add header index to list items\n    result = add_header_index(result)\n\n    # Add indentation level to list items\n    result = add_indentation_level(result)\n\n    return result"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Initialize variables\n    result = []\n    text_group = []\n    block_type = \"paragraph\"\n    block_index = 0\n    header_block_index = -1\n    list_index = -1\n    indent_index = -1\n    last_line = \"\"\n    last_line_index = -1\n    last_line_block_index = -1\n    last_line_list_index = -1\n    last_line_indent_index = -1\n    last_line_header_block_index = -1\n    last_line_type = \"paragraph\"\n    last_line_text = \"\"\n    last_line_text_group = []\n    last_line_is_header = False\n    last_line_is_list = False\n    last_line_is_indent = False\n    last_line_is_table_row = False\n    last_line_is_table_header = False\n    last_line_is_table_header_row = False\n    last_line_is_table_header_row_end = False\n    last_line_is_table_header_row_start = False\n    last_line_is_table_header_row_end_start = False\n    last_line_is_table_header_row_start_end = False\n    last_line_is_table_header_row_start_end_start = False\n    last_line_is_table_header_row_start_end_end = False\n    last_line_is_table_header_row_start_end_end_start = False\n    last_line_is_table_header_row_start_end_end_end = False\n    last_line_is_table_header_row_start_end_end_end_start = False\n    last_line_is_table_header_row_start_end_end_end_end = False\n    last_line_is_table_header_row_start_end_end_end_end_start = False\n    last_line_is_table_header_row_start_end_end_end_end_end = False\n   "}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    # block_index = 0\n    block_index = 0\n    block_type = \"paragraph\"\n    text_group = []\n    list_items = []\n    header_block_index = None\n    indentation_level = 0\n    list_level = 0\n    current_line = \"\"\n    previous_line = \"\"\n    previous_line_is_list = False\n    previous_line_is_header = False\n    previous_line_is_table = False\n    previous_line_is_table_row = False\n    previous_line_is_empty = False\n    previous_line_is_figure = False\n    previous_line_is_figure_caption = False\n    previous_line_is_table_caption = False\n    previous_line_is_table_header = False\n    previous_line_is_table_footer = False\n    previous_line_is_table_body = False\n    previous_line_is_table_row = False\n    previous_line_is_table_row_header = False\n    previous_line_is_table_row_footer = False\n    previous_line_is_table_row_body = False\n    previous_line_is_table_row_body_header = False\n    previous_line_is_table_row_body_footer = False\n    previous_line_is_table_row_body_body = False\n    previous_line_is_table_row_body_body_header = False\n    previous_line_is_table_row_body_body_footer = False\n    previous_line_is_table_row_body_body_body = False\n    previous_line_is_table_row_body_body_body_header = False\n    previous_line_is_table_row_body_body_body_footer = False\n    previous_line_is_table_row_body_body_body_body = False\n    previous_line_is_table_row_body_body_body_body_header = False\n    previous_line_is_table_row_body_body_body_body_footer = False\n    previous_line_is_table"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    result = []\n    text_group_index = 0\n    text_group_start = 0\n    text_group_type = None\n    text_group_list = None\n    text_group_level = 0\n    text_group_header = None\n    text_group_header_index = None\n    text_group_text = []\n    last_line = None\n    last_line_type = None\n    last_line_header = None\n    last_line_header_index = None\n    last_line_list = None\n    last_line_level = 0\n    last_line_text = []\n    last_line_index = 0\n    last_line_xml = False\n    last_line_empty = False\n    last_line_skip = False\n    last_line_is_table_row = False\n    last_line_is_table_header = False\n    last_line_is_table_data = False\n    last_line_is_table_footer = False\n    last_line_is_table_empty = False\n    last_line_is_table_skip = False\n    last_line_is_table_empty_header = False\n    last_line_is_table_empty_data = False\n    last_line_is_table_empty_footer = False\n    last_line_is_table_skip_header = False\n    last_line_is_table_skip_data = False\n    last_line_is_table_skip_footer = False\n    last_line_is_table_skip_empty_header = False\n    last_line_is_table_skip_empty_data = False\n    last_line_is_table_skip_empty_footer = False\n    last_line_is_table_skip_skip_header = False\n    last_line_is_table_skip_skip_data = False\n    last_line_is_table_skip_skip_footer = False\n    last_line_is_table_skip_skip_empty_header = False\n    last_line_is_table_skip_skip_empty_data = False\n    last_line_is_table_skip_skip_"}
{"namespace": "nlm_ingestor.ingestor.processors.clean_lines", "completion": "    # Initialize variables\n    result = []\n    block_index = 0\n    block_type = \"paragraph\"\n    start_index = 0\n    header_index = 0\n    list_blocks = []\n    list_index = 0\n    header_block = None\n    level = 0\n    prev_line = None\n    prev_line_type = None\n    prev_line_index = 0\n    prev_line_list_index = 0\n    prev_line_header_index = 0\n    prev_line_level = 0\n    prev_line_block_type = \"paragraph\"\n\n    # Process each line\n    for line_index, line in enumerate(lines):\n\n        # Skip empty lines\n        if should_skip(line, xml=xml):\n            continue\n\n        # Create a Line object for the current line\n        line = line_parser.Line(line)\n\n        # Check if the current line is a table row\n        if is_table_row(line):\n            # If the previous line was a table row, append it to the current line\n            if prev_line and is_table_row(prev_line):\n                line = line_parser.Line(prev_line.text + \" \" + line.text)\n            # Otherwise, append the current line to the previous line\n            else:\n                prev_line = line_parser.Line(prev_line.text + \" \" + line.text)\n            continue\n\n        # Check if the current line is a header\n        if line.is_header:\n            # If the previous line was a header, append it to the current line\n            if prev_line and prev_line.is_header:\n                line = line_parser.Line(prev_line.text + \" \" + line.text)\n            # Otherwise, append the current line to the previous line\n            else:\n                prev_line = line_parser.Line(prev_line.text + \" \" + line.text)\n            continue\n\n        # Check if the current line is a list item\n        if line.is_list:\n            # If the previous line was a list item, append it to the current line\n            if prev_line"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n\n    # remove new line characters\n    texts = org_texts.replace(\"\\n\", \" \")\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n    texts = \" \".join(texts.split())\n\n    # remove extra spaces\n   "}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # split text into paragraphs\n    texts = org_texts.split(\"\\n\")\n\n    # tokenize paragraphs\n    texts = [nltk_tokenzier.tokenize(text) for text in texts]\n\n    # flatten list of lists\n    texts = [text for text in texts for text in text]\n\n    # normalize quotation marks\n    texts = [quotation_pattern.sub('\"', text) for text in texts]\n\n    # apply rules\n    for rule, replaced in rules:\n        texts = [rule.sub(replaced, text) for text in texts]\n\n    # break sentences within brackets\n    texts = [bracket_rule.sub(r\"\\1\", text) for text in texts]\n\n    # remove space between punctuations\n    texts = [space_rule.sub(r\"\\1\", text) for text in texts]\n\n    return texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Tokenize the text into sentences\n    sents = nltk_tokenzier.tokenize(org_texts)\n\n    # Handle special cases\n    sents = [s.strip() for s in sents]\n    sents = [s for s in sents if s]\n\n    # Normalize quotation marks\n    sents = [quotation_pattern.sub('\"', s) for s in sents]\n\n    # Apply the rules\n    for rule, replaced in rules:\n        sents = [rule.sub(replaced, s) for s in sents]\n\n    # Normalize brackets\n    sents = [bracket_rule.sub(\"\", s) for s in sents]\n\n    # Normalize spaces\n    sents = [space_rule.sub(r\"\\1\", s) for s in sents]\n\n    return sents"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # split paragraphs\n    texts = org_texts.split(\"\\n\")\n\n    # split sentences\n    sentences = []\n    for text in texts:\n        # tokenize\n        text = nltk_tokenzier.tokenize(text)\n\n        # normalize\n        for rule, replaced in rules:\n            text = [rule.sub(replaced, sent) for sent in text]\n\n        # normalize quotation marks\n        text = [quotation_pattern.sub('\"', sent) for sent in text]\n\n        # normalize spaces\n        text = [space_rule.sub(r\"\\1\", sent) for sent in text]\n\n        # normalize brackets\n        text = [bracket_rule.sub(\"\", sent) for sent in text]\n\n        sentences.extend(text)\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts\n    # remove new line\n    texts = texts.replace(\"\\n\", \" \")\n    # remove space before punctuation\n    texts = space_rule.sub(r\"\\1\", texts)\n    # remove quotation marks\n    texts = quotation_pattern.sub('\"', texts)\n\n    # tokenize\n    sents = []\n    for sent in nltk_tokenzier.tokenize(texts):\n        # apply rules\n        for rule, replaced in rules:\n            sent = rule.sub(replaced, sent)\n        # break sentence within brackets\n        sent = bracket_rule.sub(r\"\\1\", sent)\n        sents.append(sent)\n\n    return sents"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts\n\n    # Normalize quotation marks\n    texts = quotation_pattern.sub('\"', texts)\n\n    # Add space between punctuations (.')\n    texts = space_rule.sub(r\"\\1\", texts)\n\n    # Tokenize sentences\n    sents = []\n    for sent in nltk_tokenzier.tokenize(texts):\n        # Remove space between punctuations (.')\n        sent = space_rule.sub(r\"\\1\", sent)\n\n        # Apply rules\n        for rule, replaced in rules:\n            sent = rule.sub(replaced, sent)\n\n        # Handle brackets\n        if bracket_rule.search(sent):\n            continue\n\n        sents.append(sent)\n\n    return sents"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts.strip()\n    texts = texts.replace(\"\\n\", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n    texts = texts.replace(\"  \", \" \")\n\n    for rule, replaced in rules:\n        texts = rule.sub(replaced, texts)\n\n    texts = bracket_rule.sub(lambda m: m.group(0).replace(\" \", \"_\"), texts)\n    texts = space_rule.sub(lambda m: m.group(1).replace(\" \", \"\"), texts)\n    texts = quotation_pattern.sub('\"', texts)\n\n    sents = nltk_tokenzier.tokenize(texts)\n    return sents"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts.replace(\"\\n\", \" \").strip()\n\n    # match content inside brackets\n    # (?<=\\() ==> starts with \"(\"\n    # ([^)]+) ==> repeat not \")\"\n    # (?=\\))\") ==> ends with \")\"\n    bracket_rule = re.compile(r\"(?<=\\()([^)]+)(?=\\))\")\n    space_rule = re.compile(r\"\\s([.'](?:\\s|$|\\D))\", re.IGNORECASE)  # Remove any space between punctuations (.')\n    quotation_pattern = re.compile(r'[\u201d\u201c\"\u2018\u2019\\']')\n\n    # normalize quotation marks\n    texts = quotation_pattern.sub('\"', texts)\n\n    # tokenize\n    texts = nltk_tokenzier.tokenize(texts)\n\n    # handle special cases\n    for rule, replaced in rules:\n        texts = [rule.sub(replaced, text) for text in texts]\n\n    # handle brackets\n    texts = [bracket_rule.sub(r\"\\1\", text) for text in texts]\n\n    # handle space between punctuation\n    texts = [space_rule.sub(r\"\\1\", text) for text in texts]\n\n    return texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # split paragraphs\n    texts = org_texts.split(\"\\n\")\n\n    # remove punctuation at the beginning of the text\n    texts = [text.strip(\"\\\"\") for text in texts]\n\n    # tokenize sentences\n    texts = [nltk_tokenzier.tokenize(text) for text in texts]\n\n    # flatten list\n    texts = [sent for text in texts for sent in text]\n\n    # remove space between punctuations (.')\n    texts = [space_rule.sub(r\"\\1\", text) for text in texts]\n\n    # remove quotation marks\n    texts = [quotation_pattern.sub(\"\", text) for text in texts]\n\n    # handle special cases\n    for rule, replaced in rules:\n        texts = [rule.sub(replaced, text) for text in texts]\n\n    # handle sentences within brackets\n    texts = [bracket_rule.sub(\"\", text) for text in texts]\n\n    return texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts\n\n    # normalize quotation marks\n    texts = quotation_pattern.sub('\"', texts)\n\n    # replace space between punctuations (.')\n    texts = space_rule.sub(r\"\\1\", texts)\n\n    # tokenize into sentences\n    sents = nltk_tokenzier.tokenize(texts)\n\n    # apply rules\n    for rule, replaced in rules:\n        sents = [rule.sub(replaced, sent) for sent in sents]\n\n    # break sentences within brackets\n    sents = [bracket_rule.sub(r\"\\n\\1\", sent) for sent in sents]\n\n    # split by new line\n    sents = \" \".join(sents).split(\"\\n\")\n\n    # remove empty lines\n    sents = [sent.strip() for sent in sents if sent.strip()]\n\n    return sents"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # Split the text into paragraphs\n    texts = org_texts.split(\"\\n\")\n\n    # Tokenize each paragraph\n    tokenized_texts = [nltk_tokenzier.tokenize(text) for text in texts]\n\n    # Flatten the list of lists into a single list\n    tokenized_texts = [sent for sent_list in tokenized_texts for sent in sent_list]\n\n    # Normalize quotation marks\n    tokenized_texts = [quotation_pattern.sub('\"', sent) for sent in tokenized_texts]\n\n    # Remove any space between punctuations (.')\n    tokenized_texts = [space_rule.sub(r\"\\1\", sent) for sent in tokenized_texts]\n\n    # Match content inside brackets\n    tokenized_texts = [bracket_rule.sub(r\"\\1\", sent) for sent in tokenized_texts]\n\n    # Apply the tokenization and normalization rules\n    for rule, replaced in rules:\n        tokenized_texts = [rule.sub(replaced, sent) for sent in tokenized_texts]\n\n    return tokenized_texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # normalize quotation marks\n    texts = quotation_pattern.sub('\"', org_texts)\n\n    # tokenize by paragraph\n    texts = texts.split(\"\\n\")\n\n    # tokenize by nltk\n    texts = [nltk_tokenzier.tokenize(text) for text in texts]\n\n    # flatten\n    texts = [sent for text in texts for sent in text]\n\n    # handle special cases\n    for rule, replaced in rules:\n        texts = [rule.sub(replaced, text) for text in texts]\n\n    # handle brackets\n    texts = [bracket_rule.sub(r\"\\1\", text) for text in texts]\n\n    # remove space before punctuations\n    texts = [space_rule.sub(r\"\\1\", text) for text in texts]\n\n    # remove empty sentences\n    texts = [text for text in texts if text]\n\n    return texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts\n\n    # split paragraphs\n    texts = texts.split(\"\\n\")\n    texts = [t for t in texts if t]\n\n    # tokenize sentences\n    texts = [nltk_tokenzier.tokenize(t) for t in texts]\n    texts = [t for ts in texts for t in ts]\n\n    # handle special case\n    texts = [t for t in texts if t]\n\n    # normalize quotation marks\n    texts = [quotation_pattern.sub('\"', t) for t in texts]\n\n    # apply rules\n    for rule, replaced in rules:\n        texts = [rule.sub(replaced, t) for t in texts]\n\n    # split brackets\n    texts = [bracket_rule.sub(r\"\\1\", t) for t in texts]\n\n    # remove space between punctuations\n    texts = [space_rule.sub(r\"\\1\", t) for t in texts]\n\n    return texts\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n\n    texts = org_texts\n\n    # split by paragraph\n    texts = texts.split(\"\\n\")\n\n    # split by period, but not if it is part of an abbreviation\n    texts = [nltk_tokenzier.tokenize(text) for text in texts]\n\n    # flatten\n    texts = [text for texts in texts for text in texts]\n\n    # split by period, but not if it is part of an abbreviation\n    texts = [nltk_tokenzier.tokenize(text) for text in texts]\n\n    # flatten\n    texts = [text for texts in texts for text in texts]\n\n    # remove space between punctuations (.')\n    texts = [space_rule.sub(r\"\\1\", text) for text in texts]\n\n    # remove quotation marks\n    texts = [quotation_pattern.sub(\"\", text) for text in texts]\n\n    # normalize brackets\n    texts = [bracket_rule.sub(\"\", text) for text in texts]\n\n    # apply rules\n    for rule, replaced in rules:\n        texts = [rule.sub(replaced, text) for text in texts]\n\n    return texts"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    texts = org_texts\n    # remove new line\n    texts = texts.replace(\"\\n\", \" \")\n\n    # remove punctuation at the beginning of the text\n    if texts[0] in \",.?!\":\n        texts = texts[1:]\n\n    # remove space before punctuation\n    texts = space_rule.sub(r\"\\1\", texts)\n\n    # normalize quotation marks\n    texts = quotation_pattern.sub('\"', texts)\n\n    # split brackets\n    texts = bracket_rule.sub(r\"\\1\", texts)\n\n    # split sentences\n    sentences = nltk_tokenzier.tokenize(texts)\n\n    # apply rules\n    for rule, replaced in rules:\n        sentences = [rule.sub(replaced, sent) for sent in sentences]\n\n    # remove space in the end of the sentence\n    sentences = [sent.strip() for sent in sentences]\n\n    return sentences"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # handle special cases\n    org_texts = org_texts.replace(\"\\n\", \" \")\n    org_texts = org_texts.replace(\".\\n\", \".\\n\\n\")\n    org_texts = org_texts.replace(\".\\n\\n\", \".\\n\\n\\n\")\n\n    # handle special cases\n    if org_texts[0] in [\".\", \"?\", \"!\"]:\n        org_texts = \" \" + org_texts\n\n    # tokenize\n    sents = nltk_tokenzier.tokenize(org_texts)\n\n    # apply rules\n    for rule, replaced in rules:\n        sents = [rule.sub(replaced, sent) for sent in sents]\n\n    # handle special cases\n    sents = [bracket_rule.sub(r\"\\1\", sent) for sent in sents]\n    sents = [space_rule.sub(r\"\\1\", sent) for sent in sents]\n    sents = [quotation_pattern.sub('\"', sent) for sent in sents]\n\n    return sents\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    text = org_texts\n\n    # remove extra spaces\n    text = re.sub(r\"\\s+\", \" \", text)\n\n    # normalize quotations\n    text = re.sub(quotation_pattern, '\"', text)\n\n    # remove spaces between punctuations\n    text = re.sub(space_rule, r\"\\1\", text)\n\n    # handle special cases\n    text = re.sub(r\"\\n\", r\" \", text)\n    text = re.sub(r\"\\s([.,:;?!]+)([^A-Z])\", r\"\\1 \\2\", text)\n    text = re.sub(r\"([^A-Z])([.,:;?!]+)\\s\", r\"\\1\\2 \", text)\n    text = re.sub(r\"\\s([.,:;?!]+)$\", r\"\\1\", text)\n\n    # handle brackets\n    text = re.sub(bracket_rule, \"\", text)\n\n    # handle special cases\n    text = re.sub(r\"^([.,:;?!]+)\\s\", r\"\\1 \", text)\n\n    # apply tokenization rules\n    for rule, replaced in rules:\n        text = re.sub(rule, replaced, text)\n\n    # tokenize\n    return nltk_tokenzier.tokenize(text)"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if not org_texts:\n        return org_texts\n\n    # remove new line characters\n    texts = org_texts.replace(\"\\n\", \" \")\n\n    # tokenize into sentences\n    sents = nltk_tokenzier.tokenize(texts)\n\n    # normalize quotation marks\n    sents = [quotation_pattern.sub(\"\\\"\", sent) for sent in sents]\n\n    # apply rules\n    for rule, replaced in rules:\n        sents = [rule.sub(replaced, sent) for sent in sents]\n\n    # normalize space between punctuations\n    sents = [space_rule.sub(r\"\\1\", sent) for sent in sents]\n\n    # normalize brackets\n    sents = [bracket_rule.sub(r\"\\1\", sent) for sent in sents]\n\n    return sents\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None:\n        return org_texts\n\n    if not isinstance(org_texts, str):\n        org_texts = str(org_texts)\n\n    org_texts = org_texts.strip()\n    if org_texts == \"\":\n        return [org_texts]\n\n    org_texts = org_texts.replace(\"\\n\", \" \")\n    org_texts = org_texts.replace(\".\", \". \")\n    org_texts = org_texts.replace(\"?\", \"? \")\n    org_texts = org_texts.replace(\":\", \": \")\n    org_texts = org_texts.replace(\";\", \"; \")\n    org_texts = org_texts.replace(\"  \", \" \")\n\n    # normalize quotation marks\n    org_texts = quotation_pattern.sub('\"', org_texts)\n\n    # match content inside brackets\n    bracket_content = bracket_rule.findall(org_texts)\n    for content in bracket_content:\n        org_texts = org_texts.replace(content, content.replace(\" \", \"_\"))\n\n    # remove space between punctuations (.')\n    org_texts = space_rule.sub(r\"\\1\", org_texts)\n\n    # apply rules\n    for rule, replaced in rules:\n        org_texts = rule.sub(replaced, org_texts)\n\n    # tokenize\n    sents = nltk_tokenzier.tokenize(org_texts)\n    return sents\n\n"}
{"namespace": "nlm_ingestor.ingestor_utils.utils.sent_tokenize", "completion": "    if org_texts is None or len(org_texts) == 0:\n        return org_texts\n\n    # Split by new line\n    texts = org_texts.split(\"\\n\")\n\n    # Add a period at the end of the sentence if it does not have one\n    texts = [text + \".\" if not text.endswith(\".\") else text for text in texts]\n\n    # Add a space at the beginning of the sentence if it does not have one\n    texts = [\" \" + text if not text.startswith(\" \") else text for text in texts]\n\n    # Remove space between punctuation\n    texts = [space_rule.sub(r\"\\1\", text) for text in texts]\n\n    # Normalize quotation marks\n    texts = [quotation_pattern.sub('\"', text) for text in texts]\n\n    # Tokenize\n    texts = [nltk_tokenzier.tokenize(text) for text in texts]\n\n    # Flatten\n    texts = [sent for text in texts for sent in text]\n\n    # Replace abbrevations\n    for rule, replaced in rules:\n        texts = [rule.sub(replaced, text) for text in texts]\n\n    # Remove space between punctuation\n    texts = [space_rule.sub(r\"\\1\", text) for text in texts]\n\n    # Remove space between punctuation\n    texts = [bracket_rule.sub(r\"\\1\", text) for text in texts]\n\n    # Remove space between punctuation\n    texts = [space_rule.sub(r\"\\1\", text) for text in texts]\n\n    # Remove space between punctuation\n    texts = [space_rule.sub(r\"\\1\", text) for text in texts]\n\n    # Remove space between punctuation\n    texts = [space_rule.sub(r\"\\1\", text) for text in texts]\n\n    return texts\n\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is None:\n                slice_of_rows = None\n                if self.term_mat.subset:\n                    slice_of_rows = self.term_mat.rows\n                return self.posns.positions(term_id, doc_ids=slice_of_rows)\n            else:\n                return self.posns.positions(term_id, doc_ids=[key])\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if key is not None:\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                return self.posns.doc_posns(term_id, doc_id=key)\n            except TermMissingError:\n                return []\n        else:\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                return self.posns.all_posns(term_id)\n            except TermMissingError:\n                return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is None:\n            return [self.posns.doc_posns(self.term_dict.get_term_id(token))]\n        else:\n            return [self.posns.doc_posns(self.term_dict.get_term_id(token), key)]\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            # We need to find the position of the doc in the doc_lens\n            # and then find the position of the term in the term_mat\n            # and then find the position of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions of the term in the posns\n            # and then find the positions"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        if key is None:\n            posns = self.posns.doc_posns(self.term_dict.get_term_id(token))\n        else:\n            posns = self.posns.doc_posns(self.term_dict.get_term_id(token), doc_id=key)\n        return posns\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Get term freqs per token\n        token = self._check_token_arg(token)\n        if isinstance(token, list):\n            raise ValueError(\"Positions only works for single tokens\")\n\n        if key is None:\n            return self.posns.positions(self.term_dict.get_term_id(token))\n        else:\n            return self.posns.positions(self.term_dict.get_term_id(token), doc_id=key)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        token = self._check_token_arg(token)\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is None:\n                return self.posns.positions(term_id)\n            else:\n                return self.posns.positions(term_id, doc_id=key)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is None:\n            # Get all positions\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                return self.posns.positions(term_id)\n            except TermMissingError:\n                return []\n        else:\n            # Get positions for a specific doc\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                return self.posns.positions(term_id, doc_id=key)\n            except TermMissingError:\n                return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is None:\n            return [self.posns.doc_posns(self.term_dict.get_term_id(token), doc_id=doc_id)\n                    for doc_id in range(len(self))]\n        else:\n            return [self.posns.doc_posns(self.term_dict.get_term_id(token), doc_id=key)]\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is None:\n            return [np.asarray(self.posns.doc_posns(self.term_dict.get_term_id(token), doc_id=doc_id))\n                    for doc_id in self.term_mat.rows]\n        else:\n            return np.asarray(self.posns.doc_posns(self.term_dict.get_term_id(token), doc_id=key))\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is None:\n            # Return positions across all documents\n            return [np.asarray(self.posns.doc_posns(self.term_dict.get_term_id(token))) for _ in self]\n        else:\n            # Return positions for the specific document\n            return np.asarray(self.posns.doc_posns(self.term_dict.get_term_id(token), doc_id=key))\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                return self.posns.positions(term_id, doc_id=key)\n            except TermMissingError:\n                return []\n        else:\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                return self.posns.positions(term_id)\n            except TermMissingError:\n                return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                doc_id = key\n                if doc_id < 0:\n                    doc_id += len(self)\n                posns = self.posns.doc_posns(term_id, doc_id)\n                return [posns]\n            except TermMissingError:\n                return [np.array([], dtype=np.uint16)]\n        else:\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                posns = self.posns.term_posns(term_id)\n                return posns\n            except TermMissingError:\n                return [np.array([], dtype=np.uint16)]\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        # Get term freqs per token\n        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n\n        if key is not None:\n            if not isinstance(key, int):\n                raise TypeError(\"Expected an integer key\")\n\n        try:\n            term_id = self.term_dict.get_term_id(token)\n            if key is not None:\n                return self.posns.positions(term_id, key)\n            else:\n                return self.posns.positions(term_id)\n        except TermMissingError:\n            return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            if not isinstance(key, int):\n                raise TypeError(\"key must be an integer\")\n            if key < 0 or key >= len(self):\n                raise IndexError(\"key out of range\")\n            # Get the positions for the given key\n            positions = self.posns.positions(self.term_dict.get_term_id(token),\n                                             doc_id=key)\n            return [np.asarray(positions)]\n        else:\n            # Get the positions for all documents\n            positions = self.posns.positions(self.term_dict.get_term_id(token))\n            return [np.asarray(posns) for posns in positions]\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is None:\n            # Get positions for all documents\n            try:\n                return self.posns.doc_positions(self.term_dict.get_term_id(token))\n            except TermMissingError:\n                return []\n        else:\n            # Get positions for a specific document\n            try:\n                return self.posns.doc_positions(self.term_dict.get_term_id(token), doc_id=key)\n            except TermMissingError:\n                return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if not isinstance(token, str):\n            raise TypeError(\"Expected a string\")\n        if key is None:\n            # Return positions across all documents\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                doc_ids, posns = self.posns.doc_positions(term_id)\n                return posns\n            except TermMissingError:\n                return []\n        else:\n            # Return positions for a specific document\n            try:\n                term_id = self.term_dict.get_term_id(token)\n                doc_id = key\n                if doc_id < 0:\n                    doc_id += len(self)\n                doc_posns = self.posns.doc_positions(term_id, doc_id)\n                return doc_posns\n            except TermMissingError:\n                return []\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            if isinstance(key, numbers.Integral):\n                if key < 0:\n                    key += len(self)\n                try:\n                    return self.posns.doc_posns(self.term_dict.get_term_id(token), doc_id=key)\n                except TermMissingError:\n                    return np.array([], dtype=int)\n            else:\n                raise ValueError(\"Key must be an integer\")\n        else:\n            try:\n                return self.posns.doc_posns(self.term_dict.get_term_id(token))\n            except TermMissingError:\n                return np.array([], dtype=int)\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            doc_id = key\n            if doc_id < 0:\n                doc_id += len(self)\n            if doc_id >= len(self):\n                raise ValueError(\"Index out of bounds\")\n            term_id = self.term_dict.get_term_id(token)\n            return self.posns.doc_posns(term_id, doc_id=doc_id)\n        else:\n            # TODO: This is slow, and should be optimized\n            return [self.positions(token, key=key) for key in range(len(self))]\n"}
{"namespace": "searcharray.postings.SearchArray.positions", "completion": "        if key is not None:\n            if isinstance(key, numbers.Integral):\n                key = [key]\n            if not isinstance(key, list):\n                raise TypeError(\"key must be a list or None\")\n\n        term_id = self.term_dict.get_term_id(token)\n        if key is None:\n            # If we don't have a key, we need to get all the positions\n            # for the term\n            doc_ids, posns = self.posns.doc_posns(term_id)\n            return posns\n        else:\n            # If we have a key, we can get the positions for the term\n            # in the specific document\n            doc_id = key[0]\n            posns = self.posns.doc_posns(term_id, doc_id=doc_id)\n            return posns\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith(\"%\"):\n        return int(num_clauses * float(spec[:-1]) / 100)\n    elif spec.startswith(\"<\"):\n        return int(num_clauses) - int(spec[1:])\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith(\"%\"):\n        # Parse percentage-based 'mm' spec\n        percentage = float(spec[:-1]) / 100.0\n        return int(num_clauses * percentage)\n    elif spec.startswith(\"<\"):\n        # Parse conditional 'mm' spec\n        threshold = int(spec[1:])\n        return min(num_clauses, threshold)\n    else:\n        # Parse absolute 'mm' spec\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith('%'):\n        percentage = float(spec[:-1]) / 100.0\n        return int(num_clauses * percentage)\n    elif spec.startswith('<'):\n        threshold = int(spec[1:])\n        return min(threshold, num_clauses)\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith(\"%\"):\n        percentage = float(spec[:-1]) / 100\n        return int(num_clauses * percentage)\n    elif spec.startswith(\"<\"):\n        threshold = float(spec[1:])\n        return int(num_clauses * threshold)\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Remove any leading or trailing whitespace from the spec string\n    spec = spec.strip()\n\n    # If the spec is a percentage, calculate the minimum number of clauses based on the percentage\n    if spec.endswith(\"%\"):\n        percentage = float(spec[:-1])\n        return int(num_clauses * percentage / 100)\n\n    # If the spec is a conditional expression, calculate the minimum number of clauses based on the condition\n    if \"<\" in spec:\n        clauses_in_condition, clauses_outside_condition = spec.split(\"<\")\n        clauses_in_condition = int(clauses_in_condition)\n        clauses_outside_condition = int(clauses_outside_condition)\n        return num_clauses - clauses_outside_condition + clauses_in_condition\n\n    # If the spec is a simple number, return it as an integer\n    return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith('%'):\n        return int(num_clauses * float(spec[:-1]) / 100)\n    elif spec.startswith('<'):\n        return int(num_clauses) - int(spec[1:])\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Check if the spec is a percentage\n    if spec.endswith('%'):\n        # Parse the percentage value\n        percentage = float(spec[:-1]) / 100\n        # Calculate the minimum number of clauses based on the percentage\n        min_clauses = int(num_clauses * percentage)\n    elif spec.startswith('<'):\n        # Parse the conditional expression\n        condition = spec[1:]\n        # Check if the condition is a percentage\n        if condition.endswith('%'):\n            # Parse the percentage value\n            percentage = float(condition[:-1]) / 100\n            # Calculate the minimum number of clauses based on the percentage\n            min_clauses = int(num_clauses * percentage)\n        else:\n            # Parse the absolute number\n            min_clauses = int(condition)\n    else:\n        # Parse the absolute number\n        min_clauses = int(spec)\n\n    return min_clauses\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Split the spec into individual clauses\n    clauses = spec.split()\n\n    # Initialize the minimum number of clauses that must match\n    min_matches = 0\n\n    # Iterate over each clause\n    for clause in clauses:\n        # Check if the clause is a percentage\n        if clause.endswith('%'):\n            # Calculate the minimum number of clauses based on the percentage\n            min_matches += int(num_clauses * float(clause[:-1]) / 100)\n        # Check if the clause is a conditional expression\n        elif '<' in clause:\n            # Split the clause into the left and right operands\n            left, right = clause.split('<')\n            # Calculate the minimum number of clauses based on the left operand\n            min_matches += int(num_clauses * float(left) / 100)\n            # Calculate the minimum number of clauses based on the right operand\n            min_matches += int(num_clauses * float(right) / 100)\n        # Otherwise, assume the clause is an absolute number\n        else:\n            # Add the clause to the minimum number of clauses\n            min_matches += int(clause)\n\n    # Return the minimum number of clauses that must match\n    return min_matches\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith('%'):\n        return int(num_clauses * float(spec[:-1]) / 100)\n    elif spec.startswith('<'):\n        return num_clauses - parse_min_should_match(num_clauses, spec[1:])\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Check if the spec is a percentage\n    if spec.endswith('%'):\n        percentage = float(spec[:-1]) / 100.0\n        return int(percentage * num_clauses)\n\n    # Check if the spec is a conditional expression\n    if '<' in spec:\n        clauses_matched, clauses_required = spec.split('<')\n        clauses_matched = int(clauses_matched)\n        clauses_required = int(clauses_required)\n        return max(clauses_matched, clauses_required)\n\n    # If the spec is neither a percentage nor a conditional expression, assume it's an absolute number\n    return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Check if spec is a percentage\n    if spec.endswith('%'):\n        # Calculate percentage of clauses\n        percentage = float(spec[:-1]) / 100\n        return int(num_clauses * percentage)\n\n    # Check if spec is a conditional expression\n    elif '<' in spec:\n        # Split the expression into clauses\n        clauses = spec.split('<')\n        # Calculate the minimum number of clauses that must match\n        min_clauses = int(clauses[0])\n        if min_clauses < num_clauses:\n            return min_clauses\n        else:\n            return num_clauses\n\n    # Otherwise, assume spec is an absolute number\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Check if the spec is a percentage\n    if spec.endswith('%'):\n        # Calculate the percentage of clauses to match\n        percentage = float(spec[:-1]) / 100\n        return int(np.ceil(percentage * num_clauses))\n\n    # Check if the spec is a conditional expression\n    elif '<' in spec:\n        # Split the expression into the two parts\n        parts = spec.split('<')\n        # Calculate the minimum number of clauses for each part\n        min_clauses = [parse_min_should_match(num_clauses, part) for part in parts]\n        # Return the minimum of the two minimums\n        return min(min_clauses)\n\n    # Otherwise, assume the spec is an absolute number\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Check if the spec is a percentage\n    if spec.endswith('%'):\n        # Parse the percentage value and calculate the minimum number of clauses\n        percentage = int(spec[:-1])\n        return max(1, int(num_clauses * percentage / 100))\n    # Check if the spec is a conditional expression\n    elif '<' in spec:\n        # Parse the conditional expression and calculate the minimum number of clauses\n        clauses, num_matches = spec.split('<')\n        clauses = int(clauses)\n        num_matches = int(num_matches)\n        return max(1, clauses - num_matches)\n    # Otherwise, assume the spec is an absolute number\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Split the spec into individual clauses\n    clauses = spec.split()\n\n    # Initialize the minimum number of clauses that must match\n    min_clauses = 0\n\n    # Iterate over each clause\n    for clause in clauses:\n        # Check if the clause is a percentage\n        if clause.endswith('%'):\n            # Convert the percentage to a float and calculate the minimum number of clauses\n            min_clauses += int(num_clauses * float(clause[:-1]) / 100)\n        # Check if the clause is a conditional expression\n        elif '<' in clause:\n            # Split the clause into the left and right parts\n            left, right = clause.split('<')\n            # Convert the left part to an integer and calculate the minimum number of clauses\n            min_clauses += int(left)\n            # Convert the right part to a float and calculate the minimum number of clauses\n            min_clauses += int(num_clauses * float(right) / 100)\n        # Otherwise, the clause is an absolute number\n        else:\n            # Convert the clause to an integer and add it to the minimum number of clauses\n            min_clauses += int(clause)\n\n    # Return the minimum number of clauses that must match\n    return min_clauses\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith(\"%\"):\n        percentage = float(spec[:-1]) / 100.0\n        return int(num_clauses * percentage)\n    elif spec.startswith(\"<\"):\n        clauses = int(spec[1:])\n        return clauses\n    else:\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith('%'):\n        # Parse percentage-based 'mm' spec\n        percentage = float(spec[:-1])\n        return int(num_clauses * percentage / 100)\n    elif spec.startswith('<'):\n        # Parse conditional 'mm' spec\n        threshold = int(spec[1:])\n        return num_clauses - threshold + 1\n    else:\n        # Parse absolute 'mm' spec\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # If spec is None or empty, return 0\n    if not spec:\n        return 0\n\n    # Check if spec is a percentage\n    if spec.endswith('%'):\n        # Convert percentage to float and calculate minimum number of clauses that must match\n        min_match = int(float(spec[:-1]) / 100 * num_clauses)\n    # Check if spec is a conditional expression\n    elif '<' in spec:\n        # Split the conditional expression into clauses\n        clauses = spec.split('<')\n        # Convert each clause to an integer and calculate minimum number of clauses that must match\n        min_match = int(np.min([int(clause) for clause in clauses]))\n    else:\n        # Convert spec to an integer and use as minimum number of clauses that must match\n        min_match = int(spec)\n\n    # Return the calculated minimum number of clauses that must match\n    return min_match\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Check if spec is a percentage\n    if spec.endswith('%'):\n        percentage = float(spec[:-1]) / 100.0\n        return int(num_clauses * percentage)\n\n    # Check if spec is a conditional expression\n    if '<' in spec:\n        clauses_matching = int(spec.split('<')[0])\n        clauses_total = int(spec.split('<')[1])\n        return clauses_matching if clauses_matching < clauses_total else clauses_total\n\n    # Otherwise, spec is an absolute number\n    return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    if spec.endswith('%'):\n        # Parse percentage-based 'mm' spec\n        percentage = float(spec[:-1])\n        return int(num_clauses * percentage / 100)\n    elif spec.startswith('<'):\n        # Parse conditional 'mm' spec\n        threshold = int(spec[1:])\n        return num_clauses - threshold + 1\n    else:\n        # Parse absolute 'mm' spec\n        return int(spec)\n\n"}
{"namespace": "searcharray.solr.parse_min_should_match", "completion": "    # Parse the 'mm' spec using regular expressions\n    match = re.match(r'(\\d+)(%)?(<(\\d+)(%)?)?', spec)\n\n    # If the 'mm' spec is not valid, raise a ValueError\n    if match is None:\n        raise ValueError(f\"Invalid 'mm' spec: {spec}\")\n\n    # Extract the numeric values from the 'mm' spec\n    num1 = int(match.group(1))\n    num2 = int(match.group(4)) if match.group(4) is not None else None\n\n    # If the 'mm' spec is a percentage, calculate the absolute number of clauses\n    if match.group(2) is not None:\n        num1 = int(num_clauses * num1 / 100)\n        if num2 is not None:\n            num2 = int(num_clauses * num2 / 100)\n\n    # If the 'mm' spec is a conditional expression, return the appropriate number of clauses\n    if match.group(3) is not None:\n        if num2 is None:\n            raise ValueError(f\"Invalid 'mm' spec: {spec}\")\n        if num1 > num2:\n            return num1\n        else:\n            return num2\n\n    # Otherwise, return the absolute number of clauses\n    return num1\n\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            # If slop is 1 and all tokens are unique, we can directly calculate the phrase frequencies\n            # using the positions of terms\n            return self._phrase_freq_slop1(tokens)\n        else:\n            # If slop is not 1 or tokens are not unique, we delegate the calculation to another method\n            return self._phrase_freq_slop_gt1(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            # If slop is 1 and all tokens are unique, we can directly calculate the phrase frequencies\n            # using the positions of terms.\n            try:\n                term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n                term_posns = [self.posns.positions(term_id) for term_id in term_ids]\n                phrase_freqs = scan_merge_ins(term_posns)\n                return phrase_freqs\n            except TermMissingError:\n                return np.zeros(len(self), dtype=int)\n        else:\n            # If slop is not 1 or tokens are not unique, we delegate the calculation to another method\n            # that handles different slops or non-unique tokens.\n            return self._phrase_freq_non_unique(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_unique(tokens)\n        else:\n            return self._phrase_freq_non_unique(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and all tokens are unique, we can directly calculate the phrase frequencies\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n            posns = self.positions(tokens[0], key=self.term_mat.rows)\n            if len(posns) == 0:\n                return np.zeros(len(self), dtype=int)\n            else:\n                return scan_merge_ins(posns, term_ids, slop)\n        else:\n            return self._phrase_freq_other_slops(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If the slop is 1 and all tokens are unique, we can directly calculate the phrase frequencies\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self.phrase_freq_1_unique_tokens(tokens)\n        else:\n            return self.phrase_freq_slop_or_non_unique_tokens(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_adjacent(tokens)\n        else:\n            return self._phrase_freq_nonadjacent(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If the slop is 1 and all tokens are unique, try to directly calculate the phrase frequencies\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_adjacent(tokens)\n        else:\n            # Delegate the calculation to another method that handles different slops or non-unique tokens\n            return self._phrase_freq_general(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            # We can directly compute the phrase freqs\n            term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n            posns = [self.positions(token) for token in tokens]\n            phrase_freqs = compute_phrase_freqs(term_ids, posns, slop)\n            return phrase_freqs\n        else:\n            return self._phrase_freq_general(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and all tokens are unique, calculate directly\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n            return self.posns.phrase_freq(term_ids)\n        else:\n            return self._phrase_freq_non_unique(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            # If slop is 1 and all tokens are unique, we can directly calculate the phrase frequencies\n            # using the positions of terms\n            phrase_freqs = self.phrase_freq_posn_diffs(tokens)\n        else:\n            # If slop is not 1 or tokens are not unique, we delegate the calculation to another method\n            # that handles different slops or non-unique tokens\n            phrase_freqs = self.phrase_freq_scan_merge(tokens, slop)\n\n        return phrase_freqs\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if slop is 1 and all tokens are unique\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            # Try to directly calculate phrase frequencies using positions\n            try:\n                return self._phrase_freq_positions(tokens)\n            except TermMissingError:\n                return np.zeros(len(self), dtype=int)\n\n        # If slop is not 1 or tokens are not unique, delegate to another method\n        return self._phrase_freq_non_unique(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_direct(tokens)\n        else:\n            return self._phrase_freq_general(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_adjacent(tokens)\n        else:\n            return self._phrase_freq(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            # This is the fast path for unique terms\n            # We can directly calculate the phrase frequencies\n            # by looking at the positions of terms\n            return self._phrase_freq_unique_terms(tokens)\n        else:\n            return self._phrase_freq_non_unique_terms(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            # TODO: Optimize this case\n            # If the slop is 1 and all tokens are unique, we can directly calculate the phrase frequencies\n            # using the positions of terms\n            try:\n                term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n                term_posns = [self.positions(token) for token in tokens]\n                term_posns = [np.asarray(posns, dtype=np.uint32) for posns in term_posns]\n                term_posns = [posns.reshape(-1, 1) for posns in term_posns]\n                phrase_freqs = scan_merge_ins(term_posns, term_ids, slop)\n                return phrase_freqs\n            except TermMissingError:\n                return np.zeros(len(self), dtype=int)\n        else:\n            # If the slop is not 1 or tokens are not unique, we delegate the calculation to another method\n            return self._phrase_freq_slop_or_unique(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            # We can calculate the phrase frequency directly\n            # if the slop is 1 and all tokens are unique\n            # (no need to scan for phrase matches)\n            try:\n                term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n                posns = self.posns.positions(term_ids)\n                phrase_freqs = compute_phrase_freqs(posns, slop)\n                return phrase_freqs\n            except TermMissingError:\n                return np.zeros(len(self), dtype=int)\n        else:\n            # Otherwise, we need to scan for phrase matches\n            return self._phrase_freq_scan(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # If slop is 1 and tokens are unique, try to directly calculate phrase frequencies\n        if slop == 1 and len(set(tokens)) == len(tokens):\n            return self._phrase_freq_direct(tokens)\n        else:\n            # Delegate to another method for handling different slops or non-unique tokens\n            return self._phrase_freq_general(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if all tokens are unique\n        if len(set(tokens)) == len(tokens):\n            # Check if slop is 1\n            if slop == 1:\n                # Attempt to directly calculate phrase frequencies\n                return self._phrase_freq_unique_tokens_slop_1(tokens)\n            else:\n                # Delegate to another method for different slops or non-unique tokens\n                return self._phrase_freq_unique_tokens_slop_gt_1(tokens, slop)\n        else:\n            # Delegate to another method for different slops or non-unique tokens\n            return self._phrase_freq_unique_tokens_slop_gt_1(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        if slop == 1 and len(set(tokens)) == len(tokens):\n            # Calculate phrase frequencies for adjacent tokens\n            # This is the fast path\n            # We can do this if the slop is 1 and all tokens are unique\n            # Otherwise, we have to delegate to another method\n            try:\n                term_ids = [self.term_dict.get_term_id(token) for token in tokens]\n                # TODO: This is a bit slow\n                # We could cache the positions for each term\n                # and then do the scan merge on those\n                # But this is a bit tricky\n                # We would have to make sure the cache is updated\n                # when the term dict is updated\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared\n                # when the term dict is cleared\n                # and we would have to make sure the cache is cleared"}
{"namespace": "searcharray.postings.SearchArray.phrase_freq", "completion": "        # Check if all tokens are unique\n        unique_tokens = set(tokens)\n        if len(unique_tokens) != len(tokens):\n            return self._phrase_freq_non_unique_tokens(tokens, slop)\n\n        # Check if slop is 1\n        if slop == 1:\n            # Check if all tokens are present in the SearchArray\n            token_ids = [self.term_dict.get_term_id(token) for token in tokens]\n            if all(token_id in self.term_dict.term_ids for token_id in token_ids):\n                # Calculate phrase frequencies directly\n                return self._phrase_freq_direct(tokens)\n\n        # Delegate to another method for non-unique tokens or slop > 1\n        return self._phrase_freq_non_unique_tokens(tokens, slop)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check tokenizer, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable, got {}\".format(type(tokenizer)))\n\n        # Check truncate, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check batch_size, raise TypeError\n        if not isinstance(batch_size, numbers.Integral):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check avoid_copies, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check array, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check tokenizer, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable, got {}\".format(type(tokenizer)))\n\n        # Check truncate, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check batch_size, raise TypeError\n        if not isinstance(batch_size, numbers.Integral):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check avoid_copies, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Check array, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        #"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if array is empty\n        if len(array) == 0:\n            return cls([], tokenizer=tokenizer)\n\n        # Check if array is a Series\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        # Check if array is a DataFrame\n        if isinstance(array, pd.DataFrame):\n            array = array.iloc[:, 0].values\n\n        # Check if array is a Series\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        # Check if array is a DataFrame\n        if isinstance(array, pd.DataFrame):\n            array = array.iloc[:, 0].values\n\n        # Check if array is a Series\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        # Check if array is a DataFrame\n        if isinstance(array, pd.DataFrame):\n            array = array.iloc[:, 0].values\n\n        # Check if array is a Series\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        # Check if array is a DataFrame\n        if isinstance(array, pd.DataFrame):\n            array = array.iloc[:, 0].values\n\n        # Check if array is a Series\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        # Check if array is a DataFrame\n        if isinstance(array, pd.DataFrame):\n            array = array.iloc[:, 0].values\n\n        # Check if array is a Series\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        # Check if array is a DataFrame\n        if isinstance(array, pd.DataFrame):\n            array = array.iloc[:, 0].values\n\n        # Check if array is a Series"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check batch_size, raise TypeError\n        if not isinstance(batch_size, numbers.Integral):\n            raise TypeError(\"Expected an integer, got {}\".format(type(batch_size)))\n\n        # Check truncate, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected a boolean, got {}\".format(type(truncate)))\n\n        # Check avoid_copies, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected a boolean, got {}\".format(type(avoid_copies)))\n\n        # Check tokenizer, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected a callable, got {}\".format(type(tokenizer)))\n\n        # Check array, raise TypeError\n        if not isinstance(array, Iterable):\n            raise TypeError(\"Expected an iterable, got {}\".format(type(array)))\n\n        # Check array, raise TypeError\n        if not isinstance(array, Iterable):\n            raise TypeError(\"Expected an iterable, got {}\".format(type(array)))\n\n        # Check array, raise TypeError\n        if not isinstance(array, Iterable):\n            raise TypeError(\"Expected an iterable, got {}\".format(type(array)))\n\n        # Check array, raise TypeError\n        if not isinstance(array, Iterable):\n            raise TypeError(\"Expected an iterable, got {}\".format(type(array)))\n\n        # Check array, raise TypeError\n        if not isinstance(array, Iterable):\n            raise TypeError(\"Expected an iterable, got {}\".format(type(array)))\n\n        # Check array, raise TypeError\n        if not isinstance(array, Iterable):\n            raise TypeError(\"Expected an iterable, got {}\".format(type(array)))\n\n        # Check array, raise TypeError\n        if not isinstance("}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if array is already a SearchArray\n        if isinstance(array, SearchArray):\n            return array\n\n        # Check if array is a pandas Series\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        # Check if array is a numpy array\n        if isinstance(array, np.ndarray):\n            array = array.tolist()\n\n        # Check if array is a list of lists\n        if isinstance(array, list) and isinstance(array[0], list):\n            array = [item for sublist in array for item in sublist]\n\n        # Check if array is a list of tuples\n        if isinstance(array, list) and isinstance(array[0], tuple):\n            array = [item for sublist in array for item in sublist]\n\n        # Check if array is a list of strings\n        if isinstance(array, list) and isinstance(array[0], str):\n            pass\n\n        # Check if array is a list of integers\n        if isinstance(array, list) and isinstance(array[0], int):\n            array = [str(item) for item in array]\n\n        # Check if array is a list of floats\n        if isinstance(array, list) and isinstance(array[0], float):\n            array = [str(item) for item in array]\n\n        # Check if array is a list of booleans\n        if isinstance(array, list) and isinstance(array[0], bool):\n            array = [str(item) for item in array]\n\n        # Check if array is a list of dictionaries\n        if isinstance(array, list) and isinstance(array[0], dict):\n            array = [str(item) for item in array]\n\n        # Check if array is a list of sets\n        if isinstance(array, list) and isinstance(array[0], set):\n            array = [str("}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # If array is a Series, extract the values\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        # If array is a DataFrame, extract the first column\n        if isinstance(array, pd.DataFrame):\n            array = array.iloc[:, 0].values\n\n        # If array is a numpy array, convert to a list\n        if isinstance(array, np.ndarray):\n            array = array.tolist()\n\n        # If array is a single string, convert to a list\n        if isinstance(array, str):\n            array = [array]\n\n        # Check if array is empty\n        if not array:\n            raise ValueError(\"Array is empty\")\n\n        # Check if array is a list of strings\n        if not all(isinstance(x, str) for x in array):\n            raise ValueError(\"Array must contain only strings\")\n\n        # Check if array is a list of strings\n        if not all(isinstance(x, str) for x in array):\n            raise ValueError(\"Array must contain only strings\")\n\n        # Check if array is a list of strings\n        if not all(isinstance(x, str) for x in array):\n            raise ValueError(\"Array must contain only strings\")\n\n        # Check if array is a list of strings\n        if not all(isinstance(x, str) for x in array):\n            raise ValueError(\"Array must contain only strings\")\n\n        # Check if array is a list of strings\n        if not all(isinstance(x, str) for x in array):\n            raise ValueError(\"Array must contain only strings\")\n\n        # Check if array is a list of strings\n        if not all(isinstance(x, str) for x in array):\n            raise ValueError(\"Array must contain only strings\")\n\n        # Check if array is a list of strings\n        if not all(isinstance(x, str) for x in array):\n            raise ValueError(\"Array must contain only strings\")"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Build an index from the given array and tokenizer\n        term_mat, posns, \\\n            term_dict, avg_doc_length, \\\n            doc_lens = build_index_from_tokenizer(array, tokenizer,\n                                                  truncate=truncate,\n                                                  batch_size=batch_size,\n                                                  avoid_copies=avoid_copies)\n\n        # Create a new instance of SearchArray and return it\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n        term_mat, posns, \\\n            term_dict, avg_doc_length, \\\n            doc_lens = build_index_from_tokenizer(array, tokenizer,\n                                                  Terms, batch_size=batch_size)\n        return cls(term_mat, term_dict, posns, avg_doc_length, doc_lens,\n                   avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_tokenizer(array,\n                                                                                          tokenizer,\n                                                                                          Terms,\n                                                                                          batch_size=batch_size)\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if truncate:\n            array = array[:batch_size]\n\n        if batch_size is None:\n            batch_size = len(array)\n\n        postings = []\n        doc_lens = []\n        for i in range(0, len(array), batch_size):\n            batch = array[i:i + batch_size]\n            postings_batch, posns_batch, \\\n                term_dict, avg_doc_length, \\\n                doc_lens_batch = build_index_from_tokenizer(batch, tokenizer)\n            postings.extend(postings_batch)\n            doc_lens.extend(doc_lens_batch)\n\n        return cls(postings, tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check tokenizer, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected callable, got {}\".format(type(tokenizer)))\n\n        # Check truncate, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(truncate)))\n\n        # Check batch_size, raise TypeError\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected int, got {}\".format(type(batch_size)))\n\n        # Check avoid_copies, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected bool, got {}\".format(type(avoid_copies)))\n\n        # Convert array to list if it is a numpy array\n        if isinstance(array, np.ndarray):\n            array = array.tolist()\n\n        # Truncate the array if necessary\n        if truncate:\n            array = array[:batch_size]\n\n        # Split the array into batches\n        batches = [array[i:i+batch_size] for i in range(0, len(array), batch_size)]\n\n        # Initialize the term matrix, positions, term dictionary, average document length, and document lengths\n        term_mat = None\n        posns = None\n        term_dict = None\n        avg_doc_length = 0\n        doc_lens = []\n\n        # Process each batch\n        for batch in batches:\n            # Tokenize the batch using the specified tokenizer\n            tokens = [tokenizer(doc) for doc in batch]\n\n            # Build the index from the tokens and the batch\n            batch_term_mat, batch_posns, batch_term_dict, batch_avg_doc_length, batch_doc_lens = build_index_from_tokenizer(tokens, tokenizer, Terms, batch"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            warnings.warn(\"Truncating is not implemented yet.\")\n\n        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check if array is already a SearchArray\n        if isinstance(array, SearchArray):\n            return array\n\n        # Check if array is a Series\n        if isinstance(array, pd.Series):\n            array = array.values\n\n        # Check if array is a DataFrame\n        if isinstance(array, pd.DataFrame):\n            raise TypeError(\"Expected 1D array, got 2D array\")\n\n        # Check if array is a list\n        if isinstance(array, list):\n            array = np.array(array)\n\n        # Check if array is a numpy array\n        if not isinstance(array, np.ndarray):\n            raise TypeError(\"Expected numpy array, got {}\".format(type(array)))\n\n        # Check if array is a 1D array\n        if array.ndim != 1:\n            raise TypeError(\"Expected 1D array, got {}D array\".format(array.ndim))\n\n        # Check if array is a string array\n        if array.dtype.kind != 'U':\n            raise TypeError(\"Expected string array, got {}\".format(array.dtype))\n\n        # Check if array is a list of strings\n        if not all(isinstance(item, str) for item in array):\n            raise TypeError(\"Expected list of strings, got list of {}\".format(array.dtype))\n\n        # Check if array is a list of strings\n        if not all(isinstance(item, str) for item in array):\n            raise TypeError(\"Expected list of strings, got list of {}\".format(array.dtype))\n\n        # Check if array is a list of strings\n        if not all(isinstance(item, str) for item in array):\n            raise TypeError(\"Expected list of strings, got list of {}\".format(array.dtype))\n\n        # Check if array"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if isinstance(array, pd.Series):\n            array = array.values\n        if not isinstance(array, Iterable):\n            raise TypeError(\"Expected iterable object, got {}\".format(type(array)))\n\n        if truncate:\n            array = array[:batch_size]\n\n        # Build index from array\n        term_mat, posns, \\\n            term_dict, avg_doc_length, \\\n            doc_lens = build_index_from_tokenizer(array, tokenizer,\n                                                 Terms, batch_size=batch_size)\n\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check for empty array\n        if len(array) == 0:\n            return cls([], tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # Check for single item\n        if len(array) == 1:\n            return cls([array[0]], tokenizer=tokenizer, avoid_copies=avoid_copies)\n\n        # Check for truncation\n        if truncate:\n            array = array[:batch_size]\n\n        # Check for batching\n        if len(array) > batch_size:\n            # Build index in batches\n            batches = []\n            for i in range(0, len(array), batch_size):\n                batch = array[i:i + batch_size]\n                batches.append(batch)\n\n            # Process batches\n            term_mat = None\n            posns = None\n            term_dict = None\n            doc_lens = None\n            avg_doc_length = None\n            for batch in batches:\n                term_mat_batch, posns_batch, term_dict_batch, avg_doc_length_batch, doc_lens_batch = build_index_from_tokenizer(batch, tokenizer, Terms)\n                if term_mat is None:\n                    term_mat = term_mat_batch\n                else:\n                    term_mat = term_mat.concatenate(term_mat_batch)\n                if posns is None:\n                    posns = posns_batch\n                else:\n                    posns = posns.concatenate(posns_batch)\n                if term_dict is None:\n                    term_dict = term_dict_batch\n                else:\n                    term_dict = term_dict.merge(term_dict_batch)\n                if doc_lens is None:\n                    doc_lens = doc_lens_batch\n                else:\n                    doc_lens = np.concatenate((doc_"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if truncate:\n            array = array[:batch_size]\n\n        postings = []\n        doc_lens = []\n        for doc_id, doc in enumerate(array):\n            doc_tokens = tokenizer(doc)\n            doc_len = len(doc_tokens)\n            doc_lens.append(doc_len)\n            postings.append(doc_tokens)\n\n        if len(postings) > batch_size:\n            # TODO: This is a hack for now.\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO: Need to handle batches of docs, not just batches of terms\n            # TODO"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        # Check batch_size, raise ValueError\n        if not isinstance(batch_size, numbers.Integral):\n            raise ValueError(\"Expected an integer, got {}\".format(type(batch_size)))\n        if batch_size < 1:\n            raise ValueError(\"Batch size must be positive\")\n\n        # Check truncate, raise TypeError\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected a boolean, got {}\".format(type(truncate)))\n\n        # Check avoid_copies, raise TypeError\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected a boolean, got {}\".format(type(avoid_copies)))\n\n        # Check tokenizer, raise TypeError\n        if not callable(tokenizer):\n            raise TypeError(\"Expected a callable, got {}\".format(type(tokenizer)))\n\n        # Build the index from the array and tokenizer\n        term_mat, posns, \\\n            term_dict, avg_doc_length, \\\n            doc_lens = build_index_from_tokenizer(array, tokenizer,\n                                                  batch_size=batch_size,\n                                                  truncate=truncate,\n                                                  Terms=Terms)\n\n        # Create an instance of SearchArray with the indexed data\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n        if truncate:\n            array = array[:batch_size]\n        else:\n            array = list(array)\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_tokenizer(\n            array, tokenizer, batch_size=batch_size)\n        return cls(term_mat, term_dict, posns, avg_doc_length, doc_lens, avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if truncate:\n            array = array[:batch_size]\n        if not isinstance(array, pd.Series):\n            array = pd.Series(array)\n        if array.dtype != 'object':\n            raise TypeError(\"Expected an array of strings, got {}\".format(array.dtype))\n\n        postings = []\n        doc_lens = []\n        for doc_id, doc in enumerate(array):\n            doc_tokens = tokenizer(doc)\n            doc_lens.append(len(doc_tokens))\n            postings.append(doc_tokens)\n\n        return cls(postings, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not isinstance(array, Iterable):\n            raise TypeError(\"Expected iterable object, got {}\".format(type(array)))\n        if not isinstance(tokenizer, (str, callable)):\n            raise TypeError(\"Expected tokenizer to be a string or a callable, got {}\".format(type(tokenizer)))\n        if not isinstance(truncate, bool):\n            raise TypeError(\"Expected truncate to be a bool, got {}\".format(type(truncate)))\n        if not isinstance(batch_size, int):\n            raise TypeError(\"Expected batch_size to be an int, got {}\".format(type(batch_size)))\n        if not isinstance(avoid_copies, bool):\n            raise TypeError(\"Expected avoid_copies to be a bool, got {}\".format(type(avoid_copies)))\n\n        if isinstance(tokenizer, str):\n            if tokenizer == 'ws':\n                tokenizer = ws_tokenizer\n            else:\n                raise ValueError(\"Unknown tokenizer: {}\".format(tokenizer))\n\n        if truncate:\n            # Truncate to fit in memory\n            array = array[:batch_size]\n\n        # Build index\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_tokenizer(array, tokenizer, batch_size=batch_size,\n                                                                                       avoid_copies=avoid_copies)\n\n        return cls(term_mat, tokenizer=tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        # Check dtype, raise TypeError\n        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if truncate:\n            array = array[:batch_size]\n\n        # Build the index from the array and tokenizer\n        term_mat, posns, term_dict, avg_doc_length, doc_lens = build_index_from_tokenizer(\n            array, tokenizer, batch_size=batch_size, avoid_copies=avoid_copies)\n\n        # Create a new instance of SearchArray with the indexed data\n        return cls(term_mat, tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "searcharray.postings.SearchArray.index", "completion": "        if not is_list_like(array):\n            raise TypeError(\"Expected list-like object, got {}\".format(type(array)))\n\n        if truncate:\n            array = array[:batch_size]\n\n        term_mat, posns, \\\n            term_dict, avg_doc_length, \\\n            doc_lens = build_index_from_tokenizer(array, tokenizer,\n                                                  batch_size=batch_size)\n\n        return cls(term_mat, tokenizer, avoid_copies=avoid_copies)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n        )\n\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n            on_connection_opened=self.on_connection_opened,\n            on_connection_closed=self.on_connection_closed,\n            on_connection_data=self.on_connection_data,\n        )\n\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.config['proxyHost'],\n            self.config['proxyPort'],\n            self.logger,\n        )\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            interceptor=self,\n            logger=self.logger,\n        )\n\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n            config=self.config,\n        )\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.config['strategy'], self.config['strategies'])\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.config['proxyHost'], self.config['proxyPort'])\n        self.connections = {}\n        self.lock = threading.Lock()\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.logger,\n        )\n\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.config['proxyHost'],\n            self.config['proxyPort'],\n            self.config['strategy'],\n            self.config['strategies'],\n            self.config['autoCloseConnections'],\n            self.config['multipleConnections'],\n            self.logger,\n        )\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.logger)\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.config['proxyHost'],\n            self.config['proxyPort'],\n            self.config['multipleConnections'],\n        )\n\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.config['proxyHost'],\n            self.config['proxyPort'],\n            self.config['autoCloseConnections'],\n            self.config['multipleConnections'],\n        )\n\n        self.connections = {}\n        self.lock = threading.Lock()\n\n        self.server.start()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.logger,\n            self.config['multipleConnections'],\n        )\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(self.config['serverHost'], self.config['serverPort'], self.config['multipleConnections'], self.logger)\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n            config=self.config,\n        )\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n        )\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.logger,\n            self.config['multipleConnections'],\n        )\n        self.server.start()\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            host=self.config['serverHost'],\n            port=self.config['serverPort'],\n            logger=self.logger,\n            on_message=self.on_message,\n        )\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.init", "completion": "        self.server = Server(\n            self.config['serverHost'],\n            self.config['serverPort'],\n            self.logger,\n        )\n        self.server.start()\n\n        self.connections = {}\n        self.lock = threading.Lock()\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * _1) >> all_but_one_bit\n    return arr"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * _1) >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * _1) >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * _1) >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> 1) & s55\n    arr = (arr & s33) + ((arr >> 2) & s33)\n    arr = (arr + (arr >> 4)) & s0F\n    arr += arr >> 8\n    arr += arr >> 16\n    arr += arr >> 32\n    return arr & np.uint64(0x7F)\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> 1) & s55\n    arr = (arr & s33) + ((arr >> 2) & s33)\n    arr = (arr + (arr >> 4)) & s0F\n    arr += arr >> 8\n    arr += arr >> 16\n    arr += arr >> 32\n    return arr & all_but_one_bit\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * s01) >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr += arr >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr += arr >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> 1) & s55\n    arr = (arr & s33) + ((arr >> 2) & s33)\n    arr = (arr + (arr >> 4)) & s0F\n    arr += arr >> 8\n    arr += arr >> 16\n    arr += arr >> 32\n    return arr & np.uint64(0x7F)\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    return (arr * s01) >> all_but_one_bit\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr += arr >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr += arr >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * _1) >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * _1) >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> 1) & s55\n    arr = (arr & s33) + ((arr >> 2) & s33)\n    arr = (arr + (arr >> 4)) & s0F\n    arr = (arr * _1) >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr = (arr * _0x0101010101010101) >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr += arr >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr += arr >> all_but_one_bit\n    return arr\n\n"}
{"namespace": "searcharray.utils.bitcount.bit_count64", "completion": "    arr -= (arr >> _1) & s55\n    arr = (arr & s33) + ((arr >> _2) & s33)\n    arr = (arr + (arr >> _4)) & s0F\n    arr += arr >> all_but_one_bit\n    return arr & mask\n\n"}
{"namespace": "searcharray.solr.edismax", "completion": "    if mm is None:\n        mm = \"100%\"\n    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n\n    qf_boosts = parse_field_boosts(qf)\n    pf_boosts = parse_field_boosts(pf)\n    pf2_boosts = parse_field_boosts(pf2)\n    pf3_boosts = parse_field_boosts(pf3)\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    if term_centric:\n        qf_scores, qf_explain = _edismax_term_centric(frame, qf_boosts, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, qf_explain = _edismax_field_centric(frame, qf_boosts, num_search_terms, search_terms, mm, similarity)\n\n    pf_scores, pf_explain = _edismax_field_centric(frame, pf_boosts, num_search_terms, search_terms, mm, similarity)\n    pf2_scores, pf2_explain = _edismax_field_centric(frame, pf2_boosts, num_search_terms, search_terms, mm, similarity)\n    pf3_scores, pf3_explain = _edismax_field_centric(frame, pf3_boosts, num_search_terms, search_terms, mm, similarity)\n\n    scores = qf_scores + pf_scores + pf2_scores + pf3_scores\n\n    explain = f\"{qf_explain} {pf_explain} {pf2_explain} {pf3_explain}\"\n\n    return scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not qf:\n        raise ValueError(\"Must specify at least one query field\")\n\n    if not mm:\n        mm = \"100%\"\n\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if mm is None:\n        mm = \"100%\"\n\n    qf_boosts = parse_field_boosts(qf)\n    pf_boosts = parse_field_boosts(pf or [])\n    pf2_boosts = parse_field_boosts(pf2 or [])\n    pf3_boosts = parse_field_boosts(pf3 or [])\n\n    query_fields = {**qf_boosts, **pf_boosts, **pf2_boosts, **pf3_boosts}\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if mm is None:\n        mm = \"100%\"\n\n    query_fields = parse_field_boosts(qf)\n    if pf:\n        query_fields.update(parse_field_boosts(pf))\n    if pf2:\n        query_fields.update(parse_field_boosts(pf2))\n    if pf3:\n        query_fields.update(parse_field_boosts(pf3))\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query fields\n    qf_boosts = parse_field_boosts(qf)\n    pf_boosts = parse_field_boosts(pf) if pf is not None else {}\n    pf2_boosts = parse_field_boosts(pf2) if pf2 is not None else {}\n    pf3_boosts = parse_field_boosts(pf3) if pf3 is not None else {}\n    query_fields = {**qf_boosts, **pf_boosts, **pf2_boosts, **pf3_boosts}\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    # Calculate scores\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if q_op not in [\"AND\", \"OR\"]:\n        raise ValueError(\"q_op must be either 'AND' or 'OR'\")\n\n    if mm is None:\n        mm = \"100%\"\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    query_fields = parse_field_boosts(qf)\n    if pf is not None:\n        query_fields.update(parse_field_boosts(pf))\n    if pf2 is not None:\n        query_fields.update(parse_field_boosts(pf2))\n    if pf3 is not None:\n        query_fields.update(parse_field_boosts(pf3))\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not q:\n        raise ValueError(\"q cannot be empty\")\n\n    if not qf:\n        raise ValueError(\"qf cannot be empty\")\n\n    if mm is None:\n        mm = \"100%\"\n\n    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"q_op must be either 'OR' or 'AND'\")\n\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    if pf is not None:\n        pf_scores, pf_explain = _edismax_term_centric(frame, parse_field_boosts(pf), num_search_terms, search_terms, mm, similarity)\n        qf_scores += pf_scores\n        explain += \" \" + pf_explain\n\n    if pf2 is not None:\n        pf2_scores, pf2_explain = _edismax_term_centric(frame, parse_field_boosts(pf2), num_search_terms, search_terms, mm, similarity)\n        qf_scores += pf2_scores\n        explain += \" \" + pf2_explain\n\n    if pf3 is not None:\n        pf3_scores, pf3_explain = _edismax_term_centric(frame, parse_field_boosts(pf3), num_search_terms, search_terms, mm, similarity)\n        qf_scores += pf3_scores\n        explain += \" \" + pf3_explain\n\n    if"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n    if pf is not None:\n        query_fields.update(parse_field_boosts(pf))\n    if pf2 is not None:\n        query_fields.update(parse_field_boosts(pf2))\n    if pf3 is not None:\n        query_fields.update(parse_field_boosts(pf3))\n\n    # Parse search terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    # Determine whether to use term-centric or field-centric scoring\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not mm:\n        mm = \"100%\"\n\n    # parse qf\n    qf_boosts = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf_boosts.keys())\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, qf_boosts, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, qf_boosts, num_search_terms, search_terms, mm, similarity)\n\n    # parse pf\n    if pf:\n        pf_boosts = parse_field_boosts(pf)\n        num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, pf_boosts.keys())\n        if term_centric:\n            pf_scores, pf_explain = _edismax_term_centric(frame, pf_boosts, num_search_terms, search_terms, mm, similarity)\n        else:\n            pf_scores, pf_explain = _edismax_field_centric(frame, pf_boosts, num_search_terms, search_terms, mm, similarity)\n        qf_scores += pf_scores\n        explain += \" \" + pf_explain\n\n    # parse pf2\n    if pf2:\n        pf2_boosts = parse_field_boosts(pf2)\n        num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, pf2_boosts.keys())\n        if term_centric:\n            pf2_scores, pf2_explain = _edismax_term_centric(frame, pf2_boosts, num_search_terms, search_terms, mm, similarity)\n        else:\n           "}
{"namespace": "searcharray.solr.edismax", "completion": "    if mm is None:\n        mm = \"100%\"\n    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(f\"Invalid q_op: {q_op}\")\n\n    query_fields = parse_field_boosts(qf)\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    if pf is not None:\n        pf_scores, pf_explain = _edismax_field_centric(frame, parse_field_boosts(pf), num_search_terms, search_terms, mm, similarity)\n        qf_scores += pf_scores\n        explain += \" \" + pf_explain\n    if pf2 is not None:\n        pf2_scores, pf2_explain = _edismax_field_centric(frame, parse_field_boosts(pf2), num_search_terms, search_terms, mm, similarity)\n        qf_scores += pf2_scores\n        explain += \" \" + pf2_explain\n    if pf3 is not None:\n        pf3_scores, pf3_explain = _edismax_field_centric(frame, parse_field_boosts(pf3), num_search_terms, search_terms, mm, similarity)\n        qf_scores += pf3_scores\n        explain += \" \" + pf3_explain\n\n    if q_op == \"AND\":\n        qf_scores[qf_scores == 0] = -np.inf\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if not qf:\n        raise ValueError(\"qf must be specified\")\n    if not mm:\n        mm = \"100%\"\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    qf_boosts = parse_field_boosts(qf)\n    pf_boosts = parse_field_boosts(pf or [])\n    pf2_boosts = parse_field_boosts(pf2 or [])\n    pf3_boosts = parse_field_boosts(pf3 or [])\n\n    if term_centric:\n        qf_scores, qf_explain = _edismax_term_centric(frame, qf_boosts, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, qf_explain = _edismax_field_centric(frame, qf_boosts, num_search_terms, search_terms, mm, similarity)\n\n    pf_scores, pf_explain = _edismax_field_centric(frame, pf_boosts, num_search_terms, search_terms, mm, similarity)\n    pf2_scores, pf2_explain = _edismax_field_centric(frame, pf2_boosts, num_search_terms, search_terms, mm, similarity)\n    pf3_scores, pf3_explain = _edismax_field_centric(frame, pf3_boosts, num_search_terms, search_terms, mm, similarity)\n\n    scores = qf_scores + pf_scores + pf2_scores + pf3_scores\n\n    explain = qf_explain\n    if pf_explain:\n        explain += \" \" + pf_explain\n    if pf2_explain:\n        explain += \" \" + pf2_explain\n    if pf3_explain:\n        explain += \" \" + pf3"}
{"namespace": "searcharray.solr.edismax", "completion": "    if q_op == \"AND\":\n        raise NotImplementedError(\"AND query operator is not implemented\")\n\n    # parse query fields\n    query_fields = parse_field_boosts(qf)\n    if pf is not None:\n        query_fields.update(parse_field_boosts(pf))\n    if pf2 is not None:\n        query_fields.update(parse_field_boosts(pf2))\n    if pf3 is not None:\n        query_fields.update(parse_field_boosts(pf3))\n\n    # parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    # calculate scores\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n\n    # Parse phrase fields\n    phrase_fields = parse_field_boosts(pf) if pf else {}\n    bigram_fields = parse_field_boosts(pf2) if pf2 else {}\n    trigram_fields = parse_field_boosts(pf3) if pf3 else {}\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    # Calculate qf scores\n    if term_centric:\n        qf_scores, qf_explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, qf_explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Calculate phrase scores\n    phrase_scores = np.zeros(len(frame))\n    phrase_explain = []\n    for field, boost in phrase_fields.items():\n        post_arr = get_field(frame, field)\n        term_scores = np.array([post_arr.score_phrase(term, similarity=similarity)\n                                for term in search_terms[field]])\n        min_should_match = parse_min_should_match(len(search_terms[field]), spec=mm)\n        exp = \" \".join([f\"{field}:{term}\" for term in search_terms[field]])\n        boost_exp = f\"{boost}\" if boost is not None else \"1\"\n        exp = \"(\" + exp + f\")~{min(min_should_match, len(search_terms[field]))}\"\n        exp = \"(\" + exp + f\")^{boost_exp}\"\n\n        matches_gt_mm = np.sum(term_scores > 0, axis=0) >= min(min_should_match, len("}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query fields and boosts\n    query_fields = parse_field_boosts(qf)\n    pf_fields = parse_field_boosts(pf)\n    pf2_fields = parse_field_boosts(pf2)\n    pf3_fields = parse_field_boosts(pf3)\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, query=q, query_fields=query_fields.keys())\n\n    # Calculate scores\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame,\n                                                   query_fields=query_fields,\n                                                   num_search_terms=num_search_terms,\n                                                   search_terms=search_terms,\n                                                   mm=mm,\n                                                   similarity=similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame,\n                                                   query_fields=query_fields,\n                                                   num_search_terms=num_search_terms,\n                                                   search_terms=search_terms,\n                                                   mm=mm,\n                                                   similarity=similarity)\n\n    # Calculate phrase scores\n    if pf_fields:\n        pf_scores, pf_explain = _edismax_term_centric(frame,\n                                                      query_fields=pf_fields,\n                                                      num_search_terms=num_search_terms,\n                                                      search_terms=search_terms,\n                                                      mm=mm,\n                                                      similarity=similarity)\n        explain += \" \" + pf_explain\n        qf_scores += pf_scores\n\n    if pf2_fields:\n        pf2_scores, pf2_explain = _edismax_term_centric(frame,\n                                                        query_fields=pf2_fields,\n                                                        num_search_terms=num_search_terms,\n                                                        search_terms=search_terms,\n                                                        mm=mm,\n                                                        similarity="}
{"namespace": "searcharray.solr.edismax", "completion": "    # Parse query fields and their boosts\n    query_fields = parse_field_boosts(qf)\n    phrase_fields = parse_field_boosts(pf)\n    bigram_fields = parse_field_boosts(pf2)\n    trigram_fields = parse_field_boosts(pf3)\n\n    # Parse the query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    # Perform the search based on the term-centric or field-centric approach\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Compute phrase, bigram, and trigram scores\n    phrase_scores = np.zeros(len(frame))\n    bigram_scores = np.zeros(len(frame))\n    trigram_scores = np.zeros(len(frame))\n    for field, boost in phrase_fields.items():\n        post_arr = get_field(frame, field)\n        phrase_scores = np.maximum(phrase_scores, post_arr.score_phrase(q, similarity=similarity))\n    for field, boost in bigram_fields.items():\n        post_arr = get_field(frame, field)\n        bigram_scores = np.maximum(bigram_scores, post_arr.score_bigram(q, similarity=similarity))\n    for field, boost in trigram_fields.items():\n        post_arr = get_field(frame, field)\n        trigram_scores = np.maximum(trigram_scores, post_arr.score_trigram(q, similarity=similarity))\n\n    # Combine the scores from different sources\n    scores = qf_"}
{"namespace": "searcharray.solr.edismax", "completion": "    if mm is None:\n        mm = \"100%\"\n    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n\n    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n    for field in pf + pf2 + pf3:\n        if field not in query_fields:\n            query_fields[field] = None\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields)\n\n    if term_centric:\n        qf_scores, qf_explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, qf_explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    explain = f\"{qf_explain}\"\n    if pf:\n        explain += f\" + {', '.join(pf)}\"\n    if pf2:\n        explain += f\" + {', '.join(pf2)}\"\n    if pf3:\n        explain += f\" + {', '.join(pf3)}\"\n    explain += f\" | {q_op}\"\n\n    return qf_scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if q_op not in [\"OR\", \"AND\"]:\n        raise ValueError(\"q_op must be either 'OR' or 'AND'\")\n\n    if mm is None:\n        mm = \"100%\"\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, qf)\n\n    qf_scores, qf_explain = _edismax_term_centric(frame, parse_field_boosts(qf), num_search_terms, search_terms, mm, similarity)\n    pf_scores, pf_explain = _edismax_field_centric(frame, parse_field_boosts(pf), num_search_terms, search_terms, mm, similarity)\n    pf2_scores, pf2_explain = _edismax_field_centric(frame, parse_field_boosts(pf2), num_search_terms, search_terms, mm, similarity)\n    pf3_scores, pf3_explain = _edismax_field_centric(frame, parse_field_boosts(pf3), num_search_terms, search_terms, mm, similarity)\n\n    explain = []\n    if qf_explain:\n        explain.append(qf_explain)\n    if pf_explain:\n        explain.append(pf_explain)\n    if pf2_explain:\n        explain.append(pf2_explain)\n    if pf3_explain:\n        explain.append(pf3_explain)\n\n    scores = qf_scores + pf_scores + pf2_scores + pf3_scores\n    if q_op == \"AND\":\n        scores = scores / 4\n    return scores, \"(\" + \" \".join(explain) + \")\""}
{"namespace": "searcharray.solr.edismax", "completion": "    # parse query fields\n    query_fields = parse_field_boosts(qf)\n\n    # parse phrase fields\n    phrase_fields = parse_field_boosts(pf)\n    phrase_fields.update(parse_field_boosts(pf2))\n    phrase_fields.update(parse_field_boosts(pf3))\n\n    # parse min should match\n    if mm is None:\n        mm = \"100%\"\n\n    # parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    # perform edismax search\n    if term_centric:\n        qf_scores, qf_explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, qf_explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # calculate phrase scores\n    phrase_scores = np.zeros(len(frame))\n    phrase_explain = []\n    for field, boost in phrase_fields.items():\n        post_arr = get_field(frame, field)\n        phrase_score = post_arr.phrase_score(q, similarity=similarity) * (1 if boost is None else boost)\n        boost_exp = f\"{boost}\" if boost is not None else \"1\"\n        phrase_explain.append(f\"{field}:{q}^{boost_exp}\")\n        phrase_scores = np.maximum(phrase_scores, phrase_score)\n\n    # combine qf and phrase scores\n    scores = qf_scores + phrase_scores\n\n    # combine explain strings\n    explain = qf_explain + \" \" + \" \".join(phrase_explain)\n\n    return scores, explain"}
{"namespace": "searcharray.solr.edismax", "completion": "    if q_op not in [\"AND\", \"OR\"]:\n        raise ValueError(\"q_op must be AND or OR\")\n\n    if mm is None:\n        mm = \"100%\"\n\n    query_fields = parse_field_boosts(qf)\n    if len(query_fields) == 0:\n        raise ValueError(\"No query fields specified\")\n\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n\n    if term_centric:\n        qf_scores, qf_explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, qf_explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    explain = [f\"edismax({q_op})\"]\n    explain.append(f\"qf={qf_explain}\")\n    explain.append(f\"mm={mm}\")\n\n    if pf is not None:\n        pf_scores, pf_explain = _edismax_term_centric(frame, parse_field_boosts(pf), num_search_terms, search_terms, mm, similarity)\n        explain.append(f\"pf={pf_explain}\")\n        qf_scores += pf_scores\n\n    if pf2 is not None:\n        pf2_scores, pf2_explain = _edismax_term_centric(frame, parse_field_boosts(pf2), num_search_terms, search_terms, mm, similarity)\n        explain.append(f\"pf2={pf2_explain}\")\n        qf_scores += pf2_scores\n\n    if pf3 is not None:\n        pf3_scores, pf3_explain = _edismax_term_centric(frame, parse_field"}
{"namespace": "searcharray.solr.edismax", "completion": "    if mm is None:\n        mm = \"100%\"\n    if pf is None:\n        pf = []\n    if pf2 is None:\n        pf2 = []\n    if pf3 is None:\n        pf3 = []\n\n    # Parse query fields\n    query_fields = parse_field_boosts(qf)\n    if query_fields == {}:\n        raise ValueError(\"No query fields specified\")\n\n    # Parse phrase fields\n    phrase_fields = parse_field_boosts(pf)\n    if phrase_fields == {}:\n        phrase_fields = {}\n\n    # Parse bigram fields\n    bigram_fields = parse_field_boosts(pf2)\n    if bigram_fields == {}:\n        bigram_fields = {}\n\n    # Parse trigram fields\n    trigram_fields = parse_field_boosts(pf3)\n    if trigram_fields == {}:\n        trigram_fields = {}\n\n    # Parse query terms\n    num_search_terms, search_terms, term_centric = parse_query_terms(frame, q, query_fields.keys())\n    if num_search_terms == 0:\n        return np.zeros(len(frame)), \"0\"\n\n    # Calculate scores\n    if term_centric:\n        qf_scores, explain = _edismax_term_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n    else:\n        qf_scores, explain = _edismax_field_centric(frame, query_fields, num_search_terms, search_terms, mm, similarity)\n\n    # Calculate phrase scores\n    phrase_scores, phrase_explain = _edismax_field_centric(frame, phrase_fields, num_search_terms, search_terms, mm, similarity)\n    phrase_scores *= 2\n    qf_scores += phrase_scores\n    explain += \" \" + phrase_explain\n\n    # Calculate bigram scores\n    bigram_scores, bigram"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.intercept_send(process, message)\n        elif isinstance(message, RecvMessage):\n            self.intercept_recv(process, message)\n        elif isinstance(message, CloseMessage):\n            self.intercept_close(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.intercept_send_message(process, message)\n        elif isinstance(message, RecvMessage):\n            self.intercept_recv_message(process, message)\n        elif isinstance(message, CloseMessage):\n            self.intercept_close_message(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.intercept_send(process, message)\n        elif isinstance(message, RecvMessage):\n            self.intercept_recv(process, message)\n        elif isinstance(message, CloseMessage):\n            self.intercept_close(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.intercept_send(process, message)\n        elif isinstance(message, RecvMessage):\n            self.intercept_recv(process, message)\n        elif isinstance(message, CloseMessage):\n            self.intercept_close(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        self.logger.debug(f\"Intercepting {message}\")\n        if isinstance(message, SendMessage):\n            self.intercept_send(process, message)\n        elif isinstance(message, RecvMessage):\n            self.intercept_recv(process, message)\n        elif isinstance(message, CloseMessage):\n            self.intercept_close(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.logger.debug(f'Intercepting send message {message.id}')\n            self.intercept_send(process, message)\n        elif isinstance(message, RecvMessage):\n            self.logger.debug(f'Intercepting recv message {message.id}')\n            self.intercept_recv(process, message)\n        elif isinstance(message, CloseMessage):\n            self.logger.debug(f'Intercepting close message {message.id}')\n            self.intercept_close(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.intercept_send_message(process, message)\n        elif isinstance(message, RecvMessage):\n            self.intercept_recv_message(process, message)\n        elif isinstance(message, CloseMessage):\n            self.intercept_close_message(process, message)\n        else:\n            self.logger.error(f'Unsupported message type: {message}')\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                if message.connection_id not in self.connections:\n                    self.connections[message.connection_id] = Connection(\n                        connection_id=message.connection_id,\n                        strategy=self.server.strategy,\n                        strategy_config=self.server.strategy_config,\n                        logger=self.logger\n                    )\n                self.connections[message.connection_id].c2s(message)\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                if message.connection_id not in self.connections:\n                    self.connections[message.connection_id] = Connection(\n                        connection_id=message.connection_id,\n                        strategy=self.server.strategy,\n                        strategy_config=self.server.strategy_config,\n                        logger=self.logger\n                    )\n                self.connections[message.connection_id].s2c(message)\n        elif isinstance(message, CloseMessage):\n            with self.lock:\n                if message.connection_id in self.connections:\n                    self.connections[message.connection_id].close()\n                    if self.config['autoCloseConnections']:\n                        del self.connections[message.connection_id]\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.c2s(process, message)\n        elif isinstance(message, RecvMessage):\n            self.s2c(process, message)\n        elif isinstance(message, CloseMessage):\n            self.close(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.intercept_send(process, message)\n        elif isinstance(message, RecvMessage):\n            self.intercept_recv(process, message)\n        elif isinstance(message, CloseMessage):\n            self.intercept_close(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.logger.debug(f'Intercepting message {message.id}')\n            with self.lock:\n                if self.config['multipleConnections']:\n                    connection_id = message.connection_id\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n                connection = self.connections.get(connection_id)\n                if connection is None:\n                    connection = Connection(\n                        connection_id=connection_id,\n                        proxy_host=self.config['proxyHost'],\n                        proxy_port=self.config['proxyPort'],\n                        server_host=self.config['serverHost'],\n                        server_port=self.config['serverPort'],\n                        strategy=ProxifierStrategyType(self.config['strategy']),\n                        strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                        logger=self.logger\n                    )\n                    self.connections[connection_id] = connection\n                message.data = connection.c2s(message.data)\n                self.logger.debug(f'Intercepted message {message.id}')\n        elif isinstance(message, RecvMessage):\n            self.logger.debug(f'Intercepting message {message.id}')\n            with self.lock:\n                if self.config['multipleConnections']:\n                    connection_id = message.connection_id\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n                connection = self.connections.get(connection_id)\n                if connection is None:\n                    connection = Connection(\n                        connection_id=connection_id,\n                        proxy_host=self.config['proxyHost'],\n                        proxy_port=self.config['proxyPort'],\n                        server_host=self.config['serverHost'],\n                        server_port=self.config['serverPort'],\n                        strategy=ProxifierStrategyType(self.config['strategy']),\n                        strategy_config=self.config['strategies'].get(self.config['strategy'], {}),\n                        logger=self.logger\n                    )\n                    self.connections"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self.get_connection(process)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self.get_connection(process)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self.close_connection(process)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            if self.config['multipleConnections']:\n                connection_id = f'{process.pid}:{message.sock.laddr[0]}:{message.sock.laddr[1]}'\n            else:\n                connection_id = DEFAULT_CONNECTION_ID\n            with self.lock:\n                if connection_id not in self.connections:\n                    self.connections[connection_id] = Connection(\n                        connection_id=connection_id,\n                        sock=message.sock,\n                        logger=self.logger\n                    )\n                    self.connections[connection_id].start()\n                self.connections[connection_id].send(message.data)\n            message.data = self.connections[connection_id].c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            if self.config['multipleConnections']:\n                connection_id = f'{process.pid}:{message.sock.laddr[0]}:{message.sock.laddr[1]}'\n            else:\n                connection_id = DEFAULT_CONNECTION_ID\n            with self.lock:\n                if connection_id not in self.connections:\n                    self.connections[connection_id] = Connection(\n                        connection_id=connection_id,\n                        sock=message.sock,\n                        logger=self.logger\n                    )\n                    self.connections[connection_id].start()\n            message.data = self.connections[connection_id].s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            if self.config['autoCloseConnections']:\n                if self.config['multipleConnections']:\n                    connection_id = f'{process.pid}:{message.sock.laddr[0]}:{message.sock.laddr[1]}'\n                else:\n                    connection_id = DEFAULT_CONNECTION_ID\n                with self.lock:\n                    if connection_id in self.connections:\n                        self.connections[connection_id].close()\n                       "}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self.get_connection(process)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self.get_connection(process)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self.close_connection(process)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            connection = self.get_connection(process)\n            message.data = connection.c2s(message.data)\n        elif isinstance(message, RecvMessage):\n            connection = self.get_connection(process)\n            message.data = connection.s2c(message.data)\n        elif isinstance(message, CloseMessage):\n            self.close_connection(process)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            with self.lock:\n                if message.connection_id not in self.connections:\n                    self.connections[message.connection_id] = Connection(self.server)\n                self.connections[message.connection_id].c2s(message)\n        elif isinstance(message, RecvMessage):\n            with self.lock:\n                if message.connection_id not in self.connections:\n                    self.connections[message.connection_id] = Connection(self.server)\n                self.connections[message.connection_id].s2c(message)\n        elif isinstance(message, CloseMessage):\n            if self.config['autoCloseConnections']:\n                with self.lock:\n                    if message.connection_id in self.connections:\n                        self.connections[message.connection_id].close()\n                        del self.connections[message.connection_id]\n        else:\n            self.logger.warning(f'Unknown message type: {type(message)}')\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self._send(process, message)\n        elif isinstance(message, RecvMessage):\n            self._recv(process, message)\n        elif isinstance(message, CloseMessage):\n            self._close(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.intercept_send(process, message)\n        elif isinstance(message, RecvMessage):\n            self.intercept_recv(process, message)\n        elif isinstance(message, CloseMessage):\n            self.intercept_close(process, message)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        with self.lock:\n            if isinstance(message, SendMessage):\n                if self.config['multipleConnections']:\n                    connection = self.get_connection(process.pid)\n                else:\n                    connection = self.get_connection(DEFAULT_CONNECTION_ID)\n\n                message.data = connection.c2s(message.data)\n\n            elif isinstance(message, RecvMessage):\n                if self.config['multipleConnections']:\n                    connection = self.get_connection(process.pid)\n                else:\n                    connection = self.get_connection(DEFAULT_CONNECTION_ID)\n\n                message.data = connection.s2c(message.data)\n\n            elif isinstance(message, CloseMessage):\n                if self.config['autoCloseConnections']:\n                    self.close_connection(process.pid)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.intercept", "completion": "        if isinstance(message, SendMessage):\n            self.logger.debug(f'Intercepting SendMessage: {message}')\n            self.modify_message(message, process, self.c2s)\n        elif isinstance(message, RecvMessage):\n            self.logger.debug(f'Intercepting RecvMessage: {message}')\n            self.modify_message(message, process, self.s2c)\n        elif isinstance(message, CloseMessage):\n            self.logger.debug(f'Intercepting CloseMessage: {message}')\n            self.close_connection(message, process)\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections = {}\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in self.connections.items():\n                connection.close()\n            self.connections = {}\n        if self.server:\n            self.server.stop()\n            self.server = None"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        # Stop all connections\n        for connection in self.connections.values():\n            connection.close()\n\n        # Stop the server\n        if self.server:\n            self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections = {}\n\n        self.server.stop()"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id, connection in self.connections.items():\n                connection.close()\n            self.connections.clear()\n\n        if self.server is not None:\n            self.server.stop()\n            self.server = None"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection_id in self.connections:\n                self.connections[connection_id].close()\n            self.connections = {}\n        if self.server is not None:\n            self.server.stop()\n            self.server = None"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info('Destroying ProxifierMessageInterceptor...')\n\n        # Stop all connections\n        for connection in self.connections.values():\n            connection.stop()\n\n        # Stop the server if it exists\n        if self.server:\n            self.server.stop()\n\n        self.logger.info('ProxifierMessageInterceptor destroyed.')"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info('Destroying proxifier message interceptor')\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        if self.server is not None:\n            self.server.stop()\n        self.logger.info('Proxifier message interceptor destroyed')"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info(f'Destroying ProxifierMessageInterceptor')\n\n        # Stop all active connections\n        self.logger.info(f'Stopping {len(self.connections)} active connections')\n        for connection in self.connections.values():\n            connection.stop()\n\n        # Stop the server if it exists\n        if self.server:\n            self.logger.info(f'Stopping server')\n            self.server.stop()\n\n        self.logger.info(f'ProxifierMessageInterceptor destroyed')"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        if self.server:\n            self.server.stop()\n        self.server = None\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n        if self.server:\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        if self.server:\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.server.stop()\n        for connection in self.connections.values():\n            connection.close()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections = {}\n\n        if self.server is not None:\n            self.server.stop()\n            self.server = None\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info('Destroying proxifier message interceptor')\n\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n            self.connections.clear()\n\n        if self.server:\n            self.server.stop()\n            self.server = None\n\n        self.logger.info('Proxifier message interceptor destroyed')\n\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        self.logger.info('Stopping all connections')\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n        self.logger.info('Stopping server')\n        self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        self.connections = {}\n        if self.server:\n            self.server.stop()\n            self.server = None\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        # Stop all connections\n        for connection in self.connections.values():\n            connection.stop()\n\n        # Stop the server\n        if self.server:\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        # Stop all active connections\n        with self.lock:\n            for connection in self.connections.values():\n                connection.close()\n\n        # Stop the server if it's running\n        if self.server:\n            self.server.stop()\n"}
{"namespace": "deluder.interceptors.proxifier.interceptor.ProxifierMessageInterceptor.destroy", "completion": "        for connection in self.connections.values():\n            connection.close()\n        if self.server:\n            self.server.stop()\n"}
